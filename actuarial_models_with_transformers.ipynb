{"cells":[{"cell_type":"markdown","metadata":{"id":"_I2LuIoojymG"},"source":["***\n","<center>Research Project</center>\n","<h1><center>Research Project</center></h1>\n","<h2><center>Enhancing actuarial non-life pricing models via transformers</center></h2>\n","<center>by Alexej Brauer </center>\n","<center>M.Sc. (TUM) / Aktuar DAV / CADS </center>\n","\n","***"]},{"cell_type":"markdown","metadata":{"id":"22zt2a5cjymK"},"source":["# This notebook will provide the code to reproduce the data cleaning/preparation and results of the paper: Enhancing actuarial non-life pricing models via transformers."]},{"cell_type":"markdown","metadata":{"id":"oAHaEQNcMKNY"},"source":["I used here the following work as a foundation:     \n","* Ronald Richman, Mario V. Wüthrich \"LocalGLMnet: interpretable deep learning for tabular data\" 2023\n","* Mario V. Wüthrich, M. Merz, \"Statistical Foundations of Actuarial Learning and its Applications\" 2023\n","* Gorishniy, Rubachev, Khrulkov, Babenko \"Revisiting Deep Learning Models for Tabular Data\" 2021\n","* Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin, \"Attention Is All You Need\", NeurIPS 2017"]},{"cell_type":"markdown","metadata":{"id":"lTJJtjEYjymL"},"source":["# 1. Basic Setting:"]},{"cell_type":"markdown","metadata":{"id":"ArsRIwe_lsGa"},"source":["## 1.1 Load packages:"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4842,"status":"ok","timestamp":1699568754158,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"b20Q_krDjymL"},"outputs":[],"source":["# sys and os imports\n","import os\n","import sys\n","import platform\n","import subprocess\n","import re\n","import warnings\n","\n","# display and plotting\n","from IPython.display import Image\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","# data\n","import numpy as np\n","import pandas as pd\n","from dataclasses import dataclass, field\n","\n","# modelling\n","import random\n","# modelling scikit-learn\n","import sklearn as sk\n","from sklearn.linear_model import PoissonRegressor\n","from sklearn.preprocessing import StandardScaler\n","# modelling tensorflow\n","import tensorflow as tf\n","import keras\n","from keras.activations import (tanh, exponential, gelu)\n","\n","# saveing & time\n","import pickle\n","import time\n","import datetime\n","\n","# for multiprocessing\n","from multiprocessing import Process\n","import logging\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JwwzFre4l9L3"},"source":["## 1.2 Storage settings:"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23448,"status":"ok","timestamp":1699568777598,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"1UVA7TnLl-yY","outputId":"8158037b-cdf7-4942-857f-88f9dfa95fa7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# set the path to the storage folder:\n","storage_path = \".\"\n","\n","# import my classes for the ft-transformer models:\n","# ----------------------\n","sys.path.insert(1, f'{storage_path}/helper')\n","import main_model_classes as EnhActuar\n","import helper as helper"]},{"cell_type":"markdown","metadata":{"id":"1PV82qH-mP74"},"source":["## 1.3 Display settings:"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699568777598,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"NkS37qPMmS74"},"outputs":[],"source":["pd.set_option('display.max_columns', None)"]},{"cell_type":"markdown","metadata":{"id":"ZIUBtBS0lgB0"},"source":["## 1.4 Get information about the system:"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":745,"status":"ok","timestamp":1699568778341,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"NRfwcUjHlEfK","outputId":"94eba63d-b5e6-43df-e4c6-9a73acb6c2c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Version of Python: \n","--------------------\n","Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n","\n","Version of main Packages (full list below): \n","--------------------\n","Tensor Flow Version: 2.14.0\n","Keras Version: 2.14.0\n","Pandas Version: 1.5.3\n","Scikit-Learn: 1.2.2\n","\n","Information about CPU: \n","--------------------\n"," Intel(R) Xeon(R) CPU @ 2.00GHz\n","\n","Information about GPU: \n","--------------------\n","GPU is available\n","[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","Thu Nov  9 22:26:17 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   50C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# if one has a kernel installed that supports gpu's uncomment this:\n","# -----------\n","# Printing the versions of the main packages:\n","print(f\"Version of Python: \")\n","print(\"--------------------\")\n","print(f\"Python {sys.version}\")\n","print()\n","print(f\"Version of main Packages (full list below): \")\n","print(\"--------------------\")\n","print(f\"Tensor Flow Version: {tf.__version__}\")\n","print(f\"Keras Version: {keras.__version__}\")\n","print(f\"Pandas Version: {pd.__version__}\")\n","print(f\"Scikit-Learn: {sk.__version__}\")\n","\n","print()\n","print(\"Information about CPU: \")\n","print(\"--------------------\")\n","# code from: https://stackoverflow.com/a/13078519\n","def get_processor_name():\n","    if platform.system() == \"Windows\":\n","        return platform.processor()\n","    elif platform.system() == \"Darwin\":\n","        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin'\n","        command =\"sysctl -n machdep.cpu.brand_string\"\n","        return subprocess.check_output(command).strip()\n","    elif platform.system() == \"Linux\":\n","        command = \"cat /proc/cpuinfo\"\n","        all_info = subprocess.check_output(command, shell=True).decode().strip()\n","        for line in all_info.split(\"\\n\"):\n","            if \"model name\" in line:\n","                return re.sub( \".*model name.*:\", \"\", line,1)\n","    return \"\"\n","print(get_processor_name())\n","\n","print()\n","print(\"Information about GPU: \")\n","print(\"--------------------\")\n","print(\"GPU is\", \"available\" if len(tf.config.list_physical_devices('GPU'))>0 else \"NOT AVAILABLE\")\n","gpus = tf.config.list_physical_devices('GPU')\n","if len(gpus) != 0:\n","  tf.config.set_visible_devices(gpus[0], 'GPU')\n","  # Set GPU Device:\n","  tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n","  tf.config.experimental.set_memory_growth(gpus[0], True)\n","  print(gpus)\n","  !nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"_cfBAUgzkBVI"},"source":["For further details regarding the environment, see last chapter of this notebook."]},{"cell_type":"markdown","metadata":{"id":"avrhgXfKjymV"},"source":["## 1.5 Set random seeds:"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699568778341,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"TU0YUePQjymW"},"outputs":[],"source":["def set_random_seeds(seed_nr):\n","    tf.random.set_seed(seed_nr)\n","    np.random.seed(seed_nr)\n","    random.seed(seed_nr)\n","    os.environ['PYTHONHASHSEED']=str(seed_nr)\n","\n","set_random_seeds(42)\n","\n","# create 15 random seeds for the 15 models\n","random_seeds = np.random.randint(0, 1000000000, 15)\n"]},{"cell_type":"markdown","metadata":{"id":"V4RYzAlFjymW"},"source":["# 2. Load & prepare the Data:"]},{"cell_type":"markdown","metadata":{"id":"F9qNpCkwjymX"},"source":["## 2.1 Load-File"]},{"cell_type":"markdown","metadata":{"id":"fV8mgLsIjymX"},"source":["We are using the same data and data preperation as described in this Paper/Book:\n","* 2023 Book by  M. V. Wüthrich, M. Merz, \"Statistical Foundations of Actuarial Learning and its Applications\"\n","* 2023 Richmann & Wüthrich: \"LocalGLMnet: interpretable deep learning for tabular data\""]},{"cell_type":"markdown","metadata":{"id":"-Sr4_oEpjymX"},"source":["We refer here to section 3.4 in then LocalGLMnet paper.\n","Note that we are not just downloading the French Motor Third Party Liability Data files from CASdatasets.\n","They are downloading another version and they describe why in the Footnote 2 of page 553 of the 2023 Book by  M. V. Wüthrich, M. Merz.  \n","\n","So we download the data in the same way (the R code looks like this):\n","```R\n","--------------------------\n","library(OpenML)\n","library(farff)\n","library(feather)\n","freMTPL2freq <- getOMLDataSet(data.id = 41214)$data\n","freMTPL2sev<-getOMLDataSet(data.id = 41215)$data\n","\n","str(freMTPL2freq)\n","str(freMTPL2sev)\n","\n","# Save the Datasets as feather files\n","write_feather(freMTPL2freq, \"./Data/freMTPL2freq.feather\")\n","write_feather(freMTPL2sev, \"./Data/freMTPL2sev.feather\")\n","```\n","\n","In Python we are now loading in the feather files:"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2380,"status":"ok","timestamp":1699568780719,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"KY2xrO9YjymX"},"outputs":[],"source":["df_freq = pd.read_feather(f'{storage_path}/Data/freMTPL2freq.feather')\n","df_sev = pd.read_feather(f'{storage_path}/Data/freMTPL2sev.feather')"]},{"cell_type":"markdown","metadata":{"id":"1-mb7OYrjymY"},"source":["## 2.2 Data Cleaning"]},{"cell_type":"markdown","metadata":{"id":"SyAOxlaLjymY"},"source":["Now it gets a bit complicated:\n","\n","If one wants to replicate the Results of these Papers (1):\n","* 2018 Noll Case Study: \"French Motor Third-Party Liability Claims\"\n","* 2019 Schelldorfer Paper: \"Nesting Classical Actuarial Models into Neural Networks\"\n","* 2020 Wüthrich Paper: \"From Generalized Linear Models to Neural Networks, and Back\"\n","\n","Then:\n","1. One does not delete raws/lines of this data set\n","2. One uses the ClaimNb as it was in the original dataset\n","\n","Whereas if one wants to replicate the Results of these Papers (2):\n","* 2023 Book by  M. V. Wüthrich, M. Merz, \"Statistical Foundations of Actuarial Learning and its Applications\"\n","* 2023 Richmann & Wüthrich: \"LocalGLMnet: interpretable deep learning for tabular data\"\n","\n","Then:\n","1. One uses ClaimNb as aggregation of claim from the freMTPL2sev dataset\n","2. One does delete raws/lines of this data set that have more than 4 claim\n","\n","Since this notebook focuses on the second 2 papers the data-prep part is done in the same why as described there."]},{"cell_type":"markdown","metadata":{"id":"3PE_uyMYjymY"},"source":["They are doing here some basic data cleaning that we will also do before we go into the actually data preperation chapter.\n","For the original R-Code for the data cleaning we refer here to Listing 13.1 of 2023 Book by  M. V. Wüthrich, M. Merz. Regarding the summary of the data please see there Listing 13.2."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1422,"status":"ok","timestamp":1699568782136,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"tj4PL1DHjymY","outputId":"689e6dff-6a54-4dac-d413-3f0154cff558"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-7-353b70ea31e7>:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_freq[\"VehBrand\"] = df_freq[\"VehBrand\"].cat.reorder_categories([\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B10\",\"B11\",\"B12\",\"B13\",\"B14\"])\n"]}],"source":["# drop the column ClaimNb from df_freq:\n","df_freq = df_freq.drop(columns=[\"ClaimNb\"])\n","# convert the column \"VehGas\" into categorical:\n","df_freq[\"VehGas\"] = df_freq[\"VehGas\"].astype(\"category\")\n","# create a temporary dataframe with the column IDpol and the number of claims per policy:\n","temp_df_ClaimNb_from_sev_df = pd.DataFrame(df_sev[\"IDpol\"].value_counts()).reset_index()\n","temp_df_ClaimNb_from_sev_df.columns = [\"IDpol\", \"ClaimNb_from_sev_df\"]\n","# we merge the two dataframes so that we have the column \"ClaimNb_from_sev_df\" in df_freq:\n","df_freq = pd.merge(df_freq, temp_df_ClaimNb_from_sev_df, on='IDpol', how='left')\n","df_freq[\"ClaimNb_from_sev_df\"] = df_freq[\"ClaimNb_from_sev_df\"].fillna(0)\n","# rename the column \"ClaimNb_from_sev_df\" to \"ClaimNb\":\n","df_freq = df_freq.rename(columns={\"ClaimNb_from_sev_df\":\"ClaimNb\"})\n","# replace all nan values of numerical columns in the dataframe with 0:\n","for col in df_freq.select_dtypes(include=['number']).columns:\n","    df_freq[col] = df_freq[col].fillna(0)\n","# restrict the dataframe to those raws that have a ClaimNb smaller or equal to 5:\n","df_freq = df_freq[df_freq[\"ClaimNb\"]<=5]\n","# if exposure is bigger then 1 set it to 1:\n","df_freq.loc[df_freq[\"Exposure\"]>1,\"Exposure\"] = 1\n","# reordering the categories of the column VehBrand to \"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B10\",\"B11\",\"B12\",\"B13\",\"B14\":\n","df_freq[\"VehBrand\"] = df_freq[\"VehBrand\"].cat.reorder_categories([\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B10\",\"B11\",\"B12\",\"B13\",\"B14\"])\n"]},{"cell_type":"markdown","metadata":{"id":"iRWWeLDTjymY"},"source":["They described in the paper that they have after data cleaning the claim counts, time exposures and feature information, with  \n","> six continuous feature components (called ‘Area Code’, ‘Bonus-Malus Level’, ‘Density’, ‘Driver’s Age’, ‘Vehicle Age’, ‘Vehicle Power’), 1 binary component (called ‘Vehicle Gas’) and two categorical components with more than two levels (called ‘Vehicle Brand’ and ‘Region’).\n","\n","Note that in the listing of the book they change area code at another stage, but will transform already here since the LocalGLMnet paper says so:  "]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1699568782136,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"h6V_wFXxjymY","outputId":"c54c36ce-04d6-4a36-d117-ba2403684bde"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-8-a72a6d03efb2>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_freq[\"Area\"] = df_freq[\"Area\"].map({\"A\":1,\"B\":2,\"C\":3,\"D\":4,\"E\":5,\"F\":6}).astype(int)\n"]}],"source":["df_freq[\"Area\"] = df_freq[\"Area\"].map({\"A\":1,\"B\":2,\"C\":3,\"D\":4,\"E\":5,\"F\":6}).astype(int)"]},{"cell_type":"markdown","metadata":{"id":"UDWZZG8ZjymZ"},"source":["Sort the Dataset:"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1699568782136,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"dDlB6moZjymZ"},"outputs":[],"source":["# sort the dataframe by IDpol:\n","df_freq = df_freq.sort_values(by=[\"IDpol\"])"]},{"cell_type":"markdown","metadata":{"id":"K_7tZR-TjymZ"},"source":["## 2.3 Data Exploration"]},{"cell_type":"markdown","metadata":{"id":"EA7Ev0T7jymZ"},"source":["After saving and loading the dataframe as a feather file in python and doing the same small datacleaning part as described in the book the summary looks like this:"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1699568782136,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"EAucpfYkjymZ","outputId":"b9cae9e1-86c4-4dd2-b2fe-4bab9d8e314c"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-148b0306-b9a5-43e9-ba72-284f9ce19d68\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>IDpol</th>\n","      <th>Exposure</th>\n","      <th>Area</th>\n","      <th>VehPower</th>\n","      <th>VehAge</th>\n","      <th>DrivAge</th>\n","      <th>BonusMalus</th>\n","      <th>VehBrand</th>\n","      <th>VehGas</th>\n","      <th>Density</th>\n","      <th>Region</th>\n","      <th>ClaimNb</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>0.10</td>\n","      <td>4</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>55.0</td>\n","      <td>50.0</td>\n","      <td>B12</td>\n","      <td>Regular</td>\n","      <td>1217.0</td>\n","      <td>R82</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3.0</td>\n","      <td>0.77</td>\n","      <td>4</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>55.0</td>\n","      <td>50.0</td>\n","      <td>B12</td>\n","      <td>Regular</td>\n","      <td>1217.0</td>\n","      <td>R82</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5.0</td>\n","      <td>0.75</td>\n","      <td>2</td>\n","      <td>6.0</td>\n","      <td>2.0</td>\n","      <td>52.0</td>\n","      <td>50.0</td>\n","      <td>B12</td>\n","      <td>Diesel</td>\n","      <td>54.0</td>\n","      <td>R22</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10.0</td>\n","      <td>0.09</td>\n","      <td>2</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>46.0</td>\n","      <td>50.0</td>\n","      <td>B12</td>\n","      <td>Diesel</td>\n","      <td>76.0</td>\n","      <td>R72</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11.0</td>\n","      <td>0.84</td>\n","      <td>2</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>46.0</td>\n","      <td>50.0</td>\n","      <td>B12</td>\n","      <td>Diesel</td>\n","      <td>76.0</td>\n","      <td>R72</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-148b0306-b9a5-43e9-ba72-284f9ce19d68')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-148b0306-b9a5-43e9-ba72-284f9ce19d68 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-148b0306-b9a5-43e9-ba72-284f9ce19d68');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-68267848-95a5-43fc-b561-95d7cdf5bcb0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68267848-95a5-43fc-b561-95d7cdf5bcb0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-68267848-95a5-43fc-b561-95d7cdf5bcb0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["   IDpol  Exposure  Area  VehPower  VehAge  DrivAge  BonusMalus VehBrand  \\\n","0    1.0      0.10     4       5.0     0.0     55.0        50.0      B12   \n","1    3.0      0.77     4       5.0     0.0     55.0        50.0      B12   \n","2    5.0      0.75     2       6.0     2.0     52.0        50.0      B12   \n","3   10.0      0.09     2       7.0     0.0     46.0        50.0      B12   \n","4   11.0      0.84     2       7.0     0.0     46.0        50.0      B12   \n","\n","    VehGas  Density Region  ClaimNb  \n","0  Regular   1217.0    R82      0.0  \n","1  Regular   1217.0    R82      0.0  \n","2   Diesel     54.0    R22      0.0  \n","3   Diesel     76.0    R72      0.0  \n","4   Diesel     76.0    R72      0.0  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df_freq.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699568782137,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"fu9TmgVBjymZ","outputId":"6949a360-28c1-472e-c115-e3ff34ae4e90"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 678007 entries, 0 to 678012\n","Data columns (total 12 columns):\n"," #   Column      Non-Null Count   Dtype   \n","---  ------      --------------   -----   \n"," 0   IDpol       678007 non-null  float64 \n"," 1   Exposure    678007 non-null  float64 \n"," 2   Area        678007 non-null  int64   \n"," 3   VehPower    678007 non-null  float64 \n"," 4   VehAge      678007 non-null  float64 \n"," 5   DrivAge     678007 non-null  float64 \n"," 6   BonusMalus  678007 non-null  float64 \n"," 7   VehBrand    678007 non-null  category\n"," 8   VehGas      678007 non-null  category\n"," 9   Density     678007 non-null  float64 \n"," 10  Region      678007 non-null  category\n"," 11  ClaimNb     678007 non-null  float64 \n","dtypes: category(3), float64(8), int64(1)\n","memory usage: 53.7 MB\n"]}],"source":["df_freq.info()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"elapsed":571,"status":"ok","timestamp":1699568782701,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"7B9nqoIBjymZ","outputId":"87db5939-e0fa-4f93-b493-92ccaa214a64"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-a20ca035-a7b4-4e16-b0df-318b6f1676aa\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>IDpol</th>\n","      <th>Exposure</th>\n","      <th>Area</th>\n","      <th>VehPower</th>\n","      <th>VehAge</th>\n","      <th>DrivAge</th>\n","      <th>BonusMalus</th>\n","      <th>VehBrand</th>\n","      <th>VehGas</th>\n","      <th>Density</th>\n","      <th>Region</th>\n","      <th>ClaimNb</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>6.780070e+05</td>\n","      <td>678007.000000</td>\n","      <td>678007.000000</td>\n","      <td>678007.000000</td>\n","      <td>678007.000000</td>\n","      <td>678007.000000</td>\n","      <td>678007.000000</td>\n","      <td>678007</td>\n","      <td>678007</td>\n","      <td>678007.000000</td>\n","      <td>678007</td>\n","      <td>678007.000000</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>22</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>B12</td>\n","      <td>Regular</td>\n","      <td>NaN</td>\n","      <td>R24</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>166024</td>\n","      <td>345871</td>\n","      <td>NaN</td>\n","      <td>160601</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.621857e+06</td>\n","      <td>0.528547</td>\n","      <td>3.289692</td>\n","      <td>6.454653</td>\n","      <td>7.044218</td>\n","      <td>45.499061</td>\n","      <td>59.761588</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1792.430975</td>\n","      <td>NaN</td>\n","      <td>0.038913</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.641789e+06</td>\n","      <td>0.364081</td>\n","      <td>1.382689</td>\n","      <td>2.050902</td>\n","      <td>5.666235</td>\n","      <td>14.137492</td>\n","      <td>15.636700</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3958.663031</td>\n","      <td>NaN</td>\n","      <td>0.204752</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000e+00</td>\n","      <td>0.002732</td>\n","      <td>1.000000</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>18.000000</td>\n","      <td>50.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.000000</td>\n","      <td>NaN</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.157948e+06</td>\n","      <td>0.180000</td>\n","      <td>2.000000</td>\n","      <td>5.000000</td>\n","      <td>2.000000</td>\n","      <td>34.000000</td>\n","      <td>50.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>92.000000</td>\n","      <td>NaN</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2.272153e+06</td>\n","      <td>0.490000</td>\n","      <td>3.000000</td>\n","      <td>6.000000</td>\n","      <td>6.000000</td>\n","      <td>44.000000</td>\n","      <td>50.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>393.000000</td>\n","      <td>NaN</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>4.046278e+06</td>\n","      <td>0.990000</td>\n","      <td>4.000000</td>\n","      <td>7.000000</td>\n","      <td>11.000000</td>\n","      <td>55.000000</td>\n","      <td>64.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1658.000000</td>\n","      <td>NaN</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>6.114330e+06</td>\n","      <td>1.000000</td>\n","      <td>6.000000</td>\n","      <td>15.000000</td>\n","      <td>100.000000</td>\n","      <td>100.000000</td>\n","      <td>230.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>27000.000000</td>\n","      <td>NaN</td>\n","      <td>5.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a20ca035-a7b4-4e16-b0df-318b6f1676aa')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a20ca035-a7b4-4e16-b0df-318b6f1676aa button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a20ca035-a7b4-4e16-b0df-318b6f1676aa');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d80e4438-4db3-46e9-9641-d5bc3a630dc7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d80e4438-4db3-46e9-9641-d5bc3a630dc7')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d80e4438-4db3-46e9-9641-d5bc3a630dc7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["               IDpol       Exposure           Area       VehPower  \\\n","count   6.780070e+05  678007.000000  678007.000000  678007.000000   \n","unique           NaN            NaN            NaN            NaN   \n","top              NaN            NaN            NaN            NaN   \n","freq             NaN            NaN            NaN            NaN   \n","mean    2.621857e+06       0.528547       3.289692       6.454653   \n","std     1.641789e+06       0.364081       1.382689       2.050902   \n","min     1.000000e+00       0.002732       1.000000       4.000000   \n","25%     1.157948e+06       0.180000       2.000000       5.000000   \n","50%     2.272153e+06       0.490000       3.000000       6.000000   \n","75%     4.046278e+06       0.990000       4.000000       7.000000   \n","max     6.114330e+06       1.000000       6.000000      15.000000   \n","\n","               VehAge        DrivAge     BonusMalus VehBrand   VehGas  \\\n","count   678007.000000  678007.000000  678007.000000   678007   678007   \n","unique            NaN            NaN            NaN       11        2   \n","top               NaN            NaN            NaN      B12  Regular   \n","freq              NaN            NaN            NaN   166024   345871   \n","mean         7.044218      45.499061      59.761588      NaN      NaN   \n","std          5.666235      14.137492      15.636700      NaN      NaN   \n","min          0.000000      18.000000      50.000000      NaN      NaN   \n","25%          2.000000      34.000000      50.000000      NaN      NaN   \n","50%          6.000000      44.000000      50.000000      NaN      NaN   \n","75%         11.000000      55.000000      64.000000      NaN      NaN   \n","max        100.000000     100.000000     230.000000      NaN      NaN   \n","\n","              Density  Region        ClaimNb  \n","count   678007.000000  678007  678007.000000  \n","unique            NaN      22            NaN  \n","top               NaN     R24            NaN  \n","freq              NaN  160601            NaN  \n","mean      1792.430975     NaN       0.038913  \n","std       3958.663031     NaN       0.204752  \n","min          1.000000     NaN       0.000000  \n","25%         92.000000     NaN       0.000000  \n","50%        393.000000     NaN       0.000000  \n","75%       1658.000000     NaN       0.000000  \n","max      27000.000000     NaN       5.000000  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df_freq.describe(include=\"all\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1WvhTlWvzMihienIqcV7ewOPa13nQtVvz"},"executionInfo":{"elapsed":12759,"status":"ok","timestamp":1699568795456,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"g3qKuuUyjymZ","outputId":"e7c82c12-7cbb-4fae-8398-dc474d531fc1"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["for column in df_freq.columns.drop([\"IDpol\",\"Exposure\",\"Density\"]):\n","    value_counts = df_freq[column].value_counts(dropna=False).sort_index()\n","    fig = px.bar(x=value_counts.index, y=value_counts.values)\n","    fig.update_layout(\n","        title=f\"Value Counts Bar Chart of: {column}\",\n","        xaxis_title=f\"{column}\",\n","        yaxis_title=\"Count\",\n","        showlegend=False)\n","    fig.show()\n","column=\"Density\"\n","fig = px.histogram(df_freq[column])\n","fig.update_layout(\n","    title=f\"Histogram {column}\",\n","    xaxis_title=\"Values\",\n","    yaxis_title=\"Frequency\",\n","    showlegend=False\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"GGUTrEsHjyma"},"source":["Quick test if the column IDPol is unique: yes they are unique :)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1699568795457,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"XHEKvHU0jyma","outputId":"6c1a266d-0bb2-4f61-bff3-ebf3b5b0129d"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df_freq[\"IDpol\"].value_counts().max()"]},{"cell_type":"markdown","metadata":{"id":"vCf6Ex8qjyma"},"source":["## 2.4 Split: Learn/Val/Test definition:"]},{"cell_type":"markdown","metadata":{"id":"2rzMeYnmjyma"},"source":["In the LocalGLMnet paper they are mentioning that they do it exactly like it is done in the Book Wüthrich & Merz (2021):  \n","> To do a proper out-of-sample generalization analysis we partition the data randomly into a learning data set $L$ and a test data set $T$ . The learning data L contains\n","$n = 610,206$ instances and the test data set $T$ contains $67,801$ instances; we use exactly the same split as in Table 5.2 of Wüthrich & Merz (2021). The learning data L will be used to learn the network parameters and the test data $T$ is used to perform an out-of-sample generalization analysis.\n","\n","So to get the same results I also run the code splitting code in R instead of python and exported the splitting feature to later then import it to python.\n","The R Code looked like this to reproduce the results (Note here the RNGversion!):\n","\n","```R\n","\n","RNGversion(\"3.5.0\")\n","set.seed(100)\n","ll_replicate_papers_2 <- sample (c(1: nrow(freMTPL2freq)) , round(0.9* nrow(freMTPL2freq)), replace = FALSE)\n","learn <- freMTPL2freq[ll_replicate_papers_1 ,]\n","test <- freMTPL2freq[-ll_replicate_papers_1 ,]\n","\n","# Save the list to a text file\n","write.table(learn$IDpol, \"./Data/learn_split_IDpols_2.txt\", row.names = FALSE, col.names = FALSE)\n","```\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3169,"status":"ok","timestamp":1699568798607,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"bmS4X8Ywjyma"},"outputs":[],"source":["ids_in_learn = list(np.genfromtxt(f\"{storage_path}/Data/learn_split_IDpols_2.txt\").astype(int))\n","ids_in_test = list(df_freq[~df_freq[\"IDpol\"].isin(ids_in_learn)][\"IDpol\"].astype(int))\n","\n","bool_in_learn = df_freq['IDpol'].isin(ids_in_learn) # be careful if the dataset is not sorted by IDpol\n","bool_in_test = df_freq['IDpol'].isin(ids_in_test) # be careful if the dataset is not sorted by IDpol"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":93},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699568798607,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"-g5VcSkbjyma","outputId":"b2baf8f8-5d1c-4b84-9053-9b29f04d959f"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'The learning data L contains so many instances: 610206'"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'The test data T contains so many instances: 67801'"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Test the resulting portfolio freq (w.r.t Exposure) in learn df:  7.36%'"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Test the resulting portfolio freq (w.r.t Exposure) in test df:  7.35%'"]},"metadata":{},"output_type":"display_data"}],"source":["display(f\"The learning data L contains so many instances: {len(ids_in_learn)}\")\n","display(f\"The test data T contains so many instances: {len(ids_in_test)}\")\n","\n","freq_learn = df_freq[bool_in_learn]['ClaimNb'].sum()/df_freq[bool_in_learn]['Exposure'].sum()\n","freq_test = df_freq[bool_in_test]['ClaimNb'].sum()/df_freq[bool_in_test]['Exposure'].sum()\n","display(f\"Test the resulting portfolio freq (w.r.t Exposure) in learn df: {freq_learn: .2%}\")\n","display(f\"Test the resulting portfolio freq (w.r.t Exposure) in test df: {freq_test: .2%}\")"]},{"cell_type":"markdown","metadata":{"id":"5Mw1ByCBjyma"},"source":["We add also a split of the the learn dataset into train and validation: (90% / 10%). In the LocalGLMnet Paper I didn't found a specific split here so a create a new one. We create here 15 train/val splits because we want to fit 15 differant models."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":93},"executionInfo":{"elapsed":2501,"status":"ok","timestamp":1699568801104,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"-XE2xr4Djymb","outputId":"4240a156-7d13-4cd9-bd27-96f1d8fbf17c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Example train/validation split freq: \n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Test the resulting portfolio freq (w.r.t Exposure) in learn df:  7.36%'"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Test the resulting portfolio freq (w.r.t Exposure) in learn-train df:  7.37%'"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Test the resulting portfolio freq (w.r.t Exposure) in learn-val df:  7.28%'"]},"metadata":{},"output_type":"display_data"}],"source":["# create 15 new train and validation split with sklearn:\n","train_val_split = {}\n","for run_index in range(15):\n","  temp_learn_train, temp_learn_val = sk.model_selection.train_test_split(df_freq[bool_in_learn][['IDpol']],\n","                                                                        test_size=0.1,\n","                                                                        random_state=random_seeds[run_index])\n","  train_val_split[f\"learn_train_{run_index}\"] = df_freq['IDpol'].isin(temp_learn_train['IDpol']) # be careful if the dataset is not sorted by IDpol\n","  train_val_split[f\"learn_val_{run_index}\"]  = df_freq['IDpol'].isin(temp_learn_val['IDpol']) # be careful if the dataset is not sorted by IDpol\n","\n","print(\"Example train/validation split freq: \")\n","freq_learn_train = df_freq[train_val_split[f\"learn_train_{run_index}\"]]['ClaimNb'\n","                          ].sum()/df_freq[train_val_split[f\"learn_train_{run_index}\"]]['Exposure'].sum()\n","freq_learn_val = df_freq[train_val_split[f\"learn_val_{run_index}\"]]['ClaimNb'\n","                        ].sum()/df_freq[train_val_split[f\"learn_val_{run_index}\"]]['Exposure'].sum()\n","\n","display(f\"Test the resulting portfolio freq (w.r.t Exposure) in learn df: {freq_learn: .2%}\")\n","display(f\"Test the resulting portfolio freq (w.r.t Exposure) in learn-train df: {freq_learn_train: .2%}\")\n","display(f\"Test the resulting portfolio freq (w.r.t Exposure) in learn-val df: {freq_learn_val: .2%}\")\n","del temp_learn_train, temp_learn_val"]},{"cell_type":"markdown","metadata":{"id":"FpIgmUwSjymb"},"source":["Also create a really small learn set (for dummy training of transformers - basically just to check if the code is running)."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699568801104,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"SVBuVEBnjymb","outputId":"8aaecf61-44a6-4711-c37e-2a975bf93639"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Test the resulting portfolio freq (w.r.t Exposure) in learn train dummy df:  7.66%'"]},"metadata":{},"output_type":"display_data"}],"source":["# create a new train and test split with sklearn:\n","temp_1, temp_lean_train_dummy = sk.model_selection.train_test_split(df_freq[train_val_split[f\"learn_train_{run_index}\"]][['IDpol']],\n","                                                                    test_size=0.01,\n","                                                                    random_state=random_seeds[0]+1)\n","bool_in_learn_train_dummy = df_freq['IDpol'].isin(temp_lean_train_dummy['IDpol']) # be careful if the dataset is not sorted by IDpol\n","\n","freq_learn_train_dummy = df_freq[bool_in_learn_train_dummy]['ClaimNb'].sum()/df_freq[bool_in_learn_train_dummy]['Exposure'].sum()\n","\n","display(f\"Test the resulting portfolio freq (w.r.t Exposure) in learn train dummy df: {freq_learn_train_dummy: .2%}\")\n","del temp_1, temp_lean_train_dummy"]},{"cell_type":"markdown","metadata":{"id":"B7Bov2OWjymb"},"source":["## 2.5 Data-Preperation for GLMs"]},{"cell_type":"markdown","metadata":{"id":"Ap67eQXJjymb"},"source":["We use the same data preperation as described in the Book by Wüthrich & Merz (2023)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3003,"status":"ok","timestamp":1699568804102,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"YUBpkSTDjymb"},"outputs":[],"source":["# Copy the dataframe df_freq:\n","df_freq_glm = df_freq.copy()\n","# Area:\n","# is already numerical (due to the mapping above)\n","# VehPower:\n","temp_dict_change_VehPower={}\n","for i,v in enumerate(sorted(df_freq[\"VehPower\"].unique())):\n","    if v <9:\n","        temp_dict_change_VehPower[v]=i+1\n","    else:\n","        temp_dict_change_VehPower[v]=6\n","df_freq_glm[\"VehPower\"] = df_freq[\"VehPower\"].map(temp_dict_change_VehPower).astype('category')\n","# VehAge:\n","# note: this part is different from the one in these papers:\n","# * 2018 Noll Case Study: \"French Motor Third-Party Liability Claims\"\n","# * 2019 Schelldorfer Paper: \"Nesting Classical Actuarial Models into Neural Networks\"\n","# * 2020 Wüthrich Paper: \"From Generalized Linear Models to Neural Networks, and Back\"\n","bins = [0, 6, 13, float('inf')]\n","labels = ['[0, 6)', '[6, 13)', '[13, ∞)']\n","df_freq_glm[\"VehAge\"] = pd.cut(df_freq[\"VehAge\"],bins=bins, labels=labels, right=False).astype('category')\n","# DrivAge:\n","bins = [18, 21, 26, 31, 41, 51, 71, float('inf')]\n","labels = ['[18, 21)', '[21, 26)', '[26, 31)', '[31, 41)', '[41, 51)', '[51, 71)', '[71, ∞)']\n","df_freq_glm[\"DrivAge\"] = pd.cut(df_freq[\"DrivAge\"],bins=bins, labels=labels, right=False).astype('category')\n","df_freq_glm[\"DrivAge_Nr\"] = df_freq[\"DrivAge\"]\n","# BonusMalus:\n","df_freq_glm.loc[df_freq_glm[\"BonusMalus\"] >= 150, \"BonusMalus\"] = 150\n","# VehBrand:\n","# is already categorical (due to the reordering above)\n","# VehGas:\n","# is already categorical (due to the cast above)\n","# Density:\n","df_freq_glm[\"Density\"] = np.log(df_freq_glm[\"Density\"])\n","# Region:\n","# is already categorical\n","\n","# check if we have the same number of features that we need for the glms as in the paper:\n","'''\n","print(\"Check if we have the same number of features that we need for the glms as in the paper\")\n","print(\"------------\")\n","test_dim_feature_space = 0\n","for col in df_freq_glm.select_dtypes(include=[int,float]).columns.drop([\"IDpol\",\"ClaimNb\",\"Exposure\",\"DrivAge_Nr\"]):\n","    display(f\"Dimensions for feature space of {col}: 1\")\n","    test_dim_feature_space+=1\n","for col in df_freq_glm.select_dtypes(include=['category']).columns:\n","    display(f\"Dimensions for feature space of {col}: {len(df_freq_glm[col].cat.categories)-1}\")\n","    test_dim_feature_space=test_dim_feature_space+len(df_freq_glm[col].cat.categories)-1\n","display(f\"Total dimensions for feature space: {test_dim_feature_space}\")\n","'''\n","\n","# Dummy encode all categorical variable for GLM1:\n","X_glm1 = pd.get_dummies(df_freq_glm, columns=df_freq_glm.select_dtypes(include=['category']).columns,drop_first=True).drop(columns=[\"IDpol\",\"ClaimNb\",\"Exposure\",\"DrivAge_Nr\"])\n","X_glm1_learn = X_glm1[bool_in_learn]\n","X_glm1_test = X_glm1[bool_in_test]\n","\n","# Create the new DrivAge (power and log) columns for GLM2:\n","columns_to_drop = [col for col in X_glm1.columns if col.startswith('DrivAge_')]\n","X_glm2 = X_glm1.drop(columns=columns_to_drop)\n","X_glm2[\"DrivAge_1\"] = df_freq_glm[\"DrivAge_Nr\"]\n","X_glm2[\"DrivAge_2\"] = df_freq_glm[\"DrivAge_Nr\"]**2\n","X_glm2[\"DrivAge_3\"] = df_freq_glm[\"DrivAge_Nr\"]**3\n","X_glm2[\"DrivAge_4\"] = df_freq_glm[\"DrivAge_Nr\"]**4\n","X_glm2[\"DrivAge_log\"] = np.log(df_freq_glm[\"DrivAge_Nr\"])\n","X_glm2_learn = X_glm2[bool_in_learn].reset_index(drop=True)\n","means_DrivAge_learn = X_glm2_learn[[col for col in X_glm2_learn.columns if col.startswith('DrivAge_')]].mean()\n","for col in X_glm2_learn.columns:\n","    if col.startswith('DrivAge_'):\n","        X_glm2[col] = np.array(X_glm2[col]/means_DrivAge_learn[col])\n","X_glm2_learn = X_glm2[bool_in_learn].reset_index(drop=True)\n","X_glm2_test = X_glm2[bool_in_test].reset_index(drop=True)\n","\n","# Adding interaction columns to the data frame for GLM3:\n","# one has to be careful here since the dataframes before are reindexed:\n","X_glm3 = X_glm2.copy()\n","X_glm3[\"DrivAge_1_x_BonusMalus\"] = list(df_freq_glm[\"BonusMalus\"]*df_freq_glm[\"DrivAge_Nr\"])\n","X_glm3[\"DrivAge_2_x_BonusMalus\"] = list(df_freq_glm[\"BonusMalus\"]*df_freq_glm[\"DrivAge_Nr\"]**2)\n","X_glm3_learn = X_glm2_learn.copy()\n","X_glm3_learn[\"DrivAge_1_x_BonusMalus\"] = list(df_freq_glm[bool_in_learn][\"BonusMalus\"]*df_freq_glm[bool_in_learn][\"DrivAge_Nr\"])\n","X_glm3_learn[\"DrivAge_2_x_BonusMalus\"] = list(df_freq_glm[bool_in_learn][\"BonusMalus\"]*df_freq_glm[bool_in_learn][\"DrivAge_Nr\"]**2)\n","means_DrivAge_x_BonusMalus_learn = X_glm3_learn[[\"DrivAge_1_x_BonusMalus\", \"DrivAge_2_x_BonusMalus\"]].mean()\n","for col in list(means_DrivAge_x_BonusMalus_learn.index):\n","    X_glm3[col] = np.array(X_glm3[col]/means_DrivAge_x_BonusMalus_learn[col])\n","X_glm3_learn = X_glm3[bool_in_learn].reset_index(drop=True)\n","X_glm3_test = X_glm3[bool_in_test].reset_index(drop=True)\n"]},{"cell_type":"markdown","metadata":{"id":"Qd3GcgdGjymc"},"source":["## 2.6 Data-Preperation as described in the LocalGLMnet Paper:"]},{"cell_type":"markdown","metadata":{"id":"hH-T_L5ojyml"},"source":["In the LocalGLMnet paper they write regarding the data pre-processing:\n","\n","> We pre-process these components as follows: we center and normalize\n","to unit variance the six continuous and the binary components. We apply one-hot encoding to the\n","two categorical variables, we emphasize that we do not use dummy coding as it is usually done in\n","GLMs. Below, in Section 3.6, we are going to motivate this one-hot encoding choice (which does not\n","lead to full rank design matrices); for one-hot encoding vs. dummy coding we refer to formulas (5.21)\n","and (7.29) in Wüthrich & Merz (2021).\n","\n","\n","> As a control variable, we add two random feature components that are $i.i.d.$, centered and with unit\n","variance, the first one having a uniform distribution and the second one having a standard normal\n","distribution, we call these two additional feature components ‘RandU’ and ‘RandN’. We consider\n","two additional independent components to understand whether the distributional choice influences\n","the results of hypothesis testing using the empirical interval $I_\\alpha$, see (16).\n","Altogether (and using one-hot encoding) we receive q = 42 dimensional tabular feature variables $x_i ∈ R^q$; this includes the two additional components RandU and RandN.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GZcmAE9Ijyml"},"source":["So we try now to replicate it:"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1699568804518,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"e0KAskvFjyml"},"outputs":[],"source":["df_freq_prep_nn = df_freq.copy()\n","# change VehGas to binary:\n","df_freq_prep_nn[\"VehGas\"] = df_freq_prep_nn[\"VehGas\"].map({\"Diesel\":1,\"Regular\":0}).astype(int)\n","\n","nr_col = [\"Area\", \"VehPower\", \"VehAge\", \"DrivAge\", \"BonusMalus\", \"VehGas\", \"Density\"]\n","cat_col = [\"VehBrand\", \"Region\"]\n","\n","# Note: StandardScaler : = (x-mean)/standard_deviation\n","# Since it is good practice we are training the standardscaler (mean and standard_deviation) only the training data and apply it on the hole dataset (including the test data)\n","prep_standardscaler = StandardScaler()\n","prep_standardscaler.fit(df_freq_prep_nn[bool_in_learn][nr_col])\n","\n","df_freq_prep_nn[nr_col] = prep_standardscaler.transform(df_freq_prep_nn[nr_col])\n","# add the dummy columns to the df_freq_prep_nn dataframe:\n","df_freq_prep_nn = pd.concat([df_freq_prep_nn.drop(columns=cat_col),\n","                             pd.get_dummies(df_freq_prep_nn[cat_col], columns=cat_col, drop_first=False).astype(int)\n","                             ], axis=1)\n","# add back the for the categorical columns that have been dropped above:\n","df_freq_prep_nn[list(map(lambda item: \"Cat_\" + item, cat_col))] = df_freq[cat_col]\n","cat_col = list(map(lambda item: \"Cat_\" + item, cat_col))"]},{"cell_type":"markdown","metadata":{"id":"94Llo5h7jyml"},"source":["Add to random features as columns. One that is normal distributed with mean = 0 and variance = 1 and one that is uniform distributed with mean = 0 and variance = 1.\n","\n","Note that the variance of the uniform distribution is $\\displaystyle{\\frac{1}{12}}(b-a)^{2}$. So we choose $b=\\frac{\\sqrt{12}}{2}$"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1LaXqZdWsRTb1uDqfnMA6oy5WWaQ-voD8"},"executionInfo":{"elapsed":91107,"status":"ok","timestamp":1699568895622,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"WNUKmEEBjymm","outputId":"4c18996a-d862-4d0c-82c9-1db85f6ba346"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# create a random column that is centered around 0 and has a standard deviation of 1 and has uniform distribution:\n","df_freq_prep_nn[\"RandU\"] = np.random.uniform(-np.sqrt(12)/2,np.sqrt(12)/2,len(df_freq_prep_nn))\n","# create a random column that is centered around 0 and has a standard deviation of 1 and has normal distribution:\n","df_freq_prep_nn[\"RandN\"] = np.random.normal(0,1,len(df_freq_prep_nn))\n","\n","column=\"RandU\"\n","fig = px.histogram(df_freq_prep_nn[column])\n","fig.update_layout(\n","    title=f\"Histogram {column}\",\n","    xaxis_title=\"Values\",\n","    yaxis_title=\"Frequency\",\n","    showlegend=False\n",")\n","fig.show()\n","\n","column=\"RandN\"\n","fig = px.histogram(df_freq_prep_nn[column])\n","fig.update_layout(\n","    title=f\"Histogram {column}\",\n","    xaxis_title=\"Values\",\n","    yaxis_title=\"Frequency\",\n","    showlegend=False\n",")\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"naLkCOhNjymm"},"source":["Check if all numerical features now have the right mean and variance:"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87,"status":"ok","timestamp":1699568895624,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"F9ECHuA9jymm","outputId":"b02ebb1b-afc1-492f-d05d-691f622b108e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Area         -0.000056\n","VehPower     -0.000085\n","VehAge       -0.000090\n","DrivAge       0.000082\n","BonusMalus   -0.000078\n","VehGas       -0.000212\n","Density      -0.000675\n","RandU         0.000565\n","RandN         0.000442\n","dtype: float64\n","Area          0.999080\n","VehPower      0.999729\n","VehAge        0.997462\n","DrivAge       1.000098\n","BonusMalus    1.000379\n","VehGas        0.999993\n","Density       0.996537\n","RandU         1.000032\n","RandN         1.001442\n","dtype: float64\n"]}],"source":["print(df_freq_prep_nn[nr_col + [\"RandU\",\"RandN\"]].mean())\n","print(df_freq_prep_nn[nr_col + [\"RandU\",\"RandN\"]].var())\n"]},{"cell_type":"markdown","metadata":{"id":"OjI_2zDsjymm"},"source":["Adding some encodings for the categorical features, in case we want to use later some embeddings:"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":68,"status":"ok","timestamp":1699568895625,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"PeAJxwsGjymm"},"outputs":[],"source":["cat_encoder_all = {}\n","for col in [\"VehBrand\", \"Region\"]:\n","    cat_encoder = {}\n","    unique_cat = df_freq.dtypes[col].categories.to_list()\n","    for i in range(len(unique_cat)):\n","        cat_encoder[unique_cat[i]] = i\n","    cat_encoder_all[col]=cat_encoder # we save the encoder dict incase we will need it later to back transform the results.\n","    df_freq_prep_nn[f\"NN_EMB_{col}\"] = df_freq[col].map(cat_encoder_all[col]).astype(int)"]},{"cell_type":"markdown","metadata":{"id":"sngkMSsYjymm"},"source":["Creating the learning and test datasets for the neural network models:"]},{"cell_type":"markdown","metadata":{"id":"7l3P1gdBJ_Js"},"source":["Note we are not creating here every train and validation split dataset but instead create those when fitting the model.\n","So that we are not polluting the RAM."]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":68,"status":"ok","timestamp":1699568895625,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"rnk7Xjt8GNI7"},"outputs":[],"source":["# Note we are not creating here every train and validation split dataset but instead create those when fitting the model.\n","# So that we are not polluting the RAM (notebooks have no garbage collector).\n","\n","# Create Datasets for OHE FNN:\n","# ------------------------\n","col_x_fnn_ohe = nr_col + [col for col in df_freq_prep_nn.columns if col.startswith('VehBrand_') or col.startswith('Region_')]\n","def create_ffn_ohe_data(bool_list, exposure_name=\"Exposure\", response_name=\"ClaimNb\"):\n","    X_nn_ohe = np.array(df_freq_prep_nn[bool_list][col_x_fnn_ohe].values)\n","    exposure = np.array(df_freq[bool_list][exposure_name])\n","    y_true= np.array(df_freq[bool_list][response_name])\n","    return [X_nn_ohe, exposure], y_true\n","\n","\n","# Create Datasets for cat embedding FNN:\n","# ------------------------\n","def create_ffn_cat_emb_data(bool_list, exposure_name=\"Exposure\", response_name=\"ClaimNb\"):\n","    X_nn_just_nr = np.array(df_freq_prep_nn[bool_list][nr_col].values),\n","    Input_EMB_VehBrand = np.array(df_freq_prep_nn[bool_list][\"NN_EMB_VehBrand\"].values)\n","    Input_EMB_Region = np.array(df_freq_prep_nn[bool_list][\"NN_EMB_Region\"].values)\n","    exposure = np.array(df_freq_prep_nn[bool_list][exposure_name])\n","    y_true = np.array(df_freq_prep_nn[bool_list][response_name])\n","    return [X_nn_just_nr, Input_EMB_VehBrand, Input_EMB_Region, exposure], y_true\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hbrlygD3cenQ"},"source":["## 2.7 Data-Preperation for Transformer models:"]},{"cell_type":"markdown","metadata":{"id":"mnd_iViNdGub"},"source":["Since the FT transformer need the every feature as a separate tensor we create a new tensor dataset:"]},{"cell_type":"markdown","metadata":{"id":"BfeHJqoGdKey"},"source":["Note we are not creating here every train and validation split dataset but instead create those when fitting the model.\n","So that we are not polluting the RAM. Note that notebooks have usually no garbage collector, so we try to be carefull."]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":68,"status":"ok","timestamp":1699568895626,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"kjY0BD6AcfCK"},"outputs":[],"source":["def df_to_tensor(df: pd.DataFrame, feature_cols: list, exposure: str=None, target: str=None, batch_size: int = 512, dummy_data_for_build=False):\n","    \"\"\"\n","    transforms the pandas dataframe to a tensorflow dataset as input for the model\n","\n","    Args:\n","        df (pd dataframe): the pandas dataframe that includes the features\n","        feature_cols (list): the list of feature columns that should be included in the model\n","        exposure (str): if the exposure is included it will be used a a separate input (if None it will be ignored)\n","        target (str): if the target is included it will be used in as a separate input (if None it will be ignored)\n","        batch_size (int): the batch size for the tensorflow dataset\n","        dummy_data_for_build (bool): build a dummy dataset for the model (only for building the model) that is not prefetched (default: False)\n","\n","    Returns:\n","        tensorflow Dataset (Prefetched and Batched)\n","    \"\"\"\n","    if exposure:\n","        feature_cols = feature_cols+[exposure]\n","    temp_dict = {k.lower(): np.array(v).reshape(-1, 1).astype(np.float32, copy=False)\n","                            if v.dtype in [\"float64\",\"float32\",\"int64\",\"int32\"] else\n","                            np.array(v).reshape(-1, 1) for k, v in df[feature_cols].items()}\n","    if target:\n","        temp_input = (temp_dict, np.array(df[target]))\n","    else:\n","        temp_input = (temp_dict)\n","    tf_dataset = tf.data.Dataset.from_tensor_slices(temp_input) # create the tf dataset\n","    tf_dataset = tf_dataset.batch(batch_size) # for parallelizing the calc\n","    if dummy_data_for_build == False:\n","        tf_dataset = tf_dataset.prefetch(batch_size) # Prefetch the data for better performance (helps to overlaps the data preprocessing and model execution)\n","    return tf_dataset\n","\n","cat_vocabulary = {}\n","for c in cat_col:\n","    cat_vocabulary[c] = df_freq_prep_nn.dtypes[c].categories.tolist()\n"]},{"cell_type":"markdown","metadata":{"id":"-2ro9ldJjymm"},"source":["## 2.8 Loss function definition:  "]},{"cell_type":"markdown","metadata":{"id":"R8gdbPNUjymn"},"source":["In the paper there are mentioning that they are using the poisson loss function:\n","\n","> As loss function for parameter fitting and generalization analysis we choose the Poisson deviance loss, which is a distribution adapted and strictly consistent loss function for the mean within the Poisson model, for details we refer to Section 4.1.3 in Wüthrich & Merz (2021).\n","\n","So we create quickly the loss function in this step.\n","* Note: on could also just use sklearn.metrics import mean_poisson_deviance\n","* Note the mean of $d(y, \\mu) = 2*\\left(y \\log \\frac{y}{\\mu} - y + \\mu\\right)$: is the same as the formula (5.28) in the Book (2023)\n"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":67,"status":"ok","timestamp":1699568895626,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"cLZJKvvejymn"},"outputs":[],"source":["# Loss-function (for numpy arrays)\n","# ----------------------\n","def poisson_deviance_loss(y_true, y_pred):\n","    with np.errstate(divide='ignore'):\n","        with warnings.catch_warnings():\n","            warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n","            xlogy = np.where(y_true != 0, y_true * np.log(y_true / y_pred), 0)\n","            dev = 2 * (xlogy - y_true + y_pred)\n","    return dev.mean()\n","\n","# Loss-Function\n","# ----------------------\n","# we use our own loss function here (because it is not included in tensorflow in the same way):\n","# normally here i would use the tf loss class (using the LossFunctionWrapper but this does not work on colab\n","# since there is no @keras_export() in the source code...):\n","# @keras.saving.register_keras_serializable(package=\"my_package\", name=\"poisson_loss_for_tf\")\n","@tf.function()\n","def poisson_loss_for_tf(y_true, y_pred, mean=True):\n","    \"\"\"Computes the Poisson loss between y_true and y_pred.\n","\n","    The Poisson loss is the mean of the elements of the `Tensor`\n","    `2 * (y_true * log(y_true / y_pred) - y_true + y_pred)`.\n","\n","    Args:\n","        y_true: A tensor of true values with shape (batch_size,).\n","        y_pred: A tensor of predicted values with shape (batch_size,).\n","\n","    Returns:\n","        The Poisson loss between y_true and y_pred.\n","   \"\"\"\n","   # NOTE: this squeeze is not very professional :) but it does its job right now...\n","    ''' TODO: check if this commented squeeze is needed or not?\n","    if y_pred.shape != y_true.shape:\n","        if y_pred.ndim > y_true.ndim:\n","            y_pred = tf.squeeze(y_pred, [-1])\n","        elif y_pred.ndim < y_true.ndim:\n","                y_true = tf.squeeze(y_true, [-1])\n","    '''\n","    if y_pred.shape != y_true.shape:\n","        y_pred = tf.squeeze(y_pred, [-1])\n","    y_pred = tf.convert_to_tensor(y_pred)\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    loss = 2 * (y_true * tf.math.log((y_true + keras.backend.epsilon()) / (y_pred + keras.backend.epsilon())) - y_true + y_pred)\n","    if mean:\n","        return keras.backend.mean(loss, axis=-1)\n","    else:\n","        return loss\n","\n","# Loss Function Wrapper\n","# ----------------------\n","class Poisson_loss_for_tf_Wrapped:\n","    def __init__(self, y_true=None, y_pred=None, name=\"poisson_loss_for_tf\"):\n","        self.name = name\n","        self.y_true = y_true\n","        self.y_pred = y_pred\n","    def __call__(self, y_true, y_pred):\n","        return poisson_loss_for_tf(y_true, y_pred)\n","\n","\n","# Loss Metrics.\n","# ----------------------\n","# See here: https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Metric\n","class Poisson_Metric_for_tf(tf.keras.metrics.Metric):\n","    def __init__(self, name='mae', **kwargs):\n","        super(Poisson_Metric_for_tf, self).__init__(name=name, **kwargs)\n","        self.total = self.add_weight(name='total', initializer='zeros')\n","        self.count = self.add_weight(name='count', initializer='zeros')\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        batch_poisson_loss = poisson_loss_for_tf(y_true, y_pred,mean=False)\n","        sum_batch_poisson_loss = tf.reduce_sum(batch_poisson_loss)\n","        num_samples = tf.cast(tf.size(y_true), tf.float32)\n","        if sample_weight is not None:\n","            raise ValueError('Code for sample_weight is not jet implemented')\n","        self.total.assign_add(sum_batch_poisson_loss)\n","        self.count.assign_add(num_samples)\n","\n","    def result(self):\n","        return self.total / self.count\n","\n","    def reset_states(self):\n","        self.total.assign(0)\n","        self.count.assign(0)\n","\n","\n","# note that the function tf.keras.losses.Poisson() is not the same as the poisson_deviance_loss function above.\n","# the function tf.keras.losses.Poisson() is the same as mean(y_pred - y_true * tf.math.log(y_pred + 1e-10))."]},{"cell_type":"markdown","metadata":{"id":"8JCW6DkAjymn"},"source":["## 2.9 Initialize container for results:\n","(dataframe/hash-table/functions that help to store results)"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":68,"status":"ok","timestamp":1699568895627,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"WqoVhBFdjymn"},"outputs":[],"source":["# init hash tables for results\n","y_pred = {}\n","y_pred[\"train\"]={}\n","y_pred[\"test\"]={}\n","\n","y_true = {}\n","y_true[\"train\"] = np.array(df_freq[bool_in_learn][\"ClaimNb\"])\n","y_true[\"test\"] = np.array(df_freq[bool_in_test][\"ClaimNb\"])\n","\n","exposure = {}\n","exposure[\"train\"] = np.array(df_freq[bool_in_learn][\"Exposure\"])\n","exposure[\"test\"] = np.array(df_freq[bool_in_test][\"Exposure\"])\n","\n","log_exposure = {}\n","log_exposure[\"train\"] = np.array(np.log(df_freq[bool_in_learn][\"Exposure\"]))\n","log_exposure[\"test\"] = np.array(np.log(df_freq[bool_in_test][\"Exposure\"]))\n","\n","epochs_and_time = {}\n","\n","df_results = pd.DataFrame(columns=[\"model\",\n","                                   \"epochs\",\n","                                   \"run_time\",\n","                                   \"# parameters\",\n","                                   \"poisson deviance loss: train\",\n","                                   \"poisson deviance loss: test\",\n","                                   f\"pred-avg-freq: train (obs = {freq_learn: .2%})\",\n","                                   f\"pred-avg-freq: test (obs = {freq_test: .2%})\"])\n","\n","# create a python data class to store the results:\n","@dataclass\n","class Results:\n","    model: str\n","    epochs: int = field(default=None)\n","    run_time: float = field(default=None)\n","    nr_parameters: int = field(default=None)\n","    poisson_deviance_loss_train: float = field(default=None)\n","    poisson_deviance_loss_test: float = field(default=None)\n","    pred_avg_freq_train: float = field(default=None)\n","    pred_avg_freq_test: float = field(default=None)\n","\n","# create a function that stores the results in a dataframe not using append since dataframe object has no attribute append:\n","def store_results_in_df(results):\n","    global df_results\n","    global freq_learn\n","    global freq_test\n","    if len(df_results[df_results[\"model\"]!=results.model])==0:\n","        df_results = pd.DataFrame({\"model\":results.model,\n","                                            \"epochs\":results.epochs,\n","                                            \"run_time\":results.run_time,\n","                                            \"nr_parameters\":results.nr_parameters,\n","                                            \"loss_train\":results.poisson_deviance_loss_train,\n","                                            \"loss_test\":results.poisson_deviance_loss_test,\n","                                            f\"pred_avg_freq_train\":results.pred_avg_freq_train,\n","                                            f\"pred_avg_freq_test\":results.pred_avg_freq_test},\n","                                  index=[0])\n","    else:\n","        df_results = pd.concat([df_results[df_results[\"model\"]!=results.model],\n","                                pd.DataFrame({\"model\":results.model,\n","                                                \"epochs\":results.epochs,\n","                                                \"run_time\":results.run_time,\n","                                                \"nr_parameters\":results.nr_parameters,\n","                                                \"loss_train\":results.poisson_deviance_loss_train,\n","                                                \"loss_test\":results.poisson_deviance_loss_test,\n","                                                f\"pred_avg_freq_train\":results.pred_avg_freq_train,\n","                                                f\"pred_avg_freq_test\":results.pred_avg_freq_test},\n","                                             index=[0])\n","                                ], ignore_index=True).reset_index(drop=True)\n","\n","\n","def calc_avg_df(list_models):\n","    for i, model in enumerate(list_models):\n","        filtered_results = df_results[df_results['model'].str.startswith(model)]\n","        averages = pd.DataFrame(filtered_results.select_dtypes(include=['number']).mean()).T\n","        averages.insert(0, 'model', model)\n","        if i == 0:\n","            df_avg = averages\n","        else:\n","            df_avg = pd.concat([df_avg, averages], ignore_index=True)\n","    return df_avg\n","\n","\n","def calc_std_df(list_models):\n","    for i, model in enumerate(list_models):\n","        filtered_results = df_results[df_results['model'].str.startswith(model)]\n","        averages = pd.DataFrame(filtered_results.select_dtypes(include=['number']).std()).T\n","        averages.insert(0, 'model', model)\n","        if i == 0:\n","            df_std = averages\n","        else:\n","            df_std = pd.concat([df_std, averages], ignore_index=True)\n","    return df_std\n","\n"]},{"cell_type":"markdown","metadata":{"id":"amX41e9cjymn"},"source":["# 3. Benchmark-Models:"]},{"cell_type":"markdown","metadata":{"id":"c7NJtImPjymn"},"source":["Note for a lot of the following models we use the same model architecture as described in the Book by Wüthrich & Merz (2023)"]},{"cell_type":"markdown","metadata":{"id":"QZBEDZnRjymo"},"source":["## 3.1 Mean-Model:"]},{"cell_type":"markdown","metadata":{"id":"Ya_s-PBxjymo"},"source":["Note we run the code 15 times to get the results for an average of the runtimes."]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":1439,"status":"ok","timestamp":1699569023526,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"mxQUjLAljymo"},"outputs":[],"source":["for run_index in range(15):\n","    start_time = time.time()\n","    constant_model=df_freq[bool_in_learn]['ClaimNb'].sum()/df_freq[bool_in_learn]['Exposure'].sum()\n","    end_time = time.time()\n","    execution_time_mean_model = end_time - start_time\n","\n","    y_pred[\"train\"][\"homogeneous model\"] = constant_model*exposure[\"train\"]\n","    y_pred[\"test\"][\"homogeneous model\"] = constant_model*exposure[\"test\"]\n","\n","    mean_model_results = Results(model=f\"homogeneous model (run: {run_index})\",\n","                                    epochs=0,\n","                                    run_time=execution_time_mean_model,\n","                                    nr_parameters=1,\n","                                    poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][\"homogeneous model\"]),\n","                                    poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][\"homogeneous model\"]),\n","                                    pred_avg_freq_train=constant_model,\n","                                    pred_avg_freq_test=constant_model)\n","    # store the results in the dataframe:\n","    store_results_in_df(mean_model_results)\n","\n","# display(df_results)"]},{"cell_type":"markdown","metadata":{"id":"rzj1JR3Vjymo"},"source":["## 3.2 GLM results:"]},{"cell_type":"markdown","metadata":{"id":"Dmsq5nsajymo"},"source":["Due to the fact:\n","> \"GLM, which is currently the industry standard for non-life claim frequency prediction\"\n","\n","We replicate here the results for the GLM (GLM3) that are shown in the LocalGLMnet Paper and the Book by Wüthrich & Merz (2023):  "]},{"cell_type":"markdown","metadata":{"id":"U_JdKWqojymo"},"source":["Note we run the code 15 times to get the results for an average of the runtimes."]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":111586,"status":"ok","timestamp":1699569137681,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"Fnl1Gwp2jymo"},"outputs":[],"source":["# Recreating results GLM1:\n","# -------------------------\n","for run_index in range(15):\n","    start_time = time.time()\n","    poisson_glm1 = PoissonRegressor(alpha = 0,max_iter=1000, solver='newton-cholesky') # scikit-learn.org: alpha = 0 is equivalent to unpenalized GLMs\n","    poisson_glm1.fit(X_glm1_learn,y_true[\"train\"]/exposure[\"train\"],sample_weight=exposure[\"train\"])\n","    end_time = time.time()\n","    execution_time_glm1 = end_time - start_time\n","    # Make predictions using the fitted model\n","    y_pred[\"train\"][\"GLM1\"] = poisson_glm1.predict(X_glm1_learn)*exposure[\"train\"]\n","    y_pred[\"test\"][\"GLM1\"] = poisson_glm1.predict(X_glm1_test)*exposure[\"test\"]\n","    # store the results in the results class:\n","    glm1_results = Results(model=f\"GLM1 (run: {run_index})\",\n","                            epochs=0,\n","                            run_time=execution_time_glm1,\n","                            nr_parameters=len(poisson_glm1.coef_)+len([poisson_glm1.intercept_]),\n","                            poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][\"GLM1\"]),\n","                            poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][\"GLM1\"]),\n","                            pred_avg_freq_train=y_pred[\"train\"][\"GLM1\"].sum()/exposure[\"train\"].sum(),\n","                            pred_avg_freq_test=y_pred[\"test\"][\"GLM1\"].sum()/exposure[\"test\"].sum())\n","    # store the results in the dataframe:\n","    store_results_in_df(glm1_results)\n","\n","\n","# Recreating results GLM2:\n","# -------------------------\n","for run_index in range(15):\n","    start_time = time.time()\n","    poisson_glm2 = PoissonRegressor(alpha = 0,max_iter=1000, solver='newton-cholesky') # scikit-learn.org: alpha = 0 is equivalent to unpenalized GLMs\n","    poisson_glm2.fit(X_glm2_learn,y_true[\"train\"]/exposure[\"train\"],sample_weight=exposure[\"train\"])\n","    end_time = time.time()\n","    execution_time_glm2 = end_time - start_time\n","    # Make predictions using the fitted model\n","    y_pred[\"train\"][\"GLM2\"] = poisson_glm2.predict(X_glm2_learn)*exposure[\"train\"]\n","    y_pred[\"test\"][\"GLM2\"] = poisson_glm2.predict(X_glm2_test)*exposure[\"test\"]\n","    # store the results in the results class:\n","    glm2_results = Results(model=f\"GLM2 (run: {run_index})\",\n","                            epochs=0,\n","                            run_time=execution_time_glm2,\n","                            nr_parameters=len(poisson_glm2.coef_)+len([poisson_glm2.intercept_]),\n","                            poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][\"GLM2\"]),\n","                            poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][\"GLM2\"]),\n","                            pred_avg_freq_train=y_pred[\"train\"][\"GLM2\"].sum()/exposure[\"train\"].sum(),\n","                            pred_avg_freq_test=y_pred[\"test\"][\"GLM2\"].sum()/exposure[\"test\"].sum())\n","    # store the results in the dataframe:\n","    store_results_in_df(glm2_results)\n","\n","\n","# Recreating results GLM3:\n","# -------------------------\n","for run_index in range(15):\n","    start_time = time.time()\n","    poisson_glm3 = PoissonRegressor(alpha = 0,max_iter=1000, solver='newton-cholesky') # scikit-learn.org: alpha = 0 is equivalent to unpenalized GLMs\n","    poisson_glm3.fit(X_glm3_learn,y_true[\"train\"]/exposure[\"train\"],sample_weight=exposure[\"train\"])\n","    end_time = time.time()\n","    execution_time_glm3 = end_time - start_time\n","\n","    # Make predictions using the fitted model\n","    y_pred[\"train\"][\"GLM3\"] = poisson_glm3.predict(X_glm3_learn)*exposure[\"train\"]\n","    y_pred[\"test\"][\"GLM3\"] = poisson_glm3.predict(X_glm3_test)*exposure[\"test\"]\n","\n","    # store the results in the results class:\n","    glm3_results = Results(model=f\"GLM3 (run: {run_index})\",\n","                            epochs=0,\n","                            run_time=execution_time_glm3,\n","                            nr_parameters=len(poisson_glm3.coef_)+len([poisson_glm3.intercept_]),\n","                            poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][\"GLM3\"]),\n","                            poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][\"GLM3\"]),\n","                            pred_avg_freq_train=y_pred[\"train\"][\"GLM3\"].sum()/exposure[\"train\"].sum(),\n","                            pred_avg_freq_test=y_pred[\"test\"][\"GLM3\"].sum()/exposure[\"test\"].sum())\n","    # store the results in the dataframe:\n","    store_results_in_df(glm3_results)\n","# display(df_results)"]},{"cell_type":"markdown","metadata":{"id":"0adpvxc8jymo"},"source":["## 3.3 Feedforward Neural Network OHE:"]},{"cell_type":"markdown","metadata":{"id":"fQdvi-8ujymp"},"source":["Note: we run the code 15 times on different seeds (to calc the avg and std of runtime and results)."]},{"cell_type":"markdown","metadata":{"id":"5E-8_pU6jymp"},"source":["Create and Build the model:"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":708404,"status":"ok","timestamp":1699569846048,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"bkmyxbENjymp","outputId":"90c6a3fe-7f8f-4282-c25a-b95127b14221"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: 0\n","7/7 [==============================] - 0s 10ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Model: 1\n","7/7 [==============================] - 0s 7ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Model: 2\n","7/7 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Model: 3\n","7/7 [==============================] - 0s 10ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 4\n","7/7 [==============================] - 0s 7ms/step\n","1/1 [==============================] - 0s 31ms/step\n","Model: 5\n","7/7 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Model: 6\n","7/7 [==============================] - 0s 7ms/step\n","1/1 [==============================] - 0s 34ms/step\n","Model: 7\n","7/7 [==============================] - 0s 10ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 8\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Model: 9\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Model: 10\n","7/7 [==============================] - 0s 12ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Model: 11\n","7/7 [==============================] - 0s 7ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Model: 12\n","7/7 [==============================] - 0s 7ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 13\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 26ms/step\n","Model: 14\n","7/7 [==============================] - 0s 7ms/step\n","1/1 [==============================] - 0s 28ms/step\n"]}],"source":["# Create the dataframes needed for evaluation:\n","data_nn_ohe_learn, y_true_learn = create_ffn_ohe_data(bool_in_learn)\n","data_nn_ohe_test, y_true_test = create_ffn_ohe_data(bool_in_test)\n","\n","for run_index in range(15):\n","    # Create the dataframes needed for training:\n","    data_nn_ohe_learn_train, y_true_learn_train = create_ffn_ohe_data(train_val_split[f\"learn_train_{run_index}\"])\n","    data_nn_ohe_learn_val, y_true_learn_val = create_ffn_ohe_data(train_val_split[f\"learn_val_{run_index}\"])\n","\n","    print(f\"Model: {run_index}\")\n","    # Define FNN Model:\n","    # ----------------------\n","    # note we use here the function api instead of the model subclassing\n","    # to make the code more readable and easier to understand:\n","    # (for the transformer based models we will use model subclasses)\n","    def Create_Poisson_FFN_OHE(input_dim=42,mean_model_results=1):\n","        # set random seeds\n","        set_random_seeds(int(random_seeds[run_index]))\n","        # Build the network\n","        Input_Matrix_OHE = tf.keras.layers.Input(shape=(input_dim,), dtype='float32', name='Input_Matrix')\n","        Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","        hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(Input_Matrix_OHE)\n","        hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","        hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","        Result_FFN1 = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_FFN1',\n","                        weights=[np.zeros((10, 1)), np.array([np.log(mean_model_results)])],\n","                        trainable=True)(hidden3)\n","        Response = tf.keras.layers.Multiply(name='Result')([Result_FFN1, Input_Exposure])\n","        # Define and Return the model\n","        return tf.keras.models.Model(inputs=[Input_Matrix_OHE, Input_Exposure], outputs=[Response], name='Poisson_FFN_OHE')\n","\n","    # create the model:\n","    # ----------------------\n","    FFN_OHE = Create_Poisson_FFN_OHE(input_dim=40,mean_model_results=constant_model)\n","\n","    # Compile the models\n","    # ----------------------\n","    FFN_OHE.compile(optimizer='nadam', loss=poisson_loss_for_tf, metrics=[poisson_loss_for_tf])\n","\n","    # model callbacks:\n","    # ----------------------\n","    early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=15, monitor='val_poisson_loss_for_tf', restore_best_weights=True)\n","\n","\n","    # model fitting:\n","    # ----------------------\n","    # model without RandU and RandN:\n","    start_time = time.time()\n","    epochs_OHE=500\n","\n","    FFN_OHE_history = FFN_OHE.fit( x=data_nn_ohe_learn_train,\n","                                   y=y_true_learn_train,\n","                                  validation_data=[data_nn_ohe_learn_val, y_true_learn_val],\n","                                    epochs=epochs_OHE,\n","                                    batch_size=5000,\n","                                    verbose=0,\n","                                    callbacks=[early_stopping_callback]\n","                                    )\n","    end_time = time.time()\n","    execution_time_nn_ohe = end_time - start_time\n","    best_epoch_FFN_ohe = np.argmin(FFN_OHE_history.history['val_poisson_loss_for_tf'])+1\n","\n","    # save models:\n","    # ----------------------\n","    FFN_OHE.save_weights(f'{storage_path}/saved_models/Poisson_FFN_OHE_{run_index}.weights.h5')\n","\n","\n","    # load the saved model weights:\n","    # ----------------------\n","    FFN_OHE.load_weights(f'{storage_path}/saved_models/Poisson_FFN_OHE_{run_index}.weights.h5')\n","\n","\n","    # predict with the models:\n","    # ----------------------\n","    y_pred[\"train\"][\"FFN_OHE\"] = np.array([x for [x] in FFN_OHE.predict(data_nn_ohe_learn,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","    y_pred[\"test\"][\"FFN_OHE\"] = np.array([x for [x] in FFN_OHE.predict(data_nn_ohe_test,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","\n","    # evaluate the models:\n","    # ----------------------\n","    # store the results in the results class:\n","    FFN_OHE_results = Results(model=f\"FFN_OHE (run: {run_index})\",\n","                                epochs=best_epoch_FFN_ohe,\n","                                run_time=execution_time_nn_ohe,\n","                                nr_parameters=[np.sum([np.prod(v.get_shape().as_list()) for v in FFN_OHE.trainable_weights])],\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][\"FFN_OHE\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][\"FFN_OHE\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][\"FFN_OHE\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][\"FFN_OHE\"].sum()/exposure[\"test\"].sum())\n","\n","    # store the results in the result-dataframe:\n","    store_results_in_df(FFN_OHE_results)\n","# display(df_results)\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_ohe_learn, data_nn_ohe_test, data_nn_ohe_learn_train, data_nn_ohe_learn_val\n"]},{"cell_type":"markdown","metadata":{"id":"10ICfGxV_oOq"},"source":["NOTE: in the case of FNN_OHE:\n","if i use the tf-dataframes instead of the array inputs: the fit is 4-5 times slower and i get way worse results...\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ur8BMzqajymp"},"source":["## 3.4 Feedforward Neural Network with Categorical Embeddings:\n"]},{"cell_type":"markdown","metadata":{"id":"65TVT5jEjymp"},"source":["Note: we run the code 15 times on different seeds (to calc the avg and std of runtime and results)."]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1087843,"status":"ok","timestamp":1699570933878,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"gabNPqKxjymp","outputId":"79c5000f-eb3b-4e39-ec22-4fcd7f2da9ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: 0\n","7/7 [==============================] - 0s 6ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Model: 1\n","7/7 [==============================] - 0s 10ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Model: 2\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Model: 3\n","7/7 [==============================] - 0s 4ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 4\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Model: 5\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 6\n","7/7 [==============================] - 0s 13ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 7\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 8\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Model: 9\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Model: 10\n","7/7 [==============================] - 0s 6ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Model: 11\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Model: 12\n","7/7 [==============================] - 0s 7ms/step\n","1/1 [==============================] - 0s 38ms/step\n","Model: 13\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Model: 14\n","7/7 [==============================] - 0s 4ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]}],"source":["# Create the dataframes needed for evaluation:\n","data_nn_emb_learn, y_true_learn = create_ffn_cat_emb_data(bool_in_learn)\n","data_nn_emb_test, y_true_test = create_ffn_cat_emb_data(bool_in_test)\n","\n","for run_index in range(15):\n","    # Create the dataframes needed for training:\n","    data_nn_emb_learn_train, y_true_learn_train = create_ffn_cat_emb_data(train_val_split[f\"learn_train_{run_index}\"])\n","    data_nn_emb_learn_val, y_true_learn_val = create_ffn_cat_emb_data(train_val_split[f\"learn_val_{run_index}\"])\n","\n","    # Define FNN with Cat. Embedding Model:\n","    # ----------------------\n","    # note we use here the function api instead of the model subclassing\n","    # to make the code more readable and easier to understand:\n","    # (for the transformer based models we will use model subclasses)\n","    print(f\"Model: {run_index}\")\n","    def Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=1,mean_model_results=1):\n","        # set random seeds\n","        set_random_seeds(int(random_seeds[run_index]))\n","\n","        Input_Matrix_Num = tf.keras.layers.Input(shape=(input_nr_dim,), dtype='float32', name='Input_Matrix_Num')\n","        Input_VehBrand = tf.keras.layers.Input(shape=(1,), name='Input_VehBrand')\n","        Input_Region = tf.keras.layers.Input(shape=(1,), name='Input_Region')\n","        Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","\n","        All_Inputs = [Input_Matrix_Num,Input_VehBrand,Input_Region,Input_Exposure]\n","\n","        Emb_VehBrand = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"VehBrand\"].keys()),output_dim=emb_dim,\n","                                embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05 ),\n","                                name=\"Embedding_VehBrand\")(Input_VehBrand)\n","        Emb_Region = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"Region\"].keys()),output_dim=emb_dim,\n","                                embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05),\n","                            name=\"Embedding_Region\")(Input_Region)\n","\n","        Reshaped_Emb_VehBrand = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_VehBrand\")(Emb_VehBrand)\n","        Reshaped_Emb_Region = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_Region\")(Emb_Region)\n","\n","        concatenation_layer = tf.keras.layers.Concatenate(name=\"concatenation_layer\")([Input_Matrix_Num,Reshaped_Emb_VehBrand,Reshaped_Emb_Region])\n","\n","        # Build the network\n","        hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(concatenation_layer)\n","        hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","        hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","        Result_FFN1 = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_FFN1',\n","                        weights=[np.zeros((10, 1)), np.array([np.log(mean_model_results)])],\n","                        trainable=True)(hidden3)\n","\n","        Response = tf.keras.layers.Multiply(name='Result')([Result_FFN1, Input_Exposure])\n","\n","        # Define the model\n","        return tf.keras.models.Model(inputs=All_Inputs, outputs=[Response], name='Poisson_CAT_EMB')\n","\n","    # create the model:\n","    # ----------------------\n","    emb_dim=2\n","    FNN_CAT_EMB = Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=emb_dim,mean_model_results=constant_model)\n","\n","    # Compile the model\n","    # ----------------------\n","    FNN_CAT_EMB.compile(optimizer='nadam', loss=poisson_loss_for_tf, metrics=[poisson_loss_for_tf])\n","\n","    # model callbacks:\n","    # ----------------------\n","    early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=15, monitor='val_poisson_loss_for_tf', restore_best_weights=True)\n","\n","    # model fitting:\n","    # ----------------------\n","    start_time = time.time()\n","    epochs_CAT_EMB=500\n","    FNN_CAT_EMB_history = FNN_CAT_EMB.fit(x=data_nn_emb_learn_train,\n","                                    y=y_true_learn_train,\n","                                    validation_data=[data_nn_emb_learn_val, y_true_learn_val],\n","                                    epochs=epochs_CAT_EMB,\n","                                    batch_size=7000,\n","                                    verbose=0,\n","                                    callbacks=[early_stopping_callback]\n","                                    )\n","\n","    end_time = time.time()\n","    execution_time_FNN_CAT_EMB = end_time - start_time\n","    best_epoch_FNN_CAT_EMB = np.argmin(FNN_CAT_EMB_history.history['val_poisson_loss_for_tf'])+1\n","\n","    # save models:\n","    # ----------------------\n","    FNN_CAT_EMB.save_weights(f'{storage_path}/saved_models/Poisson_FNN_CAT_EMB_{run_index}.weights.h5')\n","\n","    # load the saved model weights:\n","    # ----------------------\n","    FNN_CAT_EMB.load_weights(f'{storage_path}/saved_models/Poisson_FNN_CAT_EMB_{run_index}.weights.h5')\n","\n","    # predict with the model:\n","    # ----------------------\n","    y_pred[\"train\"][\"FNN_CAT_EMB\"] = np.array([x for [x] in FNN_CAT_EMB.predict(data_nn_emb_learn,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","    y_pred[\"test\"][\"FNN_CAT_EMB\"] = np.array([x for [x] in FNN_CAT_EMB.predict(data_nn_emb_test,\n","                                                                    batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","    # evaluate the model:\n","    # ----------------------\n","    FNN_CAT_EMB_results = Results(model=f\"FNN_CAT_EMB (run: {run_index})\",\n","                                epochs=best_epoch_FNN_CAT_EMB,\n","                                run_time=execution_time_FNN_CAT_EMB,\n","                                nr_parameters=[np.sum([np.prod(v.get_shape().as_list()) for v in FNN_CAT_EMB.trainable_weights])],\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][\"FNN_CAT_EMB\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][\"FNN_CAT_EMB\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][\"FNN_CAT_EMB\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][\"FNN_CAT_EMB\"].sum()/exposure[\"test\"].sum())\n","    store_results_in_df(FNN_CAT_EMB_results)\n","# display(df_results)\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_emb_learn, data_nn_emb_test, data_nn_emb_learn_train, data_nn_emb_learn_val"]},{"cell_type":"markdown","metadata":{"id":"qsvACKJID4ti"},"source":["## 3.5 CANN (GLM3 and FNN_CAT_EMB):"]},{"cell_type":"markdown","metadata":{"id":"EtnDoeUJIXHG"},"source":["Note: we run the code 15 times on different seeds (to calc the avg and std of runtime and results)."]},{"cell_type":"markdown","metadata":{"id":"AR_ytor4QRBD"},"source":["Note: the Code for the CANN below is basically the same code as for the FNN with categorical embeddings. The only changes are\n","* we use a other exposure column (Exposure_x_GLM3_pred instead of Exposure)\n","* we set the initial weights and bias of the last layer to zero"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699570934454,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"uQldY6Y0Tt2h"},"outputs":[],"source":["# create the new exposure times GLM3_pred column for CANN models.\n","df_freq_prep_nn[\"Exposure_x_GLM3_pred\"] = list(poisson_glm3.predict(X_glm3)*df_freq_prep_nn[\"Exposure\"])"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1169899,"status":"ok","timestamp":1699572104349,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"RKIfZOQuD4eO","outputId":"8a6d8cf9-a131-4e0c-d5bf-f679aea78dab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: 0\n","7/7 [==============================] - 0s 7ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Model: 1\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Model: 2\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 3\n","7/7 [==============================] - 0s 4ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Model: 4\n","7/7 [==============================] - 0s 4ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 5\n","7/7 [==============================] - 0s 4ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Model: 6\n","7/7 [==============================] - 0s 4ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Model: 7\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 8\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Model: 9\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 23ms/step\n","Model: 10\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 11\n","7/7 [==============================] - 0s 5ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Model: 12\n","7/7 [==============================] - 0s 9ms/step\n","1/1 [==============================] - 0s 40ms/step\n","Model: 13\n","7/7 [==============================] - 0s 4ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 14\n","7/7 [==============================] - 0s 4ms/step\n","1/1 [==============================] - 0s 28ms/step\n"]}],"source":["# Create the dataframes needed for evaluation:\n","data_nn_emb_learn, y_true_learn = create_ffn_cat_emb_data(bool_in_learn, exposure_name = \"Exposure_x_GLM3_pred\")\n","data_nn_emb_test, y_true_test = create_ffn_cat_emb_data(bool_in_test, exposure_name = \"Exposure_x_GLM3_pred\")\n","\n","for run_index in range(15):\n","    # Create the dataframes needed for training:\n","    data_nn_emb_learn_train, y_true_learn_train = create_ffn_cat_emb_data(train_val_split[f\"learn_train_{run_index}\"],\n","                                                                          exposure_name = \"Exposure_x_GLM3_pred\")\n","    data_nn_emb_learn_val, y_true_learn_val = create_ffn_cat_emb_data(train_val_split[f\"learn_val_{run_index}\"],\n","                                                                      exposure_name = \"Exposure_x_GLM3_pred\")\n","\n","    # Define FNN with Cat. Embedding Model:\n","    # ----------------------\n","    # note we use here the function api instead of the model subclassing\n","    # to make the code more readable and easier to understand:\n","    # (for the transformer based models we will use model subclasses)\n","    print(f\"Model: {run_index}\")\n","    def Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=1,mean_model_results=1):\n","        # set random seeds\n","        set_random_seeds(int(random_seeds[run_index]))\n","\n","        Input_Matrix_Num = tf.keras.layers.Input(shape=(input_nr_dim,), dtype='float32', name='Input_Matrix_Num')\n","        Input_VehBrand = tf.keras.layers.Input(shape=(1,), name='Input_VehBrand')\n","        Input_Region = tf.keras.layers.Input(shape=(1,), name='Input_Region')\n","        Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","\n","        All_Inputs = [Input_Matrix_Num,Input_VehBrand,Input_Region,Input_Exposure]\n","\n","        Emb_VehBrand = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"VehBrand\"].keys()),output_dim=emb_dim,\n","                                embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05 ),\n","                                name=\"Embedding_VehBrand\")(Input_VehBrand)\n","        Emb_Region = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"Region\"].keys()),output_dim=emb_dim,\n","                                embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05),\n","                            name=\"Embedding_Region\")(Input_Region)\n","\n","        Reshaped_Emb_VehBrand = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_VehBrand\")(Emb_VehBrand)\n","        Reshaped_Emb_Region = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_Region\")(Emb_Region)\n","\n","        concatenation_layer = tf.keras.layers.Concatenate(name=\"concatenation_layer\")([Input_Matrix_Num,Reshaped_Emb_VehBrand,Reshaped_Emb_Region])\n","\n","        # Build the network\n","        hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(concatenation_layer)\n","        hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","        hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","        Result_FFN1 = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_FFN1',\n","                        weights=[np.zeros((10, 1)), np.array([0])],\n","                        trainable=True)(hidden3)\n","\n","        Response = tf.keras.layers.Multiply(name='Result')([Result_FFN1, Input_Exposure])\n","\n","        # Define the model\n","        return tf.keras.models.Model(inputs=All_Inputs, outputs=[Response], name='Poisson_CAT_EMB')\n","\n","    # create the model:\n","    # ----------------------\n","    emb_dim=2\n","    CANN = Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=emb_dim,mean_model_results=constant_model)\n","\n","    # Compile the model\n","    # ----------------------\n","    CANN.compile(optimizer='nadam', loss=poisson_loss_for_tf, metrics=[poisson_loss_for_tf])\n","\n","    # model callbacks:\n","    # ----------------------\n","    early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=15, monitor='val_poisson_loss_for_tf', restore_best_weights=True)\n","\n","    # model fitting:\n","    # ----------------------\n","    start_time = time.time()\n","    epochs_CAT_EMB=500\n","\n","    CANN_history = CANN.fit(x=data_nn_emb_learn_train,\n","                                    y=y_true_learn_train,\n","                                    validation_data=[data_nn_emb_learn_val, y_true_learn_val],\n","                                    epochs=epochs_CAT_EMB,\n","                                    batch_size=7000,\n","                                    verbose=0,\n","                                    callbacks=[early_stopping_callback]\n","                                    )\n","\n","    end_time = time.time()\n","\n","    execution_time_CANN = end_time - start_time\n","    best_epoch_CANN = np.argmin(CANN_history.history['val_poisson_loss_for_tf'])+1\n","\n","    # save models:\n","    # ----------------------\n","    CANN.save_weights(f'{storage_path}/saved_models/Poisson_CANN_{run_index}.weights.h5')\n","\n","    # load the saved model weights:\n","    # ----------------------\n","    CANN.load_weights(f'{storage_path}/saved_models/Poisson_CANN_{run_index}.weights.h5')\n","\n","\n","    # predict with the model:\n","    # ----------------------\n","    y_pred[\"train\"][\"CANN\"] = np.array([x for [x] in CANN.predict(data_nn_emb_learn,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","    y_pred[\"test\"][\"CANN\"] = np.array([x for [x] in CANN.predict(data_nn_emb_test,\n","                                                                    batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","    # evaluate the model:\n","    # ----------------------\n","    CANN_results = Results(model=f\"CANN (run: {run_index})\",\n","                                epochs=best_epoch_CANN,\n","                                run_time=execution_time_CANN,\n","                                nr_parameters=[np.sum([np.prod(v.get_shape().as_list()) for v in CANN.trainable_weights])],\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][\"CANN\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][\"CANN\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][\"CANN\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][\"CANN\"].sum()/exposure[\"test\"].sum())\n","    store_results_in_df(CANN_results)\n","# display(df_results)\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_emb_learn, data_nn_emb_test, data_nn_emb_learn_train, data_nn_emb_learn_val\n"]},{"cell_type":"markdown","metadata":{"id":"Ms5YwgH7jymq"},"source":["## 3.6 LocalGLMnets OHE\n","(excl. Random Features):"]},{"cell_type":"markdown","metadata":{"id":"la5nsKcjjymq"},"source":["Note: we run the code 15 times on different seeds (to calc the avg and std of runtime and results)."]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":581554,"status":"ok","timestamp":1699572685888,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"fn7AAk8Wjymq","outputId":"077af650-0116-414e-ca27-a1f6dca5433a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: 0\n","7/7 [==============================] - 0s 13ms/step\n","1/1 [==============================] - 0s 35ms/step\n","Model: 1\n","7/7 [==============================] - 0s 10ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Model: 2\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Model: 3\n","7/7 [==============================] - 0s 11ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 4\n","7/7 [==============================] - 0s 10ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Model: 5\n","7/7 [==============================] - 0s 9ms/step\n","1/1 [==============================] - 0s 27ms/step\n","Model: 6\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Model: 7\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 30ms/step\n","Model: 8\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 9\n","7/7 [==============================] - 0s 11ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 10\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 11\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 12\n","7/7 [==============================] - 0s 8ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Model: 13\n","7/7 [==============================] - 0s 12ms/step\n","1/1 [==============================] - 0s 36ms/step\n","Model: 14\n","7/7 [==============================] - 0s 7ms/step\n","1/1 [==============================] - 0s 26ms/step\n"]}],"source":["# Create the dataframes needed for evaluation:\n","data_nn_ohe_learn, y_true_learn = create_ffn_ohe_data(bool_in_learn)\n","data_nn_ohe_test, y_true_test = create_ffn_ohe_data(bool_in_test)\n","\n","for run_index in range(15):\n","    # Create the dataframes needed for training:\n","    data_nn_ohe_learn_train, y_true_learn_train = create_ffn_ohe_data(train_val_split[f\"learn_train_{run_index}\"])\n","    data_nn_ohe_learn_val, y_true_learn_val = create_ffn_ohe_data(train_val_split[f\"learn_val_{run_index}\"])\n","\n","    print(f\"Model: {run_index}\")\n","    # Define FNN with Cat. Embedding Model:\n","    # ----------------------\n","    # note we use here the function api instead of the model subclassing\n","    # to make the code more readable and easier to understand:\n","    # (for the transformer based models we will use model subclasses)\n","\n","    # create dummy glm for initial weights\n","    # ----------------------\n","    poisson_glm_dummy = PoissonRegressor(alpha = 0,max_iter=1000) # scikit-learn.org: alpha = 0 is equivalent to unpenalized GLMs\n","    poisson_glm_dummy.fit(data_nn_ohe_learn[0],y_true_learn/data_nn_ohe_learn[1],sample_weight=data_nn_ohe_learn[1]) # note: data_nn_ohe_learn = [X_ohe,exposure]\n","\n","    # Define LocalGLMnet:\n","    # ----------------------\n","    def Create_Poisson_LocalGLMnet(input_dim=40,initial_glm_bias=1, initial_glm_betas=None):\n","        # set random seeds\n","        set_random_seeds(int(random_seeds[run_index]))\n","        Input_Matrix_OHE = tf.keras.layers.Input(shape=(input_dim,), dtype='float32', name='Input_Matrix')\n","        Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","        # Build the network\n","        hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(Input_Matrix_OHE)\n","        hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","        hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","        Attention = tf.keras.layers.Dense(units=input_dim, activation='linear', name='attention',\n","                        weights=[np.zeros((10, input_dim)), initial_glm_betas])(hidden3)\n","        # note that the weights are set to 0 and the bias is set to the initial glm betas\n","        # create a layer that calculates the dot product between the attention weights (Attention) and the input matrix Input_Matrix_OHE:\n","        # (Attention has the same dimension as the input matrix Input_Matrix_OHE):\n","        weighted_input = tf.keras.layers.Multiply(name='feature_contributions')([Attention, Input_Matrix_OHE])\n","        scalar_product = tf.keras.layers.Dense(units=1, activation='linear', name='scalar_product',\n","                            weights=[np.ones((input_dim, 1)), np.array([0])],\n","                            trainable=False)(weighted_input)\n","        # Note that we actually don't want to make the following weights trainable,\n","        # but to get the bias to be trainable we need to do so. see comment in Book Wüthrich & Merz (2023) page 500\n","        Result_LocalGLMnet_without_Exposure = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_LocalGLMnet_without_Exposure',\n","                        weights=[np.ones((1, 1)), np.array([initial_glm_bias])],\n","                        trainable=True)(scalar_product)\n","        Response = tf.keras.layers.Multiply(name='Result')([Result_LocalGLMnet_without_Exposure, Input_Exposure])\n","        return tf.keras.models.Model(inputs=[Input_Matrix_OHE, Input_Exposure], outputs=[Response], name='Poisson_LocalGLMnet')\n","\n","    # create the model:\n","    # ----------------------\n","    LocalGLMnet = Create_Poisson_LocalGLMnet(input_dim=40,initial_glm_bias=poisson_glm_dummy.intercept_,initial_glm_betas=poisson_glm_dummy.coef_)\n","\n","    # Compile the model\n","    # ----------------------\n","    LocalGLMnet.compile(optimizer='nadam', loss=poisson_loss_for_tf, metrics=[poisson_loss_for_tf])\n","\n","    # model callbacks:\n","    # ----------------------\n","    early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=15, monitor='val_poisson_loss_for_tf', restore_best_weights=True)\n","\n","    # model fitting:\n","    # ----------------------\n","    start_time = time.time()\n","    epochs_OHE=500\n","    LocalGLMnet_history = LocalGLMnet.fit(x=data_nn_ohe_learn_train,\n","                                          y=y_true_learn_train,\n","                                          validation_data=[data_nn_ohe_learn_val, y_true_learn_val],\n","                                          epochs=epochs_OHE,\n","                                          batch_size=5000,\n","                                          verbose=0,\n","                                          callbacks=[early_stopping_callback]\n","                                          )\n","    end_time = time.time()\n","    execution_time_LocalGLMnet = end_time - start_time\n","    best_epoch_LocalGLMnet = np.argmin(LocalGLMnet_history.history['val_poisson_loss_for_tf'])+1\n","\n","    # save models:\n","    # ----------------------\n","    LocalGLMnet.save_weights(f'{storage_path}/saved_models/Poisson_LocalGLMnet_{run_index}.weights.h5')\n","\n","    # load the saved model weights:\n","    # ----------------------\n","    LocalGLMnet.load_weights(f'{storage_path}/saved_models/Poisson_LocalGLMnet_{run_index}.weights.h5')\n","\n","    # predict with the model:\n","    # ----------------------\n","    y_pred[\"train\"][\"LocalGLMnet\"] = np.array([x for [x] in LocalGLMnet.predict(data_nn_ohe_learn,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","    y_pred[\"test\"][\"LocalGLMnet\"] = np.array([x for [x] in LocalGLMnet.predict(data_nn_ohe_test,\n","                                                                    batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","    # evaluate the model:\n","    # ----------------------\n","    LocalGLMnet_results = Results(model=f\"LocalGLMnet (run: {run_index})\",\n","                                epochs=best_epoch_LocalGLMnet,\n","                                run_time=execution_time_LocalGLMnet,\n","                                nr_parameters=[np.sum([np.prod(v.get_shape().as_list()) for v in LocalGLMnet.trainable_weights])],\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][\"LocalGLMnet\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][\"LocalGLMnet\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][\"LocalGLMnet\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][\"LocalGLMnet\"].sum()/exposure[\"test\"].sum())\n","    # store the results in the dataframe:\n","    store_results_in_df(LocalGLMnet_results)\n","# display(df_results)\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_ohe_learn, data_nn_ohe_test, data_nn_ohe_learn_train, data_nn_ohe_learn_val"]},{"cell_type":"markdown","metadata":{"id":"g9-LDq0Ejymq"},"source":["## 3.7 Compare Benchmark Results:\n","to those in the LocalGLM Paper and Wüthrich & Merz Book (2023):"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699573189710,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"DzbmYL4gjSaB"},"outputs":[],"source":["# # save the results:\n","# with open(f'{storage_path}/Data/df_results.pickle', 'wb') as handle:\n","#     pickle.dump(df_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# load the results:\n","with open(f'{storage_path}/Data/df_results.pickle', 'rb') as handle:\n","    df_results = pickle.load(handle)"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":475,"status":"ok","timestamp":1699572910356,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"yDaNGET_jymq"},"outputs":[],"source":["# display(df_results)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":620},"executionInfo":{"elapsed":419,"status":"ok","timestamp":1699573192872,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"C1mnI-L3DIRz","outputId":"e940b4a4-7dbf-4ec3-e665-b0d2a92c7c3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results Average:\n"]},{"data":{"text/html":["\n","  <div id=\"df-60c368f6-68ec-4a3f-b51a-13cf9676cc9d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model</td>\n","      <td>0.000000</td>\n","      <td>0.054847</td>\n","      <td>1.0</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GLM1</td>\n","      <td>0.000000</td>\n","      <td>2.220158</td>\n","      <td>49.0</td>\n","      <td>0.241015</td>\n","      <td>0.241463</td>\n","      <td>0.073631</td>\n","      <td>0.073900</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GLM2</td>\n","      <td>0.000000</td>\n","      <td>2.752693</td>\n","      <td>48.0</td>\n","      <td>0.240911</td>\n","      <td>0.241125</td>\n","      <td>0.073631</td>\n","      <td>0.073981</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GLM3</td>\n","      <td>0.000000</td>\n","      <td>1.900497</td>\n","      <td>50.0</td>\n","      <td>0.240844</td>\n","      <td>0.241022</td>\n","      <td>0.073631</td>\n","      <td>0.074048</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FFN_OHE</td>\n","      <td>42.200000</td>\n","      <td>37.805560</td>\n","      <td>1306.0</td>\n","      <td>0.237535</td>\n","      <td>0.238652</td>\n","      <td>0.073906</td>\n","      <td>0.074310</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>FNN_CAT_EMB</td>\n","      <td>72.933333</td>\n","      <td>58.728892</td>\n","      <td>792.0</td>\n","      <td>0.237682</td>\n","      <td>0.238267</td>\n","      <td>0.073774</td>\n","      <td>0.074238</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CANN</td>\n","      <td>90.333333</td>\n","      <td>68.559120</td>\n","      <td>792.0</td>\n","      <td>0.237420</td>\n","      <td>0.238102</td>\n","      <td>0.074019</td>\n","      <td>0.074438</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LocalGLMnet</td>\n","      <td>25.333333</td>\n","      <td>29.720892</td>\n","      <td>1737.0</td>\n","      <td>0.237095</td>\n","      <td>0.239211</td>\n","      <td>0.073825</td>\n","      <td>0.074267</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60c368f6-68ec-4a3f-b51a-13cf9676cc9d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-60c368f6-68ec-4a3f-b51a-13cf9676cc9d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-60c368f6-68ec-4a3f-b51a-13cf9676cc9d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b4d71c6a-08b5-4ee4-85b9-55002f9e647e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4d71c6a-08b5-4ee4-85b9-55002f9e647e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b4d71c6a-08b5-4ee4-85b9-55002f9e647e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["               model     epochs   run_time  nr_parameters  loss_train  \\\n","0  homogeneous model   0.000000   0.054847            1.0    0.252132   \n","1               GLM1   0.000000   2.220158           49.0    0.241015   \n","2               GLM2   0.000000   2.752693           48.0    0.240911   \n","3               GLM3   0.000000   1.900497           50.0    0.240844   \n","4            FFN_OHE  42.200000  37.805560         1306.0    0.237535   \n","5        FNN_CAT_EMB  72.933333  58.728892          792.0    0.237682   \n","6               CANN  90.333333  68.559120          792.0    0.237420   \n","7        LocalGLMnet  25.333333  29.720892         1737.0    0.237095   \n","\n","   loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0   0.254454             0.073631            0.073631  \n","1   0.241463             0.073631            0.073900  \n","2   0.241125             0.073631            0.073981  \n","3   0.241022             0.073631            0.074048  \n","4   0.238652             0.073906            0.074310  \n","5   0.238267             0.073774            0.074238  \n","6   0.238102             0.074019            0.074438  \n","7   0.239211             0.073825            0.074267  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Results Standard-Deviation:\n"]},{"data":{"text/html":["\n","  <div id=\"df-e0f3dc27-48a4-48d9-af5f-09c90f05030c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model</td>\n","      <td>0.000000</td>\n","      <td>0.002512</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>5.745950e-17</td>\n","      <td>2.872975e-17</td>\n","      <td>2.872975e-17</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GLM1</td>\n","      <td>0.000000</td>\n","      <td>0.473819</td>\n","      <td>0.0</td>\n","      <td>5.745950e-17</td>\n","      <td>5.745950e-17</td>\n","      <td>1.436488e-17</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GLM2</td>\n","      <td>0.000000</td>\n","      <td>0.970156</td>\n","      <td>0.0</td>\n","      <td>5.745950e-17</td>\n","      <td>2.872975e-17</td>\n","      <td>0.000000e+00</td>\n","      <td>1.436488e-17</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GLM3</td>\n","      <td>0.000000</td>\n","      <td>0.408252</td>\n","      <td>0.0</td>\n","      <td>2.872975e-17</td>\n","      <td>2.872975e-17</td>\n","      <td>0.000000e+00</td>\n","      <td>1.436488e-17</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FFN_OHE</td>\n","      <td>14.663853</td>\n","      <td>8.624492</td>\n","      <td>0.0</td>\n","      <td>3.255191e-04</td>\n","      <td>1.570462e-04</td>\n","      <td>1.223993e-03</td>\n","      <td>1.209107e-03</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>FNN_CAT_EMB</td>\n","      <td>21.661245</td>\n","      <td>13.907265</td>\n","      <td>0.0</td>\n","      <td>1.590947e-04</td>\n","      <td>1.514444e-04</td>\n","      <td>1.071399e-03</td>\n","      <td>1.088943e-03</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CANN</td>\n","      <td>53.898935</td>\n","      <td>33.162059</td>\n","      <td>0.0</td>\n","      <td>6.076588e-04</td>\n","      <td>3.253586e-04</td>\n","      <td>1.111365e-03</td>\n","      <td>1.103431e-03</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LocalGLMnet</td>\n","      <td>7.622023</td>\n","      <td>5.097405</td>\n","      <td>0.0</td>\n","      <td>3.340630e-04</td>\n","      <td>2.176521e-04</td>\n","      <td>8.787938e-04</td>\n","      <td>9.078453e-04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0f3dc27-48a4-48d9-af5f-09c90f05030c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e0f3dc27-48a4-48d9-af5f-09c90f05030c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e0f3dc27-48a4-48d9-af5f-09c90f05030c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e50fe240-f7e6-4339-b99d-6180b4e8c4b1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e50fe240-f7e6-4339-b99d-6180b4e8c4b1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e50fe240-f7e6-4339-b99d-6180b4e8c4b1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["               model     epochs   run_time  nr_parameters    loss_train  \\\n","0  homogeneous model   0.000000   0.002512            0.0  0.000000e+00   \n","1               GLM1   0.000000   0.473819            0.0  5.745950e-17   \n","2               GLM2   0.000000   0.970156            0.0  5.745950e-17   \n","3               GLM3   0.000000   0.408252            0.0  2.872975e-17   \n","4            FFN_OHE  14.663853   8.624492            0.0  3.255191e-04   \n","5        FNN_CAT_EMB  21.661245  13.907265            0.0  1.590947e-04   \n","6               CANN  53.898935  33.162059            0.0  6.076588e-04   \n","7        LocalGLMnet   7.622023   5.097405            0.0  3.340630e-04   \n","\n","      loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0  5.745950e-17         2.872975e-17        2.872975e-17  \n","1  5.745950e-17         1.436488e-17        0.000000e+00  \n","2  2.872975e-17         0.000000e+00        1.436488e-17  \n","3  2.872975e-17         0.000000e+00        1.436488e-17  \n","4  1.570462e-04         1.223993e-03        1.209107e-03  \n","5  1.514444e-04         1.071399e-03        1.088943e-03  \n","6  3.253586e-04         1.111365e-03        1.103431e-03  \n","7  2.176521e-04         8.787938e-04        9.078453e-04  "]},"metadata":{},"output_type":"display_data"}],"source":["print(\"Results Average:\")\n","display(calc_avg_df([\"homogeneous model\",\"GLM1\",\"GLM2\",\"GLM3\",\"FFN_OHE\",\"FNN_CAT_EMB\",\"CANN\",\"LocalGLMnet\"]))\n","print(\"Results Standard-Deviation:\")\n","display(calc_std_df([\"homogeneous model\",\"GLM1\",\"GLM2\",\"GLM3\",\"FFN_OHE\",\"FNN_CAT_EMB\",\"CANN\",\"LocalGLMnet\"]))"]},{"cell_type":"markdown","metadata":{"id":"LjrC4DzIjymq"},"source":["Note that we have the same results as described in the book 2023 by Wüthrich and Merz for the Mean and GLM Models:\n","\n","| Model | In-sample | Out-of-sample |\n","|-------|-----------|---------------|\n","| Poisson null | 25.213 | 25.445 |\n","| Poisson GLM3 | 24.101 | 24.146 |\n","| Poisson GLM3 | 24.091 | 24.113 |\n","| Poisson GLM3 | 24.084 | 24.102 |\n","\n","And for the other models we have very similar results compared to those in the paper LocalGLMnet (2023):\n","(Our Results to those in the following table from from the paper (results from the paper): (a),(b),(d),(e),(f). We changed here the validation set for LocalGLMnet from 20% (in Paper) to 10% but the results is very similar the one in the 2023 LocalGLMnet paper (d) (see our std analysis).\n","\n","| Model | In-sample | Out-of-sample |\n","|-------|-----------|---------------|\n","| (a) null model | 25.213 | 25.445 |\n","| (b) FFN network | 23.764 | 23.873 |\n","| (c) LocalGLMnet | 23.728 | 23.945 |\n","| (d) reduced LocalGLMnet | 23.714 | 23.912 |\n","| (e) Poisson GLM3 | 24.084 | 24.102 |\n","| (f) Categorical Embedding network | 23.690 | 23.824 |\n","| (g) Nagging network | 23.691 | 23.783 |"]},{"cell_type":"markdown","metadata":{"id":"IEViNXYcjymr"},"source":["# 4. Transformer Models"]},{"cell_type":"markdown","metadata":{"id":"8X_3qCXojyms"},"source":["## 4.1 FT-Transformer-Model:"]},{"cell_type":"markdown","metadata":{"id":"WBWfWoyXjyms"},"source":["The FT-Transformer Model was introduced by Gorishniy et al 2021.\n","\n","So the code ideas are based on the code from [gorishniy2021revisiting]\n","\n","Please see the paper for more details: https://arxiv.org/abs/2106.11959\n","\n","Please see here their code written for torch nn's: https://github.com/Yura52/rtdl\n","\n","References:\n","        * [gorishniy2021revisiting]  Gorishniy, Rubachev, Khrulkov, Babenko \"Revisiting Deep Learning Models for Tabular Data\" 2021\n"]},{"cell_type":"markdown","metadata":{"id":"spa-ASdtmNFF"},"source":["NOTE: I rewrote the original code quite a bit to suit our purpose, one can find my oop code (on the tensorflow framework) in the helper folder provided with this notebook."]},{"cell_type":"markdown","metadata":{"id":"wOAMlX3Vn9De"},"source":["NOTE: Below we use instead of the .fit function a costum training loop (to have a extra bit of freedom)."]},{"cell_type":"markdown","metadata":{"id":"KDkbII4ie6ny"},"source":["NOTE: we run the code 15 times on different seeds (to calc the avg and std of runtime and results)."]},{"cell_type":"markdown","metadata":{"id":"Kxt0W9Aejymu"},"source":["NOTE: It is very important that the learn/test split stays the same for all models, otherwise the results are not comparable!\n","But we can change up the learn-train/learn-val split for each model to get a better estimate of the generalization error."]},{"cell_type":"markdown","metadata":{"id":"qeE3SWg8ilUn"},"source":["NOTE: as described in the data preperation section, we are not creating here every train and validation split dataset at once but instead create those when fitting the model. So that we are not polluting the RAM. Note that notebooks have usually no garbage collector, so we try to be carefull."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":23800400,"status":"ok","timestamp":1699028216650,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"WUudp72lguxP","outputId":"a5741090-5d9a-44fd-f736-fe47aed2b615"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 00-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 00/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 0 / Train-Loss: 0.3631 / Val-Loss: 0.2746 / Test-Loss: 0.2746 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0304  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 1 / Train-Loss: 0.2621 / Val-Loss: 0.2576 / Test-Loss: 0.2570 / Time taken: 0:00:57 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.03    : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 2 / Train-Loss: 0.2527 / Val-Loss: 0.2547 / Test-Loss: 0.2538 / Time taken: 0:01:18 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0305  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 3 / Train-Loss: 0.2467 / Val-Loss: 0.2519 / Test-Loss: 0.2502 / Time taken: 0:01:31 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0309  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 4 / Train-Loss: 0.2425 / Val-Loss: 0.2509 / Test-Loss: 0.2486 / Time taken: 0:01:44 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0313  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 5 / Train-Loss: 0.2410 / Val-Loss: 0.2501 / Test-Loss: 0.2474 / Time taken: 0:01:58 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0317  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 6 / Train-Loss: 0.2404 / Val-Loss: 0.2497 / Test-Loss: 0.2467 / Time taken: 0:02:20 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0319  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 7 / Train-Loss: 0.2400 / Val-Loss: 0.2494 / Test-Loss: 0.2463 / Time taken: 0:02:33 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 8 / Train-Loss: 0.2397 / Val-Loss: 0.2487 / Test-Loss: 0.2455 / Time taken: 0:02:46 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 9 / Train-Loss: 0.2396 / Val-Loss: 0.2488 / Test-Loss: 0.2455 / Time taken: 0:03:00 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 00/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 10 / Train-Loss: 0.2392 / Val-Loss: 0.2484 / Test-Loss: 0.2449 / Time taken: 0:03:22 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 11 / Batch: 2 / Train-Loss (Batch): 0.1576   : [------------------------------] 0.4%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 00/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 11 / Train-Loss: 0.2390 / Val-Loss: 0.2483 / Test-Loss: 0.2447 / Time taken: 0:03:43 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 12 / Train-Loss: 0.2388 / Val-Loss: 0.2482 / Test-Loss: 0.2446 / Time taken: 0:03:56 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 13 / Train-Loss: 0.2387 / Val-Loss: 0.2478 / Test-Loss: 0.2441 / Time taken: 0:04:13 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 14 / Train-Loss: 0.2385 / Val-Loss: 0.2479 / Test-Loss: 0.2441 / Time taken: 0:04:25 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 00/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 15 / Train-Loss: 0.2386 / Val-Loss: 0.2479 / Test-Loss: 0.2441 / Time taken: 0:04:37 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 00/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 16 / Train-Loss: 0.2384 / Val-Loss: 0.2474 / Test-Loss: 0.2435 / Time taken: 0:04:59 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 17 / Train-Loss: 0.2385 / Val-Loss: 0.2473 / Test-Loss: 0.2435 / Time taken: 0:05:15 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 18 / Train-Loss: 0.2383 / Val-Loss: 0.2473 / Test-Loss: 0.2435 / Time taken: 0:05:28 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 00/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 19 / Train-Loss: 0.2382 / Val-Loss: 0.2469 / Test-Loss: 0.2429 / Time taken: 0:05:40 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 20 / Train-Loss: 0.2382 / Val-Loss: 0.2469 / Test-Loss: 0.2431 / Time taken: 0:05:53 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 00/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 21 / Train-Loss: 0.2381 / Val-Loss: 0.2465 / Test-Loss: 0.2426 / Time taken: 0:06:08 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 22 / Train-Loss: 0.2381 / Val-Loss: 0.2462 / Test-Loss: 0.2424 / Time taken: 0:06:21 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 23 / Train-Loss: 0.2381 / Val-Loss: 0.2466 / Test-Loss: 0.2426 / Time taken: 0:06:35 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 00/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 24 / Train-Loss: 0.2380 / Val-Loss: 0.2466 / Test-Loss: 0.2425 / Time taken: 0:06:48 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 00/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 25 / Train-Loss: 0.2380 / Val-Loss: 0.2463 / Test-Loss: 0.2424 / Time taken: 0:07:01 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 00/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 26 / Train-Loss: 0.2379 / Val-Loss: 0.2461 / Test-Loss: 0.2421 / Time taken: 0:07:24 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 27 / Train-Loss: 0.2380 / Val-Loss: 0.2460 / Test-Loss: 0.2421 / Time taken: 0:07:38 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 28 / Train-Loss: 0.2379 / Val-Loss: 0.2460 / Test-Loss: 0.2419 / Time taken: 0:07:51 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 29 / Train-Loss: 0.2380 / Val-Loss: 0.2456 / Test-Loss: 0.2416 / Time taken: 0:08:06 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 30 / Train-Loss: 0.2379 / Val-Loss: 0.2455 / Test-Loss: 0.2416 / Time taken: 0:08:20 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 31 / Train-Loss: 0.2378 / Val-Loss: 0.2452 / Test-Loss: 0.2413 / Time taken: 0:08:34 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 32 / Train-Loss: 0.2379 / Val-Loss: 0.2453 / Test-Loss: 0.2414 / Time taken: 0:08:48 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 00/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 33 / Train-Loss: 0.2378 / Val-Loss: 0.2454 / Test-Loss: 0.2413 / Time taken: 0:09:01 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 00/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 34 / Train-Loss: 0.2377 / Val-Loss: 0.2453 / Test-Loss: 0.2414 / Time taken: 0:09:15 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 00/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 35 / Train-Loss: 0.2377 / Val-Loss: 0.2453 / Test-Loss: 0.2413 / Time taken: 0:09:28 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 00/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 36 / Train-Loss: 0.2378 / Val-Loss: 0.2450 / Test-Loss: 0.2411 / Time taken: 0:09:41 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 37 / Train-Loss: 0.2375 / Val-Loss: 0.2449 / Test-Loss: 0.2410 / Time taken: 0:09:55 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 38 / Train-Loss: 0.2376 / Val-Loss: 0.2448 / Test-Loss: 0.2409 / Time taken: 0:10:10 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 39 / Train-Loss: 0.2376 / Val-Loss: 0.2450 / Test-Loss: 0.2410 / Time taken: 0:10:23 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 00/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 40 / Train-Loss: 0.2376 / Val-Loss: 0.2448 / Test-Loss: 0.2409 / Time taken: 0:10:37 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 00/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 41 / Train-Loss: 0.2376 / Val-Loss: 0.2449 / Test-Loss: 0.2409 / Time taken: 0:10:50 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 00/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 42 / Train-Loss: 0.2375 / Val-Loss: 0.2447 / Test-Loss: 0.2408 / Time taken: 0:11:03 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 43 / Train-Loss: 0.2375 / Val-Loss: 0.2446 / Test-Loss: 0.2407 / Time taken: 0:11:19 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 44 / Train-Loss: 0.2375 / Val-Loss: 0.2447 / Test-Loss: 0.2408 / Time taken: 0:11:33 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 00/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 45 / Train-Loss: 0.2374 / Val-Loss: 0.2445 / Test-Loss: 0.2406 / Time taken: 0:11:46 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 46 / Train-Loss: 0.2373 / Val-Loss: 0.2449 / Test-Loss: 0.2410 / Time taken: 0:11:59 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 00/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 47 / Train-Loss: 0.2374 / Val-Loss: 0.2445 / Test-Loss: 0.2406 / Time taken: 0:12:14 / ---- Currently Best Val-Epoch: 47 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 48 / Train-Loss: 0.2374 / Val-Loss: 0.2444 / Test-Loss: 0.2404 / Time taken: 0:12:27 / ---- Currently Best Val-Epoch: 48 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 49 / Train-Loss: 0.2373 / Val-Loss: 0.2448 / Test-Loss: 0.2408 / Time taken: 0:12:41 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 00/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 50 / Train-Loss: 0.2374 / Val-Loss: 0.2444 / Test-Loss: 0.2405 / Time taken: 0:12:55 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 00/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 51 / Train-Loss: 0.2372 / Val-Loss: 0.2444 / Test-Loss: 0.2404 / Time taken: 0:13:16 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 00/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 52 / Train-Loss: 0.2373 / Val-Loss: 0.2445 / Test-Loss: 0.2405 / Time taken: 0:13:30 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 00/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 53 / Train-Loss: 0.2372 / Val-Loss: 0.2442 / Test-Loss: 0.2403 / Time taken: 0:13:43 / ---- Currently Best Val-Epoch: 53 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 54 / Train-Loss: 0.2372 / Val-Loss: 0.2445 / Test-Loss: 0.2405 / Time taken: 0:13:57 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 00/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 55 / Train-Loss: 0.2371 / Val-Loss: 0.2445 / Test-Loss: 0.2405 / Time taken: 0:14:11 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 00/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 56 / Train-Loss: 0.2372 / Val-Loss: 0.2444 / Test-Loss: 0.2404 / Time taken: 0:14:25 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 00/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 57 / Train-Loss: 0.2371 / Val-Loss: 0.2443 / Test-Loss: 0.2403 / Time taken: 0:14:40 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 00/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 58 / Train-Loss: 0.2371 / Val-Loss: 0.2446 / Test-Loss: 0.2405 / Time taken: 0:15:02 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 00/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 59 / Train-Loss: 0.2371 / Val-Loss: 0.2443 / Test-Loss: 0.2404 / Time taken: 0:15:17 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 00/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 60 / Train-Loss: 0.2371 / Val-Loss: 0.2445 / Test-Loss: 0.2404 / Time taken: 0:15:31 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 00/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 61 / Train-Loss: 0.2370 / Val-Loss: 0.2444 / Test-Loss: 0.2404 / Time taken: 0:15:44 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 00/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 62 / Train-Loss: 0.2371 / Val-Loss: 0.2442 / Test-Loss: 0.2403 / Time taken: 0:15:57 / ---- Currently Best Val-Epoch: 62 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 63 / Train-Loss: 0.2370 / Val-Loss: 0.2442 / Test-Loss: 0.2403 / Time taken: 0:16:12 / ---- Currently Best Val-Epoch: 63 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 64 / Train-Loss: 0.2369 / Val-Loss: 0.2442 / Test-Loss: 0.2403 / Time taken: 0:16:26 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 00/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 65 / Train-Loss: 0.2371 / Val-Loss: 0.2442 / Test-Loss: 0.2403 / Time taken: 0:16:40 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 00/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 66 / Train-Loss: 0.2370 / Val-Loss: 0.2440 / Test-Loss: 0.2401 / Time taken: 0:16:53 / ---- Currently Best Val-Epoch: 66 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 67 / Train-Loss: 0.2369 / Val-Loss: 0.2443 / Test-Loss: 0.2403 / Time taken: 0:17:07 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 68 / Train-Loss: 0.2370 / Val-Loss: 0.2442 / Test-Loss: 0.2402 / Time taken: 0:17:21 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 69 / Train-Loss: 0.2369 / Val-Loss: 0.2444 / Test-Loss: 0.2404 / Time taken: 0:17:35 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 70 / Train-Loss: 0.2368 / Val-Loss: 0.2445 / Test-Loss: 0.2404 / Time taken: 0:17:49 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 71 / Train-Loss: 0.2369 / Val-Loss: 0.2445 / Test-Loss: 0.2403 / Time taken: 0:18:03 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 72 / Train-Loss: 0.2369 / Val-Loss: 0.2442 / Test-Loss: 0.2402 / Time taken: 0:18:17 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 73 / Train-Loss: 0.2369 / Val-Loss: 0.2441 / Test-Loss: 0.2401 / Time taken: 0:18:30 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 74 / Train-Loss: 0.2368 / Val-Loss: 0.2443 / Test-Loss: 0.2402 / Time taken: 0:18:44 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 75 / Train-Loss: 0.2367 / Val-Loss: 0.2446 / Test-Loss: 0.2404 / Time taken: 0:18:57 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 76 / Train-Loss: 0.2367 / Val-Loss: 0.2445 / Test-Loss: 0.2404 / Time taken: 0:19:11 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 77 / Train-Loss: 0.2368 / Val-Loss: 0.2443 / Test-Loss: 0.2400 / Time taken: 0:19:24 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 78 / Train-Loss: 0.2367 / Val-Loss: 0.2442 / Test-Loss: 0.2400 / Time taken: 0:19:37 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 79 / Train-Loss: 0.2367 / Val-Loss: 0.2443 / Test-Loss: 0.2402 / Time taken: 0:19:51 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 80 / Train-Loss: 0.2367 / Val-Loss: 0.2442 / Test-Loss: 0.2401 / Time taken: 0:20:12 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 81 / Train-Loss: 0.2366 / Val-Loss: 0.2444 / Test-Loss: 0.2403 / Time taken: 0:20:25 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 00/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 82 / Train-Loss: 0.2367 / Val-Loss: 0.2440 / Test-Loss: 0.2399 / Time taken: 0:20:38 / ---- Currently Best Val-Epoch: 82 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 83 / Train-Loss: 0.2365 / Val-Loss: 0.2442 / Test-Loss: 0.2400 / Time taken: 0:20:52 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 84 / Train-Loss: 0.2365 / Val-Loss: 0.2443 / Test-Loss: 0.2402 / Time taken: 0:21:06 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 85 / Train-Loss: 0.2365 / Val-Loss: 0.2442 / Test-Loss: 0.2401 / Time taken: 0:21:20 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 86 / Train-Loss: 0.2365 / Val-Loss: 0.2443 / Test-Loss: 0.2401 / Time taken: 0:21:34 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 87 / Train-Loss: 0.2365 / Val-Loss: 0.2441 / Test-Loss: 0.2400 / Time taken: 0:21:47 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 88 / Train-Loss: 0.2365 / Val-Loss: 0.2444 / Test-Loss: 0.2402 / Time taken: 0:22:01 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 89 / Train-Loss: 0.2364 / Val-Loss: 0.2444 / Test-Loss: 0.2402 / Time taken: 0:22:16 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 90 / Train-Loss: 0.2365 / Val-Loss: 0.2443 / Test-Loss: 0.2402 / Time taken: 0:22:29 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 91 / Train-Loss: 0.2364 / Val-Loss: 0.2444 / Test-Loss: 0.2402 / Time taken: 0:22:51 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 92 / Train-Loss: 0.2363 / Val-Loss: 0.2442 / Test-Loss: 0.2400 / Time taken: 0:23:12 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 93 / Train-Loss: 0.2363 / Val-Loss: 0.2446 / Test-Loss: 0.2404 / Time taken: 0:23:26 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 94 / Train-Loss: 0.2364 / Val-Loss: 0.2443 / Test-Loss: 0.2401 / Time taken: 0:23:39 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 95 / Train-Loss: 0.2363 / Val-Loss: 0.2444 / Test-Loss: 0.2403 / Time taken: 0:23:53 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 96 / Train-Loss: 0.2362 / Val-Loss: 0.2446 / Test-Loss: 0.2404 / Time taken: 0:24:07 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 97 / Train-Loss: 0.2362 / Val-Loss: 0.2445 / Test-Loss: 0.2403 / Time taken: 0:24:22 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 00/14 / Epoch: 98 / Batch: 536 / Train-Loss (Batch): 0.0348 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 98 / Train-Loss: 0.2363 / Val-Loss: 0.2443 / Test-Loss: 0.2401 / Time taken: 0:24:43 / ---- Currently Best Val-Epoch: 82 \n","596/596 [==============================] - 11s 17ms/step\n","67/67 [==============================] - 1s 14ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-5e5fe638-43f3-409c-b43d-40fd6e437d32\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>LocalGLMnet (run: 11)</td>\n","      <td>38</td>\n","      <td>29.706788</td>\n","      <td>1737</td>\n","      <td>0.236772</td>\n","      <td>0.238934</td>\n","      <td>0.073772</td>\n","      <td>0.074275</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>LocalGLMnet (run: 12)</td>\n","      <td>11</td>\n","      <td>15.253076</td>\n","      <td>1737</td>\n","      <td>0.237896</td>\n","      <td>0.239430</td>\n","      <td>0.073266</td>\n","      <td>0.073614</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>LocalGLMnet (run: 13)</td>\n","      <td>19</td>\n","      <td>20.083682</td>\n","      <td>1737</td>\n","      <td>0.237316</td>\n","      <td>0.239288</td>\n","      <td>0.073202</td>\n","      <td>0.073597</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>LocalGLMnet (run: 14)</td>\n","      <td>28</td>\n","      <td>24.299453</td>\n","      <td>1737</td>\n","      <td>0.236903</td>\n","      <td>0.239005</td>\n","      <td>0.075655</td>\n","      <td>0.076141</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>FT_transformer (run: 0)</td>\n","      <td>82</td>\n","      <td>1483.549221</td>\n","      <td>27133</td>\n","      <td>0.238317</td>\n","      <td>0.239865</td>\n","      <td>0.060856</td>\n","      <td>0.061208</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>121 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e5fe638-43f3-409c-b43d-40fd6e437d32')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5e5fe638-43f3-409c-b43d-40fd6e437d32 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5e5fe638-43f3-409c-b43d-40fd6e437d32');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-58fd327b-c260-4c7b-a27c-a92f564595c2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58fd327b-c260-4c7b-a27c-a92f564595c2')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-58fd327b-c260-4c7b-a27c-a92f564595c2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","116       LocalGLMnet (run: 11)      38    29.706788           1737   \n","117       LocalGLMnet (run: 12)      11    15.253076           1737   \n","118       LocalGLMnet (run: 13)      19    20.083682           1737   \n","119       LocalGLMnet (run: 14)      28    24.299453           1737   \n","120     FT_transformer (run: 0)      82  1483.549221          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","116    0.236772   0.238934             0.073772            0.074275  \n","117    0.237896   0.239430             0.073266            0.073614  \n","118    0.237316   0.239288             0.073202            0.073597  \n","119    0.236903   0.239005             0.075655            0.076141  \n","120    0.238317   0.239865             0.060856            0.061208  \n","\n","[121 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 01-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 01/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0084  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 0 / Train-Loss: 0.3070 / Val-Loss: 0.2569 / Test-Loss: 0.2548 / Time taken: 0:00:31 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.007   : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 1 / Train-Loss: 0.2504 / Val-Loss: 0.2551 / Test-Loss: 0.2524 / Time taken: 0:00:46 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0065  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 2 / Train-Loss: 0.2443 / Val-Loss: 0.2537 / Test-Loss: 0.2504 / Time taken: 0:01:08 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0061  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 3 / Train-Loss: 0.2422 / Val-Loss: 0.2528 / Test-Loss: 0.2492 / Time taken: 0:01:21 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0063  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 4 / Train-Loss: 0.2412 / Val-Loss: 0.2516 / Test-Loss: 0.2478 / Time taken: 0:01:33 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0063  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 5 / Train-Loss: 0.2403 / Val-Loss: 0.2508 / Test-Loss: 0.2469 / Time taken: 0:01:53 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0062  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 6 / Train-Loss: 0.2401 / Val-Loss: 0.2507 / Test-Loss: 0.2466 / Time taken: 0:02:17 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0062  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 7 / Train-Loss: 0.2397 / Val-Loss: 0.2503 / Test-Loss: 0.2461 / Time taken: 0:02:31 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0064  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 8 / Train-Loss: 0.2394 / Val-Loss: 0.2499 / Test-Loss: 0.2455 / Time taken: 0:02:44 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0061  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 9 / Train-Loss: 0.2392 / Val-Loss: 0.2501 / Test-Loss: 0.2456 / Time taken: 0:02:57 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 01/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 10 / Train-Loss: 0.2390 / Val-Loss: 0.2504 / Test-Loss: 0.2457 / Time taken: 0:03:10 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 01/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 11 / Train-Loss: 0.2387 / Val-Loss: 0.2505 / Test-Loss: 0.2457 / Time taken: 0:03:24 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 01/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 12 / Train-Loss: 0.2386 / Val-Loss: 0.2494 / Test-Loss: 0.2446 / Time taken: 0:03:37 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 13 / Batch: 1 / Train-Loss (Batch): 0.1702   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 01/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 13 / Train-Loss: 0.2384 / Val-Loss: 0.2489 / Test-Loss: 0.2440 / Time taken: 0:03:51 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.006  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 14 / Train-Loss: 0.2385 / Val-Loss: 0.2492 / Test-Loss: 0.2441 / Time taken: 0:04:13 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 01/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 15 / Train-Loss: 0.2381 / Val-Loss: 0.2487 / Test-Loss: 0.2437 / Time taken: 0:04:35 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 16 / Train-Loss: 0.2381 / Val-Loss: 0.2488 / Test-Loss: 0.2437 / Time taken: 0:04:48 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 01/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 17 / Train-Loss: 0.2382 / Val-Loss: 0.2480 / Test-Loss: 0.2429 / Time taken: 0:05:00 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 18 / Train-Loss: 0.2381 / Val-Loss: 0.2487 / Test-Loss: 0.2436 / Time taken: 0:05:14 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 01/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 19 / Train-Loss: 0.2380 / Val-Loss: 0.2483 / Test-Loss: 0.2431 / Time taken: 0:05:28 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 01/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 20 / Train-Loss: 0.2380 / Val-Loss: 0.2480 / Test-Loss: 0.2429 / Time taken: 0:05:41 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 01/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 21 / Train-Loss: 0.2380 / Val-Loss: 0.2473 / Test-Loss: 0.2423 / Time taken: 0:05:54 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 22 / Train-Loss: 0.2379 / Val-Loss: 0.2474 / Test-Loss: 0.2424 / Time taken: 0:06:08 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 01/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 23 / Train-Loss: 0.2378 / Val-Loss: 0.2472 / Test-Loss: 0.2422 / Time taken: 0:06:23 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 24 / Train-Loss: 0.2379 / Val-Loss: 0.2473 / Test-Loss: 0.2422 / Time taken: 0:06:36 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 01/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 25 / Train-Loss: 0.2378 / Val-Loss: 0.2469 / Test-Loss: 0.2418 / Time taken: 0:06:50 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 26 / Train-Loss: 0.2378 / Val-Loss: 0.2467 / Test-Loss: 0.2417 / Time taken: 0:07:12 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 27 / Train-Loss: 0.2377 / Val-Loss: 0.2465 / Test-Loss: 0.2414 / Time taken: 0:07:34 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 28 / Train-Loss: 0.2377 / Val-Loss: 0.2466 / Test-Loss: 0.2416 / Time taken: 0:07:57 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 01/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 29 / Train-Loss: 0.2376 / Val-Loss: 0.2469 / Test-Loss: 0.2417 / Time taken: 0:08:12 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 01/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 30 / Train-Loss: 0.2377 / Val-Loss: 0.2466 / Test-Loss: 0.2416 / Time taken: 0:08:26 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 01/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 31 / Train-Loss: 0.2376 / Val-Loss: 0.2463 / Test-Loss: 0.2413 / Time taken: 0:08:39 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 32 / Train-Loss: 0.2376 / Val-Loss: 0.2464 / Test-Loss: 0.2413 / Time taken: 0:08:53 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 01/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 33 / Train-Loss: 0.2375 / Val-Loss: 0.2464 / Test-Loss: 0.2413 / Time taken: 0:09:08 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 01/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 34 / Train-Loss: 0.2374 / Val-Loss: 0.2467 / Test-Loss: 0.2416 / Time taken: 0:09:21 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 01/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 35 / Train-Loss: 0.2375 / Val-Loss: 0.2459 / Test-Loss: 0.2410 / Time taken: 0:09:34 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 36 / Train-Loss: 0.2375 / Val-Loss: 0.2459 / Test-Loss: 0.2409 / Time taken: 0:09:48 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 37 / Train-Loss: 0.2375 / Val-Loss: 0.2457 / Test-Loss: 0.2408 / Time taken: 0:10:03 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 38 / Train-Loss: 0.2374 / Val-Loss: 0.2458 / Test-Loss: 0.2408 / Time taken: 0:10:17 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 01/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 39 / Train-Loss: 0.2374 / Val-Loss: 0.2457 / Test-Loss: 0.2408 / Time taken: 0:10:31 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 40 / Train-Loss: 0.2374 / Val-Loss: 0.2456 / Test-Loss: 0.2407 / Time taken: 0:10:46 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 41 / Train-Loss: 0.2373 / Val-Loss: 0.2457 / Test-Loss: 0.2406 / Time taken: 0:11:02 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 01/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 42 / Train-Loss: 0.2372 / Val-Loss: 0.2457 / Test-Loss: 0.2407 / Time taken: 0:11:15 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 01/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 43 / Train-Loss: 0.2372 / Val-Loss: 0.2453 / Test-Loss: 0.2405 / Time taken: 0:11:30 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 44 / Train-Loss: 0.2372 / Val-Loss: 0.2456 / Test-Loss: 0.2406 / Time taken: 0:11:43 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 01/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 45 / Train-Loss: 0.2371 / Val-Loss: 0.2456 / Test-Loss: 0.2407 / Time taken: 0:11:59 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 01/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 46 / Train-Loss: 0.2373 / Val-Loss: 0.2454 / Test-Loss: 0.2405 / Time taken: 0:12:13 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 01/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 47 / Train-Loss: 0.2371 / Val-Loss: 0.2452 / Test-Loss: 0.2403 / Time taken: 0:12:27 / ---- Currently Best Val-Epoch: 47 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 48 / Train-Loss: 0.2371 / Val-Loss: 0.2452 / Test-Loss: 0.2403 / Time taken: 0:12:41 / ---- Currently Best Val-Epoch: 48 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 49 / Train-Loss: 0.2370 / Val-Loss: 0.2453 / Test-Loss: 0.2404 / Time taken: 0:12:55 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 01/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 50 / Train-Loss: 0.2371 / Val-Loss: 0.2451 / Test-Loss: 0.2402 / Time taken: 0:13:08 / ---- Currently Best Val-Epoch: 50 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 51 / Train-Loss: 0.2370 / Val-Loss: 0.2448 / Test-Loss: 0.2402 / Time taken: 0:13:23 / ---- Currently Best Val-Epoch: 51 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 52 / Train-Loss: 0.2370 / Val-Loss: 0.2450 / Test-Loss: 0.2403 / Time taken: 0:13:36 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 01/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 53 / Train-Loss: 0.2369 / Val-Loss: 0.2449 / Test-Loss: 0.2401 / Time taken: 0:13:50 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 01/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 54 / Train-Loss: 0.2368 / Val-Loss: 0.2451 / Test-Loss: 0.2403 / Time taken: 0:14:04 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 01/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 55 / Train-Loss: 0.2367 / Val-Loss: 0.2449 / Test-Loss: 0.2401 / Time taken: 0:14:18 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 01/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 56 / Train-Loss: 0.2369 / Val-Loss: 0.2446 / Test-Loss: 0.2398 / Time taken: 0:14:31 / ---- Currently Best Val-Epoch: 56 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 57 / Train-Loss: 0.2368 / Val-Loss: 0.2445 / Test-Loss: 0.2399 / Time taken: 0:14:46 / ---- Currently Best Val-Epoch: 57 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 58 / Train-Loss: 0.2366 / Val-Loss: 0.2442 / Test-Loss: 0.2396 / Time taken: 0:15:00 / ---- Currently Best Val-Epoch: 58 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 59 / Train-Loss: 0.2366 / Val-Loss: 0.2441 / Test-Loss: 0.2396 / Time taken: 0:15:22 / ---- Currently Best Val-Epoch: 59 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 60 / Train-Loss: 0.2365 / Val-Loss: 0.2441 / Test-Loss: 0.2396 / Time taken: 0:15:37 / ---- Currently Best Val-Epoch: 60 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 61 / Train-Loss: 0.2365 / Val-Loss: 0.2442 / Test-Loss: 0.2397 / Time taken: 0:15:59 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 01/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 62 / Train-Loss: 0.2366 / Val-Loss: 0.2440 / Test-Loss: 0.2395 / Time taken: 0:16:22 / ---- Currently Best Val-Epoch: 62 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 63 / Train-Loss: 0.2363 / Val-Loss: 0.2439 / Test-Loss: 0.2394 / Time taken: 0:16:36 / ---- Currently Best Val-Epoch: 63 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 64 / Train-Loss: 0.2363 / Val-Loss: 0.2439 / Test-Loss: 0.2394 / Time taken: 0:16:50 / ---- Currently Best Val-Epoch: 64 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 65 / Train-Loss: 0.2362 / Val-Loss: 0.2437 / Test-Loss: 0.2393 / Time taken: 0:17:05 / ---- Currently Best Val-Epoch: 65 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 66 / Train-Loss: 0.2362 / Val-Loss: 0.2439 / Test-Loss: 0.2393 / Time taken: 0:17:19 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 01/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 67 / Train-Loss: 0.2362 / Val-Loss: 0.2438 / Test-Loss: 0.2393 / Time taken: 0:17:33 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 01/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 68 / Train-Loss: 0.2362 / Val-Loss: 0.2437 / Test-Loss: 0.2392 / Time taken: 0:17:47 / ---- Currently Best Val-Epoch: 68 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 69 / Train-Loss: 0.2362 / Val-Loss: 0.2438 / Test-Loss: 0.2392 / Time taken: 0:18:01 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 01/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 70 / Train-Loss: 0.2360 / Val-Loss: 0.2438 / Test-Loss: 0.2395 / Time taken: 0:18:15 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 01/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 71 / Train-Loss: 0.2361 / Val-Loss: 0.2440 / Test-Loss: 0.2393 / Time taken: 0:18:29 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 01/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 72 / Train-Loss: 0.2361 / Val-Loss: 0.2442 / Test-Loss: 0.2397 / Time taken: 0:18:44 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 01/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 73 / Train-Loss: 0.2360 / Val-Loss: 0.2437 / Test-Loss: 0.2393 / Time taken: 0:18:57 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 01/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 74 / Train-Loss: 0.2360 / Val-Loss: 0.2440 / Test-Loss: 0.2394 / Time taken: 0:19:10 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 01/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 75 / Train-Loss: 0.2360 / Val-Loss: 0.2438 / Test-Loss: 0.2393 / Time taken: 0:19:24 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 01/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 76 / Train-Loss: 0.2358 / Val-Loss: 0.2440 / Test-Loss: 0.2394 / Time taken: 0:19:45 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 01/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 77 / Train-Loss: 0.2359 / Val-Loss: 0.2436 / Test-Loss: 0.2392 / Time taken: 0:20:08 / ---- Currently Best Val-Epoch: 77 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 78 / Train-Loss: 0.2358 / Val-Loss: 0.2434 / Test-Loss: 0.2390 / Time taken: 0:20:22 / ---- Currently Best Val-Epoch: 78 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 79 / Train-Loss: 0.2358 / Val-Loss: 0.2438 / Test-Loss: 0.2393 / Time taken: 0:20:37 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 01/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 80 / Train-Loss: 0.2358 / Val-Loss: 0.2438 / Test-Loss: 0.2392 / Time taken: 0:20:51 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 01/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 81 / Train-Loss: 0.2358 / Val-Loss: 0.2436 / Test-Loss: 0.2391 / Time taken: 0:21:04 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 01/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 82 / Train-Loss: 0.2357 / Val-Loss: 0.2437 / Test-Loss: 0.2392 / Time taken: 0:21:18 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 01/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 83 / Train-Loss: 0.2357 / Val-Loss: 0.2438 / Test-Loss: 0.2393 / Time taken: 0:21:32 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 01/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 84 / Train-Loss: 0.2357 / Val-Loss: 0.2437 / Test-Loss: 0.2391 / Time taken: 0:21:47 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 01/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 85 / Train-Loss: 0.2356 / Val-Loss: 0.2435 / Test-Loss: 0.2390 / Time taken: 0:22:00 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 01/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 86 / Train-Loss: 0.2357 / Val-Loss: 0.2434 / Test-Loss: 0.2387 / Time taken: 0:22:13 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 01/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 87 / Train-Loss: 0.2356 / Val-Loss: 0.2436 / Test-Loss: 0.2389 / Time taken: 0:22:27 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 01/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 88 / Train-Loss: 0.2356 / Val-Loss: 0.2437 / Test-Loss: 0.2389 / Time taken: 0:22:42 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 01/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 89 / Train-Loss: 0.2356 / Val-Loss: 0.2433 / Test-Loss: 0.2388 / Time taken: 0:22:55 / ---- Currently Best Val-Epoch: 89 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 90 / Train-Loss: 0.2357 / Val-Loss: 0.2434 / Test-Loss: 0.2389 / Time taken: 0:23:09 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 91 / Train-Loss: 0.2354 / Val-Loss: 0.2436 / Test-Loss: 0.2393 / Time taken: 0:23:24 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 92 / Train-Loss: 0.2356 / Val-Loss: 0.2437 / Test-Loss: 0.2391 / Time taken: 0:23:38 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 93 / Train-Loss: 0.2355 / Val-Loss: 0.2437 / Test-Loss: 0.2391 / Time taken: 0:23:52 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 94 / Train-Loss: 0.2354 / Val-Loss: 0.2436 / Test-Loss: 0.2389 / Time taken: 0:24:05 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 95 / Train-Loss: 0.2354 / Val-Loss: 0.2437 / Test-Loss: 0.2391 / Time taken: 0:24:20 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 96 / Train-Loss: 0.2353 / Val-Loss: 0.2439 / Test-Loss: 0.2393 / Time taken: 0:24:34 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 97 / Train-Loss: 0.2354 / Val-Loss: 0.2434 / Test-Loss: 0.2389 / Time taken: 0:24:48 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 98 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 98 / Train-Loss: 0.2353 / Val-Loss: 0.2435 / Test-Loss: 0.2389 / Time taken: 0:25:02 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 99 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 99 / Train-Loss: 0.2354 / Val-Loss: 0.2435 / Test-Loss: 0.2392 / Time taken: 0:25:16 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 100 / Batch: 536 / Train-Loss (Batch): 0.0065: [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 100 / Train-Loss: 0.2353 / Val-Loss: 0.2435 / Test-Loss: 0.2391 / Time taken: 0:25:30 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 101 / Batch: 536 / Train-Loss (Batch): 0.0063: [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 101 / Train-Loss: 0.2352 / Val-Loss: 0.2437 / Test-Loss: 0.2391 / Time taken: 0:25:51 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 102 / Batch: 536 / Train-Loss (Batch): 0.0065: [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 102 / Train-Loss: 0.2354 / Val-Loss: 0.2434 / Test-Loss: 0.2390 / Time taken: 0:26:05 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 103 / Batch: 536 / Train-Loss (Batch): 0.0063: [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 103 / Train-Loss: 0.2352 / Val-Loss: 0.2438 / Test-Loss: 0.2390 / Time taken: 0:26:27 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 104 / Batch: 536 / Train-Loss (Batch): 0.0063: [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 104 / Train-Loss: 0.2352 / Val-Loss: 0.2437 / Test-Loss: 0.2391 / Time taken: 0:26:40 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 01/14 / Epoch: 105 / Batch: 536 / Train-Loss (Batch): 0.0063: [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 105 / Train-Loss: 0.2351 / Val-Loss: 0.2434 / Test-Loss: 0.2390 / Time taken: 0:26:54 / ---- Currently Best Val-Epoch: 89 \n","596/596 [==============================] - 9s 14ms/step\n","67/67 [==============================] - 1s 16ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-a3673264-83f6-41ad-8380-497a4c411bf0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>LocalGLMnet (run: 12)</td>\n","      <td>11</td>\n","      <td>15.253076</td>\n","      <td>1737</td>\n","      <td>0.237896</td>\n","      <td>0.239430</td>\n","      <td>0.073266</td>\n","      <td>0.073614</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>LocalGLMnet (run: 13)</td>\n","      <td>19</td>\n","      <td>20.083682</td>\n","      <td>1737</td>\n","      <td>0.237316</td>\n","      <td>0.239288</td>\n","      <td>0.073202</td>\n","      <td>0.073597</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>LocalGLMnet (run: 14)</td>\n","      <td>28</td>\n","      <td>24.299453</td>\n","      <td>1737</td>\n","      <td>0.236903</td>\n","      <td>0.239005</td>\n","      <td>0.075655</td>\n","      <td>0.076141</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>FT_transformer (run: 0)</td>\n","      <td>82</td>\n","      <td>1483.549221</td>\n","      <td>27133</td>\n","      <td>0.238317</td>\n","      <td>0.239865</td>\n","      <td>0.060856</td>\n","      <td>0.061208</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>FT_transformer (run: 1)</td>\n","      <td>89</td>\n","      <td>1614.216463</td>\n","      <td>27133</td>\n","      <td>0.237163</td>\n","      <td>0.238795</td>\n","      <td>0.061112</td>\n","      <td>0.061284</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>122 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3673264-83f6-41ad-8380-497a4c411bf0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a3673264-83f6-41ad-8380-497a4c411bf0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a3673264-83f6-41ad-8380-497a4c411bf0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-857c9146-68b4-4eae-b5b3-a7c2fdddba1e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-857c9146-68b4-4eae-b5b3-a7c2fdddba1e')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-857c9146-68b4-4eae-b5b3-a7c2fdddba1e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","117       LocalGLMnet (run: 12)      11    15.253076           1737   \n","118       LocalGLMnet (run: 13)      19    20.083682           1737   \n","119       LocalGLMnet (run: 14)      28    24.299453           1737   \n","120     FT_transformer (run: 0)      82  1483.549221          27133   \n","121     FT_transformer (run: 1)      89  1614.216463          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","117    0.237896   0.239430             0.073266            0.073614  \n","118    0.237316   0.239288             0.073202            0.073597  \n","119    0.236903   0.239005             0.075655            0.076141  \n","120    0.238317   0.239865             0.060856            0.061208  \n","121    0.237163   0.238795             0.061112            0.061284  \n","\n","[122 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 02-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 02/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0299  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 0 / Train-Loss: 0.2769 / Val-Loss: 0.2522 / Test-Loss: 0.2546 / Time taken: 0:00:29 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0307  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 1 / Train-Loss: 0.2496 / Val-Loss: 0.2493 / Test-Loss: 0.2516 / Time taken: 0:00:42 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.031   : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 2 / Train-Loss: 0.2444 / Val-Loss: 0.2476 / Test-Loss: 0.2495 / Time taken: 0:00:55 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0317  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 3 / Train-Loss: 0.2421 / Val-Loss: 0.2464 / Test-Loss: 0.2479 / Time taken: 0:01:08 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0316  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 4 / Train-Loss: 0.2412 / Val-Loss: 0.2456 / Test-Loss: 0.2470 / Time taken: 0:01:30 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0324  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 5 / Train-Loss: 0.2407 / Val-Loss: 0.2453 / Test-Loss: 0.2467 / Time taken: 0:01:43 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0321  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 6 / Train-Loss: 0.2403 / Val-Loss: 0.2450 / Test-Loss: 0.2463 / Time taken: 0:01:56 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 7 / Train-Loss: 0.2401 / Val-Loss: 0.2444 / Test-Loss: 0.2457 / Time taken: 0:02:11 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 8 / Train-Loss: 0.2398 / Val-Loss: 0.2439 / Test-Loss: 0.2452 / Time taken: 0:02:34 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 9 / Train-Loss: 0.2396 / Val-Loss: 0.2438 / Test-Loss: 0.2450 / Time taken: 0:02:55 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 10 / Train-Loss: 0.2393 / Val-Loss: 0.2434 / Test-Loss: 0.2447 / Time taken: 0:03:17 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 11 / Batch: 2 / Train-Loss (Batch): 0.1449   : [------------------------------] 0.4%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 02/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 11 / Train-Loss: 0.2393 / Val-Loss: 0.2431 / Test-Loss: 0.2444 / Time taken: 0:03:31 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 12 / Train-Loss: 0.2392 / Val-Loss: 0.2429 / Test-Loss: 0.2441 / Time taken: 0:03:45 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 13 / Train-Loss: 0.2389 / Val-Loss: 0.2425 / Test-Loss: 0.2438 / Time taken: 0:03:59 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 14 / Train-Loss: 0.2389 / Val-Loss: 0.2418 / Test-Loss: 0.2431 / Time taken: 0:04:13 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 15 / Train-Loss: 0.2388 / Val-Loss: 0.2417 / Test-Loss: 0.2431 / Time taken: 0:04:27 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 16 / Train-Loss: 0.2389 / Val-Loss: 0.2415 / Test-Loss: 0.2428 / Time taken: 0:04:40 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 17 / Train-Loss: 0.2388 / Val-Loss: 0.2412 / Test-Loss: 0.2425 / Time taken: 0:04:55 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 18 / Train-Loss: 0.2387 / Val-Loss: 0.2414 / Test-Loss: 0.2427 / Time taken: 0:05:09 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 02/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 19 / Train-Loss: 0.2388 / Val-Loss: 0.2410 / Test-Loss: 0.2423 / Time taken: 0:05:22 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 20 / Train-Loss: 0.2386 / Val-Loss: 0.2409 / Test-Loss: 0.2422 / Time taken: 0:05:45 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 21 / Train-Loss: 0.2387 / Val-Loss: 0.2405 / Test-Loss: 0.2419 / Time taken: 0:06:02 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 22 / Train-Loss: 0.2386 / Val-Loss: 0.2408 / Test-Loss: 0.2421 / Time taken: 0:06:16 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 02/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 23 / Train-Loss: 0.2386 / Val-Loss: 0.2405 / Test-Loss: 0.2418 / Time taken: 0:06:30 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 24 / Train-Loss: 0.2386 / Val-Loss: 0.2402 / Test-Loss: 0.2415 / Time taken: 0:06:44 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 25 / Train-Loss: 0.2385 / Val-Loss: 0.2402 / Test-Loss: 0.2416 / Time taken: 0:06:58 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 02/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 26 / Train-Loss: 0.2384 / Val-Loss: 0.2399 / Test-Loss: 0.2413 / Time taken: 0:07:12 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 27 / Train-Loss: 0.2384 / Val-Loss: 0.2400 / Test-Loss: 0.2413 / Time taken: 0:07:26 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 02/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 28 / Train-Loss: 0.2383 / Val-Loss: 0.2402 / Test-Loss: 0.2415 / Time taken: 0:07:40 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 02/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 29 / Train-Loss: 0.2383 / Val-Loss: 0.2399 / Test-Loss: 0.2413 / Time taken: 0:08:02 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 30 / Train-Loss: 0.2383 / Val-Loss: 0.2398 / Test-Loss: 0.2411 / Time taken: 0:08:24 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 31 / Train-Loss: 0.2383 / Val-Loss: 0.2398 / Test-Loss: 0.2411 / Time taken: 0:08:46 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 02/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 32 / Train-Loss: 0.2382 / Val-Loss: 0.2396 / Test-Loss: 0.2410 / Time taken: 0:08:59 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 33 / Train-Loss: 0.2382 / Val-Loss: 0.2394 / Test-Loss: 0.2409 / Time taken: 0:09:13 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 34 / Train-Loss: 0.2382 / Val-Loss: 0.2394 / Test-Loss: 0.2408 / Time taken: 0:09:28 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 35 / Train-Loss: 0.2381 / Val-Loss: 0.2395 / Test-Loss: 0.2410 / Time taken: 0:09:42 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 36 / Train-Loss: 0.2381 / Val-Loss: 0.2394 / Test-Loss: 0.2409 / Time taken: 0:10:04 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 37 / Train-Loss: 0.2380 / Val-Loss: 0.2393 / Test-Loss: 0.2408 / Time taken: 0:10:18 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 38 / Train-Loss: 0.2381 / Val-Loss: 0.2392 / Test-Loss: 0.2407 / Time taken: 0:10:33 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 39 / Train-Loss: 0.2381 / Val-Loss: 0.2393 / Test-Loss: 0.2408 / Time taken: 0:10:46 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 02/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 40 / Train-Loss: 0.2381 / Val-Loss: 0.2391 / Test-Loss: 0.2407 / Time taken: 0:11:00 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 41 / Train-Loss: 0.2381 / Val-Loss: 0.2393 / Test-Loss: 0.2409 / Time taken: 0:11:13 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 02/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 42 / Train-Loss: 0.2379 / Val-Loss: 0.2392 / Test-Loss: 0.2407 / Time taken: 0:11:28 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 02/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 43 / Train-Loss: 0.2381 / Val-Loss: 0.2391 / Test-Loss: 0.2406 / Time taken: 0:11:42 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 44 / Train-Loss: 0.2380 / Val-Loss: 0.2391 / Test-Loss: 0.2406 / Time taken: 0:11:55 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 02/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 45 / Train-Loss: 0.2378 / Val-Loss: 0.2390 / Test-Loss: 0.2405 / Time taken: 0:12:09 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 46 / Train-Loss: 0.2378 / Val-Loss: 0.2390 / Test-Loss: 0.2405 / Time taken: 0:12:24 / ---- Currently Best Val-Epoch: 46 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 47 / Train-Loss: 0.2378 / Val-Loss: 0.2389 / Test-Loss: 0.2405 / Time taken: 0:12:38 / ---- Currently Best Val-Epoch: 47 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 48 / Train-Loss: 0.2378 / Val-Loss: 0.2389 / Test-Loss: 0.2405 / Time taken: 0:12:51 / ---- Currently Best Val-Epoch: 47 \n","Ensemble: 02/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 49 / Train-Loss: 0.2377 / Val-Loss: 0.2389 / Test-Loss: 0.2405 / Time taken: 0:13:05 / ---- Currently Best Val-Epoch: 47 \n","Ensemble: 02/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 50 / Train-Loss: 0.2377 / Val-Loss: 0.2387 / Test-Loss: 0.2404 / Time taken: 0:13:20 / ---- Currently Best Val-Epoch: 50 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 51 / Train-Loss: 0.2377 / Val-Loss: 0.2388 / Test-Loss: 0.2405 / Time taken: 0:13:34 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 02/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 52 / Train-Loss: 0.2377 / Val-Loss: 0.2388 / Test-Loss: 0.2404 / Time taken: 0:13:48 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 02/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 53 / Train-Loss: 0.2376 / Val-Loss: 0.2388 / Test-Loss: 0.2404 / Time taken: 0:14:02 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 02/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 54 / Train-Loss: 0.2377 / Val-Loss: 0.2390 / Test-Loss: 0.2405 / Time taken: 0:14:16 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 02/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 55 / Train-Loss: 0.2376 / Val-Loss: 0.2388 / Test-Loss: 0.2404 / Time taken: 0:14:29 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 02/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 56 / Train-Loss: 0.2375 / Val-Loss: 0.2388 / Test-Loss: 0.2403 / Time taken: 0:14:43 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 02/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 57 / Train-Loss: 0.2375 / Val-Loss: 0.2386 / Test-Loss: 0.2401 / Time taken: 0:14:57 / ---- Currently Best Val-Epoch: 57 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 58 / Train-Loss: 0.2375 / Val-Loss: 0.2389 / Test-Loss: 0.2404 / Time taken: 0:15:19 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 02/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 59 / Train-Loss: 0.2374 / Val-Loss: 0.2387 / Test-Loss: 0.2402 / Time taken: 0:15:32 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 02/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 60 / Train-Loss: 0.2376 / Val-Loss: 0.2388 / Test-Loss: 0.2403 / Time taken: 0:15:46 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 02/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 61 / Train-Loss: 0.2375 / Val-Loss: 0.2385 / Test-Loss: 0.2401 / Time taken: 0:16:07 / ---- Currently Best Val-Epoch: 61 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 62 / Train-Loss: 0.2374 / Val-Loss: 0.2385 / Test-Loss: 0.2401 / Time taken: 0:16:29 / ---- Currently Best Val-Epoch: 62 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 63 / Train-Loss: 0.2374 / Val-Loss: 0.2385 / Test-Loss: 0.2401 / Time taken: 0:16:45 / ---- Currently Best Val-Epoch: 63 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 64 / Train-Loss: 0.2373 / Val-Loss: 0.2384 / Test-Loss: 0.2400 / Time taken: 0:17:08 / ---- Currently Best Val-Epoch: 64 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 65 / Train-Loss: 0.2372 / Val-Loss: 0.2386 / Test-Loss: 0.2402 / Time taken: 0:17:22 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 02/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 66 / Train-Loss: 0.2372 / Val-Loss: 0.2382 / Test-Loss: 0.2399 / Time taken: 0:17:37 / ---- Currently Best Val-Epoch: 66 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 67 / Train-Loss: 0.2370 / Val-Loss: 0.2384 / Test-Loss: 0.2399 / Time taken: 0:17:51 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 02/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 68 / Train-Loss: 0.2371 / Val-Loss: 0.2383 / Test-Loss: 0.2399 / Time taken: 0:18:04 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 02/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 69 / Train-Loss: 0.2371 / Val-Loss: 0.2385 / Test-Loss: 0.2402 / Time taken: 0:18:18 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 02/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 70 / Train-Loss: 0.2371 / Val-Loss: 0.2384 / Test-Loss: 0.2401 / Time taken: 0:18:33 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 02/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 71 / Train-Loss: 0.2370 / Val-Loss: 0.2381 / Test-Loss: 0.2399 / Time taken: 0:18:47 / ---- Currently Best Val-Epoch: 71 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 72 / Train-Loss: 0.2369 / Val-Loss: 0.2383 / Test-Loss: 0.2401 / Time taken: 0:19:01 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 02/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 73 / Train-Loss: 0.2369 / Val-Loss: 0.2380 / Test-Loss: 0.2396 / Time taken: 0:19:16 / ---- Currently Best Val-Epoch: 73 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 74 / Train-Loss: 0.2368 / Val-Loss: 0.2389 / Test-Loss: 0.2404 / Time taken: 0:19:31 / ---- Currently Best Val-Epoch: 73 \n","Ensemble: 02/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 75 / Train-Loss: 0.2367 / Val-Loss: 0.2380 / Test-Loss: 0.2398 / Time taken: 0:19:45 / ---- Currently Best Val-Epoch: 75 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 76 / Train-Loss: 0.2368 / Val-Loss: 0.2378 / Test-Loss: 0.2396 / Time taken: 0:19:59 / ---- Currently Best Val-Epoch: 76 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 77 / Train-Loss: 0.2367 / Val-Loss: 0.2378 / Test-Loss: 0.2397 / Time taken: 0:20:21 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 78 / Train-Loss: 0.2365 / Val-Loss: 0.2380 / Test-Loss: 0.2398 / Time taken: 0:20:34 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 79 / Train-Loss: 0.2366 / Val-Loss: 0.2383 / Test-Loss: 0.2400 / Time taken: 0:20:49 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 80 / Train-Loss: 0.2365 / Val-Loss: 0.2379 / Test-Loss: 0.2396 / Time taken: 0:21:10 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0348 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 81 / Train-Loss: 0.2366 / Val-Loss: 0.2389 / Test-Loss: 0.2401 / Time taken: 0:21:32 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 82 / Train-Loss: 0.2365 / Val-Loss: 0.2381 / Test-Loss: 0.2397 / Time taken: 0:21:45 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 83 / Train-Loss: 0.2366 / Val-Loss: 0.2387 / Test-Loss: 0.2399 / Time taken: 0:22:01 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 84 / Train-Loss: 0.2364 / Val-Loss: 0.2382 / Test-Loss: 0.2399 / Time taken: 0:22:22 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 85 / Train-Loss: 0.2364 / Val-Loss: 0.2390 / Test-Loss: 0.2403 / Time taken: 0:22:35 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 86 / Train-Loss: 0.2364 / Val-Loss: 0.2383 / Test-Loss: 0.2398 / Time taken: 0:22:48 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 87 / Train-Loss: 0.2364 / Val-Loss: 0.2381 / Test-Loss: 0.2398 / Time taken: 0:23:03 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 88 / Train-Loss: 0.2363 / Val-Loss: 0.2383 / Test-Loss: 0.2400 / Time taken: 0:23:17 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 89 / Train-Loss: 0.2364 / Val-Loss: 0.2381 / Test-Loss: 0.2399 / Time taken: 0:23:31 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 90 / Train-Loss: 0.2364 / Val-Loss: 0.2383 / Test-Loss: 0.2398 / Time taken: 0:23:46 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 91 / Train-Loss: 0.2363 / Val-Loss: 0.2381 / Test-Loss: 0.2398 / Time taken: 0:24:00 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 02/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 92 / Train-Loss: 0.2363 / Val-Loss: 0.2384 / Test-Loss: 0.2397 / Time taken: 0:24:13 / ---- Currently Best Val-Epoch: 76 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 15ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-7dcd3730-3cda-4e8a-a5a0-da30b087f676\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>LocalGLMnet (run: 13)</td>\n","      <td>19</td>\n","      <td>20.083682</td>\n","      <td>1737</td>\n","      <td>0.237316</td>\n","      <td>0.239288</td>\n","      <td>0.073202</td>\n","      <td>0.073597</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>LocalGLMnet (run: 14)</td>\n","      <td>28</td>\n","      <td>24.299453</td>\n","      <td>1737</td>\n","      <td>0.236903</td>\n","      <td>0.239005</td>\n","      <td>0.075655</td>\n","      <td>0.076141</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>FT_transformer (run: 0)</td>\n","      <td>82</td>\n","      <td>1483.549221</td>\n","      <td>27133</td>\n","      <td>0.238317</td>\n","      <td>0.239865</td>\n","      <td>0.060856</td>\n","      <td>0.061208</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>FT_transformer (run: 1)</td>\n","      <td>89</td>\n","      <td>1614.216463</td>\n","      <td>27133</td>\n","      <td>0.237163</td>\n","      <td>0.238795</td>\n","      <td>0.061112</td>\n","      <td>0.061284</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>FT_transformer (run: 2)</td>\n","      <td>76</td>\n","      <td>1453.342622</td>\n","      <td>27133</td>\n","      <td>0.238176</td>\n","      <td>0.239629</td>\n","      <td>0.060320</td>\n","      <td>0.060438</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>123 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dcd3730-3cda-4e8a-a5a0-da30b087f676')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7dcd3730-3cda-4e8a-a5a0-da30b087f676 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7dcd3730-3cda-4e8a-a5a0-da30b087f676');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-516224f2-86a1-483c-9961-e7b7b3464225\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-516224f2-86a1-483c-9961-e7b7b3464225')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-516224f2-86a1-483c-9961-e7b7b3464225 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","118       LocalGLMnet (run: 13)      19    20.083682           1737   \n","119       LocalGLMnet (run: 14)      28    24.299453           1737   \n","120     FT_transformer (run: 0)      82  1483.549221          27133   \n","121     FT_transformer (run: 1)      89  1614.216463          27133   \n","122     FT_transformer (run: 2)      76  1453.342622          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","118    0.237316   0.239288             0.073202            0.073597  \n","119    0.236903   0.239005             0.075655            0.076141  \n","120    0.238317   0.239865             0.060856            0.061208  \n","121    0.237163   0.238795             0.061112            0.061284  \n","122    0.238176   0.239629             0.060320            0.060438  \n","\n","[123 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 03-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 03/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0299  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 0 / Train-Loss: 0.2761 / Val-Loss: 0.2597 / Test-Loss: 0.2550 / Time taken: 0:00:44 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0304  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 1 / Train-Loss: 0.2509 / Val-Loss: 0.2575 / Test-Loss: 0.2524 / Time taken: 0:00:57 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0309  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 2 / Train-Loss: 0.2450 / Val-Loss: 0.2554 / Test-Loss: 0.2500 / Time taken: 0:01:11 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0316  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 3 / Train-Loss: 0.2417 / Val-Loss: 0.2538 / Test-Loss: 0.2481 / Time taken: 0:01:25 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.032   : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 4 / Train-Loss: 0.2406 / Val-Loss: 0.2531 / Test-Loss: 0.2471 / Time taken: 0:01:38 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0322  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 5 / Train-Loss: 0.2401 / Val-Loss: 0.2524 / Test-Loss: 0.2463 / Time taken: 0:01:52 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 6 / Train-Loss: 0.2397 / Val-Loss: 0.2519 / Test-Loss: 0.2457 / Time taken: 0:02:06 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 7 / Train-Loss: 0.2394 / Val-Loss: 0.2513 / Test-Loss: 0.2451 / Time taken: 0:02:20 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 8 / Train-Loss: 0.2392 / Val-Loss: 0.2511 / Test-Loss: 0.2448 / Time taken: 0:02:34 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 9 / Train-Loss: 0.2391 / Val-Loss: 0.2507 / Test-Loss: 0.2444 / Time taken: 0:02:55 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 10 / Train-Loss: 0.2388 / Val-Loss: 0.2503 / Test-Loss: 0.2439 / Time taken: 0:03:10 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 03/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 11 / Train-Loss: 0.2388 / Val-Loss: 0.2503 / Test-Loss: 0.2439 / Time taken: 0:03:23 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 12 / Train-Loss: 0.2385 / Val-Loss: 0.2501 / Test-Loss: 0.2437 / Time taken: 0:03:38 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 13 / Train-Loss: 0.2384 / Val-Loss: 0.2497 / Test-Loss: 0.2433 / Time taken: 0:04:00 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 14 / Train-Loss: 0.2383 / Val-Loss: 0.2496 / Test-Loss: 0.2433 / Time taken: 0:04:13 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 15 / Train-Loss: 0.2384 / Val-Loss: 0.2491 / Test-Loss: 0.2427 / Time taken: 0:04:35 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 16 / Train-Loss: 0.2381 / Val-Loss: 0.2493 / Test-Loss: 0.2429 / Time taken: 0:04:50 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 03/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 17 / Train-Loss: 0.2380 / Val-Loss: 0.2489 / Test-Loss: 0.2426 / Time taken: 0:05:12 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 18 / Train-Loss: 0.2379 / Val-Loss: 0.2487 / Test-Loss: 0.2423 / Time taken: 0:05:26 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 19 / Train-Loss: 0.2378 / Val-Loss: 0.2487 / Test-Loss: 0.2422 / Time taken: 0:05:50 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 20 / Train-Loss: 0.2379 / Val-Loss: 0.2488 / Test-Loss: 0.2423 / Time taken: 0:06:05 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 03/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 21 / Train-Loss: 0.2379 / Val-Loss: 0.2485 / Test-Loss: 0.2421 / Time taken: 0:06:21 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 22 / Train-Loss: 0.2377 / Val-Loss: 0.2485 / Test-Loss: 0.2420 / Time taken: 0:06:35 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 03/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 23 / Train-Loss: 0.2377 / Val-Loss: 0.2484 / Test-Loss: 0.2418 / Time taken: 0:06:49 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 24 / Train-Loss: 0.2377 / Val-Loss: 0.2484 / Test-Loss: 0.2418 / Time taken: 0:07:03 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 03/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 25 / Train-Loss: 0.2377 / Val-Loss: 0.2480 / Test-Loss: 0.2414 / Time taken: 0:07:19 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 26 / Train-Loss: 0.2376 / Val-Loss: 0.2482 / Test-Loss: 0.2416 / Time taken: 0:07:37 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 03/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 27 / Train-Loss: 0.2375 / Val-Loss: 0.2482 / Test-Loss: 0.2416 / Time taken: 0:07:52 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 03/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 28 / Train-Loss: 0.2374 / Val-Loss: 0.2484 / Test-Loss: 0.2418 / Time taken: 0:08:14 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 03/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 29 / Train-Loss: 0.2375 / Val-Loss: 0.2481 / Test-Loss: 0.2415 / Time taken: 0:08:31 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 03/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 30 / Train-Loss: 0.2375 / Val-Loss: 0.2480 / Test-Loss: 0.2414 / Time taken: 0:08:46 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 31 / Train-Loss: 0.2373 / Val-Loss: 0.2481 / Test-Loss: 0.2414 / Time taken: 0:09:02 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 03/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 32 / Train-Loss: 0.2373 / Val-Loss: 0.2481 / Test-Loss: 0.2414 / Time taken: 0:09:17 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 03/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 33 / Train-Loss: 0.2372 / Val-Loss: 0.2477 / Test-Loss: 0.2411 / Time taken: 0:09:32 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 34 / Train-Loss: 0.2372 / Val-Loss: 0.2478 / Test-Loss: 0.2411 / Time taken: 0:09:48 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 03/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0349 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 35 / Train-Loss: 0.2372 / Val-Loss: 0.2473 / Test-Loss: 0.2408 / Time taken: 0:10:09 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 36 / Train-Loss: 0.2372 / Val-Loss: 0.2473 / Test-Loss: 0.2408 / Time taken: 0:10:32 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 03/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 37 / Train-Loss: 0.2370 / Val-Loss: 0.2469 / Test-Loss: 0.2405 / Time taken: 0:10:48 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 38 / Train-Loss: 0.2371 / Val-Loss: 0.2471 / Test-Loss: 0.2406 / Time taken: 0:11:10 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 03/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 39 / Train-Loss: 0.2371 / Val-Loss: 0.2474 / Test-Loss: 0.2409 / Time taken: 0:11:29 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 03/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 40 / Train-Loss: 0.2370 / Val-Loss: 0.2469 / Test-Loss: 0.2406 / Time taken: 0:11:44 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 03/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 41 / Train-Loss: 0.2368 / Val-Loss: 0.2469 / Test-Loss: 0.2406 / Time taken: 0:12:00 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 03/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 42 / Train-Loss: 0.2365 / Val-Loss: 0.2466 / Test-Loss: 0.2403 / Time taken: 0:12:21 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 43 / Train-Loss: 0.2368 / Val-Loss: 0.2473 / Test-Loss: 0.2408 / Time taken: 0:12:37 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 03/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 44 / Train-Loss: 0.2366 / Val-Loss: 0.2458 / Test-Loss: 0.2398 / Time taken: 0:12:50 / ---- Currently Best Val-Epoch: 44 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0348 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 45 / Train-Loss: 0.2367 / Val-Loss: 0.2465 / Test-Loss: 0.2402 / Time taken: 0:13:06 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 46 / Train-Loss: 0.2365 / Val-Loss: 0.2463 / Test-Loss: 0.2401 / Time taken: 0:13:25 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 47 / Train-Loss: 0.2364 / Val-Loss: 0.2462 / Test-Loss: 0.2401 / Time taken: 0:13:39 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 48 / Train-Loss: 0.2365 / Val-Loss: 0.2461 / Test-Loss: 0.2400 / Time taken: 0:13:53 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 49 / Train-Loss: 0.2364 / Val-Loss: 0.2464 / Test-Loss: 0.2401 / Time taken: 0:14:07 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 50 / Train-Loss: 0.2364 / Val-Loss: 0.2465 / Test-Loss: 0.2402 / Time taken: 0:14:28 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 51 / Train-Loss: 0.2363 / Val-Loss: 0.2460 / Test-Loss: 0.2399 / Time taken: 0:14:44 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 52 / Train-Loss: 0.2363 / Val-Loss: 0.2460 / Test-Loss: 0.2402 / Time taken: 0:15:06 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 53 / Train-Loss: 0.2363 / Val-Loss: 0.2463 / Test-Loss: 0.2403 / Time taken: 0:15:19 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 54 / Train-Loss: 0.2362 / Val-Loss: 0.2461 / Test-Loss: 0.2401 / Time taken: 0:15:33 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 55 / Train-Loss: 0.2361 / Val-Loss: 0.2466 / Test-Loss: 0.2406 / Time taken: 0:15:49 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 56 / Train-Loss: 0.2361 / Val-Loss: 0.2460 / Test-Loss: 0.2400 / Time taken: 0:16:03 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 57 / Train-Loss: 0.2360 / Val-Loss: 0.2460 / Test-Loss: 0.2403 / Time taken: 0:16:18 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 58 / Train-Loss: 0.2363 / Val-Loss: 0.2461 / Test-Loss: 0.2405 / Time taken: 0:16:32 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 59 / Train-Loss: 0.2361 / Val-Loss: 0.2467 / Test-Loss: 0.2406 / Time taken: 0:16:47 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 03/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 60 / Train-Loss: 0.2360 / Val-Loss: 0.2465 / Test-Loss: 0.2405 / Time taken: 0:17:01 / ---- Currently Best Val-Epoch: 44 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 2s 24ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-fdba4ed3-e46a-405d-9218-8d752bdb261c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>LocalGLMnet (run: 14)</td>\n","      <td>28</td>\n","      <td>24.299453</td>\n","      <td>1737</td>\n","      <td>0.236903</td>\n","      <td>0.239005</td>\n","      <td>0.075655</td>\n","      <td>0.076141</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>FT_transformer (run: 0)</td>\n","      <td>82</td>\n","      <td>1483.549221</td>\n","      <td>27133</td>\n","      <td>0.238317</td>\n","      <td>0.239865</td>\n","      <td>0.060856</td>\n","      <td>0.061208</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>FT_transformer (run: 1)</td>\n","      <td>89</td>\n","      <td>1614.216463</td>\n","      <td>27133</td>\n","      <td>0.237163</td>\n","      <td>0.238795</td>\n","      <td>0.061112</td>\n","      <td>0.061284</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>FT_transformer (run: 2)</td>\n","      <td>76</td>\n","      <td>1453.342622</td>\n","      <td>27133</td>\n","      <td>0.238176</td>\n","      <td>0.239629</td>\n","      <td>0.060320</td>\n","      <td>0.060438</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>FT_transformer (run: 3)</td>\n","      <td>44</td>\n","      <td>1021.084522</td>\n","      <td>27133</td>\n","      <td>0.238937</td>\n","      <td>0.239780</td>\n","      <td>0.059604</td>\n","      <td>0.059712</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>124 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdba4ed3-e46a-405d-9218-8d752bdb261c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fdba4ed3-e46a-405d-9218-8d752bdb261c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fdba4ed3-e46a-405d-9218-8d752bdb261c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-64834fa2-6311-48d4-8e84-0906e7782b51\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64834fa2-6311-48d4-8e84-0906e7782b51')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-64834fa2-6311-48d4-8e84-0906e7782b51 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","119       LocalGLMnet (run: 14)      28    24.299453           1737   \n","120     FT_transformer (run: 0)      82  1483.549221          27133   \n","121     FT_transformer (run: 1)      89  1614.216463          27133   \n","122     FT_transformer (run: 2)      76  1453.342622          27133   \n","123     FT_transformer (run: 3)      44  1021.084522          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","119    0.236903   0.239005             0.075655            0.076141  \n","120    0.238317   0.239865             0.060856            0.061208  \n","121    0.237163   0.238795             0.061112            0.061284  \n","122    0.238176   0.239629             0.060320            0.060438  \n","123    0.238937   0.239780             0.059604            0.059712  \n","\n","[124 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 04-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 04/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0311  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 0 / Train-Loss: 0.3085 / Val-Loss: 0.2607 / Test-Loss: 0.2655 / Time taken: 0:00:33 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.03    : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 1 / Train-Loss: 0.2575 / Val-Loss: 0.2500 / Test-Loss: 0.2553 / Time taken: 0:00:56 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0303  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 2 / Train-Loss: 0.2518 / Val-Loss: 0.2461 / Test-Loss: 0.2511 / Time taken: 0:01:17 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0304  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 3 / Train-Loss: 0.2449 / Val-Loss: 0.2438 / Test-Loss: 0.2483 / Time taken: 0:01:37 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0313  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 4 / Train-Loss: 0.2424 / Val-Loss: 0.2421 / Test-Loss: 0.2465 / Time taken: 0:01:52 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0317  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 5 / Train-Loss: 0.2414 / Val-Loss: 0.2411 / Test-Loss: 0.2455 / Time taken: 0:02:05 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.032   : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 6 / Train-Loss: 0.2408 / Val-Loss: 0.2407 / Test-Loss: 0.2450 / Time taken: 0:02:19 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0324  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 7 / Train-Loss: 0.2404 / Val-Loss: 0.2402 / Test-Loss: 0.2444 / Time taken: 0:02:38 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0319  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 8 / Train-Loss: 0.2403 / Val-Loss: 0.2400 / Test-Loss: 0.2443 / Time taken: 0:02:55 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 9 / Train-Loss: 0.2400 / Val-Loss: 0.2393 / Test-Loss: 0.2434 / Time taken: 0:03:08 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 10 / Train-Loss: 0.2397 / Val-Loss: 0.2397 / Test-Loss: 0.2437 / Time taken: 0:03:22 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 04/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 11 / Train-Loss: 0.2396 / Val-Loss: 0.2392 / Test-Loss: 0.2432 / Time taken: 0:03:36 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 12 / Batch: 2 / Train-Loss (Batch): 0.1327   : [------------------------------] 0.4%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 04/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 12 / Train-Loss: 0.2394 / Val-Loss: 0.2389 / Test-Loss: 0.2430 / Time taken: 0:03:52 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 13 / Train-Loss: 0.2393 / Val-Loss: 0.2385 / Test-Loss: 0.2426 / Time taken: 0:04:14 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 14 / Train-Loss: 0.2392 / Val-Loss: 0.2385 / Test-Loss: 0.2425 / Time taken: 0:04:29 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 15 / Train-Loss: 0.2391 / Val-Loss: 0.2384 / Test-Loss: 0.2424 / Time taken: 0:04:50 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 16 / Train-Loss: 0.2392 / Val-Loss: 0.2379 / Test-Loss: 0.2418 / Time taken: 0:05:09 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 17 / Train-Loss: 0.2390 / Val-Loss: 0.2382 / Test-Loss: 0.2421 / Time taken: 0:05:35 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 04/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 18 / Train-Loss: 0.2390 / Val-Loss: 0.2381 / Test-Loss: 0.2420 / Time taken: 0:05:55 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 04/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 19 / Train-Loss: 0.2390 / Val-Loss: 0.2376 / Test-Loss: 0.2416 / Time taken: 0:06:14 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 20 / Train-Loss: 0.2390 / Val-Loss: 0.2374 / Test-Loss: 0.2412 / Time taken: 0:06:31 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 21 / Train-Loss: 0.2389 / Val-Loss: 0.2373 / Test-Loss: 0.2411 / Time taken: 0:06:54 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 22 / Train-Loss: 0.2388 / Val-Loss: 0.2372 / Test-Loss: 0.2410 / Time taken: 0:07:10 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 23 / Train-Loss: 0.2389 / Val-Loss: 0.2371 / Test-Loss: 0.2409 / Time taken: 0:07:33 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 24 / Train-Loss: 0.2387 / Val-Loss: 0.2374 / Test-Loss: 0.2413 / Time taken: 0:07:56 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 04/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 25 / Train-Loss: 0.2388 / Val-Loss: 0.2371 / Test-Loss: 0.2409 / Time taken: 0:08:12 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 26 / Train-Loss: 0.2387 / Val-Loss: 0.2370 / Test-Loss: 0.2408 / Time taken: 0:08:35 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 27 / Train-Loss: 0.2387 / Val-Loss: 0.2369 / Test-Loss: 0.2407 / Time taken: 0:08:52 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 28 / Train-Loss: 0.2387 / Val-Loss: 0.2369 / Test-Loss: 0.2407 / Time taken: 0:09:16 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 29 / Train-Loss: 0.2386 / Val-Loss: 0.2368 / Test-Loss: 0.2405 / Time taken: 0:09:34 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 30 / Train-Loss: 0.2385 / Val-Loss: 0.2370 / Test-Loss: 0.2407 / Time taken: 0:09:57 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 04/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 31 / Train-Loss: 0.2385 / Val-Loss: 0.2367 / Test-Loss: 0.2405 / Time taken: 0:10:20 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 32 / Train-Loss: 0.2384 / Val-Loss: 0.2366 / Test-Loss: 0.2403 / Time taken: 0:10:36 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 33 / Train-Loss: 0.2385 / Val-Loss: 0.2367 / Test-Loss: 0.2404 / Time taken: 0:10:56 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 04/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 34 / Train-Loss: 0.2385 / Val-Loss: 0.2366 / Test-Loss: 0.2403 / Time taken: 0:11:13 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 35 / Train-Loss: 0.2383 / Val-Loss: 0.2367 / Test-Loss: 0.2405 / Time taken: 0:11:32 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 04/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 36 / Train-Loss: 0.2385 / Val-Loss: 0.2365 / Test-Loss: 0.2402 / Time taken: 0:11:53 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 37 / Train-Loss: 0.2383 / Val-Loss: 0.2366 / Test-Loss: 0.2403 / Time taken: 0:12:16 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 04/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 38 / Train-Loss: 0.2384 / Val-Loss: 0.2363 / Test-Loss: 0.2401 / Time taken: 0:12:35 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 39 / Train-Loss: 0.2382 / Val-Loss: 0.2364 / Test-Loss: 0.2402 / Time taken: 0:12:56 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 04/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 40 / Train-Loss: 0.2382 / Val-Loss: 0.2363 / Test-Loss: 0.2400 / Time taken: 0:13:17 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 41 / Train-Loss: 0.2383 / Val-Loss: 0.2363 / Test-Loss: 0.2400 / Time taken: 0:13:37 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 42 / Train-Loss: 0.2382 / Val-Loss: 0.2362 / Test-Loss: 0.2400 / Time taken: 0:13:58 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 43 / Train-Loss: 0.2381 / Val-Loss: 0.2361 / Test-Loss: 0.2399 / Time taken: 0:14:18 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 44 / Train-Loss: 0.2380 / Val-Loss: 0.2363 / Test-Loss: 0.2400 / Time taken: 0:14:42 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 45 / Train-Loss: 0.2380 / Val-Loss: 0.2359 / Test-Loss: 0.2397 / Time taken: 0:15:00 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 46 / Train-Loss: 0.2381 / Val-Loss: 0.2359 / Test-Loss: 0.2397 / Time taken: 0:15:22 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 04/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 47 / Train-Loss: 0.2380 / Val-Loss: 0.2359 / Test-Loss: 0.2398 / Time taken: 0:15:40 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 04/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 48 / Train-Loss: 0.2380 / Val-Loss: 0.2359 / Test-Loss: 0.2397 / Time taken: 0:16:02 / ---- Currently Best Val-Epoch: 48 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 49 / Train-Loss: 0.2379 / Val-Loss: 0.2359 / Test-Loss: 0.2398 / Time taken: 0:16:19 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 04/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 50 / Train-Loss: 0.2378 / Val-Loss: 0.2358 / Test-Loss: 0.2395 / Time taken: 0:16:36 / ---- Currently Best Val-Epoch: 50 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 51 / Train-Loss: 0.2378 / Val-Loss: 0.2358 / Test-Loss: 0.2397 / Time taken: 0:16:58 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 04/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 52 / Train-Loss: 0.2377 / Val-Loss: 0.2356 / Test-Loss: 0.2394 / Time taken: 0:17:16 / ---- Currently Best Val-Epoch: 52 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 53 / Train-Loss: 0.2377 / Val-Loss: 0.2357 / Test-Loss: 0.2395 / Time taken: 0:17:37 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 54 / Train-Loss: 0.2376 / Val-Loss: 0.2354 / Test-Loss: 0.2394 / Time taken: 0:17:54 / ---- Currently Best Val-Epoch: 54 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 55 / Train-Loss: 0.2376 / Val-Loss: 0.2354 / Test-Loss: 0.2394 / Time taken: 0:18:16 / ---- Currently Best Val-Epoch: 55 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 56 / Train-Loss: 0.2377 / Val-Loss: 0.2355 / Test-Loss: 0.2394 / Time taken: 0:18:38 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 04/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 57 / Train-Loss: 0.2375 / Val-Loss: 0.2354 / Test-Loss: 0.2393 / Time taken: 0:18:56 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 04/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 58 / Train-Loss: 0.2374 / Val-Loss: 0.2356 / Test-Loss: 0.2394 / Time taken: 0:19:14 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 04/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0347 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 59 / Train-Loss: 0.2373 / Val-Loss: 0.2350 / Test-Loss: 0.2390 / Time taken: 0:19:38 / ---- Currently Best Val-Epoch: 59 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 60 / Train-Loss: 0.2373 / Val-Loss: 0.2353 / Test-Loss: 0.2391 / Time taken: 0:20:01 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 04/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 61 / Train-Loss: 0.2372 / Val-Loss: 0.2352 / Test-Loss: 0.2390 / Time taken: 0:20:23 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 04/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 62 / Train-Loss: 0.2372 / Val-Loss: 0.2355 / Test-Loss: 0.2391 / Time taken: 0:20:39 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 04/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 63 / Train-Loss: 0.2371 / Val-Loss: 0.2350 / Test-Loss: 0.2391 / Time taken: 0:20:59 / ---- Currently Best Val-Epoch: 63 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 64 / Train-Loss: 0.2370 / Val-Loss: 0.2354 / Test-Loss: 0.2393 / Time taken: 0:21:21 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 65 / Train-Loss: 0.2371 / Val-Loss: 0.2356 / Test-Loss: 0.2392 / Time taken: 0:21:43 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 66 / Train-Loss: 0.2371 / Val-Loss: 0.2354 / Test-Loss: 0.2391 / Time taken: 0:22:05 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 67 / Train-Loss: 0.2370 / Val-Loss: 0.2355 / Test-Loss: 0.2391 / Time taken: 0:22:27 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 68 / Train-Loss: 0.2369 / Val-Loss: 0.2361 / Test-Loss: 0.2394 / Time taken: 0:22:44 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0356 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 69 / Train-Loss: 0.2369 / Val-Loss: 0.2351 / Test-Loss: 0.2391 / Time taken: 0:23:02 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 70 / Train-Loss: 0.2369 / Val-Loss: 0.2354 / Test-Loss: 0.2390 / Time taken: 0:23:20 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0347 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 71 / Train-Loss: 0.2369 / Val-Loss: 0.2352 / Test-Loss: 0.2391 / Time taken: 0:23:39 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 72 / Train-Loss: 0.2368 / Val-Loss: 0.2353 / Test-Loss: 0.2391 / Time taken: 0:24:02 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0348 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 73 / Train-Loss: 0.2368 / Val-Loss: 0.2352 / Test-Loss: 0.2390 / Time taken: 0:24:24 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 74 / Train-Loss: 0.2368 / Val-Loss: 0.2352 / Test-Loss: 0.2389 / Time taken: 0:24:44 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 04/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 75 / Train-Loss: 0.2368 / Val-Loss: 0.2349 / Test-Loss: 0.2388 / Time taken: 0:25:06 / ---- Currently Best Val-Epoch: 75 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 76 / Train-Loss: 0.2367 / Val-Loss: 0.2352 / Test-Loss: 0.2391 / Time taken: 0:25:25 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0352 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 77 / Train-Loss: 0.2368 / Val-Loss: 0.2353 / Test-Loss: 0.2389 / Time taken: 0:25:39 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 78 / Train-Loss: 0.2367 / Val-Loss: 0.2350 / Test-Loss: 0.2390 / Time taken: 0:25:53 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0351 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 79 / Train-Loss: 0.2365 / Val-Loss: 0.2351 / Test-Loss: 0.2388 / Time taken: 0:26:11 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 80 / Train-Loss: 0.2367 / Val-Loss: 0.2350 / Test-Loss: 0.2389 / Time taken: 0:26:35 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0353 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 81 / Train-Loss: 0.2367 / Val-Loss: 0.2352 / Test-Loss: 0.2392 / Time taken: 0:26:53 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 82 / Train-Loss: 0.2366 / Val-Loss: 0.2351 / Test-Loss: 0.2389 / Time taken: 0:27:15 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 83 / Train-Loss: 0.2367 / Val-Loss: 0.2350 / Test-Loss: 0.2389 / Time taken: 0:27:38 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 84 / Train-Loss: 0.2366 / Val-Loss: 0.2351 / Test-Loss: 0.2389 / Time taken: 0:27:59 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 85 / Train-Loss: 0.2365 / Val-Loss: 0.2350 / Test-Loss: 0.2387 / Time taken: 0:28:22 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0347 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 86 / Train-Loss: 0.2365 / Val-Loss: 0.2352 / Test-Loss: 0.2389 / Time taken: 0:28:38 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0352 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 87 / Train-Loss: 0.2366 / Val-Loss: 0.2351 / Test-Loss: 0.2391 / Time taken: 0:29:20 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0349 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 88 / Train-Loss: 0.2365 / Val-Loss: 0.2351 / Test-Loss: 0.2390 / Time taken: 0:29:42 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0353 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 89 / Train-Loss: 0.2365 / Val-Loss: 0.2351 / Test-Loss: 0.2389 / Time taken: 0:30:01 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 04/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 90 / Train-Loss: 0.2365 / Val-Loss: 0.2348 / Test-Loss: 0.2387 / Time taken: 0:30:22 / ---- Currently Best Val-Epoch: 90 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 91 / Train-Loss: 0.2364 / Val-Loss: 0.2350 / Test-Loss: 0.2389 / Time taken: 0:30:40 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 92 / Train-Loss: 0.2364 / Val-Loss: 0.2353 / Test-Loss: 0.2391 / Time taken: 0:30:57 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 93 / Train-Loss: 0.2363 / Val-Loss: 0.2352 / Test-Loss: 0.2391 / Time taken: 0:31:19 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.0349 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 94 / Train-Loss: 0.2364 / Val-Loss: 0.2349 / Test-Loss: 0.2388 / Time taken: 0:31:36 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.0354 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 95 / Train-Loss: 0.2363 / Val-Loss: 0.2350 / Test-Loss: 0.2389 / Time taken: 0:31:52 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0349 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 96 / Train-Loss: 0.2362 / Val-Loss: 0.2351 / Test-Loss: 0.2388 / Time taken: 0:32:15 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.0361 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 97 / Train-Loss: 0.2363 / Val-Loss: 0.2349 / Test-Loss: 0.2385 / Time taken: 0:32:30 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 98 / Batch: 536 / Train-Loss (Batch): 0.035  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 98 / Train-Loss: 0.2362 / Val-Loss: 0.2349 / Test-Loss: 0.2387 / Time taken: 0:32:52 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 99 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 99 / Train-Loss: 0.2362 / Val-Loss: 0.2351 / Test-Loss: 0.2389 / Time taken: 0:33:09 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 100 / Batch: 536 / Train-Loss (Batch): 0.034 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 100 / Train-Loss: 0.2362 / Val-Loss: 0.2350 / Test-Loss: 0.2389 / Time taken: 0:33:23 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 101 / Batch: 536 / Train-Loss (Batch): 0.0351: [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 101 / Train-Loss: 0.2362 / Val-Loss: 0.2350 / Test-Loss: 0.2388 / Time taken: 0:33:38 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 102 / Batch: 536 / Train-Loss (Batch): 0.0353: [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 102 / Train-Loss: 0.2361 / Val-Loss: 0.2349 / Test-Loss: 0.2386 / Time taken: 0:33:52 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 103 / Batch: 536 / Train-Loss (Batch): 0.0349: [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 103 / Train-Loss: 0.2361 / Val-Loss: 0.2351 / Test-Loss: 0.2390 / Time taken: 0:34:14 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 104 / Batch: 536 / Train-Loss (Batch): 0.0345: [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 104 / Train-Loss: 0.2362 / Val-Loss: 0.2348 / Test-Loss: 0.2387 / Time taken: 0:34:28 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 105 / Batch: 536 / Train-Loss (Batch): 0.034 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 105 / Train-Loss: 0.2361 / Val-Loss: 0.2350 / Test-Loss: 0.2388 / Time taken: 0:34:51 / ---- Currently Best Val-Epoch: 90 \n","Ensemble: 04/14 / Epoch: 106 / Batch: 536 / Train-Loss (Batch): 0.0348: [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 106 / Train-Loss: 0.2360 / Val-Loss: 0.2350 / Test-Loss: 0.2390 / Time taken: 0:35:07 / ---- Currently Best Val-Epoch: 90 \n","596/596 [==============================] - 11s 17ms/step\n","67/67 [==============================] - 1s 19ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-d7f6620d-ef26-4f67-9e37-0f679c21d03d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>FT_transformer (run: 0)</td>\n","      <td>82</td>\n","      <td>1483.549221</td>\n","      <td>27133</td>\n","      <td>0.238317</td>\n","      <td>0.239865</td>\n","      <td>0.060856</td>\n","      <td>0.061208</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>FT_transformer (run: 1)</td>\n","      <td>89</td>\n","      <td>1614.216463</td>\n","      <td>27133</td>\n","      <td>0.237163</td>\n","      <td>0.238795</td>\n","      <td>0.061112</td>\n","      <td>0.061284</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>FT_transformer (run: 2)</td>\n","      <td>76</td>\n","      <td>1453.342622</td>\n","      <td>27133</td>\n","      <td>0.238176</td>\n","      <td>0.239629</td>\n","      <td>0.060320</td>\n","      <td>0.060438</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>FT_transformer (run: 3)</td>\n","      <td>44</td>\n","      <td>1021.084522</td>\n","      <td>27133</td>\n","      <td>0.238937</td>\n","      <td>0.239780</td>\n","      <td>0.059604</td>\n","      <td>0.059712</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>FT_transformer (run: 4)</td>\n","      <td>90</td>\n","      <td>2107.885792</td>\n","      <td>27133</td>\n","      <td>0.236846</td>\n","      <td>0.238730</td>\n","      <td>0.063062</td>\n","      <td>0.063192</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>125 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7f6620d-ef26-4f67-9e37-0f679c21d03d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d7f6620d-ef26-4f67-9e37-0f679c21d03d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d7f6620d-ef26-4f67-9e37-0f679c21d03d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b2b960c4-bfbb-44fa-be81-c9ccbe89065b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2b960c4-bfbb-44fa-be81-c9ccbe89065b')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b2b960c4-bfbb-44fa-be81-c9ccbe89065b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","120     FT_transformer (run: 0)      82  1483.549221          27133   \n","121     FT_transformer (run: 1)      89  1614.216463          27133   \n","122     FT_transformer (run: 2)      76  1453.342622          27133   \n","123     FT_transformer (run: 3)      44  1021.084522          27133   \n","124     FT_transformer (run: 4)      90  2107.885792          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","120    0.238317   0.239865             0.060856            0.061208  \n","121    0.237163   0.238795             0.061112            0.061284  \n","122    0.238176   0.239629             0.060320            0.060438  \n","123    0.238937   0.239780             0.059604            0.059712  \n","124    0.236846   0.238730             0.063062            0.063192  \n","\n","[125 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 05-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 05/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0304  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 0 / Train-Loss: 0.2981 / Val-Loss: 0.2504 / Test-Loss: 0.2561 / Time taken: 0:00:33 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0305  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 1 / Train-Loss: 0.2520 / Val-Loss: 0.2464 / Test-Loss: 0.2516 / Time taken: 0:00:48 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0305  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 2 / Train-Loss: 0.2444 / Val-Loss: 0.2444 / Test-Loss: 0.2489 / Time taken: 0:01:02 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0315  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 3 / Train-Loss: 0.2420 / Val-Loss: 0.2435 / Test-Loss: 0.2475 / Time taken: 0:01:18 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0318  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 4 / Train-Loss: 0.2411 / Val-Loss: 0.2429 / Test-Loss: 0.2467 / Time taken: 0:01:32 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0322  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 5 / Train-Loss: 0.2405 / Val-Loss: 0.2428 / Test-Loss: 0.2464 / Time taken: 0:01:47 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 6 / Train-Loss: 0.2402 / Val-Loss: 0.2421 / Test-Loss: 0.2455 / Time taken: 0:02:02 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 7 / Train-Loss: 0.2399 / Val-Loss: 0.2423 / Test-Loss: 0.2456 / Time taken: 0:02:17 / ---- Currently Best Val-Epoch: 6 \n","Ensemble: 05/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 8 / Train-Loss: 0.2396 / Val-Loss: 0.2419 / Test-Loss: 0.2451 / Time taken: 0:02:31 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 9 / Train-Loss: 0.2395 / Val-Loss: 0.2418 / Test-Loss: 0.2447 / Time taken: 0:02:45 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 10 / Train-Loss: 0.2393 / Val-Loss: 0.2416 / Test-Loss: 0.2445 / Time taken: 0:03:01 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 11 / Batch: 2 / Train-Loss (Batch): 0.1502   : [------------------------------] 0.4%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 05/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 11 / Train-Loss: 0.2391 / Val-Loss: 0.2415 / Test-Loss: 0.2444 / Time taken: 0:03:15 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 12 / Train-Loss: 0.2391 / Val-Loss: 0.2413 / Test-Loss: 0.2440 / Time taken: 0:03:29 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 13 / Train-Loss: 0.2389 / Val-Loss: 0.2411 / Test-Loss: 0.2439 / Time taken: 0:03:47 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 14 / Train-Loss: 0.2390 / Val-Loss: 0.2410 / Test-Loss: 0.2438 / Time taken: 0:04:13 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 15 / Train-Loss: 0.2389 / Val-Loss: 0.2411 / Test-Loss: 0.2438 / Time taken: 0:04:28 / ---- Currently Best Val-Epoch: 14 \n","Ensemble: 05/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 16 / Train-Loss: 0.2387 / Val-Loss: 0.2409 / Test-Loss: 0.2436 / Time taken: 0:04:43 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 17 / Train-Loss: 0.2387 / Val-Loss: 0.2408 / Test-Loss: 0.2434 / Time taken: 0:04:59 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 18 / Train-Loss: 0.2387 / Val-Loss: 0.2407 / Test-Loss: 0.2433 / Time taken: 0:05:13 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 19 / Train-Loss: 0.2387 / Val-Loss: 0.2406 / Test-Loss: 0.2432 / Time taken: 0:05:28 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 20 / Train-Loss: 0.2386 / Val-Loss: 0.2405 / Test-Loss: 0.2430 / Time taken: 0:05:44 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 21 / Train-Loss: 0.2386 / Val-Loss: 0.2404 / Test-Loss: 0.2429 / Time taken: 0:05:59 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 22 / Train-Loss: 0.2386 / Val-Loss: 0.2404 / Test-Loss: 0.2428 / Time taken: 0:06:13 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 23 / Train-Loss: 0.2386 / Val-Loss: 0.2400 / Test-Loss: 0.2425 / Time taken: 0:06:28 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 24 / Train-Loss: 0.2385 / Val-Loss: 0.2400 / Test-Loss: 0.2425 / Time taken: 0:06:46 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 25 / Train-Loss: 0.2385 / Val-Loss: 0.2401 / Test-Loss: 0.2426 / Time taken: 0:07:02 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 05/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 26 / Train-Loss: 0.2384 / Val-Loss: 0.2399 / Test-Loss: 0.2422 / Time taken: 0:07:16 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 27 / Train-Loss: 0.2386 / Val-Loss: 0.2398 / Test-Loss: 0.2422 / Time taken: 0:07:38 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 28 / Train-Loss: 0.2386 / Val-Loss: 0.2397 / Test-Loss: 0.2421 / Time taken: 0:07:52 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 29 / Train-Loss: 0.2384 / Val-Loss: 0.2395 / Test-Loss: 0.2419 / Time taken: 0:08:07 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 30 / Train-Loss: 0.2384 / Val-Loss: 0.2394 / Test-Loss: 0.2419 / Time taken: 0:08:23 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 31 / Train-Loss: 0.2384 / Val-Loss: 0.2397 / Test-Loss: 0.2420 / Time taken: 0:08:45 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 05/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 32 / Train-Loss: 0.2383 / Val-Loss: 0.2394 / Test-Loss: 0.2417 / Time taken: 0:09:00 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 33 / Train-Loss: 0.2383 / Val-Loss: 0.2393 / Test-Loss: 0.2416 / Time taken: 0:09:17 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 34 / Train-Loss: 0.2383 / Val-Loss: 0.2392 / Test-Loss: 0.2415 / Time taken: 0:09:32 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 35 / Train-Loss: 0.2383 / Val-Loss: 0.2392 / Test-Loss: 0.2416 / Time taken: 0:09:48 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 05/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 36 / Train-Loss: 0.2382 / Val-Loss: 0.2392 / Test-Loss: 0.2414 / Time taken: 0:10:10 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 37 / Train-Loss: 0.2382 / Val-Loss: 0.2392 / Test-Loss: 0.2414 / Time taken: 0:10:32 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 05/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 38 / Train-Loss: 0.2382 / Val-Loss: 0.2392 / Test-Loss: 0.2415 / Time taken: 0:10:47 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 05/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 39 / Train-Loss: 0.2383 / Val-Loss: 0.2388 / Test-Loss: 0.2411 / Time taken: 0:11:03 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 40 / Train-Loss: 0.2382 / Val-Loss: 0.2388 / Test-Loss: 0.2411 / Time taken: 0:11:18 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 05/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 41 / Train-Loss: 0.2381 / Val-Loss: 0.2388 / Test-Loss: 0.2411 / Time taken: 0:11:34 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 42 / Train-Loss: 0.2381 / Val-Loss: 0.2384 / Test-Loss: 0.2406 / Time taken: 0:11:50 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 43 / Train-Loss: 0.2379 / Val-Loss: 0.2387 / Test-Loss: 0.2409 / Time taken: 0:12:07 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 05/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 44 / Train-Loss: 0.2380 / Val-Loss: 0.2386 / Test-Loss: 0.2409 / Time taken: 0:12:20 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 05/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 45 / Train-Loss: 0.2379 / Val-Loss: 0.2385 / Test-Loss: 0.2407 / Time taken: 0:12:35 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 05/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 46 / Train-Loss: 0.2379 / Val-Loss: 0.2383 / Test-Loss: 0.2406 / Time taken: 0:12:50 / ---- Currently Best Val-Epoch: 46 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 47 / Train-Loss: 0.2378 / Val-Loss: 0.2385 / Test-Loss: 0.2409 / Time taken: 0:13:07 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 05/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 48 / Train-Loss: 0.2379 / Val-Loss: 0.2382 / Test-Loss: 0.2405 / Time taken: 0:13:22 / ---- Currently Best Val-Epoch: 48 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 49 / Train-Loss: 0.2378 / Val-Loss: 0.2384 / Test-Loss: 0.2405 / Time taken: 0:13:36 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 05/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 50 / Train-Loss: 0.2377 / Val-Loss: 0.2382 / Test-Loss: 0.2405 / Time taken: 0:13:52 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 05/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 51 / Train-Loss: 0.2377 / Val-Loss: 0.2381 / Test-Loss: 0.2403 / Time taken: 0:14:06 / ---- Currently Best Val-Epoch: 51 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 52 / Train-Loss: 0.2376 / Val-Loss: 0.2380 / Test-Loss: 0.2404 / Time taken: 0:14:21 / ---- Currently Best Val-Epoch: 52 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 53 / Train-Loss: 0.2376 / Val-Loss: 0.2382 / Test-Loss: 0.2404 / Time taken: 0:14:38 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 05/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 54 / Train-Loss: 0.2375 / Val-Loss: 0.2382 / Test-Loss: 0.2404 / Time taken: 0:14:52 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 05/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 55 / Train-Loss: 0.2374 / Val-Loss: 0.2380 / Test-Loss: 0.2403 / Time taken: 0:15:07 / ---- Currently Best Val-Epoch: 55 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 56 / Train-Loss: 0.2375 / Val-Loss: 0.2379 / Test-Loss: 0.2402 / Time taken: 0:15:22 / ---- Currently Best Val-Epoch: 56 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 57 / Train-Loss: 0.2373 / Val-Loss: 0.2378 / Test-Loss: 0.2400 / Time taken: 0:15:37 / ---- Currently Best Val-Epoch: 57 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 58 / Train-Loss: 0.2373 / Val-Loss: 0.2377 / Test-Loss: 0.2400 / Time taken: 0:15:52 / ---- Currently Best Val-Epoch: 58 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 59 / Train-Loss: 0.2373 / Val-Loss: 0.2377 / Test-Loss: 0.2400 / Time taken: 0:16:06 / ---- Currently Best Val-Epoch: 59 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 60 / Train-Loss: 0.2372 / Val-Loss: 0.2378 / Test-Loss: 0.2400 / Time taken: 0:16:21 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 05/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 61 / Train-Loss: 0.2372 / Val-Loss: 0.2377 / Test-Loss: 0.2401 / Time taken: 0:16:37 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 05/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 62 / Train-Loss: 0.2371 / Val-Loss: 0.2376 / Test-Loss: 0.2399 / Time taken: 0:16:50 / ---- Currently Best Val-Epoch: 62 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0347 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 63 / Train-Loss: 0.2370 / Val-Loss: 0.2376 / Test-Loss: 0.2399 / Time taken: 0:17:13 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 05/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 64 / Train-Loss: 0.2371 / Val-Loss: 0.2372 / Test-Loss: 0.2396 / Time taken: 0:17:29 / ---- Currently Best Val-Epoch: 64 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 65 / Train-Loss: 0.2369 / Val-Loss: 0.2373 / Test-Loss: 0.2396 / Time taken: 0:17:43 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 05/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 66 / Train-Loss: 0.2369 / Val-Loss: 0.2371 / Test-Loss: 0.2395 / Time taken: 0:17:58 / ---- Currently Best Val-Epoch: 66 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 67 / Train-Loss: 0.2368 / Val-Loss: 0.2371 / Test-Loss: 0.2395 / Time taken: 0:18:14 / ---- Currently Best Val-Epoch: 67 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 68 / Train-Loss: 0.2369 / Val-Loss: 0.2375 / Test-Loss: 0.2399 / Time taken: 0:18:36 / ---- Currently Best Val-Epoch: 67 \n","Ensemble: 05/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 69 / Train-Loss: 0.2369 / Val-Loss: 0.2372 / Test-Loss: 0.2396 / Time taken: 0:18:57 / ---- Currently Best Val-Epoch: 67 \n","Ensemble: 05/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 70 / Train-Loss: 0.2369 / Val-Loss: 0.2372 / Test-Loss: 0.2397 / Time taken: 0:19:13 / ---- Currently Best Val-Epoch: 67 \n","Ensemble: 05/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 71 / Train-Loss: 0.2368 / Val-Loss: 0.2370 / Test-Loss: 0.2394 / Time taken: 0:19:27 / ---- Currently Best Val-Epoch: 71 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 72 / Train-Loss: 0.2366 / Val-Loss: 0.2374 / Test-Loss: 0.2397 / Time taken: 0:19:41 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 73 / Train-Loss: 0.2368 / Val-Loss: 0.2373 / Test-Loss: 0.2396 / Time taken: 0:20:04 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 74 / Train-Loss: 0.2366 / Val-Loss: 0.2374 / Test-Loss: 0.2397 / Time taken: 0:20:18 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 75 / Train-Loss: 0.2366 / Val-Loss: 0.2374 / Test-Loss: 0.2397 / Time taken: 0:20:32 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 76 / Train-Loss: 0.2366 / Val-Loss: 0.2373 / Test-Loss: 0.2397 / Time taken: 0:20:46 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 77 / Train-Loss: 0.2365 / Val-Loss: 0.2372 / Test-Loss: 0.2395 / Time taken: 0:21:02 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 78 / Train-Loss: 0.2365 / Val-Loss: 0.2372 / Test-Loss: 0.2393 / Time taken: 0:21:16 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 79 / Train-Loss: 0.2365 / Val-Loss: 0.2374 / Test-Loss: 0.2397 / Time taken: 0:21:32 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 80 / Train-Loss: 0.2364 / Val-Loss: 0.2372 / Test-Loss: 0.2395 / Time taken: 0:21:47 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 81 / Train-Loss: 0.2365 / Val-Loss: 0.2371 / Test-Loss: 0.2393 / Time taken: 0:22:09 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 82 / Train-Loss: 0.2364 / Val-Loss: 0.2374 / Test-Loss: 0.2397 / Time taken: 0:22:22 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 83 / Train-Loss: 0.2364 / Val-Loss: 0.2374 / Test-Loss: 0.2397 / Time taken: 0:22:37 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 84 / Train-Loss: 0.2364 / Val-Loss: 0.2371 / Test-Loss: 0.2392 / Time taken: 0:22:52 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 85 / Train-Loss: 0.2363 / Val-Loss: 0.2371 / Test-Loss: 0.2394 / Time taken: 0:23:07 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 86 / Train-Loss: 0.2362 / Val-Loss: 0.2373 / Test-Loss: 0.2397 / Time taken: 0:23:21 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 05/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 87 / Train-Loss: 0.2363 / Val-Loss: 0.2373 / Test-Loss: 0.2398 / Time taken: 0:23:36 / ---- Currently Best Val-Epoch: 71 \n","596/596 [==============================] - 11s 17ms/step\n","67/67 [==============================] - 1s 19ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-05b6b788-2e09-4271-9692-daa384b05766\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>FT_transformer (run: 1)</td>\n","      <td>89</td>\n","      <td>1614.216463</td>\n","      <td>27133</td>\n","      <td>0.237163</td>\n","      <td>0.238795</td>\n","      <td>0.061112</td>\n","      <td>0.061284</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>FT_transformer (run: 2)</td>\n","      <td>76</td>\n","      <td>1453.342622</td>\n","      <td>27133</td>\n","      <td>0.238176</td>\n","      <td>0.239629</td>\n","      <td>0.060320</td>\n","      <td>0.060438</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>FT_transformer (run: 3)</td>\n","      <td>44</td>\n","      <td>1021.084522</td>\n","      <td>27133</td>\n","      <td>0.238937</td>\n","      <td>0.239780</td>\n","      <td>0.059604</td>\n","      <td>0.059712</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>FT_transformer (run: 4)</td>\n","      <td>90</td>\n","      <td>2107.885792</td>\n","      <td>27133</td>\n","      <td>0.236846</td>\n","      <td>0.238730</td>\n","      <td>0.063062</td>\n","      <td>0.063192</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>FT_transformer (run: 5)</td>\n","      <td>71</td>\n","      <td>1416.576316</td>\n","      <td>27133</td>\n","      <td>0.237981</td>\n","      <td>0.239434</td>\n","      <td>0.060926</td>\n","      <td>0.061031</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>126 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05b6b788-2e09-4271-9692-daa384b05766')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-05b6b788-2e09-4271-9692-daa384b05766 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-05b6b788-2e09-4271-9692-daa384b05766');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cb87eeb9-e62a-424a-b1ac-7a15618452a7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb87eeb9-e62a-424a-b1ac-7a15618452a7')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cb87eeb9-e62a-424a-b1ac-7a15618452a7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","121     FT_transformer (run: 1)      89  1614.216463          27133   \n","122     FT_transformer (run: 2)      76  1453.342622          27133   \n","123     FT_transformer (run: 3)      44  1021.084522          27133   \n","124     FT_transformer (run: 4)      90  2107.885792          27133   \n","125     FT_transformer (run: 5)      71  1416.576316          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","121    0.237163   0.238795             0.061112            0.061284  \n","122    0.238176   0.239629             0.060320            0.060438  \n","123    0.238937   0.239780             0.059604            0.059712  \n","124    0.236846   0.238730             0.063062            0.063192  \n","125    0.237981   0.239434             0.060926            0.061031  \n","\n","[126 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 06-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 06/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0306  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 0 / Train-Loss: 0.2971 / Val-Loss: 0.2553 / Test-Loss: 0.2581 / Time taken: 0:00:27 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0303  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 1 / Train-Loss: 0.2526 / Val-Loss: 0.2496 / Test-Loss: 0.2519 / Time taken: 0:00:49 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0307  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 2 / Train-Loss: 0.2445 / Val-Loss: 0.2470 / Test-Loss: 0.2485 / Time taken: 0:01:03 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0315  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 3 / Train-Loss: 0.2421 / Val-Loss: 0.2460 / Test-Loss: 0.2472 / Time taken: 0:01:16 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0318  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 4 / Train-Loss: 0.2409 / Val-Loss: 0.2455 / Test-Loss: 0.2466 / Time taken: 0:01:31 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 5 / Train-Loss: 0.2406 / Val-Loss: 0.2452 / Test-Loss: 0.2461 / Time taken: 0:01:46 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 6 / Train-Loss: 0.2402 / Val-Loss: 0.2448 / Test-Loss: 0.2457 / Time taken: 0:02:00 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 7 / Train-Loss: 0.2400 / Val-Loss: 0.2447 / Test-Loss: 0.2456 / Time taken: 0:02:13 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 8 / Train-Loss: 0.2397 / Val-Loss: 0.2439 / Test-Loss: 0.2447 / Time taken: 0:02:29 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 9 / Train-Loss: 0.2395 / Val-Loss: 0.2439 / Test-Loss: 0.2446 / Time taken: 0:02:50 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 06/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 10 / Train-Loss: 0.2393 / Val-Loss: 0.2439 / Test-Loss: 0.2445 / Time taken: 0:03:13 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 11 / Batch: 1 / Train-Loss (Batch): 0.175    : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 06/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 11 / Train-Loss: 0.2391 / Val-Loss: 0.2438 / Test-Loss: 0.2444 / Time taken: 0:03:27 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 12 / Train-Loss: 0.2390 / Val-Loss: 0.2437 / Test-Loss: 0.2442 / Time taken: 0:03:41 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 13 / Train-Loss: 0.2390 / Val-Loss: 0.2430 / Test-Loss: 0.2434 / Time taken: 0:03:55 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 14 / Train-Loss: 0.2388 / Val-Loss: 0.2431 / Test-Loss: 0.2435 / Time taken: 0:04:10 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 06/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 15 / Train-Loss: 0.2387 / Val-Loss: 0.2429 / Test-Loss: 0.2432 / Time taken: 0:04:24 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 16 / Train-Loss: 0.2386 / Val-Loss: 0.2426 / Test-Loss: 0.2429 / Time taken: 0:04:39 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 17 / Train-Loss: 0.2387 / Val-Loss: 0.2424 / Test-Loss: 0.2427 / Time taken: 0:04:53 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 18 / Train-Loss: 0.2385 / Val-Loss: 0.2424 / Test-Loss: 0.2426 / Time taken: 0:05:08 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 19 / Train-Loss: 0.2384 / Val-Loss: 0.2424 / Test-Loss: 0.2426 / Time taken: 0:05:23 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 20 / Train-Loss: 0.2383 / Val-Loss: 0.2421 / Test-Loss: 0.2422 / Time taken: 0:05:38 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 21 / Train-Loss: 0.2383 / Val-Loss: 0.2424 / Test-Loss: 0.2427 / Time taken: 0:05:52 / ---- Currently Best Val-Epoch: 20 \n","Ensemble: 06/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 22 / Train-Loss: 0.2383 / Val-Loss: 0.2421 / Test-Loss: 0.2423 / Time taken: 0:06:14 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 23 / Train-Loss: 0.2383 / Val-Loss: 0.2421 / Test-Loss: 0.2422 / Time taken: 0:06:28 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 06/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 24 / Train-Loss: 0.2382 / Val-Loss: 0.2419 / Test-Loss: 0.2421 / Time taken: 0:06:42 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 25 / Train-Loss: 0.2382 / Val-Loss: 0.2418 / Test-Loss: 0.2420 / Time taken: 0:07:04 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 26 / Train-Loss: 0.2381 / Val-Loss: 0.2417 / Test-Loss: 0.2419 / Time taken: 0:07:19 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 27 / Train-Loss: 0.2380 / Val-Loss: 0.2416 / Test-Loss: 0.2419 / Time taken: 0:07:33 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 28 / Train-Loss: 0.2380 / Val-Loss: 0.2413 / Test-Loss: 0.2414 / Time taken: 0:07:47 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 29 / Train-Loss: 0.2379 / Val-Loss: 0.2414 / Test-Loss: 0.2415 / Time taken: 0:08:03 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 06/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 30 / Train-Loss: 0.2379 / Val-Loss: 0.2413 / Test-Loss: 0.2414 / Time taken: 0:08:18 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 31 / Train-Loss: 0.2378 / Val-Loss: 0.2412 / Test-Loss: 0.2415 / Time taken: 0:08:32 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 32 / Train-Loss: 0.2378 / Val-Loss: 0.2412 / Test-Loss: 0.2415 / Time taken: 0:08:46 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 33 / Train-Loss: 0.2377 / Val-Loss: 0.2408 / Test-Loss: 0.2410 / Time taken: 0:09:01 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 34 / Train-Loss: 0.2376 / Val-Loss: 0.2409 / Test-Loss: 0.2411 / Time taken: 0:09:16 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 06/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 35 / Train-Loss: 0.2376 / Val-Loss: 0.2410 / Test-Loss: 0.2412 / Time taken: 0:09:30 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 06/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 36 / Train-Loss: 0.2375 / Val-Loss: 0.2416 / Test-Loss: 0.2414 / Time taken: 0:09:43 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 06/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 37 / Train-Loss: 0.2374 / Val-Loss: 0.2403 / Test-Loss: 0.2406 / Time taken: 0:10:01 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 38 / Train-Loss: 0.2373 / Val-Loss: 0.2417 / Test-Loss: 0.2416 / Time taken: 0:10:16 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 39 / Train-Loss: 0.2373 / Val-Loss: 0.2405 / Test-Loss: 0.2406 / Time taken: 0:10:30 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 40 / Train-Loss: 0.2373 / Val-Loss: 0.2410 / Test-Loss: 0.2410 / Time taken: 0:10:52 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 41 / Train-Loss: 0.2372 / Val-Loss: 0.2409 / Test-Loss: 0.2408 / Time taken: 0:11:06 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 42 / Train-Loss: 0.2372 / Val-Loss: 0.2407 / Test-Loss: 0.2405 / Time taken: 0:11:21 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 43 / Train-Loss: 0.2372 / Val-Loss: 0.2405 / Test-Loss: 0.2404 / Time taken: 0:11:42 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 44 / Train-Loss: 0.2372 / Val-Loss: 0.2405 / Test-Loss: 0.2404 / Time taken: 0:11:58 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 45 / Train-Loss: 0.2372 / Val-Loss: 0.2408 / Test-Loss: 0.2407 / Time taken: 0:12:20 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 46 / Train-Loss: 0.2370 / Val-Loss: 0.2409 / Test-Loss: 0.2408 / Time taken: 0:12:34 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 47 / Train-Loss: 0.2371 / Val-Loss: 0.2407 / Test-Loss: 0.2406 / Time taken: 0:12:50 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 48 / Train-Loss: 0.2370 / Val-Loss: 0.2404 / Test-Loss: 0.2403 / Time taken: 0:13:11 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 49 / Train-Loss: 0.2371 / Val-Loss: 0.2406 / Test-Loss: 0.2404 / Time taken: 0:13:25 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 50 / Train-Loss: 0.2370 / Val-Loss: 0.2405 / Test-Loss: 0.2404 / Time taken: 0:13:41 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 06/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 51 / Train-Loss: 0.2370 / Val-Loss: 0.2403 / Test-Loss: 0.2402 / Time taken: 0:13:54 / ---- Currently Best Val-Epoch: 51 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 52 / Train-Loss: 0.2370 / Val-Loss: 0.2408 / Test-Loss: 0.2406 / Time taken: 0:14:09 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 06/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 53 / Train-Loss: 0.2369 / Val-Loss: 0.2400 / Test-Loss: 0.2400 / Time taken: 0:14:24 / ---- Currently Best Val-Epoch: 53 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 54 / Train-Loss: 0.2369 / Val-Loss: 0.2401 / Test-Loss: 0.2400 / Time taken: 0:14:40 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 06/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 55 / Train-Loss: 0.2367 / Val-Loss: 0.2398 / Test-Loss: 0.2398 / Time taken: 0:14:54 / ---- Currently Best Val-Epoch: 55 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 56 / Train-Loss: 0.2367 / Val-Loss: 0.2404 / Test-Loss: 0.2401 / Time taken: 0:15:10 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 06/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 57 / Train-Loss: 0.2368 / Val-Loss: 0.2398 / Test-Loss: 0.2398 / Time taken: 0:15:23 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 06/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 58 / Train-Loss: 0.2368 / Val-Loss: 0.2397 / Test-Loss: 0.2396 / Time taken: 0:15:39 / ---- Currently Best Val-Epoch: 58 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 59 / Train-Loss: 0.2367 / Val-Loss: 0.2398 / Test-Loss: 0.2399 / Time taken: 0:15:53 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 06/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 60 / Train-Loss: 0.2369 / Val-Loss: 0.2398 / Test-Loss: 0.2398 / Time taken: 0:16:14 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 06/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 61 / Train-Loss: 0.2367 / Val-Loss: 0.2399 / Test-Loss: 0.2400 / Time taken: 0:16:29 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 06/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 62 / Train-Loss: 0.2367 / Val-Loss: 0.2400 / Test-Loss: 0.2398 / Time taken: 0:16:44 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 06/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 63 / Train-Loss: 0.2366 / Val-Loss: 0.2396 / Test-Loss: 0.2397 / Time taken: 0:16:58 / ---- Currently Best Val-Epoch: 63 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 64 / Train-Loss: 0.2365 / Val-Loss: 0.2397 / Test-Loss: 0.2396 / Time taken: 0:17:13 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 65 / Train-Loss: 0.2367 / Val-Loss: 0.2394 / Test-Loss: 0.2393 / Time taken: 0:17:26 / ---- Currently Best Val-Epoch: 65 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 66 / Train-Loss: 0.2366 / Val-Loss: 0.2393 / Test-Loss: 0.2393 / Time taken: 0:17:49 / ---- Currently Best Val-Epoch: 66 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 67 / Train-Loss: 0.2365 / Val-Loss: 0.2402 / Test-Loss: 0.2400 / Time taken: 0:18:05 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 06/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 68 / Train-Loss: 0.2364 / Val-Loss: 0.2394 / Test-Loss: 0.2396 / Time taken: 0:18:20 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 06/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 69 / Train-Loss: 0.2366 / Val-Loss: 0.2395 / Test-Loss: 0.2397 / Time taken: 0:18:37 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 06/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 70 / Train-Loss: 0.2364 / Val-Loss: 0.2396 / Test-Loss: 0.2396 / Time taken: 0:18:51 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 06/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 71 / Train-Loss: 0.2364 / Val-Loss: 0.2396 / Test-Loss: 0.2396 / Time taken: 0:19:05 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 06/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 72 / Train-Loss: 0.2366 / Val-Loss: 0.2393 / Test-Loss: 0.2394 / Time taken: 0:19:20 / ---- Currently Best Val-Epoch: 72 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 73 / Train-Loss: 0.2365 / Val-Loss: 0.2394 / Test-Loss: 0.2392 / Time taken: 0:19:35 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 06/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 74 / Train-Loss: 0.2363 / Val-Loss: 0.2395 / Test-Loss: 0.2395 / Time taken: 0:19:50 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 06/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 75 / Train-Loss: 0.2363 / Val-Loss: 0.2402 / Test-Loss: 0.2400 / Time taken: 0:20:04 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 06/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 76 / Train-Loss: 0.2364 / Val-Loss: 0.2393 / Test-Loss: 0.2392 / Time taken: 0:20:18 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 06/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 77 / Train-Loss: 0.2364 / Val-Loss: 0.2393 / Test-Loss: 0.2392 / Time taken: 0:20:33 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 06/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 78 / Train-Loss: 0.2362 / Val-Loss: 0.2392 / Test-Loss: 0.2392 / Time taken: 0:20:48 / ---- Currently Best Val-Epoch: 78 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 79 / Train-Loss: 0.2362 / Val-Loss: 0.2394 / Test-Loss: 0.2392 / Time taken: 0:21:02 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 06/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 80 / Train-Loss: 0.2362 / Val-Loss: 0.2395 / Test-Loss: 0.2393 / Time taken: 0:21:17 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 06/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 81 / Train-Loss: 0.2363 / Val-Loss: 0.2393 / Test-Loss: 0.2391 / Time taken: 0:21:32 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 06/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 82 / Train-Loss: 0.2362 / Val-Loss: 0.2394 / Test-Loss: 0.2392 / Time taken: 0:21:46 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 06/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 83 / Train-Loss: 0.2361 / Val-Loss: 0.2392 / Test-Loss: 0.2391 / Time taken: 0:22:07 / ---- Currently Best Val-Epoch: 83 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 84 / Train-Loss: 0.2361 / Val-Loss: 0.2393 / Test-Loss: 0.2393 / Time taken: 0:22:24 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 06/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 85 / Train-Loss: 0.2360 / Val-Loss: 0.2390 / Test-Loss: 0.2391 / Time taken: 0:22:40 / ---- Currently Best Val-Epoch: 85 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 86 / Train-Loss: 0.2360 / Val-Loss: 0.2394 / Test-Loss: 0.2394 / Time taken: 0:22:56 / ---- Currently Best Val-Epoch: 85 \n","Ensemble: 06/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 87 / Train-Loss: 0.2359 / Val-Loss: 0.2390 / Test-Loss: 0.2391 / Time taken: 0:23:12 / ---- Currently Best Val-Epoch: 87 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 88 / Train-Loss: 0.2361 / Val-Loss: 0.2392 / Test-Loss: 0.2390 / Time taken: 0:23:27 / ---- Currently Best Val-Epoch: 87 \n","Ensemble: 06/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 89 / Train-Loss: 0.2360 / Val-Loss: 0.2394 / Test-Loss: 0.2393 / Time taken: 0:23:42 / ---- Currently Best Val-Epoch: 87 \n","Ensemble: 06/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 90 / Train-Loss: 0.2361 / Val-Loss: 0.2392 / Test-Loss: 0.2392 / Time taken: 0:23:57 / ---- Currently Best Val-Epoch: 87 \n","Ensemble: 06/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 91 / Train-Loss: 0.2359 / Val-Loss: 0.2392 / Test-Loss: 0.2392 / Time taken: 0:24:19 / ---- Currently Best Val-Epoch: 87 \n","Ensemble: 06/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 92 / Train-Loss: 0.2359 / Val-Loss: 0.2392 / Test-Loss: 0.2392 / Time taken: 0:24:32 / ---- Currently Best Val-Epoch: 87 \n","Ensemble: 06/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 93 / Train-Loss: 0.2360 / Val-Loss: 0.2387 / Test-Loss: 0.2389 / Time taken: 0:24:46 / ---- Currently Best Val-Epoch: 93 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 94 / Train-Loss: 0.2360 / Val-Loss: 0.2390 / Test-Loss: 0.2392 / Time taken: 0:25:02 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 95 / Train-Loss: 0.2361 / Val-Loss: 0.2390 / Test-Loss: 0.2390 / Time taken: 0:25:17 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 96 / Train-Loss: 0.2359 / Val-Loss: 0.2391 / Test-Loss: 0.2391 / Time taken: 0:25:31 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 97 / Train-Loss: 0.2357 / Val-Loss: 0.2392 / Test-Loss: 0.2390 / Time taken: 0:25:46 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 98 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 98 / Train-Loss: 0.2358 / Val-Loss: 0.2391 / Test-Loss: 0.2389 / Time taken: 0:26:01 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 99 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 99 / Train-Loss: 0.2359 / Val-Loss: 0.2388 / Test-Loss: 0.2389 / Time taken: 0:26:28 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 100 / Batch: 536 / Train-Loss (Batch): 0.0325: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 100 / Train-Loss: 0.2357 / Val-Loss: 0.2390 / Test-Loss: 0.2391 / Time taken: 0:26:51 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 101 / Batch: 536 / Train-Loss (Batch): 0.0329: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 101 / Train-Loss: 0.2358 / Val-Loss: 0.2390 / Test-Loss: 0.2391 / Time taken: 0:27:07 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 102 / Batch: 536 / Train-Loss (Batch): 0.0324: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 102 / Train-Loss: 0.2357 / Val-Loss: 0.2390 / Test-Loss: 0.2392 / Time taken: 0:27:29 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 103 / Batch: 536 / Train-Loss (Batch): 0.0333: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 103 / Train-Loss: 0.2357 / Val-Loss: 0.2390 / Test-Loss: 0.2391 / Time taken: 0:27:50 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 104 / Batch: 536 / Train-Loss (Batch): 0.0317: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 104 / Train-Loss: 0.2357 / Val-Loss: 0.2389 / Test-Loss: 0.2392 / Time taken: 0:28:06 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 105 / Batch: 536 / Train-Loss (Batch): 0.0322: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 105 / Train-Loss: 0.2356 / Val-Loss: 0.2389 / Test-Loss: 0.2389 / Time taken: 0:28:20 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 106 / Batch: 536 / Train-Loss (Batch): 0.0329: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 106 / Train-Loss: 0.2356 / Val-Loss: 0.2392 / Test-Loss: 0.2392 / Time taken: 0:28:35 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 107 / Batch: 536 / Train-Loss (Batch): 0.0333: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 107 / Train-Loss: 0.2355 / Val-Loss: 0.2390 / Test-Loss: 0.2391 / Time taken: 0:28:50 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 108 / Batch: 536 / Train-Loss (Batch): 0.0337: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 108 / Train-Loss: 0.2356 / Val-Loss: 0.2388 / Test-Loss: 0.2392 / Time taken: 0:29:05 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 06/14 / Epoch: 109 / Batch: 536 / Train-Loss (Batch): 0.0331: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 109 / Train-Loss: 0.2355 / Val-Loss: 0.2386 / Test-Loss: 0.2387 / Time taken: 0:29:20 / ---- Currently Best Val-Epoch: 109 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 110 / Batch: 536 / Train-Loss (Batch): 0.0338: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 110 / Train-Loss: 0.2355 / Val-Loss: 0.2388 / Test-Loss: 0.2391 / Time taken: 0:29:35 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 111 / Batch: 536 / Train-Loss (Batch): 0.0324: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 111 / Train-Loss: 0.2356 / Val-Loss: 0.2388 / Test-Loss: 0.2390 / Time taken: 0:29:49 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 112 / Batch: 536 / Train-Loss (Batch): 0.0323: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 112 / Train-Loss: 0.2356 / Val-Loss: 0.2389 / Test-Loss: 0.2392 / Time taken: 0:30:05 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 113 / Batch: 536 / Train-Loss (Batch): 0.0333: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 113 / Train-Loss: 0.2354 / Val-Loss: 0.2393 / Test-Loss: 0.2394 / Time taken: 0:30:20 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 114 / Batch: 536 / Train-Loss (Batch): 0.033 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 114 / Train-Loss: 0.2355 / Val-Loss: 0.2389 / Test-Loss: 0.2390 / Time taken: 0:30:35 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 115 / Batch: 536 / Train-Loss (Batch): 0.0326: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 115 / Train-Loss: 0.2355 / Val-Loss: 0.2387 / Test-Loss: 0.2389 / Time taken: 0:30:49 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 116 / Batch: 536 / Train-Loss (Batch): 0.0328: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 116 / Train-Loss: 0.2353 / Val-Loss: 0.2390 / Test-Loss: 0.2393 / Time taken: 0:31:06 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 117 / Batch: 536 / Train-Loss (Batch): 0.0326: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 117 / Train-Loss: 0.2356 / Val-Loss: 0.2392 / Test-Loss: 0.2393 / Time taken: 0:31:21 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 118 / Batch: 536 / Train-Loss (Batch): 0.033 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 118 / Train-Loss: 0.2355 / Val-Loss: 0.2389 / Test-Loss: 0.2392 / Time taken: 0:31:35 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 119 / Batch: 536 / Train-Loss (Batch): 0.0328: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 119 / Train-Loss: 0.2354 / Val-Loss: 0.2391 / Test-Loss: 0.2392 / Time taken: 0:31:50 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 120 / Batch: 536 / Train-Loss (Batch): 0.0327: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 120 / Train-Loss: 0.2355 / Val-Loss: 0.2390 / Test-Loss: 0.2393 / Time taken: 0:32:05 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 121 / Batch: 536 / Train-Loss (Batch): 0.0337: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 121 / Train-Loss: 0.2354 / Val-Loss: 0.2391 / Test-Loss: 0.2391 / Time taken: 0:32:20 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 122 / Batch: 536 / Train-Loss (Batch): 0.0327: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 122 / Train-Loss: 0.2353 / Val-Loss: 0.2388 / Test-Loss: 0.2391 / Time taken: 0:32:35 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 123 / Batch: 536 / Train-Loss (Batch): 0.033 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 123 / Train-Loss: 0.2352 / Val-Loss: 0.2389 / Test-Loss: 0.2392 / Time taken: 0:32:49 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 124 / Batch: 536 / Train-Loss (Batch): 0.0322: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 124 / Train-Loss: 0.2353 / Val-Loss: 0.2388 / Test-Loss: 0.2392 / Time taken: 0:33:05 / ---- Currently Best Val-Epoch: 109 \n","Ensemble: 06/14 / Epoch: 125 / Batch: 536 / Train-Loss (Batch): 0.0326: [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 125 / Train-Loss: 0.2352 / Val-Loss: 0.2388 / Test-Loss: 0.2393 / Time taken: 0:33:19 / ---- Currently Best Val-Epoch: 109 \n","596/596 [==============================] - 11s 17ms/step\n","67/67 [==============================] - 2s 23ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-613ddc90-45ec-456a-9a2f-60e30fdaaa3b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>FT_transformer (run: 2)</td>\n","      <td>76</td>\n","      <td>1453.342622</td>\n","      <td>27133</td>\n","      <td>0.238176</td>\n","      <td>0.239629</td>\n","      <td>0.060320</td>\n","      <td>0.060438</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>FT_transformer (run: 3)</td>\n","      <td>44</td>\n","      <td>1021.084522</td>\n","      <td>27133</td>\n","      <td>0.238937</td>\n","      <td>0.239780</td>\n","      <td>0.059604</td>\n","      <td>0.059712</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>FT_transformer (run: 4)</td>\n","      <td>90</td>\n","      <td>2107.885792</td>\n","      <td>27133</td>\n","      <td>0.236846</td>\n","      <td>0.238730</td>\n","      <td>0.063062</td>\n","      <td>0.063192</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>FT_transformer (run: 5)</td>\n","      <td>71</td>\n","      <td>1416.576316</td>\n","      <td>27133</td>\n","      <td>0.237981</td>\n","      <td>0.239434</td>\n","      <td>0.060926</td>\n","      <td>0.061031</td>\n","    </tr>\n","    <tr>\n","      <th>126</th>\n","      <td>FT_transformer (run: 6)</td>\n","      <td>109</td>\n","      <td>1999.786216</td>\n","      <td>27133</td>\n","      <td>0.236723</td>\n","      <td>0.238745</td>\n","      <td>0.061890</td>\n","      <td>0.061992</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>127 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-613ddc90-45ec-456a-9a2f-60e30fdaaa3b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-613ddc90-45ec-456a-9a2f-60e30fdaaa3b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-613ddc90-45ec-456a-9a2f-60e30fdaaa3b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-148f2ae5-a334-4e4d-85f1-7e7e8f87c958\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-148f2ae5-a334-4e4d-85f1-7e7e8f87c958')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-148f2ae5-a334-4e4d-85f1-7e7e8f87c958 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","122     FT_transformer (run: 2)      76  1453.342622          27133   \n","123     FT_transformer (run: 3)      44  1021.084522          27133   \n","124     FT_transformer (run: 4)      90  2107.885792          27133   \n","125     FT_transformer (run: 5)      71  1416.576316          27133   \n","126     FT_transformer (run: 6)     109  1999.786216          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","122    0.238176   0.239629             0.060320            0.060438  \n","123    0.238937   0.239780             0.059604            0.059712  \n","124    0.236846   0.238730             0.063062            0.063192  \n","125    0.237981   0.239434             0.060926            0.061031  \n","126    0.236723   0.238745             0.061890            0.061992  \n","\n","[127 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 07-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 07/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.03    : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 0 / Train-Loss: 0.2648 / Val-Loss: 0.2553 / Test-Loss: 0.2536 / Time taken: 0:00:30 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0307  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 1 / Train-Loss: 0.2458 / Val-Loss: 0.2519 / Test-Loss: 0.2489 / Time taken: 0:00:44 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0316  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 2 / Train-Loss: 0.2417 / Val-Loss: 0.2501 / Test-Loss: 0.2465 / Time taken: 0:00:58 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.032   : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 3 / Train-Loss: 0.2405 / Val-Loss: 0.2493 / Test-Loss: 0.2453 / Time taken: 0:01:14 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.032   : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 4 / Train-Loss: 0.2399 / Val-Loss: 0.2495 / Test-Loss: 0.2454 / Time taken: 0:01:29 / ---- Currently Best Val-Epoch: 3 \n","Ensemble: 07/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 5 / Train-Loss: 0.2397 / Val-Loss: 0.2492 / Test-Loss: 0.2451 / Time taken: 0:01:42 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 6 / Train-Loss: 0.2394 / Val-Loss: 0.2493 / Test-Loss: 0.2449 / Time taken: 0:01:59 / ---- Currently Best Val-Epoch: 5 \n","Ensemble: 07/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 7 / Train-Loss: 0.2392 / Val-Loss: 0.2489 / Test-Loss: 0.2445 / Time taken: 0:02:14 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 8 / Train-Loss: 0.2392 / Val-Loss: 0.2483 / Test-Loss: 0.2440 / Time taken: 0:02:30 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 9 / Train-Loss: 0.2389 / Val-Loss: 0.2478 / Test-Loss: 0.2434 / Time taken: 0:02:44 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 10 / Train-Loss: 0.2387 / Val-Loss: 0.2476 / Test-Loss: 0.2430 / Time taken: 0:02:58 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 11 / Batch: 1 / Train-Loss (Batch): 0.1536   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 07/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 11 / Train-Loss: 0.2387 / Val-Loss: 0.2476 / Test-Loss: 0.2431 / Time taken: 0:03:13 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 07/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 12 / Train-Loss: 0.2386 / Val-Loss: 0.2471 / Test-Loss: 0.2427 / Time taken: 0:03:28 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 13 / Train-Loss: 0.2386 / Val-Loss: 0.2468 / Test-Loss: 0.2423 / Time taken: 0:03:44 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 14 / Train-Loss: 0.2383 / Val-Loss: 0.2468 / Test-Loss: 0.2424 / Time taken: 0:04:00 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 15 / Train-Loss: 0.2384 / Val-Loss: 0.2463 / Test-Loss: 0.2419 / Time taken: 0:04:14 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 16 / Train-Loss: 0.2383 / Val-Loss: 0.2460 / Test-Loss: 0.2417 / Time taken: 0:04:31 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 17 / Train-Loss: 0.2382 / Val-Loss: 0.2459 / Test-Loss: 0.2415 / Time taken: 0:04:45 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 18 / Train-Loss: 0.2382 / Val-Loss: 0.2459 / Test-Loss: 0.2416 / Time taken: 0:05:00 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 07/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 19 / Train-Loss: 0.2381 / Val-Loss: 0.2457 / Test-Loss: 0.2414 / Time taken: 0:05:15 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 20 / Train-Loss: 0.2381 / Val-Loss: 0.2459 / Test-Loss: 0.2413 / Time taken: 0:05:30 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 07/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 21 / Train-Loss: 0.2380 / Val-Loss: 0.2455 / Test-Loss: 0.2412 / Time taken: 0:05:45 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 22 / Train-Loss: 0.2379 / Val-Loss: 0.2454 / Test-Loss: 0.2409 / Time taken: 0:06:00 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 23 / Train-Loss: 0.2379 / Val-Loss: 0.2452 / Test-Loss: 0.2408 / Time taken: 0:06:17 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 24 / Train-Loss: 0.2378 / Val-Loss: 0.2450 / Test-Loss: 0.2407 / Time taken: 0:06:39 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 25 / Train-Loss: 0.2378 / Val-Loss: 0.2451 / Test-Loss: 0.2406 / Time taken: 0:06:55 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 07/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 26 / Train-Loss: 0.2378 / Val-Loss: 0.2449 / Test-Loss: 0.2405 / Time taken: 0:07:18 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 27 / Train-Loss: 0.2378 / Val-Loss: 0.2449 / Test-Loss: 0.2405 / Time taken: 0:07:40 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 07/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 28 / Train-Loss: 0.2378 / Val-Loss: 0.2446 / Test-Loss: 0.2402 / Time taken: 0:07:54 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 29 / Train-Loss: 0.2377 / Val-Loss: 0.2450 / Test-Loss: 0.2405 / Time taken: 0:08:09 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 07/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 30 / Train-Loss: 0.2377 / Val-Loss: 0.2446 / Test-Loss: 0.2401 / Time taken: 0:08:25 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 07/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 31 / Train-Loss: 0.2374 / Val-Loss: 0.2449 / Test-Loss: 0.2403 / Time taken: 0:08:47 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 07/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 32 / Train-Loss: 0.2377 / Val-Loss: 0.2444 / Test-Loss: 0.2399 / Time taken: 0:09:01 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 33 / Train-Loss: 0.2375 / Val-Loss: 0.2446 / Test-Loss: 0.2401 / Time taken: 0:09:15 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 07/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 34 / Train-Loss: 0.2375 / Val-Loss: 0.2444 / Test-Loss: 0.2399 / Time taken: 0:09:30 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 07/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 35 / Train-Loss: 0.2373 / Val-Loss: 0.2447 / Test-Loss: 0.2402 / Time taken: 0:09:45 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 07/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 36 / Train-Loss: 0.2374 / Val-Loss: 0.2442 / Test-Loss: 0.2398 / Time taken: 0:09:59 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 37 / Train-Loss: 0.2374 / Val-Loss: 0.2439 / Test-Loss: 0.2395 / Time taken: 0:10:15 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 38 / Train-Loss: 0.2374 / Val-Loss: 0.2445 / Test-Loss: 0.2399 / Time taken: 0:10:30 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 07/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 39 / Train-Loss: 0.2374 / Val-Loss: 0.2439 / Test-Loss: 0.2396 / Time taken: 0:10:46 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 40 / Train-Loss: 0.2373 / Val-Loss: 0.2441 / Test-Loss: 0.2396 / Time taken: 0:11:02 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 41 / Train-Loss: 0.2373 / Val-Loss: 0.2441 / Test-Loss: 0.2395 / Time taken: 0:11:16 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 42 / Train-Loss: 0.2373 / Val-Loss: 0.2443 / Test-Loss: 0.2399 / Time taken: 0:11:30 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 43 / Train-Loss: 0.2374 / Val-Loss: 0.2441 / Test-Loss: 0.2397 / Time taken: 0:11:51 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 44 / Train-Loss: 0.2372 / Val-Loss: 0.2441 / Test-Loss: 0.2397 / Time taken: 0:12:13 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 45 / Train-Loss: 0.2372 / Val-Loss: 0.2442 / Test-Loss: 0.2397 / Time taken: 0:12:27 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 46 / Train-Loss: 0.2372 / Val-Loss: 0.2442 / Test-Loss: 0.2397 / Time taken: 0:12:40 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 47 / Train-Loss: 0.2371 / Val-Loss: 0.2437 / Test-Loss: 0.2393 / Time taken: 0:12:55 / ---- Currently Best Val-Epoch: 47 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 48 / Train-Loss: 0.2371 / Val-Loss: 0.2438 / Test-Loss: 0.2394 / Time taken: 0:13:11 / ---- Currently Best Val-Epoch: 47 \n","Ensemble: 07/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 49 / Train-Loss: 0.2371 / Val-Loss: 0.2438 / Test-Loss: 0.2394 / Time taken: 0:13:25 / ---- Currently Best Val-Epoch: 47 \n","Ensemble: 07/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 50 / Train-Loss: 0.2370 / Val-Loss: 0.2438 / Test-Loss: 0.2394 / Time taken: 0:13:39 / ---- Currently Best Val-Epoch: 47 \n","Ensemble: 07/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 51 / Train-Loss: 0.2370 / Val-Loss: 0.2439 / Test-Loss: 0.2395 / Time taken: 0:13:54 / ---- Currently Best Val-Epoch: 47 \n","Ensemble: 07/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 52 / Train-Loss: 0.2369 / Val-Loss: 0.2439 / Test-Loss: 0.2395 / Time taken: 0:14:09 / ---- Currently Best Val-Epoch: 47 \n","Ensemble: 07/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 53 / Train-Loss: 0.2369 / Val-Loss: 0.2437 / Test-Loss: 0.2394 / Time taken: 0:14:23 / ---- Currently Best Val-Epoch: 53 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 54 / Train-Loss: 0.2370 / Val-Loss: 0.2440 / Test-Loss: 0.2396 / Time taken: 0:14:38 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 55 / Train-Loss: 0.2369 / Val-Loss: 0.2438 / Test-Loss: 0.2395 / Time taken: 0:14:54 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 56 / Train-Loss: 0.2368 / Val-Loss: 0.2439 / Test-Loss: 0.2395 / Time taken: 0:15:10 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 57 / Train-Loss: 0.2367 / Val-Loss: 0.2437 / Test-Loss: 0.2395 / Time taken: 0:15:24 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 58 / Train-Loss: 0.2368 / Val-Loss: 0.2439 / Test-Loss: 0.2395 / Time taken: 0:15:38 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 59 / Train-Loss: 0.2366 / Val-Loss: 0.2438 / Test-Loss: 0.2394 / Time taken: 0:15:53 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 60 / Train-Loss: 0.2367 / Val-Loss: 0.2438 / Test-Loss: 0.2396 / Time taken: 0:16:14 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 61 / Train-Loss: 0.2367 / Val-Loss: 0.2441 / Test-Loss: 0.2397 / Time taken: 0:16:29 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 62 / Train-Loss: 0.2367 / Val-Loss: 0.2439 / Test-Loss: 0.2396 / Time taken: 0:16:43 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 63 / Train-Loss: 0.2367 / Val-Loss: 0.2437 / Test-Loss: 0.2395 / Time taken: 0:16:57 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 64 / Train-Loss: 0.2365 / Val-Loss: 0.2437 / Test-Loss: 0.2395 / Time taken: 0:17:13 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 07/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 65 / Train-Loss: 0.2367 / Val-Loss: 0.2437 / Test-Loss: 0.2393 / Time taken: 0:17:27 / ---- Currently Best Val-Epoch: 65 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 66 / Train-Loss: 0.2365 / Val-Loss: 0.2435 / Test-Loss: 0.2394 / Time taken: 0:17:41 / ---- Currently Best Val-Epoch: 66 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 67 / Train-Loss: 0.2365 / Val-Loss: 0.2433 / Test-Loss: 0.2393 / Time taken: 0:18:03 / ---- Currently Best Val-Epoch: 67 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 68 / Train-Loss: 0.2364 / Val-Loss: 0.2431 / Test-Loss: 0.2391 / Time taken: 0:18:20 / ---- Currently Best Val-Epoch: 68 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 69 / Train-Loss: 0.2363 / Val-Loss: 0.2431 / Test-Loss: 0.2393 / Time taken: 0:18:43 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 07/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 70 / Train-Loss: 0.2363 / Val-Loss: 0.2432 / Test-Loss: 0.2392 / Time taken: 0:18:57 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 07/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 71 / Train-Loss: 0.2362 / Val-Loss: 0.2433 / Test-Loss: 0.2394 / Time taken: 0:19:12 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 07/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 72 / Train-Loss: 0.2362 / Val-Loss: 0.2429 / Test-Loss: 0.2390 / Time taken: 0:19:29 / ---- Currently Best Val-Epoch: 72 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 73 / Train-Loss: 0.2361 / Val-Loss: 0.2432 / Test-Loss: 0.2391 / Time taken: 0:19:43 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 07/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 74 / Train-Loss: 0.2360 / Val-Loss: 0.2431 / Test-Loss: 0.2391 / Time taken: 0:19:57 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 07/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 75 / Train-Loss: 0.2359 / Val-Loss: 0.2430 / Test-Loss: 0.2392 / Time taken: 0:20:11 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 07/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 76 / Train-Loss: 0.2361 / Val-Loss: 0.2429 / Test-Loss: 0.2389 / Time taken: 0:20:26 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 07/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 77 / Train-Loss: 0.2360 / Val-Loss: 0.2428 / Test-Loss: 0.2390 / Time taken: 0:20:41 / ---- Currently Best Val-Epoch: 77 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 78 / Train-Loss: 0.2359 / Val-Loss: 0.2430 / Test-Loss: 0.2390 / Time taken: 0:20:56 / ---- Currently Best Val-Epoch: 77 \n","Ensemble: 07/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 79 / Train-Loss: 0.2359 / Val-Loss: 0.2427 / Test-Loss: 0.2390 / Time taken: 0:21:10 / ---- Currently Best Val-Epoch: 79 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 80 / Train-Loss: 0.2358 / Val-Loss: 0.2425 / Test-Loss: 0.2389 / Time taken: 0:21:25 / ---- Currently Best Val-Epoch: 80 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 81 / Train-Loss: 0.2357 / Val-Loss: 0.2427 / Test-Loss: 0.2388 / Time taken: 0:21:41 / ---- Currently Best Val-Epoch: 80 \n","Ensemble: 07/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 82 / Train-Loss: 0.2356 / Val-Loss: 0.2428 / Test-Loss: 0.2391 / Time taken: 0:21:55 / ---- Currently Best Val-Epoch: 80 \n","Ensemble: 07/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 83 / Train-Loss: 0.2357 / Val-Loss: 0.2424 / Test-Loss: 0.2387 / Time taken: 0:22:09 / ---- Currently Best Val-Epoch: 83 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 84 / Train-Loss: 0.2356 / Val-Loss: 0.2427 / Test-Loss: 0.2388 / Time taken: 0:22:23 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 85 / Train-Loss: 0.2356 / Val-Loss: 0.2428 / Test-Loss: 0.2390 / Time taken: 0:22:38 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 86 / Train-Loss: 0.2356 / Val-Loss: 0.2429 / Test-Loss: 0.2390 / Time taken: 0:22:53 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 87 / Train-Loss: 0.2355 / Val-Loss: 0.2428 / Test-Loss: 0.2389 / Time taken: 0:23:09 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 88 / Train-Loss: 0.2356 / Val-Loss: 0.2430 / Test-Loss: 0.2390 / Time taken: 0:23:31 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 89 / Train-Loss: 0.2355 / Val-Loss: 0.2428 / Test-Loss: 0.2388 / Time taken: 0:23:49 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 90 / Train-Loss: 0.2354 / Val-Loss: 0.2429 / Test-Loss: 0.2388 / Time taken: 0:24:10 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 91 / Train-Loss: 0.2354 / Val-Loss: 0.2428 / Test-Loss: 0.2389 / Time taken: 0:24:24 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 92 / Train-Loss: 0.2354 / Val-Loss: 0.2427 / Test-Loss: 0.2389 / Time taken: 0:24:38 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 93 / Train-Loss: 0.2353 / Val-Loss: 0.2429 / Test-Loss: 0.2389 / Time taken: 0:24:59 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 94 / Train-Loss: 0.2355 / Val-Loss: 0.2428 / Test-Loss: 0.2390 / Time taken: 0:25:14 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 95 / Train-Loss: 0.2354 / Val-Loss: 0.2431 / Test-Loss: 0.2391 / Time taken: 0:25:29 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 96 / Train-Loss: 0.2353 / Val-Loss: 0.2428 / Test-Loss: 0.2389 / Time taken: 0:25:43 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 97 / Train-Loss: 0.2354 / Val-Loss: 0.2427 / Test-Loss: 0.2389 / Time taken: 0:25:59 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 98 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 98 / Train-Loss: 0.2355 / Val-Loss: 0.2427 / Test-Loss: 0.2390 / Time taken: 0:26:13 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 07/14 / Epoch: 99 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 99 / Train-Loss: 0.2353 / Val-Loss: 0.2428 / Test-Loss: 0.2389 / Time taken: 0:26:28 / ---- Currently Best Val-Epoch: 83 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 22ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-ca0d61cc-7905-490b-8fde-838c2489fc9c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>FT_transformer (run: 3)</td>\n","      <td>44</td>\n","      <td>1021.084522</td>\n","      <td>27133</td>\n","      <td>0.238937</td>\n","      <td>0.239780</td>\n","      <td>0.059604</td>\n","      <td>0.059712</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>FT_transformer (run: 4)</td>\n","      <td>90</td>\n","      <td>2107.885792</td>\n","      <td>27133</td>\n","      <td>0.236846</td>\n","      <td>0.238730</td>\n","      <td>0.063062</td>\n","      <td>0.063192</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>FT_transformer (run: 5)</td>\n","      <td>71</td>\n","      <td>1416.576316</td>\n","      <td>27133</td>\n","      <td>0.237981</td>\n","      <td>0.239434</td>\n","      <td>0.060926</td>\n","      <td>0.061031</td>\n","    </tr>\n","    <tr>\n","      <th>126</th>\n","      <td>FT_transformer (run: 6)</td>\n","      <td>109</td>\n","      <td>1999.786216</td>\n","      <td>27133</td>\n","      <td>0.236723</td>\n","      <td>0.238745</td>\n","      <td>0.061890</td>\n","      <td>0.061992</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>FT_transformer (run: 7)</td>\n","      <td>83</td>\n","      <td>1588.023347</td>\n","      <td>27133</td>\n","      <td>0.236495</td>\n","      <td>0.238729</td>\n","      <td>0.064304</td>\n","      <td>0.064473</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>128 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca0d61cc-7905-490b-8fde-838c2489fc9c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ca0d61cc-7905-490b-8fde-838c2489fc9c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ca0d61cc-7905-490b-8fde-838c2489fc9c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9ba8bbde-3949-4401-a8a6-134ab3196fc7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ba8bbde-3949-4401-a8a6-134ab3196fc7')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9ba8bbde-3949-4401-a8a6-134ab3196fc7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","123     FT_transformer (run: 3)      44  1021.084522          27133   \n","124     FT_transformer (run: 4)      90  2107.885792          27133   \n","125     FT_transformer (run: 5)      71  1416.576316          27133   \n","126     FT_transformer (run: 6)     109  1999.786216          27133   \n","127     FT_transformer (run: 7)      83  1588.023347          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","123    0.238937   0.239780             0.059604            0.059712  \n","124    0.236846   0.238730             0.063062            0.063192  \n","125    0.237981   0.239434             0.060926            0.061031  \n","126    0.236723   0.238745             0.061890            0.061992  \n","127    0.236495   0.238729             0.064304            0.064473  \n","\n","[128 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 08-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 08/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 0 / Train-Loss: 0.3294 / Val-Loss: 0.2767 / Test-Loss: 0.2716 / Time taken: 0:00:29 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0305  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 1 / Train-Loss: 0.2601 / Val-Loss: 0.2634 / Test-Loss: 0.2568 / Time taken: 0:00:51 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0301  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 2 / Train-Loss: 0.2521 / Val-Loss: 0.2618 / Test-Loss: 0.2545 / Time taken: 0:01:06 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0305  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 3 / Train-Loss: 0.2495 / Val-Loss: 0.2597 / Test-Loss: 0.2516 / Time taken: 0:01:22 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.031   : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 4 / Train-Loss: 0.2429 / Val-Loss: 0.2569 / Test-Loss: 0.2486 / Time taken: 0:01:39 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0314  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 5 / Train-Loss: 0.2407 / Val-Loss: 0.2556 / Test-Loss: 0.2471 / Time taken: 0:01:54 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0321  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 6 / Train-Loss: 0.2398 / Val-Loss: 0.2548 / Test-Loss: 0.2462 / Time taken: 0:02:08 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 7 / Train-Loss: 0.2394 / Val-Loss: 0.2541 / Test-Loss: 0.2453 / Time taken: 0:02:22 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 8 / Train-Loss: 0.2392 / Val-Loss: 0.2536 / Test-Loss: 0.2448 / Time taken: 0:02:37 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 9 / Train-Loss: 0.2389 / Val-Loss: 0.2541 / Test-Loss: 0.2451 / Time taken: 0:02:51 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 08/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 10 / Train-Loss: 0.2388 / Val-Loss: 0.2538 / Test-Loss: 0.2448 / Time taken: 0:03:13 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 08/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 11 / Train-Loss: 0.2386 / Val-Loss: 0.2540 / Test-Loss: 0.2448 / Time taken: 0:03:27 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 08/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 12 / Train-Loss: 0.2387 / Val-Loss: 0.2537 / Test-Loss: 0.2446 / Time taken: 0:03:49 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 08/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 13 / Train-Loss: 0.2384 / Val-Loss: 0.2532 / Test-Loss: 0.2440 / Time taken: 0:04:03 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 14 / Batch: 1 / Train-Loss (Batch): 0.1789   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 08/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 14 / Train-Loss: 0.2383 / Val-Loss: 0.2530 / Test-Loss: 0.2439 / Time taken: 0:04:17 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 15 / Train-Loss: 0.2382 / Val-Loss: 0.2527 / Test-Loss: 0.2436 / Time taken: 0:04:32 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 16 / Train-Loss: 0.2381 / Val-Loss: 0.2528 / Test-Loss: 0.2437 / Time taken: 0:04:48 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 08/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 17 / Train-Loss: 0.2381 / Val-Loss: 0.2527 / Test-Loss: 0.2436 / Time taken: 0:05:09 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 18 / Train-Loss: 0.2380 / Val-Loss: 0.2520 / Test-Loss: 0.2431 / Time taken: 0:05:31 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 19 / Train-Loss: 0.2379 / Val-Loss: 0.2515 / Test-Loss: 0.2426 / Time taken: 0:05:48 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 20 / Train-Loss: 0.2380 / Val-Loss: 0.2518 / Test-Loss: 0.2428 / Time taken: 0:06:03 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 08/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 21 / Train-Loss: 0.2378 / Val-Loss: 0.2513 / Test-Loss: 0.2424 / Time taken: 0:06:17 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 22 / Train-Loss: 0.2377 / Val-Loss: 0.2513 / Test-Loss: 0.2424 / Time taken: 0:06:31 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 08/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 23 / Train-Loss: 0.2377 / Val-Loss: 0.2509 / Test-Loss: 0.2419 / Time taken: 0:06:45 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 24 / Train-Loss: 0.2376 / Val-Loss: 0.2510 / Test-Loss: 0.2421 / Time taken: 0:07:07 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 08/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 25 / Train-Loss: 0.2376 / Val-Loss: 0.2504 / Test-Loss: 0.2416 / Time taken: 0:07:29 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 26 / Train-Loss: 0.2376 / Val-Loss: 0.2509 / Test-Loss: 0.2420 / Time taken: 0:07:43 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 08/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 27 / Train-Loss: 0.2375 / Val-Loss: 0.2504 / Test-Loss: 0.2416 / Time taken: 0:07:57 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 08/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 28 / Train-Loss: 0.2375 / Val-Loss: 0.2503 / Test-Loss: 0.2415 / Time taken: 0:08:13 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 29 / Train-Loss: 0.2375 / Val-Loss: 0.2505 / Test-Loss: 0.2417 / Time taken: 0:08:27 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 08/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 30 / Train-Loss: 0.2373 / Val-Loss: 0.2502 / Test-Loss: 0.2415 / Time taken: 0:08:41 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 31 / Train-Loss: 0.2374 / Val-Loss: 0.2499 / Test-Loss: 0.2412 / Time taken: 0:08:56 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 32 / Train-Loss: 0.2373 / Val-Loss: 0.2501 / Test-Loss: 0.2412 / Time taken: 0:09:12 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 33 / Train-Loss: 0.2373 / Val-Loss: 0.2501 / Test-Loss: 0.2412 / Time taken: 0:09:27 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 34 / Train-Loss: 0.2372 / Val-Loss: 0.2500 / Test-Loss: 0.2411 / Time taken: 0:09:42 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 35 / Train-Loss: 0.2373 / Val-Loss: 0.2499 / Test-Loss: 0.2410 / Time taken: 0:09:55 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 36 / Train-Loss: 0.2372 / Val-Loss: 0.2500 / Test-Loss: 0.2411 / Time taken: 0:10:09 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 37 / Train-Loss: 0.2372 / Val-Loss: 0.2499 / Test-Loss: 0.2409 / Time taken: 0:10:25 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 38 / Train-Loss: 0.2372 / Val-Loss: 0.2498 / Test-Loss: 0.2409 / Time taken: 0:10:40 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 39 / Train-Loss: 0.2371 / Val-Loss: 0.2498 / Test-Loss: 0.2410 / Time taken: 0:10:56 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 08/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 40 / Train-Loss: 0.2370 / Val-Loss: 0.2497 / Test-Loss: 0.2408 / Time taken: 0:11:09 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 41 / Train-Loss: 0.2369 / Val-Loss: 0.2495 / Test-Loss: 0.2406 / Time taken: 0:11:25 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 42 / Train-Loss: 0.2369 / Val-Loss: 0.2495 / Test-Loss: 0.2406 / Time taken: 0:11:40 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 43 / Train-Loss: 0.2368 / Val-Loss: 0.2496 / Test-Loss: 0.2405 / Time taken: 0:11:56 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 44 / Train-Loss: 0.2367 / Val-Loss: 0.2499 / Test-Loss: 0.2407 / Time taken: 0:12:09 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 45 / Train-Loss: 0.2366 / Val-Loss: 0.2491 / Test-Loss: 0.2401 / Time taken: 0:12:24 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 46 / Train-Loss: 0.2366 / Val-Loss: 0.2491 / Test-Loss: 0.2400 / Time taken: 0:12:40 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 08/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 47 / Train-Loss: 0.2366 / Val-Loss: 0.2499 / Test-Loss: 0.2406 / Time taken: 0:12:54 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 08/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 48 / Train-Loss: 0.2364 / Val-Loss: 0.2494 / Test-Loss: 0.2403 / Time taken: 0:13:09 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 08/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 49 / Train-Loss: 0.2364 / Val-Loss: 0.2489 / Test-Loss: 0.2399 / Time taken: 0:13:24 / ---- Currently Best Val-Epoch: 49 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 50 / Train-Loss: 0.2365 / Val-Loss: 0.2494 / Test-Loss: 0.2402 / Time taken: 0:13:39 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 08/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 51 / Train-Loss: 0.2363 / Val-Loss: 0.2506 / Test-Loss: 0.2412 / Time taken: 0:13:54 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 08/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 52 / Train-Loss: 0.2365 / Val-Loss: 0.2488 / Test-Loss: 0.2399 / Time taken: 0:14:09 / ---- Currently Best Val-Epoch: 52 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 53 / Train-Loss: 0.2364 / Val-Loss: 0.2488 / Test-Loss: 0.2398 / Time taken: 0:14:24 / ---- Currently Best Val-Epoch: 53 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 54 / Train-Loss: 0.2363 / Val-Loss: 0.2488 / Test-Loss: 0.2396 / Time taken: 0:14:39 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 55 / Train-Loss: 0.2363 / Val-Loss: 0.2499 / Test-Loss: 0.2405 / Time taken: 0:14:55 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 56 / Train-Loss: 0.2362 / Val-Loss: 0.2492 / Test-Loss: 0.2399 / Time taken: 0:15:09 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 57 / Train-Loss: 0.2361 / Val-Loss: 0.2490 / Test-Loss: 0.2397 / Time taken: 0:15:24 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 58 / Train-Loss: 0.2362 / Val-Loss: 0.2494 / Test-Loss: 0.2400 / Time taken: 0:15:38 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 59 / Train-Loss: 0.2362 / Val-Loss: 0.2497 / Test-Loss: 0.2403 / Time taken: 0:15:54 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 60 / Train-Loss: 0.2361 / Val-Loss: 0.2486 / Test-Loss: 0.2394 / Time taken: 0:16:15 / ---- Currently Best Val-Epoch: 60 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 61 / Train-Loss: 0.2360 / Val-Loss: 0.2499 / Test-Loss: 0.2403 / Time taken: 0:16:30 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 08/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 62 / Train-Loss: 0.2360 / Val-Loss: 0.2489 / Test-Loss: 0.2395 / Time taken: 0:16:45 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 08/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 63 / Train-Loss: 0.2360 / Val-Loss: 0.2484 / Test-Loss: 0.2392 / Time taken: 0:17:00 / ---- Currently Best Val-Epoch: 63 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 64 / Train-Loss: 0.2360 / Val-Loss: 0.2483 / Test-Loss: 0.2393 / Time taken: 0:17:15 / ---- Currently Best Val-Epoch: 64 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 65 / Train-Loss: 0.2359 / Val-Loss: 0.2489 / Test-Loss: 0.2395 / Time taken: 0:17:30 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 08/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 66 / Train-Loss: 0.2359 / Val-Loss: 0.2487 / Test-Loss: 0.2396 / Time taken: 0:17:44 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 08/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 67 / Train-Loss: 0.2358 / Val-Loss: 0.2484 / Test-Loss: 0.2392 / Time taken: 0:17:58 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 08/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 68 / Train-Loss: 0.2358 / Val-Loss: 0.2487 / Test-Loss: 0.2393 / Time taken: 0:18:14 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 08/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 69 / Train-Loss: 0.2357 / Val-Loss: 0.2485 / Test-Loss: 0.2396 / Time taken: 0:18:28 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 08/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 70 / Train-Loss: 0.2358 / Val-Loss: 0.2482 / Test-Loss: 0.2395 / Time taken: 0:18:43 / ---- Currently Best Val-Epoch: 70 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 71 / Train-Loss: 0.2357 / Val-Loss: 0.2482 / Test-Loss: 0.2391 / Time taken: 0:18:58 / ---- Currently Best Val-Epoch: 71 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 72 / Train-Loss: 0.2357 / Val-Loss: 0.2485 / Test-Loss: 0.2396 / Time taken: 0:19:14 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 73 / Train-Loss: 0.2357 / Val-Loss: 0.2485 / Test-Loss: 0.2395 / Time taken: 0:19:30 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 74 / Train-Loss: 0.2357 / Val-Loss: 0.2486 / Test-Loss: 0.2393 / Time taken: 0:19:44 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 75 / Train-Loss: 0.2358 / Val-Loss: 0.2495 / Test-Loss: 0.2399 / Time taken: 0:19:59 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 76 / Train-Loss: 0.2356 / Val-Loss: 0.2489 / Test-Loss: 0.2395 / Time taken: 0:20:13 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 77 / Train-Loss: 0.2356 / Val-Loss: 0.2483 / Test-Loss: 0.2393 / Time taken: 0:20:30 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 78 / Train-Loss: 0.2356 / Val-Loss: 0.2482 / Test-Loss: 0.2392 / Time taken: 0:20:45 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 79 / Train-Loss: 0.2356 / Val-Loss: 0.2484 / Test-Loss: 0.2394 / Time taken: 0:20:59 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 80 / Train-Loss: 0.2355 / Val-Loss: 0.2484 / Test-Loss: 0.2392 / Time taken: 0:21:21 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 81 / Train-Loss: 0.2355 / Val-Loss: 0.2486 / Test-Loss: 0.2392 / Time taken: 0:21:42 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 82 / Train-Loss: 0.2356 / Val-Loss: 0.2489 / Test-Loss: 0.2394 / Time taken: 0:21:57 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 83 / Train-Loss: 0.2355 / Val-Loss: 0.2484 / Test-Loss: 0.2391 / Time taken: 0:22:12 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 84 / Train-Loss: 0.2355 / Val-Loss: 0.2485 / Test-Loss: 0.2392 / Time taken: 0:22:26 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 85 / Train-Loss: 0.2354 / Val-Loss: 0.2482 / Test-Loss: 0.2392 / Time taken: 0:22:42 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 86 / Train-Loss: 0.2354 / Val-Loss: 0.2485 / Test-Loss: 0.2392 / Time taken: 0:22:57 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 08/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 87 / Train-Loss: 0.2354 / Val-Loss: 0.2483 / Test-Loss: 0.2392 / Time taken: 0:23:12 / ---- Currently Best Val-Epoch: 71 \n","596/596 [==============================] - 12s 18ms/step\n","67/67 [==============================] - 1s 16ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-1b6c4326-49dc-49f1-bd72-fc3e919ae77e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>FT_transformer (run: 4)</td>\n","      <td>90</td>\n","      <td>2107.885792</td>\n","      <td>27133</td>\n","      <td>0.236846</td>\n","      <td>0.238730</td>\n","      <td>0.063062</td>\n","      <td>0.063192</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>FT_transformer (run: 5)</td>\n","      <td>71</td>\n","      <td>1416.576316</td>\n","      <td>27133</td>\n","      <td>0.237981</td>\n","      <td>0.239434</td>\n","      <td>0.060926</td>\n","      <td>0.061031</td>\n","    </tr>\n","    <tr>\n","      <th>126</th>\n","      <td>FT_transformer (run: 6)</td>\n","      <td>109</td>\n","      <td>1999.786216</td>\n","      <td>27133</td>\n","      <td>0.236723</td>\n","      <td>0.238745</td>\n","      <td>0.061890</td>\n","      <td>0.061992</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>FT_transformer (run: 7)</td>\n","      <td>83</td>\n","      <td>1588.023347</td>\n","      <td>27133</td>\n","      <td>0.236495</td>\n","      <td>0.238729</td>\n","      <td>0.064304</td>\n","      <td>0.064473</td>\n","    </tr>\n","    <tr>\n","      <th>128</th>\n","      <td>FT_transformer (run: 8)</td>\n","      <td>71</td>\n","      <td>1392.158405</td>\n","      <td>27133</td>\n","      <td>0.237939</td>\n","      <td>0.239110</td>\n","      <td>0.060636</td>\n","      <td>0.060748</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>129 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b6c4326-49dc-49f1-bd72-fc3e919ae77e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1b6c4326-49dc-49f1-bd72-fc3e919ae77e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1b6c4326-49dc-49f1-bd72-fc3e919ae77e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ee5f52f4-4c21-43a6-baaf-c52dfab22adb\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee5f52f4-4c21-43a6-baaf-c52dfab22adb')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ee5f52f4-4c21-43a6-baaf-c52dfab22adb button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","124     FT_transformer (run: 4)      90  2107.885792          27133   \n","125     FT_transformer (run: 5)      71  1416.576316          27133   \n","126     FT_transformer (run: 6)     109  1999.786216          27133   \n","127     FT_transformer (run: 7)      83  1588.023347          27133   \n","128     FT_transformer (run: 8)      71  1392.158405          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","124    0.236846   0.238730             0.063062            0.063192  \n","125    0.237981   0.239434             0.060926            0.061031  \n","126    0.236723   0.238745             0.061890            0.061992  \n","127    0.236495   0.238729             0.064304            0.064473  \n","128    0.237939   0.239110             0.060636            0.060748  \n","\n","[129 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 09-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 09/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0102  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 0 / Train-Loss: 0.3012 / Val-Loss: 0.2620 / Test-Loss: 0.2600 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0076  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 1 / Train-Loss: 0.2537 / Val-Loss: 0.2565 / Test-Loss: 0.2542 / Time taken: 0:00:57 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0065  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 2 / Train-Loss: 0.2470 / Val-Loss: 0.2540 / Test-Loss: 0.2510 / Time taken: 0:01:11 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0061  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 3 / Train-Loss: 0.2427 / Val-Loss: 0.2529 / Test-Loss: 0.2496 / Time taken: 0:01:25 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0062  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 4 / Train-Loss: 0.2415 / Val-Loss: 0.2518 / Test-Loss: 0.2482 / Time taken: 0:01:40 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.006   : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 5 / Train-Loss: 0.2406 / Val-Loss: 0.2513 / Test-Loss: 0.2475 / Time taken: 0:01:54 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0063  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 6 / Train-Loss: 0.2402 / Val-Loss: 0.2504 / Test-Loss: 0.2465 / Time taken: 0:02:10 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0062  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 7 / Train-Loss: 0.2398 / Val-Loss: 0.2501 / Test-Loss: 0.2461 / Time taken: 0:02:24 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0062  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 8 / Train-Loss: 0.2396 / Val-Loss: 0.2500 / Test-Loss: 0.2460 / Time taken: 0:02:39 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0061  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 9 / Train-Loss: 0.2396 / Val-Loss: 0.2499 / Test-Loss: 0.2457 / Time taken: 0:02:54 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 10 / Train-Loss: 0.2392 / Val-Loss: 0.2494 / Test-Loss: 0.2451 / Time taken: 0:03:08 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 11 / Batch: 1 / Train-Loss (Batch): 0.1536   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 09/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 11 / Train-Loss: 0.2391 / Val-Loss: 0.2497 / Test-Loss: 0.2453 / Time taken: 0:03:22 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 09/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 12 / Train-Loss: 0.2390 / Val-Loss: 0.2500 / Test-Loss: 0.2455 / Time taken: 0:03:37 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 09/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.006  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 13 / Train-Loss: 0.2387 / Val-Loss: 0.2499 / Test-Loss: 0.2452 / Time taken: 0:03:51 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 09/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 14 / Train-Loss: 0.2387 / Val-Loss: 0.2491 / Test-Loss: 0.2444 / Time taken: 0:04:06 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 15 / Train-Loss: 0.2386 / Val-Loss: 0.2490 / Test-Loss: 0.2442 / Time taken: 0:04:20 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 16 / Train-Loss: 0.2383 / Val-Loss: 0.2487 / Test-Loss: 0.2440 / Time taken: 0:04:35 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 17 / Train-Loss: 0.2384 / Val-Loss: 0.2491 / Test-Loss: 0.2443 / Time taken: 0:04:51 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 09/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 18 / Train-Loss: 0.2383 / Val-Loss: 0.2484 / Test-Loss: 0.2435 / Time taken: 0:05:05 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 19 / Train-Loss: 0.2381 / Val-Loss: 0.2486 / Test-Loss: 0.2436 / Time taken: 0:05:20 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 09/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.006  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 20 / Train-Loss: 0.2381 / Val-Loss: 0.2485 / Test-Loss: 0.2435 / Time taken: 0:05:34 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 09/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0061 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 21 / Train-Loss: 0.2380 / Val-Loss: 0.2481 / Test-Loss: 0.2431 / Time taken: 0:05:49 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 22 / Train-Loss: 0.2381 / Val-Loss: 0.2483 / Test-Loss: 0.2433 / Time taken: 0:06:03 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 09/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 23 / Train-Loss: 0.2380 / Val-Loss: 0.2477 / Test-Loss: 0.2428 / Time taken: 0:06:18 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 24 / Train-Loss: 0.2380 / Val-Loss: 0.2481 / Test-Loss: 0.2431 / Time taken: 0:06:32 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 09/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 25 / Train-Loss: 0.2379 / Val-Loss: 0.2477 / Test-Loss: 0.2427 / Time taken: 0:06:47 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 09/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 26 / Train-Loss: 0.2378 / Val-Loss: 0.2476 / Test-Loss: 0.2426 / Time taken: 0:07:02 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 27 / Train-Loss: 0.2378 / Val-Loss: 0.2475 / Test-Loss: 0.2426 / Time taken: 0:07:16 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 28 / Train-Loss: 0.2378 / Val-Loss: 0.2474 / Test-Loss: 0.2425 / Time taken: 0:07:30 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 29 / Train-Loss: 0.2378 / Val-Loss: 0.2472 / Test-Loss: 0.2423 / Time taken: 0:07:46 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 30 / Train-Loss: 0.2376 / Val-Loss: 0.2471 / Test-Loss: 0.2422 / Time taken: 0:08:00 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 31 / Train-Loss: 0.2376 / Val-Loss: 0.2468 / Test-Loss: 0.2421 / Time taken: 0:08:15 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 32 / Train-Loss: 0.2376 / Val-Loss: 0.2467 / Test-Loss: 0.2419 / Time taken: 0:08:29 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 33 / Train-Loss: 0.2376 / Val-Loss: 0.2469 / Test-Loss: 0.2422 / Time taken: 0:08:45 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 09/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 34 / Train-Loss: 0.2377 / Val-Loss: 0.2469 / Test-Loss: 0.2420 / Time taken: 0:08:59 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 09/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 35 / Train-Loss: 0.2376 / Val-Loss: 0.2469 / Test-Loss: 0.2420 / Time taken: 0:09:13 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 09/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 36 / Train-Loss: 0.2374 / Val-Loss: 0.2466 / Test-Loss: 0.2418 / Time taken: 0:09:27 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 37 / Train-Loss: 0.2375 / Val-Loss: 0.2465 / Test-Loss: 0.2418 / Time taken: 0:09:43 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 38 / Train-Loss: 0.2374 / Val-Loss: 0.2464 / Test-Loss: 0.2417 / Time taken: 0:09:59 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 39 / Train-Loss: 0.2375 / Val-Loss: 0.2466 / Test-Loss: 0.2419 / Time taken: 0:10:14 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 09/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 40 / Train-Loss: 0.2374 / Val-Loss: 0.2462 / Test-Loss: 0.2415 / Time taken: 0:10:28 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 41 / Train-Loss: 0.2374 / Val-Loss: 0.2465 / Test-Loss: 0.2417 / Time taken: 0:10:44 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 09/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 42 / Train-Loss: 0.2374 / Val-Loss: 0.2466 / Test-Loss: 0.2417 / Time taken: 0:10:58 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 09/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 43 / Train-Loss: 0.2374 / Val-Loss: 0.2457 / Test-Loss: 0.2409 / Time taken: 0:11:12 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 44 / Train-Loss: 0.2373 / Val-Loss: 0.2459 / Test-Loss: 0.2412 / Time taken: 0:11:28 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 09/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 45 / Train-Loss: 0.2374 / Val-Loss: 0.2460 / Test-Loss: 0.2413 / Time taken: 0:11:49 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 09/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 46 / Train-Loss: 0.2372 / Val-Loss: 0.2462 / Test-Loss: 0.2414 / Time taken: 0:12:04 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 09/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 47 / Train-Loss: 0.2372 / Val-Loss: 0.2460 / Test-Loss: 0.2412 / Time taken: 0:12:26 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 09/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 48 / Train-Loss: 0.2372 / Val-Loss: 0.2461 / Test-Loss: 0.2414 / Time taken: 0:12:47 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 09/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 49 / Train-Loss: 0.2371 / Val-Loss: 0.2458 / Test-Loss: 0.2412 / Time taken: 0:13:02 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 09/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 50 / Train-Loss: 0.2371 / Val-Loss: 0.2459 / Test-Loss: 0.2412 / Time taken: 0:13:16 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 09/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 51 / Train-Loss: 0.2370 / Val-Loss: 0.2456 / Test-Loss: 0.2410 / Time taken: 0:13:31 / ---- Currently Best Val-Epoch: 51 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 52 / Train-Loss: 0.2369 / Val-Loss: 0.2454 / Test-Loss: 0.2408 / Time taken: 0:13:45 / ---- Currently Best Val-Epoch: 52 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 53 / Train-Loss: 0.2368 / Val-Loss: 0.2460 / Test-Loss: 0.2413 / Time taken: 0:14:00 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 09/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 54 / Train-Loss: 0.2368 / Val-Loss: 0.2458 / Test-Loss: 0.2410 / Time taken: 0:14:14 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 09/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 55 / Train-Loss: 0.2367 / Val-Loss: 0.2455 / Test-Loss: 0.2409 / Time taken: 0:14:29 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 09/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 56 / Train-Loss: 0.2367 / Val-Loss: 0.2453 / Test-Loss: 0.2406 / Time taken: 0:14:50 / ---- Currently Best Val-Epoch: 56 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 57 / Train-Loss: 0.2367 / Val-Loss: 0.2455 / Test-Loss: 0.2408 / Time taken: 0:15:06 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 58 / Train-Loss: 0.2366 / Val-Loss: 0.2456 / Test-Loss: 0.2409 / Time taken: 0:15:20 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 59 / Train-Loss: 0.2366 / Val-Loss: 0.2458 / Test-Loss: 0.2409 / Time taken: 0:15:35 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 60 / Train-Loss: 0.2365 / Val-Loss: 0.2453 / Test-Loss: 0.2404 / Time taken: 0:15:57 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 61 / Train-Loss: 0.2365 / Val-Loss: 0.2457 / Test-Loss: 0.2407 / Time taken: 0:16:11 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 62 / Train-Loss: 0.2365 / Val-Loss: 0.2460 / Test-Loss: 0.2411 / Time taken: 0:16:26 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 63 / Train-Loss: 0.2364 / Val-Loss: 0.2459 / Test-Loss: 0.2410 / Time taken: 0:16:42 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 64 / Train-Loss: 0.2363 / Val-Loss: 0.2455 / Test-Loss: 0.2405 / Time taken: 0:17:03 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 65 / Train-Loss: 0.2363 / Val-Loss: 0.2456 / Test-Loss: 0.2406 / Time taken: 0:17:18 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 66 / Train-Loss: 0.2363 / Val-Loss: 0.2459 / Test-Loss: 0.2408 / Time taken: 0:17:34 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 67 / Train-Loss: 0.2361 / Val-Loss: 0.2453 / Test-Loss: 0.2404 / Time taken: 0:17:48 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 68 / Train-Loss: 0.2362 / Val-Loss: 0.2456 / Test-Loss: 0.2405 / Time taken: 0:18:03 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0062 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 69 / Train-Loss: 0.2361 / Val-Loss: 0.2458 / Test-Loss: 0.2409 / Time taken: 0:18:17 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 09/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 70 / Train-Loss: 0.2362 / Val-Loss: 0.2450 / Test-Loss: 0.2401 / Time taken: 0:18:32 / ---- Currently Best Val-Epoch: 70 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 71 / Train-Loss: 0.2361 / Val-Loss: 0.2454 / Test-Loss: 0.2405 / Time taken: 0:18:46 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 72 / Train-Loss: 0.2359 / Val-Loss: 0.2454 / Test-Loss: 0.2404 / Time taken: 0:19:00 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 73 / Train-Loss: 0.2360 / Val-Loss: 0.2453 / Test-Loss: 0.2402 / Time taken: 0:19:22 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 74 / Train-Loss: 0.2359 / Val-Loss: 0.2452 / Test-Loss: 0.2402 / Time taken: 0:19:43 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 75 / Train-Loss: 0.2360 / Val-Loss: 0.2454 / Test-Loss: 0.2404 / Time taken: 0:19:57 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 76 / Train-Loss: 0.2360 / Val-Loss: 0.2452 / Test-Loss: 0.2402 / Time taken: 0:20:11 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 77 / Train-Loss: 0.2360 / Val-Loss: 0.2455 / Test-Loss: 0.2406 / Time taken: 0:20:26 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 78 / Train-Loss: 0.2360 / Val-Loss: 0.2453 / Test-Loss: 0.2402 / Time taken: 0:20:42 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 79 / Train-Loss: 0.2359 / Val-Loss: 0.2459 / Test-Loss: 0.2409 / Time taken: 0:20:56 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 80 / Train-Loss: 0.2358 / Val-Loss: 0.2457 / Test-Loss: 0.2407 / Time taken: 0:21:10 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 81 / Train-Loss: 0.2358 / Val-Loss: 0.2460 / Test-Loss: 0.2409 / Time taken: 0:21:24 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 82 / Train-Loss: 0.2358 / Val-Loss: 0.2452 / Test-Loss: 0.2403 / Time taken: 0:21:46 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 83 / Train-Loss: 0.2357 / Val-Loss: 0.2451 / Test-Loss: 0.2402 / Time taken: 0:22:00 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0063 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 84 / Train-Loss: 0.2358 / Val-Loss: 0.2458 / Test-Loss: 0.2408 / Time taken: 0:22:14 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 85 / Train-Loss: 0.2357 / Val-Loss: 0.2452 / Test-Loss: 0.2403 / Time taken: 0:22:37 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 09/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 86 / Train-Loss: 0.2356 / Val-Loss: 0.2458 / Test-Loss: 0.2408 / Time taken: 0:22:52 / ---- Currently Best Val-Epoch: 70 \n","596/596 [==============================] - 12s 19ms/step\n","67/67 [==============================] - 1s 16ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-72c3217b-34e9-4aa0-93c3-15abb2455c23\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>FT_transformer (run: 5)</td>\n","      <td>71</td>\n","      <td>1416.576316</td>\n","      <td>27133</td>\n","      <td>0.237981</td>\n","      <td>0.239434</td>\n","      <td>0.060926</td>\n","      <td>0.061031</td>\n","    </tr>\n","    <tr>\n","      <th>126</th>\n","      <td>FT_transformer (run: 6)</td>\n","      <td>109</td>\n","      <td>1999.786216</td>\n","      <td>27133</td>\n","      <td>0.236723</td>\n","      <td>0.238745</td>\n","      <td>0.061890</td>\n","      <td>0.061992</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>FT_transformer (run: 7)</td>\n","      <td>83</td>\n","      <td>1588.023347</td>\n","      <td>27133</td>\n","      <td>0.236495</td>\n","      <td>0.238729</td>\n","      <td>0.064304</td>\n","      <td>0.064473</td>\n","    </tr>\n","    <tr>\n","      <th>128</th>\n","      <td>FT_transformer (run: 8)</td>\n","      <td>71</td>\n","      <td>1392.158405</td>\n","      <td>27133</td>\n","      <td>0.237939</td>\n","      <td>0.239110</td>\n","      <td>0.060636</td>\n","      <td>0.060748</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>FT_transformer (run: 9)</td>\n","      <td>70</td>\n","      <td>1372.753220</td>\n","      <td>27133</td>\n","      <td>0.239179</td>\n","      <td>0.240097</td>\n","      <td>0.058446</td>\n","      <td>0.058635</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>130 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72c3217b-34e9-4aa0-93c3-15abb2455c23')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-72c3217b-34e9-4aa0-93c3-15abb2455c23 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-72c3217b-34e9-4aa0-93c3-15abb2455c23');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ca8c1cd2-b509-4f66-8104-8385930714ca\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca8c1cd2-b509-4f66-8104-8385930714ca')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ca8c1cd2-b509-4f66-8104-8385930714ca button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","125     FT_transformer (run: 5)      71  1416.576316          27133   \n","126     FT_transformer (run: 6)     109  1999.786216          27133   \n","127     FT_transformer (run: 7)      83  1588.023347          27133   \n","128     FT_transformer (run: 8)      71  1392.158405          27133   \n","129     FT_transformer (run: 9)      70  1372.753220          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","125    0.237981   0.239434             0.060926            0.061031  \n","126    0.236723   0.238745             0.061890            0.061992  \n","127    0.236495   0.238729             0.064304            0.064473  \n","128    0.237939   0.239110             0.060636            0.060748  \n","129    0.239179   0.240097             0.058446            0.058635  \n","\n","[130 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 10-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 10/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0297  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 0 / Train-Loss: 0.3201 / Val-Loss: 0.2548 / Test-Loss: 0.2559 / Time taken: 0:00:28 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0301  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 1 / Train-Loss: 0.2521 / Val-Loss: 0.2519 / Test-Loss: 0.2527 / Time taken: 0:00:50 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0308  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 2 / Train-Loss: 0.2459 / Val-Loss: 0.2494 / Test-Loss: 0.2498 / Time taken: 0:01:04 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.031   : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 3 / Train-Loss: 0.2428 / Val-Loss: 0.2487 / Test-Loss: 0.2490 / Time taken: 0:01:18 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0318  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 4 / Train-Loss: 0.2417 / Val-Loss: 0.2475 / Test-Loss: 0.2476 / Time taken: 0:01:32 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0318  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 5 / Train-Loss: 0.2410 / Val-Loss: 0.2467 / Test-Loss: 0.2467 / Time taken: 0:01:54 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 6 / Train-Loss: 0.2403 / Val-Loss: 0.2462 / Test-Loss: 0.2461 / Time taken: 0:02:15 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0324  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 7 / Train-Loss: 0.2401 / Val-Loss: 0.2456 / Test-Loss: 0.2454 / Time taken: 0:02:29 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0324  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 8 / Train-Loss: 0.2398 / Val-Loss: 0.2454 / Test-Loss: 0.2451 / Time taken: 0:02:43 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0321  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 9 / Train-Loss: 0.2394 / Val-Loss: 0.2453 / Test-Loss: 0.2449 / Time taken: 0:02:58 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 10 / Train-Loss: 0.2393 / Val-Loss: 0.2451 / Test-Loss: 0.2446 / Time taken: 0:03:13 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 10/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 11 / Train-Loss: 0.2391 / Val-Loss: 0.2448 / Test-Loss: 0.2443 / Time taken: 0:03:28 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 12 / Train-Loss: 0.2391 / Val-Loss: 0.2444 / Test-Loss: 0.2439 / Time taken: 0:03:43 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 13 / Train-Loss: 0.2390 / Val-Loss: 0.2441 / Test-Loss: 0.2435 / Time taken: 0:03:58 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 14 / Train-Loss: 0.2387 / Val-Loss: 0.2438 / Test-Loss: 0.2432 / Time taken: 0:04:13 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 15 / Train-Loss: 0.2387 / Val-Loss: 0.2436 / Test-Loss: 0.2429 / Time taken: 0:04:27 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 16 / Train-Loss: 0.2387 / Val-Loss: 0.2439 / Test-Loss: 0.2433 / Time taken: 0:04:42 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 10/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 17 / Train-Loss: 0.2385 / Val-Loss: 0.2435 / Test-Loss: 0.2430 / Time taken: 0:05:03 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 18 / Train-Loss: 0.2386 / Val-Loss: 0.2435 / Test-Loss: 0.2429 / Time taken: 0:05:25 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 19 / Train-Loss: 0.2385 / Val-Loss: 0.2431 / Test-Loss: 0.2425 / Time taken: 0:05:48 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 20 / Train-Loss: 0.2385 / Val-Loss: 0.2429 / Test-Loss: 0.2423 / Time taken: 0:06:03 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 21 / Train-Loss: 0.2384 / Val-Loss: 0.2428 / Test-Loss: 0.2423 / Time taken: 0:06:25 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 22 / Train-Loss: 0.2384 / Val-Loss: 0.2427 / Test-Loss: 0.2422 / Time taken: 0:06:39 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 23 / Train-Loss: 0.2384 / Val-Loss: 0.2423 / Test-Loss: 0.2418 / Time taken: 0:06:57 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 24 / Train-Loss: 0.2383 / Val-Loss: 0.2423 / Test-Loss: 0.2418 / Time taken: 0:07:12 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 10/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 25 / Train-Loss: 0.2382 / Val-Loss: 0.2424 / Test-Loss: 0.2418 / Time taken: 0:07:26 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 10/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 26 / Train-Loss: 0.2384 / Val-Loss: 0.2423 / Test-Loss: 0.2418 / Time taken: 0:07:40 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 10/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 27 / Train-Loss: 0.2383 / Val-Loss: 0.2421 / Test-Loss: 0.2416 / Time taken: 0:07:56 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 28 / Train-Loss: 0.2381 / Val-Loss: 0.2422 / Test-Loss: 0.2417 / Time taken: 0:08:11 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 10/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 29 / Train-Loss: 0.2381 / Val-Loss: 0.2419 / Test-Loss: 0.2415 / Time taken: 0:08:33 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 30 / Train-Loss: 0.2381 / Val-Loss: 0.2418 / Test-Loss: 0.2413 / Time taken: 0:08:48 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 31 / Train-Loss: 0.2381 / Val-Loss: 0.2416 / Test-Loss: 0.2411 / Time taken: 0:09:11 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 32 / Train-Loss: 0.2380 / Val-Loss: 0.2419 / Test-Loss: 0.2414 / Time taken: 0:09:26 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 10/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 33 / Train-Loss: 0.2380 / Val-Loss: 0.2418 / Test-Loss: 0.2413 / Time taken: 0:09:40 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 10/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 34 / Train-Loss: 0.2380 / Val-Loss: 0.2416 / Test-Loss: 0.2411 / Time taken: 0:09:54 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 10/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 35 / Train-Loss: 0.2379 / Val-Loss: 0.2414 / Test-Loss: 0.2409 / Time taken: 0:10:11 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 36 / Train-Loss: 0.2379 / Val-Loss: 0.2415 / Test-Loss: 0.2410 / Time taken: 0:10:25 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 10/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 37 / Train-Loss: 0.2380 / Val-Loss: 0.2413 / Test-Loss: 0.2409 / Time taken: 0:10:39 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 38 / Train-Loss: 0.2379 / Val-Loss: 0.2411 / Test-Loss: 0.2407 / Time taken: 0:10:53 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 39 / Train-Loss: 0.2379 / Val-Loss: 0.2412 / Test-Loss: 0.2408 / Time taken: 0:11:08 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 10/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 40 / Train-Loss: 0.2378 / Val-Loss: 0.2414 / Test-Loss: 0.2410 / Time taken: 0:11:23 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 10/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 41 / Train-Loss: 0.2378 / Val-Loss: 0.2412 / Test-Loss: 0.2408 / Time taken: 0:11:37 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 10/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 42 / Train-Loss: 0.2377 / Val-Loss: 0.2411 / Test-Loss: 0.2407 / Time taken: 0:11:51 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 43 / Train-Loss: 0.2377 / Val-Loss: 0.2411 / Test-Loss: 0.2407 / Time taken: 0:12:06 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 10/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 44 / Train-Loss: 0.2377 / Val-Loss: 0.2409 / Test-Loss: 0.2407 / Time taken: 0:12:21 / ---- Currently Best Val-Epoch: 44 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 45 / Train-Loss: 0.2377 / Val-Loss: 0.2409 / Test-Loss: 0.2405 / Time taken: 0:12:35 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 46 / Train-Loss: 0.2376 / Val-Loss: 0.2408 / Test-Loss: 0.2405 / Time taken: 0:12:50 / ---- Currently Best Val-Epoch: 46 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 47 / Train-Loss: 0.2376 / Val-Loss: 0.2408 / Test-Loss: 0.2404 / Time taken: 0:13:04 / ---- Currently Best Val-Epoch: 47 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 48 / Train-Loss: 0.2375 / Val-Loss: 0.2407 / Test-Loss: 0.2404 / Time taken: 0:13:21 / ---- Currently Best Val-Epoch: 48 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 49 / Train-Loss: 0.2376 / Val-Loss: 0.2409 / Test-Loss: 0.2405 / Time taken: 0:13:35 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 10/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 50 / Train-Loss: 0.2375 / Val-Loss: 0.2405 / Test-Loss: 0.2403 / Time taken: 0:13:49 / ---- Currently Best Val-Epoch: 50 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 51 / Train-Loss: 0.2376 / Val-Loss: 0.2405 / Test-Loss: 0.2402 / Time taken: 0:14:04 / ---- Currently Best Val-Epoch: 51 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 52 / Train-Loss: 0.2375 / Val-Loss: 0.2406 / Test-Loss: 0.2404 / Time taken: 0:14:20 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 10/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 53 / Train-Loss: 0.2375 / Val-Loss: 0.2405 / Test-Loss: 0.2402 / Time taken: 0:14:35 / ---- Currently Best Val-Epoch: 53 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 54 / Train-Loss: 0.2374 / Val-Loss: 0.2406 / Test-Loss: 0.2402 / Time taken: 0:14:57 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 10/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 55 / Train-Loss: 0.2374 / Val-Loss: 0.2402 / Test-Loss: 0.2399 / Time taken: 0:15:20 / ---- Currently Best Val-Epoch: 55 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 56 / Train-Loss: 0.2374 / Val-Loss: 0.2405 / Test-Loss: 0.2401 / Time taken: 0:15:34 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 57 / Train-Loss: 0.2374 / Val-Loss: 0.2404 / Test-Loss: 0.2401 / Time taken: 0:15:48 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 58 / Train-Loss: 0.2373 / Val-Loss: 0.2404 / Test-Loss: 0.2402 / Time taken: 0:16:03 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 59 / Train-Loss: 0.2373 / Val-Loss: 0.2403 / Test-Loss: 0.2401 / Time taken: 0:16:24 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 60 / Train-Loss: 0.2373 / Val-Loss: 0.2403 / Test-Loss: 0.2400 / Time taken: 0:16:39 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 61 / Train-Loss: 0.2373 / Val-Loss: 0.2407 / Test-Loss: 0.2403 / Time taken: 0:16:53 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 62 / Train-Loss: 0.2373 / Val-Loss: 0.2405 / Test-Loss: 0.2403 / Time taken: 0:17:08 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 63 / Train-Loss: 0.2373 / Val-Loss: 0.2403 / Test-Loss: 0.2400 / Time taken: 0:17:29 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 64 / Train-Loss: 0.2372 / Val-Loss: 0.2407 / Test-Loss: 0.2404 / Time taken: 0:17:44 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 65 / Train-Loss: 0.2371 / Val-Loss: 0.2409 / Test-Loss: 0.2405 / Time taken: 0:17:58 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 66 / Train-Loss: 0.2371 / Val-Loss: 0.2408 / Test-Loss: 0.2404 / Time taken: 0:18:21 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 67 / Train-Loss: 0.2372 / Val-Loss: 0.2404 / Test-Loss: 0.2400 / Time taken: 0:18:42 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 68 / Train-Loss: 0.2371 / Val-Loss: 0.2403 / Test-Loss: 0.2400 / Time taken: 0:18:57 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 69 / Train-Loss: 0.2371 / Val-Loss: 0.2403 / Test-Loss: 0.2400 / Time taken: 0:19:11 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 70 / Train-Loss: 0.2371 / Val-Loss: 0.2402 / Test-Loss: 0.2400 / Time taken: 0:19:26 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 10/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 71 / Train-Loss: 0.2370 / Val-Loss: 0.2403 / Test-Loss: 0.2400 / Time taken: 0:19:47 / ---- Currently Best Val-Epoch: 55 \n","596/596 [==============================] - 11s 18ms/step\n","67/67 [==============================] - 1s 17ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-4b692e84-2a22-4fbf-a0f6-6b7c7b9ad7be\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>126</th>\n","      <td>FT_transformer (run: 6)</td>\n","      <td>109</td>\n","      <td>1999.786216</td>\n","      <td>27133</td>\n","      <td>0.236723</td>\n","      <td>0.238745</td>\n","      <td>0.061890</td>\n","      <td>0.061992</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>FT_transformer (run: 7)</td>\n","      <td>83</td>\n","      <td>1588.023347</td>\n","      <td>27133</td>\n","      <td>0.236495</td>\n","      <td>0.238729</td>\n","      <td>0.064304</td>\n","      <td>0.064473</td>\n","    </tr>\n","    <tr>\n","      <th>128</th>\n","      <td>FT_transformer (run: 8)</td>\n","      <td>71</td>\n","      <td>1392.158405</td>\n","      <td>27133</td>\n","      <td>0.237939</td>\n","      <td>0.239110</td>\n","      <td>0.060636</td>\n","      <td>0.060748</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>FT_transformer (run: 9)</td>\n","      <td>70</td>\n","      <td>1372.753220</td>\n","      <td>27133</td>\n","      <td>0.239179</td>\n","      <td>0.240097</td>\n","      <td>0.058446</td>\n","      <td>0.058635</td>\n","    </tr>\n","    <tr>\n","      <th>130</th>\n","      <td>FT_transformer (run: 10)</td>\n","      <td>55</td>\n","      <td>1187.509606</td>\n","      <td>27133</td>\n","      <td>0.239155</td>\n","      <td>0.239897</td>\n","      <td>0.059857</td>\n","      <td>0.060138</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>131 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b692e84-2a22-4fbf-a0f6-6b7c7b9ad7be')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4b692e84-2a22-4fbf-a0f6-6b7c7b9ad7be button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4b692e84-2a22-4fbf-a0f6-6b7c7b9ad7be');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b088b072-7b4f-4c2d-aefb-b5084db435f2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b088b072-7b4f-4c2d-aefb-b5084db435f2')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b088b072-7b4f-4c2d-aefb-b5084db435f2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","126     FT_transformer (run: 6)     109  1999.786216          27133   \n","127     FT_transformer (run: 7)      83  1588.023347          27133   \n","128     FT_transformer (run: 8)      71  1392.158405          27133   \n","129     FT_transformer (run: 9)      70  1372.753220          27133   \n","130    FT_transformer (run: 10)      55  1187.509606          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","126    0.236723   0.238745             0.061890            0.061992  \n","127    0.236495   0.238729             0.064304            0.064473  \n","128    0.237939   0.239110             0.060636            0.060748  \n","129    0.239179   0.240097             0.058446            0.058635  \n","130    0.239155   0.239897             0.059857            0.060138  \n","\n","[131 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 11-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 11/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0304  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 0 / Train-Loss: 0.2791 / Val-Loss: 0.2444 / Test-Loss: 0.2541 / Time taken: 0:00:28 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0307  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 1 / Train-Loss: 0.2491 / Val-Loss: 0.2402 / Test-Loss: 0.2497 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0313  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 2 / Train-Loss: 0.2446 / Val-Loss: 0.2386 / Test-Loss: 0.2478 / Time taken: 0:00:57 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0319  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 3 / Train-Loss: 0.2428 / Val-Loss: 0.2372 / Test-Loss: 0.2464 / Time taken: 0:01:12 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.032   : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 4 / Train-Loss: 0.2420 / Val-Loss: 0.2361 / Test-Loss: 0.2452 / Time taken: 0:01:25 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0324  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 5 / Train-Loss: 0.2414 / Val-Loss: 0.2356 / Test-Loss: 0.2446 / Time taken: 0:01:40 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0321  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 6 / Train-Loss: 0.2409 / Val-Loss: 0.2349 / Test-Loss: 0.2439 / Time taken: 0:01:55 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 7 / Train-Loss: 0.2406 / Val-Loss: 0.2348 / Test-Loss: 0.2438 / Time taken: 0:02:10 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 8 / Train-Loss: 0.2404 / Val-Loss: 0.2345 / Test-Loss: 0.2435 / Time taken: 0:02:25 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 9 / Train-Loss: 0.2402 / Val-Loss: 0.2343 / Test-Loss: 0.2432 / Time taken: 0:02:39 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 10 / Train-Loss: 0.2399 / Val-Loss: 0.2341 / Test-Loss: 0.2430 / Time taken: 0:02:55 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 11 / Batch: 2 / Train-Loss (Batch): 0.1366   : [------------------------------] 0.4%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 11/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 11 / Train-Loss: 0.2398 / Val-Loss: 0.2338 / Test-Loss: 0.2426 / Time taken: 0:03:09 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 12 / Train-Loss: 0.2398 / Val-Loss: 0.2342 / Test-Loss: 0.2432 / Time taken: 0:03:24 / ---- Currently Best Val-Epoch: 11 \n","Ensemble: 11/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 13 / Train-Loss: 0.2399 / Val-Loss: 0.2328 / Test-Loss: 0.2417 / Time taken: 0:03:38 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 14 / Train-Loss: 0.2399 / Val-Loss: 0.2333 / Test-Loss: 0.2421 / Time taken: 0:03:54 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 11/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 15 / Train-Loss: 0.2396 / Val-Loss: 0.2332 / Test-Loss: 0.2420 / Time taken: 0:04:09 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 11/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 16 / Train-Loss: 0.2395 / Val-Loss: 0.2333 / Test-Loss: 0.2420 / Time taken: 0:04:24 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 11/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 17 / Train-Loss: 0.2395 / Val-Loss: 0.2328 / Test-Loss: 0.2415 / Time taken: 0:04:39 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 18 / Train-Loss: 0.2395 / Val-Loss: 0.2328 / Test-Loss: 0.2417 / Time taken: 0:04:55 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 11/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 19 / Train-Loss: 0.2394 / Val-Loss: 0.2326 / Test-Loss: 0.2414 / Time taken: 0:05:11 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 20 / Train-Loss: 0.2393 / Val-Loss: 0.2330 / Test-Loss: 0.2417 / Time taken: 0:05:26 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 11/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 21 / Train-Loss: 0.2394 / Val-Loss: 0.2324 / Test-Loss: 0.2411 / Time taken: 0:05:41 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 22 / Train-Loss: 0.2393 / Val-Loss: 0.2321 / Test-Loss: 0.2408 / Time taken: 0:06:03 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 23 / Train-Loss: 0.2393 / Val-Loss: 0.2318 / Test-Loss: 0.2405 / Time taken: 0:06:19 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 24 / Train-Loss: 0.2392 / Val-Loss: 0.2316 / Test-Loss: 0.2404 / Time taken: 0:06:41 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 25 / Train-Loss: 0.2393 / Val-Loss: 0.2318 / Test-Loss: 0.2406 / Time taken: 0:06:56 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 11/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 26 / Train-Loss: 0.2392 / Val-Loss: 0.2317 / Test-Loss: 0.2405 / Time taken: 0:07:13 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 11/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 27 / Train-Loss: 0.2391 / Val-Loss: 0.2317 / Test-Loss: 0.2405 / Time taken: 0:07:28 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 11/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 28 / Train-Loss: 0.2391 / Val-Loss: 0.2315 / Test-Loss: 0.2403 / Time taken: 0:07:50 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 29 / Train-Loss: 0.2391 / Val-Loss: 0.2313 / Test-Loss: 0.2400 / Time taken: 0:08:07 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 30 / Train-Loss: 0.2389 / Val-Loss: 0.2317 / Test-Loss: 0.2405 / Time taken: 0:08:22 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 31 / Train-Loss: 0.2390 / Val-Loss: 0.2318 / Test-Loss: 0.2405 / Time taken: 0:08:38 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 32 / Train-Loss: 0.2390 / Val-Loss: 0.2315 / Test-Loss: 0.2403 / Time taken: 0:09:00 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 33 / Train-Loss: 0.2388 / Val-Loss: 0.2316 / Test-Loss: 0.2404 / Time taken: 0:09:16 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 34 / Train-Loss: 0.2389 / Val-Loss: 0.2314 / Test-Loss: 0.2401 / Time taken: 0:09:31 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 35 / Train-Loss: 0.2389 / Val-Loss: 0.2313 / Test-Loss: 0.2401 / Time taken: 0:09:47 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 36 / Train-Loss: 0.2387 / Val-Loss: 0.2310 / Test-Loss: 0.2398 / Time taken: 0:10:02 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 37 / Train-Loss: 0.2388 / Val-Loss: 0.2309 / Test-Loss: 0.2398 / Time taken: 0:10:17 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 38 / Train-Loss: 0.2387 / Val-Loss: 0.2312 / Test-Loss: 0.2401 / Time taken: 0:10:32 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 11/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 39 / Train-Loss: 0.2387 / Val-Loss: 0.2312 / Test-Loss: 0.2402 / Time taken: 0:10:47 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 11/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 40 / Train-Loss: 0.2387 / Val-Loss: 0.2311 / Test-Loss: 0.2399 / Time taken: 0:11:01 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 11/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 41 / Train-Loss: 0.2386 / Val-Loss: 0.2308 / Test-Loss: 0.2398 / Time taken: 0:11:23 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 42 / Train-Loss: 0.2385 / Val-Loss: 0.2312 / Test-Loss: 0.2400 / Time taken: 0:11:45 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 11/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 43 / Train-Loss: 0.2385 / Val-Loss: 0.2310 / Test-Loss: 0.2399 / Time taken: 0:12:00 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 11/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 44 / Train-Loss: 0.2386 / Val-Loss: 0.2309 / Test-Loss: 0.2398 / Time taken: 0:12:14 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 11/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 45 / Train-Loss: 0.2386 / Val-Loss: 0.2306 / Test-Loss: 0.2393 / Time taken: 0:12:31 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0347 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 46 / Train-Loss: 0.2385 / Val-Loss: 0.2310 / Test-Loss: 0.2398 / Time taken: 0:12:46 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 11/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 47 / Train-Loss: 0.2385 / Val-Loss: 0.2307 / Test-Loss: 0.2396 / Time taken: 0:13:01 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 11/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 48 / Train-Loss: 0.2385 / Val-Loss: 0.2309 / Test-Loss: 0.2397 / Time taken: 0:13:16 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 11/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 49 / Train-Loss: 0.2385 / Val-Loss: 0.2306 / Test-Loss: 0.2395 / Time taken: 0:13:32 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 11/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 50 / Train-Loss: 0.2385 / Val-Loss: 0.2306 / Test-Loss: 0.2394 / Time taken: 0:13:48 / ---- Currently Best Val-Epoch: 50 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 51 / Train-Loss: 0.2383 / Val-Loss: 0.2306 / Test-Loss: 0.2394 / Time taken: 0:14:03 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 11/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 52 / Train-Loss: 0.2385 / Val-Loss: 0.2307 / Test-Loss: 0.2396 / Time taken: 0:14:18 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 11/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 53 / Train-Loss: 0.2382 / Val-Loss: 0.2308 / Test-Loss: 0.2396 / Time taken: 0:14:40 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 11/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 54 / Train-Loss: 0.2383 / Val-Loss: 0.2306 / Test-Loss: 0.2395 / Time taken: 0:14:54 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 11/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 55 / Train-Loss: 0.2383 / Val-Loss: 0.2306 / Test-Loss: 0.2394 / Time taken: 0:15:10 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 11/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 56 / Train-Loss: 0.2382 / Val-Loss: 0.2308 / Test-Loss: 0.2396 / Time taken: 0:15:24 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 11/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 57 / Train-Loss: 0.2381 / Val-Loss: 0.2305 / Test-Loss: 0.2393 / Time taken: 0:15:41 / ---- Currently Best Val-Epoch: 57 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 58 / Train-Loss: 0.2382 / Val-Loss: 0.2306 / Test-Loss: 0.2394 / Time taken: 0:15:55 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 11/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 59 / Train-Loss: 0.2382 / Val-Loss: 0.2307 / Test-Loss: 0.2395 / Time taken: 0:16:10 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 11/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 60 / Train-Loss: 0.2382 / Val-Loss: 0.2307 / Test-Loss: 0.2395 / Time taken: 0:16:32 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 11/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 61 / Train-Loss: 0.2381 / Val-Loss: 0.2305 / Test-Loss: 0.2393 / Time taken: 0:16:55 / ---- Currently Best Val-Epoch: 61 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 62 / Train-Loss: 0.2380 / Val-Loss: 0.2305 / Test-Loss: 0.2393 / Time taken: 0:17:10 / ---- Currently Best Val-Epoch: 61 \n","Ensemble: 11/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 63 / Train-Loss: 0.2381 / Val-Loss: 0.2306 / Test-Loss: 0.2394 / Time taken: 0:17:25 / ---- Currently Best Val-Epoch: 61 \n","Ensemble: 11/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 64 / Train-Loss: 0.2380 / Val-Loss: 0.2307 / Test-Loss: 0.2394 / Time taken: 0:17:40 / ---- Currently Best Val-Epoch: 61 \n","Ensemble: 11/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 65 / Train-Loss: 0.2380 / Val-Loss: 0.2304 / Test-Loss: 0.2391 / Time taken: 0:17:56 / ---- Currently Best Val-Epoch: 65 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 66 / Train-Loss: 0.2380 / Val-Loss: 0.2305 / Test-Loss: 0.2392 / Time taken: 0:18:19 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 11/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 67 / Train-Loss: 0.2379 / Val-Loss: 0.2307 / Test-Loss: 0.2395 / Time taken: 0:18:34 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 11/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 68 / Train-Loss: 0.2379 / Val-Loss: 0.2305 / Test-Loss: 0.2392 / Time taken: 0:18:51 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 11/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 69 / Train-Loss: 0.2378 / Val-Loss: 0.2308 / Test-Loss: 0.2396 / Time taken: 0:19:05 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 11/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 70 / Train-Loss: 0.2378 / Val-Loss: 0.2306 / Test-Loss: 0.2393 / Time taken: 0:19:20 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 11/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 71 / Train-Loss: 0.2378 / Val-Loss: 0.2303 / Test-Loss: 0.2391 / Time taken: 0:19:35 / ---- Currently Best Val-Epoch: 71 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 72 / Train-Loss: 0.2377 / Val-Loss: 0.2306 / Test-Loss: 0.2393 / Time taken: 0:19:51 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 11/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 73 / Train-Loss: 0.2378 / Val-Loss: 0.2304 / Test-Loss: 0.2392 / Time taken: 0:20:08 / ---- Currently Best Val-Epoch: 71 \n","Ensemble: 11/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 74 / Train-Loss: 0.2376 / Val-Loss: 0.2303 / Test-Loss: 0.2392 / Time taken: 0:20:22 / ---- Currently Best Val-Epoch: 74 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 75 / Train-Loss: 0.2377 / Val-Loss: 0.2302 / Test-Loss: 0.2392 / Time taken: 0:20:37 / ---- Currently Best Val-Epoch: 75 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 76 / Train-Loss: 0.2375 / Val-Loss: 0.2305 / Test-Loss: 0.2394 / Time taken: 0:20:53 / ---- Currently Best Val-Epoch: 75 \n","Ensemble: 11/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 77 / Train-Loss: 0.2376 / Val-Loss: 0.2301 / Test-Loss: 0.2392 / Time taken: 0:21:09 / ---- Currently Best Val-Epoch: 77 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 78 / Train-Loss: 0.2375 / Val-Loss: 0.2302 / Test-Loss: 0.2392 / Time taken: 0:21:24 / ---- Currently Best Val-Epoch: 77 \n","Ensemble: 11/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 79 / Train-Loss: 0.2374 / Val-Loss: 0.2298 / Test-Loss: 0.2389 / Time taken: 0:21:40 / ---- Currently Best Val-Epoch: 79 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 80 / Train-Loss: 0.2373 / Val-Loss: 0.2299 / Test-Loss: 0.2390 / Time taken: 0:21:55 / ---- Currently Best Val-Epoch: 79 \n","Ensemble: 11/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 81 / Train-Loss: 0.2373 / Val-Loss: 0.2298 / Test-Loss: 0.2389 / Time taken: 0:22:17 / ---- Currently Best Val-Epoch: 79 \n","Ensemble: 11/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 82 / Train-Loss: 0.2372 / Val-Loss: 0.2297 / Test-Loss: 0.2389 / Time taken: 0:22:40 / ---- Currently Best Val-Epoch: 82 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 83 / Train-Loss: 0.2373 / Val-Loss: 0.2296 / Test-Loss: 0.2390 / Time taken: 0:22:56 / ---- Currently Best Val-Epoch: 83 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 84 / Train-Loss: 0.2371 / Val-Loss: 0.2297 / Test-Loss: 0.2388 / Time taken: 0:23:18 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 11/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 85 / Train-Loss: 0.2372 / Val-Loss: 0.2296 / Test-Loss: 0.2388 / Time taken: 0:23:34 / ---- Currently Best Val-Epoch: 85 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 86 / Train-Loss: 0.2372 / Val-Loss: 0.2294 / Test-Loss: 0.2388 / Time taken: 0:23:57 / ---- Currently Best Val-Epoch: 86 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 87 / Train-Loss: 0.2369 / Val-Loss: 0.2301 / Test-Loss: 0.2388 / Time taken: 0:24:13 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 88 / Train-Loss: 0.2370 / Val-Loss: 0.2295 / Test-Loss: 0.2387 / Time taken: 0:24:29 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 89 / Train-Loss: 0.2369 / Val-Loss: 0.2300 / Test-Loss: 0.2390 / Time taken: 0:24:44 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 90 / Train-Loss: 0.2370 / Val-Loss: 0.2297 / Test-Loss: 0.2388 / Time taken: 0:24:58 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 91 / Train-Loss: 0.2370 / Val-Loss: 0.2298 / Test-Loss: 0.2385 / Time taken: 0:25:21 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 92 / Train-Loss: 0.2369 / Val-Loss: 0.2298 / Test-Loss: 0.2385 / Time taken: 0:25:37 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 93 / Train-Loss: 0.2368 / Val-Loss: 0.2302 / Test-Loss: 0.2389 / Time taken: 0:25:52 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 94 / Train-Loss: 0.2369 / Val-Loss: 0.2296 / Test-Loss: 0.2387 / Time taken: 0:26:07 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 95 / Train-Loss: 0.2367 / Val-Loss: 0.2299 / Test-Loss: 0.2388 / Time taken: 0:26:23 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 96 / Train-Loss: 0.2370 / Val-Loss: 0.2299 / Test-Loss: 0.2387 / Time taken: 0:26:39 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 97 / Train-Loss: 0.2368 / Val-Loss: 0.2303 / Test-Loss: 0.2388 / Time taken: 0:27:01 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 98 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 98 / Train-Loss: 0.2368 / Val-Loss: 0.2302 / Test-Loss: 0.2388 / Time taken: 0:27:16 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 99 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 99 / Train-Loss: 0.2367 / Val-Loss: 0.2298 / Test-Loss: 0.2387 / Time taken: 0:27:33 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 100 / Batch: 536 / Train-Loss (Batch): 0.0329: [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 100 / Train-Loss: 0.2366 / Val-Loss: 0.2302 / Test-Loss: 0.2389 / Time taken: 0:27:48 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 101 / Batch: 536 / Train-Loss (Batch): 0.0321: [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 101 / Train-Loss: 0.2367 / Val-Loss: 0.2296 / Test-Loss: 0.2389 / Time taken: 0:28:03 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 11/14 / Epoch: 102 / Batch: 536 / Train-Loss (Batch): 0.0329: [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 102 / Train-Loss: 0.2366 / Val-Loss: 0.2303 / Test-Loss: 0.2389 / Time taken: 0:28:25 / ---- Currently Best Val-Epoch: 86 \n","596/596 [==============================] - 11s 17ms/step\n","67/67 [==============================] - 1s 17ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-00e05b62-2694-4a5d-9dfc-4f1e570784a0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>FT_transformer (run: 7)</td>\n","      <td>83</td>\n","      <td>1588.023347</td>\n","      <td>27133</td>\n","      <td>0.236495</td>\n","      <td>0.238729</td>\n","      <td>0.064304</td>\n","      <td>0.064473</td>\n","    </tr>\n","    <tr>\n","      <th>128</th>\n","      <td>FT_transformer (run: 8)</td>\n","      <td>71</td>\n","      <td>1392.158405</td>\n","      <td>27133</td>\n","      <td>0.237939</td>\n","      <td>0.239110</td>\n","      <td>0.060636</td>\n","      <td>0.060748</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>FT_transformer (run: 9)</td>\n","      <td>70</td>\n","      <td>1372.753220</td>\n","      <td>27133</td>\n","      <td>0.239179</td>\n","      <td>0.240097</td>\n","      <td>0.058446</td>\n","      <td>0.058635</td>\n","    </tr>\n","    <tr>\n","      <th>130</th>\n","      <td>FT_transformer (run: 10)</td>\n","      <td>55</td>\n","      <td>1187.509606</td>\n","      <td>27133</td>\n","      <td>0.239155</td>\n","      <td>0.239897</td>\n","      <td>0.059857</td>\n","      <td>0.060138</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>FT_transformer (run: 11)</td>\n","      <td>86</td>\n","      <td>1705.731414</td>\n","      <td>27133</td>\n","      <td>0.236645</td>\n","      <td>0.238818</td>\n","      <td>0.062893</td>\n","      <td>0.063125</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>132 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00e05b62-2694-4a5d-9dfc-4f1e570784a0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-00e05b62-2694-4a5d-9dfc-4f1e570784a0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-00e05b62-2694-4a5d-9dfc-4f1e570784a0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c1cb3424-b219-417a-8b15-e192fcb18cbf\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1cb3424-b219-417a-8b15-e192fcb18cbf')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c1cb3424-b219-417a-8b15-e192fcb18cbf button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","127     FT_transformer (run: 7)      83  1588.023347          27133   \n","128     FT_transformer (run: 8)      71  1392.158405          27133   \n","129     FT_transformer (run: 9)      70  1372.753220          27133   \n","130    FT_transformer (run: 10)      55  1187.509606          27133   \n","131    FT_transformer (run: 11)      86  1705.731414          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","127    0.236495   0.238729             0.064304            0.064473  \n","128    0.237939   0.239110             0.060636            0.060748  \n","129    0.239179   0.240097             0.058446            0.058635  \n","130    0.239155   0.239897             0.059857            0.060138  \n","131    0.236645   0.238818             0.062893            0.063125  \n","\n","[132 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 12-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 12/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0305  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 0 / Train-Loss: 0.2906 / Val-Loss: 0.2516 / Test-Loss: 0.2541 / Time taken: 0:00:45 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0306  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 1 / Train-Loss: 0.2482 / Val-Loss: 0.2485 / Test-Loss: 0.2505 / Time taken: 0:01:07 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0308  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 2 / Train-Loss: 0.2434 / Val-Loss: 0.2473 / Test-Loss: 0.2484 / Time taken: 0:01:21 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0317  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 3 / Train-Loss: 0.2415 / Val-Loss: 0.2464 / Test-Loss: 0.2470 / Time taken: 0:01:36 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0318  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 4 / Train-Loss: 0.2408 / Val-Loss: 0.2460 / Test-Loss: 0.2464 / Time taken: 0:01:58 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0324  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 5 / Train-Loss: 0.2402 / Val-Loss: 0.2458 / Test-Loss: 0.2460 / Time taken: 0:02:13 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 6 / Train-Loss: 0.2399 / Val-Loss: 0.2456 / Test-Loss: 0.2457 / Time taken: 0:02:28 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 7 / Train-Loss: 0.2396 / Val-Loss: 0.2448 / Test-Loss: 0.2447 / Time taken: 0:02:51 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0322  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 8 / Train-Loss: 0.2394 / Val-Loss: 0.2449 / Test-Loss: 0.2447 / Time taken: 0:03:06 / ---- Currently Best Val-Epoch: 7 \n","Ensemble: 12/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 9 / Train-Loss: 0.2392 / Val-Loss: 0.2449 / Test-Loss: 0.2446 / Time taken: 0:03:22 / ---- Currently Best Val-Epoch: 7 \n","Ensemble: 12/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 10 / Train-Loss: 0.2391 / Val-Loss: 0.2449 / Test-Loss: 0.2445 / Time taken: 0:03:43 / ---- Currently Best Val-Epoch: 7 \n","Ensemble: 12/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 11 / Train-Loss: 0.2390 / Val-Loss: 0.2450 / Test-Loss: 0.2445 / Time taken: 0:03:58 / ---- Currently Best Val-Epoch: 7 \n","Ensemble: 12/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 12 / Train-Loss: 0.2389 / Val-Loss: 0.2443 / Test-Loss: 0.2437 / Time taken: 0:04:14 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 13 / Batch: 1 / Train-Loss (Batch): 0.1756   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 12/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 13 / Train-Loss: 0.2388 / Val-Loss: 0.2441 / Test-Loss: 0.2434 / Time taken: 0:04:28 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 14 / Train-Loss: 0.2386 / Val-Loss: 0.2440 / Test-Loss: 0.2433 / Time taken: 0:04:43 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 15 / Train-Loss: 0.2384 / Val-Loss: 0.2438 / Test-Loss: 0.2429 / Time taken: 0:04:58 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 16 / Train-Loss: 0.2385 / Val-Loss: 0.2440 / Test-Loss: 0.2431 / Time taken: 0:05:20 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 12/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 17 / Train-Loss: 0.2386 / Val-Loss: 0.2441 / Test-Loss: 0.2432 / Time taken: 0:05:35 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 12/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 18 / Train-Loss: 0.2385 / Val-Loss: 0.2433 / Test-Loss: 0.2423 / Time taken: 0:05:56 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 19 / Train-Loss: 0.2382 / Val-Loss: 0.2438 / Test-Loss: 0.2428 / Time taken: 0:06:11 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 12/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 20 / Train-Loss: 0.2383 / Val-Loss: 0.2433 / Test-Loss: 0.2423 / Time taken: 0:06:28 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 12/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 21 / Train-Loss: 0.2385 / Val-Loss: 0.2434 / Test-Loss: 0.2423 / Time taken: 0:06:44 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 12/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 22 / Train-Loss: 0.2384 / Val-Loss: 0.2432 / Test-Loss: 0.2422 / Time taken: 0:06:58 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 23 / Train-Loss: 0.2384 / Val-Loss: 0.2430 / Test-Loss: 0.2420 / Time taken: 0:07:14 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 24 / Train-Loss: 0.2382 / Val-Loss: 0.2431 / Test-Loss: 0.2420 / Time taken: 0:07:30 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 12/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 25 / Train-Loss: 0.2382 / Val-Loss: 0.2429 / Test-Loss: 0.2418 / Time taken: 0:07:45 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 26 / Train-Loss: 0.2382 / Val-Loss: 0.2426 / Test-Loss: 0.2415 / Time taken: 0:08:07 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 27 / Train-Loss: 0.2382 / Val-Loss: 0.2425 / Test-Loss: 0.2413 / Time taken: 0:08:23 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 28 / Train-Loss: 0.2381 / Val-Loss: 0.2426 / Test-Loss: 0.2415 / Time taken: 0:08:39 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 12/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 29 / Train-Loss: 0.2381 / Val-Loss: 0.2426 / Test-Loss: 0.2414 / Time taken: 0:08:54 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 12/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 30 / Train-Loss: 0.2380 / Val-Loss: 0.2424 / Test-Loss: 0.2412 / Time taken: 0:09:09 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0348 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 31 / Train-Loss: 0.2381 / Val-Loss: 0.2422 / Test-Loss: 0.2410 / Time taken: 0:09:32 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 32 / Train-Loss: 0.2380 / Val-Loss: 0.2418 / Test-Loss: 0.2408 / Time taken: 0:09:49 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 33 / Train-Loss: 0.2379 / Val-Loss: 0.2419 / Test-Loss: 0.2408 / Time taken: 0:10:04 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 12/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 34 / Train-Loss: 0.2378 / Val-Loss: 0.2420 / Test-Loss: 0.2409 / Time taken: 0:10:25 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 12/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 35 / Train-Loss: 0.2379 / Val-Loss: 0.2417 / Test-Loss: 0.2407 / Time taken: 0:10:48 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 36 / Train-Loss: 0.2379 / Val-Loss: 0.2416 / Test-Loss: 0.2405 / Time taken: 0:11:03 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 37 / Train-Loss: 0.2378 / Val-Loss: 0.2417 / Test-Loss: 0.2406 / Time taken: 0:11:18 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 12/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 38 / Train-Loss: 0.2378 / Val-Loss: 0.2418 / Test-Loss: 0.2408 / Time taken: 0:11:33 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 12/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 39 / Train-Loss: 0.2378 / Val-Loss: 0.2415 / Test-Loss: 0.2405 / Time taken: 0:11:47 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 40 / Train-Loss: 0.2377 / Val-Loss: 0.2415 / Test-Loss: 0.2405 / Time taken: 0:12:04 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 41 / Train-Loss: 0.2375 / Val-Loss: 0.2416 / Test-Loss: 0.2406 / Time taken: 0:12:26 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 12/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 42 / Train-Loss: 0.2374 / Val-Loss: 0.2413 / Test-Loss: 0.2404 / Time taken: 0:12:41 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 43 / Train-Loss: 0.2374 / Val-Loss: 0.2412 / Test-Loss: 0.2403 / Time taken: 0:12:56 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 44 / Train-Loss: 0.2371 / Val-Loss: 0.2414 / Test-Loss: 0.2403 / Time taken: 0:13:14 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 12/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 45 / Train-Loss: 0.2370 / Val-Loss: 0.2410 / Test-Loss: 0.2400 / Time taken: 0:13:36 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 46 / Train-Loss: 0.2371 / Val-Loss: 0.2410 / Test-Loss: 0.2399 / Time taken: 0:13:52 / ---- Currently Best Val-Epoch: 46 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 47 / Train-Loss: 0.2371 / Val-Loss: 0.2412 / Test-Loss: 0.2401 / Time taken: 0:14:14 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 12/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 48 / Train-Loss: 0.2369 / Val-Loss: 0.2415 / Test-Loss: 0.2402 / Time taken: 0:14:37 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 12/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 49 / Train-Loss: 0.2369 / Val-Loss: 0.2409 / Test-Loss: 0.2400 / Time taken: 0:14:52 / ---- Currently Best Val-Epoch: 49 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 50 / Train-Loss: 0.2370 / Val-Loss: 0.2409 / Test-Loss: 0.2399 / Time taken: 0:15:07 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 12/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 51 / Train-Loss: 0.2369 / Val-Loss: 0.2411 / Test-Loss: 0.2399 / Time taken: 0:15:24 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 12/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 52 / Train-Loss: 0.2368 / Val-Loss: 0.2411 / Test-Loss: 0.2399 / Time taken: 0:15:38 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 12/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 53 / Train-Loss: 0.2367 / Val-Loss: 0.2410 / Test-Loss: 0.2401 / Time taken: 0:15:53 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 12/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 54 / Train-Loss: 0.2369 / Val-Loss: 0.2412 / Test-Loss: 0.2399 / Time taken: 0:16:14 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 12/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 55 / Train-Loss: 0.2368 / Val-Loss: 0.2407 / Test-Loss: 0.2397 / Time taken: 0:16:36 / ---- Currently Best Val-Epoch: 55 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 56 / Train-Loss: 0.2366 / Val-Loss: 0.2412 / Test-Loss: 0.2400 / Time taken: 0:16:52 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 12/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 57 / Train-Loss: 0.2367 / Val-Loss: 0.2409 / Test-Loss: 0.2397 / Time taken: 0:17:13 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 12/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 58 / Train-Loss: 0.2366 / Val-Loss: 0.2408 / Test-Loss: 0.2399 / Time taken: 0:17:30 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 12/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 59 / Train-Loss: 0.2366 / Val-Loss: 0.2406 / Test-Loss: 0.2395 / Time taken: 0:17:45 / ---- Currently Best Val-Epoch: 59 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 60 / Train-Loss: 0.2366 / Val-Loss: 0.2404 / Test-Loss: 0.2394 / Time taken: 0:18:01 / ---- Currently Best Val-Epoch: 60 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 61 / Train-Loss: 0.2364 / Val-Loss: 0.2410 / Test-Loss: 0.2397 / Time taken: 0:18:22 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 12/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 62 / Train-Loss: 0.2365 / Val-Loss: 0.2409 / Test-Loss: 0.2397 / Time taken: 0:18:39 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 12/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 63 / Train-Loss: 0.2366 / Val-Loss: 0.2410 / Test-Loss: 0.2397 / Time taken: 0:18:54 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 12/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 64 / Train-Loss: 0.2364 / Val-Loss: 0.2410 / Test-Loss: 0.2398 / Time taken: 0:19:09 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 12/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 65 / Train-Loss: 0.2365 / Val-Loss: 0.2408 / Test-Loss: 0.2396 / Time taken: 0:19:24 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 12/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 66 / Train-Loss: 0.2364 / Val-Loss: 0.2408 / Test-Loss: 0.2396 / Time taken: 0:19:40 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 12/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 67 / Train-Loss: 0.2362 / Val-Loss: 0.2412 / Test-Loss: 0.2399 / Time taken: 0:19:54 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 12/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 68 / Train-Loss: 0.2364 / Val-Loss: 0.2404 / Test-Loss: 0.2393 / Time taken: 0:20:09 / ---- Currently Best Val-Epoch: 68 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 69 / Train-Loss: 0.2362 / Val-Loss: 0.2408 / Test-Loss: 0.2395 / Time taken: 0:20:24 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 70 / Train-Loss: 0.2363 / Val-Loss: 0.2410 / Test-Loss: 0.2397 / Time taken: 0:20:46 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 71 / Train-Loss: 0.2361 / Val-Loss: 0.2407 / Test-Loss: 0.2395 / Time taken: 0:21:01 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 72 / Train-Loss: 0.2362 / Val-Loss: 0.2409 / Test-Loss: 0.2395 / Time taken: 0:21:16 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 73 / Train-Loss: 0.2361 / Val-Loss: 0.2406 / Test-Loss: 0.2393 / Time taken: 0:21:31 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 74 / Train-Loss: 0.2363 / Val-Loss: 0.2406 / Test-Loss: 0.2393 / Time taken: 0:21:45 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 75 / Train-Loss: 0.2362 / Val-Loss: 0.2405 / Test-Loss: 0.2392 / Time taken: 0:22:02 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 76 / Train-Loss: 0.2361 / Val-Loss: 0.2406 / Test-Loss: 0.2395 / Time taken: 0:22:17 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 77 / Train-Loss: 0.2361 / Val-Loss: 0.2407 / Test-Loss: 0.2395 / Time taken: 0:22:31 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 78 / Train-Loss: 0.2362 / Val-Loss: 0.2410 / Test-Loss: 0.2397 / Time taken: 0:22:45 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 79 / Train-Loss: 0.2360 / Val-Loss: 0.2409 / Test-Loss: 0.2396 / Time taken: 0:23:01 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 80 / Train-Loss: 0.2360 / Val-Loss: 0.2408 / Test-Loss: 0.2395 / Time taken: 0:23:17 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 81 / Train-Loss: 0.2360 / Val-Loss: 0.2408 / Test-Loss: 0.2395 / Time taken: 0:23:32 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 82 / Train-Loss: 0.2361 / Val-Loss: 0.2406 / Test-Loss: 0.2394 / Time taken: 0:23:46 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 83 / Train-Loss: 0.2360 / Val-Loss: 0.2406 / Test-Loss: 0.2393 / Time taken: 0:24:08 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 12/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 84 / Train-Loss: 0.2359 / Val-Loss: 0.2407 / Test-Loss: 0.2393 / Time taken: 0:24:23 / ---- Currently Best Val-Epoch: 68 \n","596/596 [==============================] - 12s 18ms/step\n","67/67 [==============================] - 1s 15ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-7c16eeb3-8d38-4f08-8ddf-b0cbbece4046\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>128</th>\n","      <td>FT_transformer (run: 8)</td>\n","      <td>71</td>\n","      <td>1392.158405</td>\n","      <td>27133</td>\n","      <td>0.237939</td>\n","      <td>0.239110</td>\n","      <td>0.060636</td>\n","      <td>0.060748</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>FT_transformer (run: 9)</td>\n","      <td>70</td>\n","      <td>1372.753220</td>\n","      <td>27133</td>\n","      <td>0.239179</td>\n","      <td>0.240097</td>\n","      <td>0.058446</td>\n","      <td>0.058635</td>\n","    </tr>\n","    <tr>\n","      <th>130</th>\n","      <td>FT_transformer (run: 10)</td>\n","      <td>55</td>\n","      <td>1187.509606</td>\n","      <td>27133</td>\n","      <td>0.239155</td>\n","      <td>0.239897</td>\n","      <td>0.059857</td>\n","      <td>0.060138</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>FT_transformer (run: 11)</td>\n","      <td>86</td>\n","      <td>1705.731414</td>\n","      <td>27133</td>\n","      <td>0.236645</td>\n","      <td>0.238818</td>\n","      <td>0.062893</td>\n","      <td>0.063125</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>FT_transformer (run: 12)</td>\n","      <td>68</td>\n","      <td>1463.326831</td>\n","      <td>27133</td>\n","      <td>0.238008</td>\n","      <td>0.239344</td>\n","      <td>0.061057</td>\n","      <td>0.061140</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>133 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c16eeb3-8d38-4f08-8ddf-b0cbbece4046')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7c16eeb3-8d38-4f08-8ddf-b0cbbece4046 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7c16eeb3-8d38-4f08-8ddf-b0cbbece4046');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-96da551c-76f2-4510-ba09-5b8aadbcd020\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96da551c-76f2-4510-ba09-5b8aadbcd020')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-96da551c-76f2-4510-ba09-5b8aadbcd020 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","128     FT_transformer (run: 8)      71  1392.158405          27133   \n","129     FT_transformer (run: 9)      70  1372.753220          27133   \n","130    FT_transformer (run: 10)      55  1187.509606          27133   \n","131    FT_transformer (run: 11)      86  1705.731414          27133   \n","132    FT_transformer (run: 12)      68  1463.326831          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","128    0.237939   0.239110             0.060636            0.060748  \n","129    0.239179   0.240097             0.058446            0.058635  \n","130    0.239155   0.239897             0.059857            0.060138  \n","131    0.236645   0.238818             0.062893            0.063125  \n","132    0.238008   0.239344             0.061057            0.061140  \n","\n","[133 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 13-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 13/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0301  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 0 / Train-Loss: 0.2791 / Val-Loss: 0.2501 / Test-Loss: 0.2547 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0306  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 1 / Train-Loss: 0.2497 / Val-Loss: 0.2465 / Test-Loss: 0.2504 / Time taken: 0:01:05 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0308  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 2 / Train-Loss: 0.2439 / Val-Loss: 0.2457 / Test-Loss: 0.2487 / Time taken: 0:01:19 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0318  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 3 / Train-Loss: 0.2423 / Val-Loss: 0.2449 / Test-Loss: 0.2474 / Time taken: 0:01:33 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0321  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 4 / Train-Loss: 0.2414 / Val-Loss: 0.2441 / Test-Loss: 0.2463 / Time taken: 0:01:49 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 5 / Train-Loss: 0.2407 / Val-Loss: 0.2440 / Test-Loss: 0.2461 / Time taken: 0:02:10 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0324  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 6 / Train-Loss: 0.2403 / Val-Loss: 0.2439 / Test-Loss: 0.2459 / Time taken: 0:02:25 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 7 / Train-Loss: 0.2400 / Val-Loss: 0.2435 / Test-Loss: 0.2454 / Time taken: 0:02:47 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 8 / Train-Loss: 0.2397 / Val-Loss: 0.2437 / Test-Loss: 0.2455 / Time taken: 0:03:02 / ---- Currently Best Val-Epoch: 7 \n","Ensemble: 13/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 9 / Train-Loss: 0.2396 / Val-Loss: 0.2435 / Test-Loss: 0.2452 / Time taken: 0:03:23 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 10 / Train-Loss: 0.2394 / Val-Loss: 0.2435 / Test-Loss: 0.2451 / Time taken: 0:03:45 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 13/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 11 / Train-Loss: 0.2393 / Val-Loss: 0.2432 / Test-Loss: 0.2447 / Time taken: 0:04:01 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 12 / Batch: 1 / Train-Loss (Batch): 0.1563   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 13/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 12 / Train-Loss: 0.2392 / Val-Loss: 0.2430 / Test-Loss: 0.2444 / Time taken: 0:04:15 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 13 / Train-Loss: 0.2391 / Val-Loss: 0.2429 / Test-Loss: 0.2443 / Time taken: 0:04:30 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 14 / Train-Loss: 0.2390 / Val-Loss: 0.2429 / Test-Loss: 0.2443 / Time taken: 0:04:45 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 15 / Train-Loss: 0.2389 / Val-Loss: 0.2424 / Test-Loss: 0.2438 / Time taken: 0:05:03 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 16 / Train-Loss: 0.2388 / Val-Loss: 0.2422 / Test-Loss: 0.2434 / Time taken: 0:05:17 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 17 / Train-Loss: 0.2387 / Val-Loss: 0.2420 / Test-Loss: 0.2432 / Time taken: 0:05:32 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 18 / Train-Loss: 0.2386 / Val-Loss: 0.2423 / Test-Loss: 0.2435 / Time taken: 0:05:48 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 13/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 19 / Train-Loss: 0.2385 / Val-Loss: 0.2418 / Test-Loss: 0.2430 / Time taken: 0:06:02 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 20 / Train-Loss: 0.2384 / Val-Loss: 0.2415 / Test-Loss: 0.2427 / Time taken: 0:06:19 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 21 / Train-Loss: 0.2385 / Val-Loss: 0.2414 / Test-Loss: 0.2425 / Time taken: 0:06:34 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 22 / Train-Loss: 0.2383 / Val-Loss: 0.2415 / Test-Loss: 0.2425 / Time taken: 0:06:50 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 13/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 23 / Train-Loss: 0.2383 / Val-Loss: 0.2412 / Test-Loss: 0.2423 / Time taken: 0:07:11 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 24 / Train-Loss: 0.2383 / Val-Loss: 0.2411 / Test-Loss: 0.2420 / Time taken: 0:07:26 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 25 / Train-Loss: 0.2382 / Val-Loss: 0.2411 / Test-Loss: 0.2420 / Time taken: 0:07:42 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 26 / Train-Loss: 0.2383 / Val-Loss: 0.2412 / Test-Loss: 0.2421 / Time taken: 0:07:57 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 13/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 27 / Train-Loss: 0.2383 / Val-Loss: 0.2409 / Test-Loss: 0.2418 / Time taken: 0:08:13 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 28 / Train-Loss: 0.2381 / Val-Loss: 0.2408 / Test-Loss: 0.2416 / Time taken: 0:08:36 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 29 / Train-Loss: 0.2383 / Val-Loss: 0.2407 / Test-Loss: 0.2416 / Time taken: 0:08:52 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 30 / Train-Loss: 0.2382 / Val-Loss: 0.2408 / Test-Loss: 0.2416 / Time taken: 0:09:07 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 13/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 31 / Train-Loss: 0.2382 / Val-Loss: 0.2405 / Test-Loss: 0.2413 / Time taken: 0:09:28 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 32 / Train-Loss: 0.2381 / Val-Loss: 0.2408 / Test-Loss: 0.2417 / Time taken: 0:09:44 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 13/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 33 / Train-Loss: 0.2381 / Val-Loss: 0.2404 / Test-Loss: 0.2411 / Time taken: 0:09:58 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 34 / Train-Loss: 0.2381 / Val-Loss: 0.2403 / Test-Loss: 0.2412 / Time taken: 0:10:14 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 35 / Train-Loss: 0.2380 / Val-Loss: 0.2402 / Test-Loss: 0.2411 / Time taken: 0:10:31 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 36 / Train-Loss: 0.2380 / Val-Loss: 0.2403 / Test-Loss: 0.2411 / Time taken: 0:10:46 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 13/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 37 / Train-Loss: 0.2379 / Val-Loss: 0.2402 / Test-Loss: 0.2411 / Time taken: 0:11:01 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 38 / Train-Loss: 0.2380 / Val-Loss: 0.2400 / Test-Loss: 0.2410 / Time taken: 0:11:16 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 39 / Train-Loss: 0.2378 / Val-Loss: 0.2402 / Test-Loss: 0.2413 / Time taken: 0:11:33 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 13/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 40 / Train-Loss: 0.2378 / Val-Loss: 0.2403 / Test-Loss: 0.2413 / Time taken: 0:11:48 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 13/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 41 / Train-Loss: 0.2378 / Val-Loss: 0.2399 / Test-Loss: 0.2410 / Time taken: 0:12:04 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 42 / Train-Loss: 0.2379 / Val-Loss: 0.2398 / Test-Loss: 0.2409 / Time taken: 0:12:19 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 43 / Train-Loss: 0.2378 / Val-Loss: 0.2399 / Test-Loss: 0.2410 / Time taken: 0:12:34 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 13/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 44 / Train-Loss: 0.2379 / Val-Loss: 0.2398 / Test-Loss: 0.2407 / Time taken: 0:12:50 / ---- Currently Best Val-Epoch: 44 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 45 / Train-Loss: 0.2378 / Val-Loss: 0.2397 / Test-Loss: 0.2407 / Time taken: 0:13:05 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0348 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 46 / Train-Loss: 0.2376 / Val-Loss: 0.2397 / Test-Loss: 0.2408 / Time taken: 0:13:20 / ---- Currently Best Val-Epoch: 46 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 47 / Train-Loss: 0.2377 / Val-Loss: 0.2397 / Test-Loss: 0.2407 / Time taken: 0:13:36 / ---- Currently Best Val-Epoch: 47 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 48 / Train-Loss: 0.2376 / Val-Loss: 0.2397 / Test-Loss: 0.2407 / Time taken: 0:13:53 / ---- Currently Best Val-Epoch: 48 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 49 / Train-Loss: 0.2377 / Val-Loss: 0.2397 / Test-Loss: 0.2407 / Time taken: 0:14:08 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 13/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 50 / Train-Loss: 0.2375 / Val-Loss: 0.2398 / Test-Loss: 0.2407 / Time taken: 0:14:23 / ---- Currently Best Val-Epoch: 48 \n","Ensemble: 13/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 51 / Train-Loss: 0.2376 / Val-Loss: 0.2396 / Test-Loss: 0.2405 / Time taken: 0:14:38 / ---- Currently Best Val-Epoch: 51 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 52 / Train-Loss: 0.2375 / Val-Loss: 0.2396 / Test-Loss: 0.2406 / Time taken: 0:15:00 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 13/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 53 / Train-Loss: 0.2375 / Val-Loss: 0.2398 / Test-Loss: 0.2406 / Time taken: 0:15:16 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 13/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 54 / Train-Loss: 0.2376 / Val-Loss: 0.2397 / Test-Loss: 0.2406 / Time taken: 0:15:31 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 13/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 55 / Train-Loss: 0.2375 / Val-Loss: 0.2397 / Test-Loss: 0.2406 / Time taken: 0:15:46 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 13/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 56 / Train-Loss: 0.2374 / Val-Loss: 0.2396 / Test-Loss: 0.2406 / Time taken: 0:16:03 / ---- Currently Best Val-Epoch: 56 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0348 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 57 / Train-Loss: 0.2375 / Val-Loss: 0.2394 / Test-Loss: 0.2404 / Time taken: 0:16:18 / ---- Currently Best Val-Epoch: 57 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 58 / Train-Loss: 0.2374 / Val-Loss: 0.2394 / Test-Loss: 0.2404 / Time taken: 0:16:33 / ---- Currently Best Val-Epoch: 58 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 59 / Train-Loss: 0.2374 / Val-Loss: 0.2394 / Test-Loss: 0.2404 / Time taken: 0:16:48 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 13/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 60 / Train-Loss: 0.2373 / Val-Loss: 0.2395 / Test-Loss: 0.2404 / Time taken: 0:17:04 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 13/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 61 / Train-Loss: 0.2374 / Val-Loss: 0.2393 / Test-Loss: 0.2402 / Time taken: 0:17:20 / ---- Currently Best Val-Epoch: 61 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 62 / Train-Loss: 0.2373 / Val-Loss: 0.2397 / Test-Loss: 0.2404 / Time taken: 0:17:42 / ---- Currently Best Val-Epoch: 61 \n","Ensemble: 13/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 63 / Train-Loss: 0.2372 / Val-Loss: 0.2396 / Test-Loss: 0.2403 / Time taken: 0:17:57 / ---- Currently Best Val-Epoch: 61 \n","Ensemble: 13/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 64 / Train-Loss: 0.2372 / Val-Loss: 0.2392 / Test-Loss: 0.2401 / Time taken: 0:18:14 / ---- Currently Best Val-Epoch: 64 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 65 / Train-Loss: 0.2370 / Val-Loss: 0.2394 / Test-Loss: 0.2401 / Time taken: 0:18:30 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 13/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 66 / Train-Loss: 0.2368 / Val-Loss: 0.2392 / Test-Loss: 0.2402 / Time taken: 0:18:52 / ---- Currently Best Val-Epoch: 66 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 67 / Train-Loss: 0.2369 / Val-Loss: 0.2393 / Test-Loss: 0.2402 / Time taken: 0:19:08 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 13/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 68 / Train-Loss: 0.2368 / Val-Loss: 0.2393 / Test-Loss: 0.2402 / Time taken: 0:19:29 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 13/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 69 / Train-Loss: 0.2367 / Val-Loss: 0.2388 / Test-Loss: 0.2398 / Time taken: 0:19:44 / ---- Currently Best Val-Epoch: 69 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 70 / Train-Loss: 0.2367 / Val-Loss: 0.2392 / Test-Loss: 0.2401 / Time taken: 0:20:00 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 13/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 71 / Train-Loss: 0.2366 / Val-Loss: 0.2390 / Test-Loss: 0.2399 / Time taken: 0:20:21 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 13/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 72 / Train-Loss: 0.2365 / Val-Loss: 0.2390 / Test-Loss: 0.2400 / Time taken: 0:20:38 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 13/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 73 / Train-Loss: 0.2367 / Val-Loss: 0.2389 / Test-Loss: 0.2398 / Time taken: 0:21:00 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 13/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 74 / Train-Loss: 0.2365 / Val-Loss: 0.2389 / Test-Loss: 0.2398 / Time taken: 0:21:15 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 13/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 75 / Train-Loss: 0.2364 / Val-Loss: 0.2392 / Test-Loss: 0.2401 / Time taken: 0:21:36 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 13/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 76 / Train-Loss: 0.2364 / Val-Loss: 0.2391 / Test-Loss: 0.2401 / Time taken: 0:21:52 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 13/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 77 / Train-Loss: 0.2365 / Val-Loss: 0.2389 / Test-Loss: 0.2401 / Time taken: 0:22:07 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 13/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 78 / Train-Loss: 0.2365 / Val-Loss: 0.2388 / Test-Loss: 0.2399 / Time taken: 0:22:22 / ---- Currently Best Val-Epoch: 78 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 79 / Train-Loss: 0.2365 / Val-Loss: 0.2388 / Test-Loss: 0.2399 / Time taken: 0:22:37 / ---- Currently Best Val-Epoch: 78 \n","Ensemble: 13/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 80 / Train-Loss: 0.2364 / Val-Loss: 0.2388 / Test-Loss: 0.2398 / Time taken: 0:22:54 / ---- Currently Best Val-Epoch: 80 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 81 / Train-Loss: 0.2365 / Val-Loss: 0.2387 / Test-Loss: 0.2397 / Time taken: 0:23:09 / ---- Currently Best Val-Epoch: 81 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 82 / Train-Loss: 0.2364 / Val-Loss: 0.2389 / Test-Loss: 0.2400 / Time taken: 0:23:25 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 83 / Train-Loss: 0.2363 / Val-Loss: 0.2389 / Test-Loss: 0.2399 / Time taken: 0:23:46 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0347 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 84 / Train-Loss: 0.2362 / Val-Loss: 0.2390 / Test-Loss: 0.2399 / Time taken: 0:24:03 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0348 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 85 / Train-Loss: 0.2363 / Val-Loss: 0.2388 / Test-Loss: 0.2398 / Time taken: 0:24:18 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 86 / Train-Loss: 0.2363 / Val-Loss: 0.2389 / Test-Loss: 0.2399 / Time taken: 0:24:33 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 87 / Train-Loss: 0.2361 / Val-Loss: 0.2389 / Test-Loss: 0.2399 / Time taken: 0:24:55 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0352 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 88 / Train-Loss: 0.2362 / Val-Loss: 0.2391 / Test-Loss: 0.2399 / Time taken: 0:25:11 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0347 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 89 / Train-Loss: 0.2362 / Val-Loss: 0.2388 / Test-Loss: 0.2399 / Time taken: 0:25:27 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 90 / Train-Loss: 0.2361 / Val-Loss: 0.2390 / Test-Loss: 0.2399 / Time taken: 0:25:41 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 91 / Train-Loss: 0.2361 / Val-Loss: 0.2393 / Test-Loss: 0.2399 / Time taken: 0:25:56 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 92 / Train-Loss: 0.2361 / Val-Loss: 0.2387 / Test-Loss: 0.2397 / Time taken: 0:26:12 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 13/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 93 / Train-Loss: 0.2361 / Val-Loss: 0.2386 / Test-Loss: 0.2396 / Time taken: 0:26:28 / ---- Currently Best Val-Epoch: 93 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.0347 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 94 / Train-Loss: 0.2361 / Val-Loss: 0.2388 / Test-Loss: 0.2399 / Time taken: 0:26:43 / ---- Currently Best Val-Epoch: 93 \n","Ensemble: 13/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 95 / Train-Loss: 0.2360 / Val-Loss: 0.2386 / Test-Loss: 0.2395 / Time taken: 0:26:59 / ---- Currently Best Val-Epoch: 95 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 96 / Train-Loss: 0.2361 / Val-Loss: 0.2387 / Test-Loss: 0.2397 / Time taken: 0:27:15 / ---- Currently Best Val-Epoch: 95 \n","Ensemble: 13/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 97 / Train-Loss: 0.2359 / Val-Loss: 0.2388 / Test-Loss: 0.2398 / Time taken: 0:27:36 / ---- Currently Best Val-Epoch: 95 \n","Ensemble: 13/14 / Epoch: 98 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 98 / Train-Loss: 0.2359 / Val-Loss: 0.2386 / Test-Loss: 0.2398 / Time taken: 0:27:52 / ---- Currently Best Val-Epoch: 95 \n","Ensemble: 13/14 / Epoch: 99 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 99 / Train-Loss: 0.2360 / Val-Loss: 0.2387 / Test-Loss: 0.2398 / Time taken: 0:28:07 / ---- Currently Best Val-Epoch: 95 \n","Ensemble: 13/14 / Epoch: 100 / Batch: 536 / Train-Loss (Batch): 0.0344: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 100 / Train-Loss: 0.2359 / Val-Loss: 0.2385 / Test-Loss: 0.2397 / Time taken: 0:28:22 / ---- Currently Best Val-Epoch: 100 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 101 / Batch: 536 / Train-Loss (Batch): 0.034 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 101 / Train-Loss: 0.2359 / Val-Loss: 0.2390 / Test-Loss: 0.2402 / Time taken: 0:28:40 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 102 / Batch: 536 / Train-Loss (Batch): 0.034 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 102 / Train-Loss: 0.2359 / Val-Loss: 0.2388 / Test-Loss: 0.2400 / Time taken: 0:29:01 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 103 / Batch: 536 / Train-Loss (Batch): 0.0341: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 103 / Train-Loss: 0.2358 / Val-Loss: 0.2386 / Test-Loss: 0.2398 / Time taken: 0:29:17 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 104 / Batch: 536 / Train-Loss (Batch): 0.0342: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 104 / Train-Loss: 0.2357 / Val-Loss: 0.2388 / Test-Loss: 0.2399 / Time taken: 0:29:33 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 105 / Batch: 536 / Train-Loss (Batch): 0.034 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 105 / Train-Loss: 0.2357 / Val-Loss: 0.2387 / Test-Loss: 0.2399 / Time taken: 0:29:49 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 106 / Batch: 536 / Train-Loss (Batch): 0.0352: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 106 / Train-Loss: 0.2357 / Val-Loss: 0.2388 / Test-Loss: 0.2399 / Time taken: 0:30:12 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 107 / Batch: 536 / Train-Loss (Batch): 0.0338: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 107 / Train-Loss: 0.2358 / Val-Loss: 0.2387 / Test-Loss: 0.2396 / Time taken: 0:30:28 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 108 / Batch: 536 / Train-Loss (Batch): 0.034 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 108 / Train-Loss: 0.2357 / Val-Loss: 0.2387 / Test-Loss: 0.2399 / Time taken: 0:30:44 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 109 / Batch: 536 / Train-Loss (Batch): 0.0338: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 109 / Train-Loss: 0.2358 / Val-Loss: 0.2390 / Test-Loss: 0.2402 / Time taken: 0:30:59 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 110 / Batch: 536 / Train-Loss (Batch): 0.0346: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 110 / Train-Loss: 0.2356 / Val-Loss: 0.2390 / Test-Loss: 0.2401 / Time taken: 0:31:14 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 111 / Batch: 536 / Train-Loss (Batch): 0.035 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 111 / Train-Loss: 0.2355 / Val-Loss: 0.2391 / Test-Loss: 0.2401 / Time taken: 0:31:36 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 112 / Batch: 536 / Train-Loss (Batch): 0.034 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 112 / Train-Loss: 0.2357 / Val-Loss: 0.2388 / Test-Loss: 0.2399 / Time taken: 0:31:58 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 113 / Batch: 536 / Train-Loss (Batch): 0.0346: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 113 / Train-Loss: 0.2357 / Val-Loss: 0.2389 / Test-Loss: 0.2401 / Time taken: 0:32:13 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 114 / Batch: 536 / Train-Loss (Batch): 0.0341: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 114 / Train-Loss: 0.2356 / Val-Loss: 0.2392 / Test-Loss: 0.2403 / Time taken: 0:32:33 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 115 / Batch: 536 / Train-Loss (Batch): 0.0336: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 115 / Train-Loss: 0.2357 / Val-Loss: 0.2388 / Test-Loss: 0.2401 / Time taken: 0:32:54 / ---- Currently Best Val-Epoch: 100 \n","Ensemble: 13/14 / Epoch: 116 / Batch: 536 / Train-Loss (Batch): 0.035 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 116 / Train-Loss: 0.2354 / Val-Loss: 0.2390 / Test-Loss: 0.2401 / Time taken: 0:33:12 / ---- Currently Best Val-Epoch: 100 \n","596/596 [==============================] - 12s 19ms/step\n","67/67 [==============================] - 1s 19ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-49032ffd-e81b-45fe-94a4-9de3b8a69223\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>FT_transformer (run: 9)</td>\n","      <td>70</td>\n","      <td>1372.753220</td>\n","      <td>27133</td>\n","      <td>0.239179</td>\n","      <td>0.240097</td>\n","      <td>0.058446</td>\n","      <td>0.058635</td>\n","    </tr>\n","    <tr>\n","      <th>130</th>\n","      <td>FT_transformer (run: 10)</td>\n","      <td>55</td>\n","      <td>1187.509606</td>\n","      <td>27133</td>\n","      <td>0.239155</td>\n","      <td>0.239897</td>\n","      <td>0.059857</td>\n","      <td>0.060138</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>FT_transformer (run: 11)</td>\n","      <td>86</td>\n","      <td>1705.731414</td>\n","      <td>27133</td>\n","      <td>0.236645</td>\n","      <td>0.238818</td>\n","      <td>0.062893</td>\n","      <td>0.063125</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>FT_transformer (run: 12)</td>\n","      <td>68</td>\n","      <td>1463.326831</td>\n","      <td>27133</td>\n","      <td>0.238008</td>\n","      <td>0.239344</td>\n","      <td>0.061057</td>\n","      <td>0.061140</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>FT_transformer (run: 13)</td>\n","      <td>100</td>\n","      <td>1992.376854</td>\n","      <td>27133</td>\n","      <td>0.237393</td>\n","      <td>0.239739</td>\n","      <td>0.060784</td>\n","      <td>0.060886</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>134 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49032ffd-e81b-45fe-94a4-9de3b8a69223')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-49032ffd-e81b-45fe-94a4-9de3b8a69223 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-49032ffd-e81b-45fe-94a4-9de3b8a69223');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-624bbfc1-4e0a-4d92-ae53-0517986abd1a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-624bbfc1-4e0a-4d92-ae53-0517986abd1a')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-624bbfc1-4e0a-4d92-ae53-0517986abd1a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","129     FT_transformer (run: 9)      70  1372.753220          27133   \n","130    FT_transformer (run: 10)      55  1187.509606          27133   \n","131    FT_transformer (run: 11)      86  1705.731414          27133   \n","132    FT_transformer (run: 12)      68  1463.326831          27133   \n","133    FT_transformer (run: 13)     100  1992.376854          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","129    0.239179   0.240097             0.058446            0.058635  \n","130    0.239155   0.239897             0.059857            0.060138  \n","131    0.236645   0.238818             0.062893            0.063125  \n","132    0.238008   0.239344             0.061057            0.061140  \n","133    0.237393   0.239739             0.060784            0.060886  \n","\n","[134 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 14-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 14/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0315  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 0 / Train-Loss: 0.3222 / Val-Loss: 0.2598 / Test-Loss: 0.2640 / Time taken: 0:00:31 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.03    : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 1 / Train-Loss: 0.2565 / Val-Loss: 0.2505 / Test-Loss: 0.2549 / Time taken: 0:00:48 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0301  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 2 / Train-Loss: 0.2523 / Val-Loss: 0.2492 / Test-Loss: 0.2537 / Time taken: 0:01:03 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0309  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 3 / Train-Loss: 0.2460 / Val-Loss: 0.2465 / Test-Loss: 0.2498 / Time taken: 0:01:18 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0314  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 4 / Train-Loss: 0.2423 / Val-Loss: 0.2453 / Test-Loss: 0.2484 / Time taken: 0:01:32 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0319  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 5 / Train-Loss: 0.2411 / Val-Loss: 0.2447 / Test-Loss: 0.2476 / Time taken: 0:01:47 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 6 / Train-Loss: 0.2407 / Val-Loss: 0.2442 / Test-Loss: 0.2469 / Time taken: 0:02:08 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0324  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 7 / Train-Loss: 0.2404 / Val-Loss: 0.2436 / Test-Loss: 0.2462 / Time taken: 0:02:24 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 8 / Train-Loss: 0.2402 / Val-Loss: 0.2434 / Test-Loss: 0.2459 / Time taken: 0:02:39 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 9 / Train-Loss: 0.2400 / Val-Loss: 0.2431 / Test-Loss: 0.2455 / Time taken: 0:02:54 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 10 / Train-Loss: 0.2398 / Val-Loss: 0.2432 / Test-Loss: 0.2456 / Time taken: 0:03:11 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 14/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 11 / Train-Loss: 0.2397 / Val-Loss: 0.2428 / Test-Loss: 0.2452 / Time taken: 0:03:25 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 12 / Batch: 1 / Train-Loss (Batch): 0.1977   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 14/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 12 / Train-Loss: 0.2394 / Val-Loss: 0.2425 / Test-Loss: 0.2448 / Time taken: 0:03:40 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 13 / Train-Loss: 0.2392 / Val-Loss: 0.2427 / Test-Loss: 0.2450 / Time taken: 0:03:55 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 14/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 14 / Train-Loss: 0.2392 / Val-Loss: 0.2422 / Test-Loss: 0.2445 / Time taken: 0:04:10 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 15 / Train-Loss: 0.2391 / Val-Loss: 0.2419 / Test-Loss: 0.2442 / Time taken: 0:04:26 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 16 / Train-Loss: 0.2390 / Val-Loss: 0.2416 / Test-Loss: 0.2438 / Time taken: 0:04:41 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 17 / Train-Loss: 0.2389 / Val-Loss: 0.2414 / Test-Loss: 0.2437 / Time taken: 0:04:56 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 18 / Train-Loss: 0.2388 / Val-Loss: 0.2415 / Test-Loss: 0.2435 / Time taken: 0:05:11 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 14/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 19 / Train-Loss: 0.2389 / Val-Loss: 0.2411 / Test-Loss: 0.2431 / Time taken: 0:05:33 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 20 / Train-Loss: 0.2388 / Val-Loss: 0.2410 / Test-Loss: 0.2431 / Time taken: 0:05:48 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 21 / Train-Loss: 0.2388 / Val-Loss: 0.2409 / Test-Loss: 0.2430 / Time taken: 0:06:03 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 22 / Train-Loss: 0.2388 / Val-Loss: 0.2407 / Test-Loss: 0.2427 / Time taken: 0:06:21 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 23 / Train-Loss: 0.2388 / Val-Loss: 0.2407 / Test-Loss: 0.2427 / Time taken: 0:06:39 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 24 / Train-Loss: 0.2385 / Val-Loss: 0.2406 / Test-Loss: 0.2426 / Time taken: 0:06:55 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 25 / Train-Loss: 0.2386 / Val-Loss: 0.2404 / Test-Loss: 0.2423 / Time taken: 0:07:17 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 26 / Train-Loss: 0.2386 / Val-Loss: 0.2405 / Test-Loss: 0.2424 / Time taken: 0:07:32 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 14/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 27 / Train-Loss: 0.2385 / Val-Loss: 0.2403 / Test-Loss: 0.2422 / Time taken: 0:07:49 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 28 / Train-Loss: 0.2384 / Val-Loss: 0.2404 / Test-Loss: 0.2423 / Time taken: 0:08:11 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 14/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 29 / Train-Loss: 0.2385 / Val-Loss: 0.2403 / Test-Loss: 0.2421 / Time taken: 0:08:26 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 30 / Train-Loss: 0.2385 / Val-Loss: 0.2402 / Test-Loss: 0.2420 / Time taken: 0:08:42 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 31 / Train-Loss: 0.2384 / Val-Loss: 0.2400 / Test-Loss: 0.2419 / Time taken: 0:08:59 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 32 / Train-Loss: 0.2384 / Val-Loss: 0.2401 / Test-Loss: 0.2418 / Time taken: 0:09:21 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 14/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 33 / Train-Loss: 0.2384 / Val-Loss: 0.2398 / Test-Loss: 0.2416 / Time taken: 0:09:35 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 34 / Train-Loss: 0.2382 / Val-Loss: 0.2400 / Test-Loss: 0.2418 / Time taken: 0:09:51 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 14/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 35 / Train-Loss: 0.2383 / Val-Loss: 0.2398 / Test-Loss: 0.2416 / Time taken: 0:10:08 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 14/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 36 / Train-Loss: 0.2382 / Val-Loss: 0.2398 / Test-Loss: 0.2416 / Time taken: 0:10:30 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 14/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 37 / Train-Loss: 0.2381 / Val-Loss: 0.2398 / Test-Loss: 0.2417 / Time taken: 0:10:46 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 14/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 38 / Train-Loss: 0.2381 / Val-Loss: 0.2398 / Test-Loss: 0.2417 / Time taken: 0:11:01 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 14/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 39 / Train-Loss: 0.2381 / Val-Loss: 0.2395 / Test-Loss: 0.2413 / Time taken: 0:11:18 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 40 / Train-Loss: 0.2380 / Val-Loss: 0.2397 / Test-Loss: 0.2415 / Time taken: 0:11:33 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 41 / Train-Loss: 0.2380 / Val-Loss: 0.2396 / Test-Loss: 0.2415 / Time taken: 0:11:48 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 42 / Train-Loss: 0.2379 / Val-Loss: 0.2393 / Test-Loss: 0.2412 / Time taken: 0:12:03 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 43 / Train-Loss: 0.2378 / Val-Loss: 0.2393 / Test-Loss: 0.2411 / Time taken: 0:12:19 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 44 / Train-Loss: 0.2378 / Val-Loss: 0.2392 / Test-Loss: 0.2410 / Time taken: 0:12:34 / ---- Currently Best Val-Epoch: 44 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 45 / Train-Loss: 0.2376 / Val-Loss: 0.2396 / Test-Loss: 0.2414 / Time taken: 0:12:50 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 14/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 46 / Train-Loss: 0.2377 / Val-Loss: 0.2393 / Test-Loss: 0.2412 / Time taken: 0:13:04 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 14/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 47 / Train-Loss: 0.2375 / Val-Loss: 0.2391 / Test-Loss: 0.2411 / Time taken: 0:13:20 / ---- Currently Best Val-Epoch: 47 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 48 / Train-Loss: 0.2375 / Val-Loss: 0.2394 / Test-Loss: 0.2413 / Time taken: 0:13:36 / ---- Currently Best Val-Epoch: 47 \n","Ensemble: 14/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 49 / Train-Loss: 0.2374 / Val-Loss: 0.2394 / Test-Loss: 0.2411 / Time taken: 0:13:52 / ---- Currently Best Val-Epoch: 47 \n","Ensemble: 14/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 50 / Train-Loss: 0.2375 / Val-Loss: 0.2393 / Test-Loss: 0.2410 / Time taken: 0:14:06 / ---- Currently Best Val-Epoch: 47 \n","Ensemble: 14/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 51 / Train-Loss: 0.2374 / Val-Loss: 0.2390 / Test-Loss: 0.2407 / Time taken: 0:14:21 / ---- Currently Best Val-Epoch: 51 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 52 / Train-Loss: 0.2373 / Val-Loss: 0.2395 / Test-Loss: 0.2411 / Time taken: 0:14:37 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 14/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 53 / Train-Loss: 0.2374 / Val-Loss: 0.2392 / Test-Loss: 0.2409 / Time taken: 0:14:52 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 14/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 54 / Train-Loss: 0.2373 / Val-Loss: 0.2389 / Test-Loss: 0.2406 / Time taken: 0:15:07 / ---- Currently Best Val-Epoch: 54 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 55 / Train-Loss: 0.2371 / Val-Loss: 0.2395 / Test-Loss: 0.2409 / Time taken: 0:15:22 / ---- Currently Best Val-Epoch: 54 \n","Ensemble: 14/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 56 / Train-Loss: 0.2371 / Val-Loss: 0.2395 / Test-Loss: 0.2411 / Time taken: 0:15:37 / ---- Currently Best Val-Epoch: 54 \n","Ensemble: 14/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 57 / Train-Loss: 0.2371 / Val-Loss: 0.2389 / Test-Loss: 0.2406 / Time taken: 0:15:59 / ---- Currently Best Val-Epoch: 54 \n","Ensemble: 14/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 58 / Train-Loss: 0.2371 / Val-Loss: 0.2388 / Test-Loss: 0.2405 / Time taken: 0:16:14 / ---- Currently Best Val-Epoch: 58 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 59 / Train-Loss: 0.2371 / Val-Loss: 0.2389 / Test-Loss: 0.2406 / Time taken: 0:16:29 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 14/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 60 / Train-Loss: 0.2370 / Val-Loss: 0.2392 / Test-Loss: 0.2407 / Time taken: 0:16:51 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 14/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 61 / Train-Loss: 0.2370 / Val-Loss: 0.2389 / Test-Loss: 0.2406 / Time taken: 0:17:13 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 14/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 62 / Train-Loss: 0.2370 / Val-Loss: 0.2389 / Test-Loss: 0.2406 / Time taken: 0:17:35 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 14/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 63 / Train-Loss: 0.2370 / Val-Loss: 0.2393 / Test-Loss: 0.2408 / Time taken: 0:17:50 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 14/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 64 / Train-Loss: 0.2368 / Val-Loss: 0.2390 / Test-Loss: 0.2407 / Time taken: 0:18:13 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 14/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 65 / Train-Loss: 0.2370 / Val-Loss: 0.2386 / Test-Loss: 0.2404 / Time taken: 0:18:28 / ---- Currently Best Val-Epoch: 65 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 66 / Train-Loss: 0.2368 / Val-Loss: 0.2387 / Test-Loss: 0.2404 / Time taken: 0:18:44 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 67 / Train-Loss: 0.2369 / Val-Loss: 0.2387 / Test-Loss: 0.2406 / Time taken: 0:18:59 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 68 / Train-Loss: 0.2368 / Val-Loss: 0.2390 / Test-Loss: 0.2407 / Time taken: 0:19:14 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 69 / Train-Loss: 0.2369 / Val-Loss: 0.2387 / Test-Loss: 0.2405 / Time taken: 0:19:31 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0345 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 70 / Train-Loss: 0.2368 / Val-Loss: 0.2388 / Test-Loss: 0.2406 / Time taken: 0:19:46 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 71 / Train-Loss: 0.2368 / Val-Loss: 0.2389 / Test-Loss: 0.2407 / Time taken: 0:20:01 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 72 / Train-Loss: 0.2367 / Val-Loss: 0.2389 / Test-Loss: 0.2406 / Time taken: 0:20:16 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 73 / Train-Loss: 0.2367 / Val-Loss: 0.2391 / Test-Loss: 0.2406 / Time taken: 0:20:32 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 74 / Train-Loss: 0.2366 / Val-Loss: 0.2389 / Test-Loss: 0.2404 / Time taken: 0:20:47 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 75 / Train-Loss: 0.2366 / Val-Loss: 0.2388 / Test-Loss: 0.2405 / Time taken: 0:21:02 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 76 / Train-Loss: 0.2367 / Val-Loss: 0.2387 / Test-Loss: 0.2404 / Time taken: 0:21:17 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 77 / Train-Loss: 0.2367 / Val-Loss: 0.2388 / Test-Loss: 0.2404 / Time taken: 0:21:32 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 78 / Train-Loss: 0.2366 / Val-Loss: 0.2388 / Test-Loss: 0.2404 / Time taken: 0:21:49 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 14/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 79 / Train-Loss: 0.2366 / Val-Loss: 0.2385 / Test-Loss: 0.2403 / Time taken: 0:22:04 / ---- Currently Best Val-Epoch: 79 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 80 / Train-Loss: 0.2364 / Val-Loss: 0.2387 / Test-Loss: 0.2403 / Time taken: 0:22:20 / ---- Currently Best Val-Epoch: 79 \n","Ensemble: 14/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 81 / Train-Loss: 0.2365 / Val-Loss: 0.2387 / Test-Loss: 0.2405 / Time taken: 0:22:35 / ---- Currently Best Val-Epoch: 79 \n","Ensemble: 14/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 82 / Train-Loss: 0.2365 / Val-Loss: 0.2384 / Test-Loss: 0.2403 / Time taken: 0:22:52 / ---- Currently Best Val-Epoch: 82 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 83 / Train-Loss: 0.2364 / Val-Loss: 0.2390 / Test-Loss: 0.2404 / Time taken: 0:23:08 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 14/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 84 / Train-Loss: 0.2364 / Val-Loss: 0.2387 / Test-Loss: 0.2402 / Time taken: 0:23:22 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 14/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 85 / Train-Loss: 0.2364 / Val-Loss: 0.2390 / Test-Loss: 0.2405 / Time taken: 0:23:37 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 14/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 86 / Train-Loss: 0.2364 / Val-Loss: 0.2387 / Test-Loss: 0.2404 / Time taken: 0:23:53 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 14/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.035  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 87 / Train-Loss: 0.2363 / Val-Loss: 0.2390 / Test-Loss: 0.2406 / Time taken: 0:24:09 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 14/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 88 / Train-Loss: 0.2362 / Val-Loss: 0.2388 / Test-Loss: 0.2407 / Time taken: 0:24:25 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 14/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 89 / Train-Loss: 0.2364 / Val-Loss: 0.2383 / Test-Loss: 0.2401 / Time taken: 0:24:40 / ---- Currently Best Val-Epoch: 89 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 90 / Train-Loss: 0.2363 / Val-Loss: 0.2389 / Test-Loss: 0.2405 / Time taken: 0:24:55 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 91 / Train-Loss: 0.2361 / Val-Loss: 0.2389 / Test-Loss: 0.2404 / Time taken: 0:25:12 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 92 / Train-Loss: 0.2363 / Val-Loss: 0.2395 / Test-Loss: 0.2409 / Time taken: 0:25:27 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 93 / Train-Loss: 0.2362 / Val-Loss: 0.2385 / Test-Loss: 0.2404 / Time taken: 0:25:42 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 94 / Train-Loss: 0.2363 / Val-Loss: 0.2383 / Test-Loss: 0.2403 / Time taken: 0:26:03 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 95 / Train-Loss: 0.2361 / Val-Loss: 0.2385 / Test-Loss: 0.2404 / Time taken: 0:26:22 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 96 / Train-Loss: 0.2361 / Val-Loss: 0.2385 / Test-Loss: 0.2404 / Time taken: 0:26:37 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 97 / Train-Loss: 0.2361 / Val-Loss: 0.2386 / Test-Loss: 0.2405 / Time taken: 0:26:59 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 98 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 98 / Train-Loss: 0.2361 / Val-Loss: 0.2389 / Test-Loss: 0.2406 / Time taken: 0:27:21 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 99 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 99 / Train-Loss: 0.2361 / Val-Loss: 0.2389 / Test-Loss: 0.2406 / Time taken: 0:27:36 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 100 / Batch: 536 / Train-Loss (Batch): 0.0337: [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 100 / Train-Loss: 0.2362 / Val-Loss: 0.2387 / Test-Loss: 0.2408 / Time taken: 0:27:51 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 101 / Batch: 536 / Train-Loss (Batch): 0.0331: [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 101 / Train-Loss: 0.2360 / Val-Loss: 0.2390 / Test-Loss: 0.2407 / Time taken: 0:28:06 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 102 / Batch: 536 / Train-Loss (Batch): 0.0331: [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 102 / Train-Loss: 0.2361 / Val-Loss: 0.2388 / Test-Loss: 0.2405 / Time taken: 0:28:21 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 103 / Batch: 536 / Train-Loss (Batch): 0.0342: [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 103 / Train-Loss: 0.2361 / Val-Loss: 0.2388 / Test-Loss: 0.2407 / Time taken: 0:28:38 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 104 / Batch: 536 / Train-Loss (Batch): 0.0343: [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 104 / Train-Loss: 0.2361 / Val-Loss: 0.2386 / Test-Loss: 0.2405 / Time taken: 0:28:54 / ---- Currently Best Val-Epoch: 89 \n","Ensemble: 14/14 / Epoch: 105 / Batch: 536 / Train-Loss (Batch): 0.0356: [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 105 / Train-Loss: 0.2358 / Val-Loss: 0.2390 / Test-Loss: 0.2408 / Time taken: 0:29:09 / ---- Currently Best Val-Epoch: 89 \n","596/596 [==============================] - 11s 18ms/step\n","67/67 [==============================] - 1s 21ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-3f917e54-64b1-4ef7-ad12-350750315e89\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>130</th>\n","      <td>FT_transformer (run: 10)</td>\n","      <td>55</td>\n","      <td>1187.509606</td>\n","      <td>27133</td>\n","      <td>0.239155</td>\n","      <td>0.239897</td>\n","      <td>0.059857</td>\n","      <td>0.060138</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>FT_transformer (run: 11)</td>\n","      <td>86</td>\n","      <td>1705.731414</td>\n","      <td>27133</td>\n","      <td>0.236645</td>\n","      <td>0.238818</td>\n","      <td>0.062893</td>\n","      <td>0.063125</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>FT_transformer (run: 12)</td>\n","      <td>68</td>\n","      <td>1463.326831</td>\n","      <td>27133</td>\n","      <td>0.238008</td>\n","      <td>0.239344</td>\n","      <td>0.061057</td>\n","      <td>0.061140</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>FT_transformer (run: 13)</td>\n","      <td>100</td>\n","      <td>1992.376854</td>\n","      <td>27133</td>\n","      <td>0.237393</td>\n","      <td>0.239739</td>\n","      <td>0.060784</td>\n","      <td>0.060886</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>FT_transformer (run: 14)</td>\n","      <td>89</td>\n","      <td>1749.585324</td>\n","      <td>27133</td>\n","      <td>0.238085</td>\n","      <td>0.240123</td>\n","      <td>0.061349</td>\n","      <td>0.061344</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>135 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f917e54-64b1-4ef7-ad12-350750315e89')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3f917e54-64b1-4ef7-ad12-350750315e89 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3f917e54-64b1-4ef7-ad12-350750315e89');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-aa762c83-99cb-4562-9f3d-2cc6c5bd343c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa762c83-99cb-4562-9f3d-2cc6c5bd343c')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-aa762c83-99cb-4562-9f3d-2cc6c5bd343c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","130    FT_transformer (run: 10)      55  1187.509606          27133   \n","131    FT_transformer (run: 11)      86  1705.731414          27133   \n","132    FT_transformer (run: 12)      68  1463.326831          27133   \n","133    FT_transformer (run: 13)     100  1992.376854          27133   \n","134    FT_transformer (run: 14)      89  1749.585324          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","130    0.239155   0.239897             0.059857            0.060138  \n","131    0.236645   0.238818             0.062893            0.063125  \n","132    0.238008   0.239344             0.061057            0.061140  \n","133    0.237393   0.239739             0.060784            0.060886  \n","134    0.238085   0.240123             0.061349            0.061344  \n","\n","[135 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# Create the dataframes needed for evaluation:\n","# --------------------\n","# NOTE: in the 2021 Gorishniy et al paper the batch size is different for the different Datasets\n","# but is not hyperparameter tuned. Bigger datasets they used a batch size of 1024 and\n","# for smaller datasets a batch size of (256/512).\n","batch_size = 1024\n","learn_data = df_to_tensor(df_freq_prep_nn[bool_in_learn], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","test_data = df_to_tensor(df_freq_prep_nn[bool_in_test], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","# NOTE we use at first just a fraction of the data to test the code:\n","learn_train_dummy_data = df_to_tensor(df_freq_prep_nn[bool_in_learn_train_dummy], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size,\n","                                      dummy_data_for_build=True)\n","\n","for run_index in range(15):\n","    # Create the dataframes needed for training:\n","    learn_train_data = df_to_tensor(df_freq_prep_nn[train_val_split[f\"learn_train_{run_index}\"]],\n","                                    feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","    learn_val_data = df_to_tensor(df_freq_prep_nn[train_val_split[f\"learn_val_{run_index}\"]],\n","                                  feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------We are at Model: {str(run_index).zfill(2)}-----------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    # Define FT-Transformer Models:\n","    # ----------------------\n","    # NOTE: we use here tensorflow/keras model subclasses (not the functional or sequential api)\n","    # NOTE: we use here instead of the .fit function a costum training loop\n","\n","    # create the model:\n","    # ----------------------\n","    set_random_seeds(int(random_seeds[run_index]))\n","\n","    FT_transformer = EnhActuar.Feature_Tokenizer_Transformer(\n","            emb_dim = 32, # NOTE: In the default setting for the 2021 Gorishniy paper they used emb_dim = 192 (but the parameter size would here go trough the roof, so we use something smaller)\n","            nr_features = nr_col,\n","            cat_features = cat_col,\n","            cat_vocabulary = cat_vocabulary,\n","            count_transformer_blocks = 3,\n","            attention_n_heads = 8,\n","            attention_dropout = 0.2,\n","            ffn_d_hidden = None, # NOTE: change to None if ReGLU should be used -> None uses default value (4/3*emb_dim), they write that they used 2*emb_dim if not ReGLU.\n","            ffn_activation_ReGLU = True, # NOTE: set True if ReGLU should be used\n","            ffn_dropout = 0.1,\n","            prenormalization = True,\n","            output_dim = 1,\n","            last_activation = 'exponential',\n","            exposure_name = \"Exposure\",\n","            seed_nr = int(random_seeds[run_index])\n","    )\n","\n","    # See here regarding costum training loop: https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch\n","\n","    # Instantiate an optimizer to train the model.\n","    # ----------------------\n","    # create an optimizer AdamW with learning rate 1e-4, weight decay 1e-5:\n","    optimizer = tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5)\n","\n","    # Instantiate a loss function\n","    # ----------------------\n","    # we use our own loss function here\n","    # because it is not included in tensorflow in the same way (see section loss function for more details):\n","    loss_fn = Poisson_loss_for_tf_Wrapped()\n","\n","    # Prepare the metrics.\n","    # ----------------------\n","    # we use a costume metric here (because it is not included in tensorflow in the same way):\n","    train_acc_metric = Poisson_Metric_for_tf()\n","    val_acc_metric = Poisson_Metric_for_tf()\n","    test_acc_metric = Poisson_Metric_for_tf()\n","\n","    @tf.function\n","    def train_step(x, y):\n","        # Open a GradientTape to record the operations run during the forward pass, which enables auto-differentiation.\n","        with tf.GradientTape() as tape:\n","            # Run the forward pass of the layer. The operations that the layer applies to its inputs are going to be recorded on the GradientTape.\n","            y_pred = FT_transformer(x, training=True)[\"output\"]  # prediction for this minibatch\n","            # Compute the loss value for this minibatch.\n","            loss_value = loss_fn(y, y_pred)\n","        # Use the gradient tape to automatically retrieve the gradients of the trainable variables with respect to the loss.\n","        grads = tape.gradient(loss_value, FT_transformer.trainable_weights)\n","        # Run one step of gradient descent by updating the value of the variables to minimize the loss.\n","        optimizer.apply_gradients(zip(grads, FT_transformer.trainable_weights))\n","        # Update training metric.\n","        train_acc_metric.update_state(y, y_pred)\n","        return loss_value\n","\n","    @tf.function\n","    def val_step(x, y):\n","        # Run the forward pass of the layer.\n","        # (note: training=False is needed because the layers have different behavior during training versus inference (e.g. Dropout))\n","        y_pred = FT_transformer(x, training=False)[\"output\"]\n","        # Update val metrics\n","        val_acc_metric.update_state(y, y_pred)\n","\n","    @tf.function\n","    def test_step(x, y):\n","        # Run the forward pass of the layer.\n","        # (note: training=False is needed because the layers have different behavior during training versus inference (e.g. Dropout))\n","        y_pred = FT_transformer(x, training=False)[\"output\"]\n","        # Update val metrics\n","        test_acc_metric.update_state(y, y_pred)\n","\n","    # model fitting:\n","    # ----------------------\n","    start_time = time.time()\n","    Val_Progress = helper.Easy_ProgressTracker(patience=15)\n","    epochs = 500\n","\n","    for epoch in range(epochs):\n","        # Iterate over the batches of the dataset.\n","        for step, (x_batch_train, y_batch_train) in enumerate(learn_train_data):\n","            loss_value = train_step(x_batch_train, y_batch_train)\n","            helper.costume_progress_bar(f\"Ensemble: {str(run_index).zfill(2)}/{14} / Epoch: {epoch} / Batch: {step} / Train-Loss (Batch): {round(float(loss_value),4)}\",step,len(learn_train_data), 30)\n","\n","        # Display metrics at the end of each epoch.\n","        print_train_loss = train_acc_metric.result()\n","        # Reset training metrics at the end of each epoch\n","        train_acc_metric.reset_states()\n","\n","        # Run a validation at the end of each epoch.\n","        for x_batch_val, y_batch_val in learn_val_data:\n","            val_step(x_batch_val, y_batch_val)\n","        print_val_loss = val_acc_metric.result()\n","        val_acc_metric.reset_states()\n","        for x_batch_test, y_batch_test in test_data:\n","            test_step(x_batch_test, y_batch_test)\n","        print_test_loss = test_acc_metric.result()\n","        test_acc_metric.reset_states()\n","\n","        Val_Progress(current_epoch=epoch, current_score = print_val_loss)\n","\n","        print(f\"\\nEnsemble: {str(run_index).zfill(2)}/{14} / Epoch: {epoch} / Train-Loss: %.4f / Val-Loss: %.4f / Test-Loss: %.4f / Time taken: %s / ---- Currently Best Val-Epoch: %d\" % (\n","            # str(run_index).zfill(2),\n","            float(print_train_loss),\n","            float(print_val_loss),\n","            float(print_test_loss),\n","            datetime.timedelta(seconds=int(time.time() - start_time)),\n","            Val_Progress.best_epoch\n","            ), end = \" \")\n","        if Val_Progress.progress == True:\n","            print(\"<------- Best VAL Epoch so far\")\n","        else:\n","            print(\"\\r\")\n","\n","\n","        # Callback: save best model / early stopping:\n","        # ----------------------\n","        earliest_epoch2save = 10\n","        if Val_Progress.progress and Val_Progress.current_epoch >= earliest_epoch2save:\n","            # FT_transformer.save(storage_path +'/Poisson_FT_transformer')\n","            FT_transformer.save_weights(f'{storage_path}/saved_models/Poisson_FT_transformer_{run_index}.weights.h5')\n","        if Val_Progress.patience_over:\n","            break\n","\n","    # create some metrics after the loop\n","    best_epoch_FT_transformer = Val_Progress.best_epoch\n","    execution_time_FT_transformer = time.time() - start_time\n","\n","    # load the best saved model and epochs_and_time from the pickle file:\n","    # ----------------------\n","    # FT_transformer = keras.models.load_model(save_path +'/Poisson_FT_transformer')\n","    FT_transformer.load_weights(f'{storage_path}/saved_models/Poisson_FT_transformer_{run_index}.weights.h5')\n","\n","    # predict with the model:\n","    # ----------------------\n","    y_pred[\"train\"][f\"FT_transformer\"] = np.array([x for [x] in FT_transformer.predict(learn_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                )[\"output\"]])\n","    y_pred[\"test\"][f\"FT_transformer\"] = np.array([x for [x] in FT_transformer.predict(test_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                )[\"output\"]])\n","\n","    # evaluate the model:\n","    # ----------------------\n","    FT_transformer_results = Results(model=f\"FT_transformer (run: {run_index})\",\n","                                epochs=best_epoch_FT_transformer,\n","                                run_time=execution_time_FT_transformer,\n","                                nr_parameters=[np.sum([np.prod(v.get_shape().as_list()) for v in FT_transformer.trainable_weights])],\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"FT_transformer\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"FT_transformer\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"FT_transformer\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"FT_transformer\"].sum()/exposure[\"test\"].sum())\n","    # store the results in the dataframe:\n","    store_results_in_df(FT_transformer_results)\n","    display(df_results)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCfKIXHQMlLA"},"outputs":[],"source":["# # save the results:\n","# with open(f'{storage_path}/Data/df_results.pickle', 'wb') as handle:\n","#     pickle.dump(df_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# load the results:\n","with open(f'{storage_path}/Data/df_results.pickle', 'rb') as handle:\n","    df_results = pickle.load(handle)"]},{"cell_type":"markdown","metadata":{"id":"rZeHvQt1jymv"},"source":["## 4.2 CANN-FT-Transformer:  "]},{"cell_type":"markdown","metadata":{"id":"KyzKR0l8IAAG"},"source":["Note: we run the code 15 times on different seeds (to calc the avg and std of runtime and results)."]},{"cell_type":"markdown","metadata":{"id":"G_pGuaF_IN5p"},"source":["Note: the Code for the CANN below is basically the same code as for the FT-Transformer. The only changes are\n","* we use a other exposure column (Exposure_x_GLM3_pred instead of Exposure)\n","* we set the initial weights and bias of the last layer to zero"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uThlQxUQITGq"},"outputs":[],"source":["# create the new exposure times GLM3_pred column for CANN models.\n","df_freq_prep_nn[\"Exposure_x_GLM3_pred\"] = list(poisson_glm3.predict(X_glm3)*df_freq_prep_nn[\"Exposure\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6448431,"status":"ok","timestamp":1699134343249,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"k8XS-9fQIlWC","outputId":"a54f5808-c361-41a5-ee42-c384f736ff5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 00-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 00/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 0 / Train-Loss: 0.2403 / Val-Loss: 0.2449 / Test-Loss: 0.2414 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 1 / Train-Loss: 0.2405 / Val-Loss: 0.2449 / Test-Loss: 0.2413 / Time taken: 0:00:56 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 2 / Train-Loss: 0.2405 / Val-Loss: 0.2448 / Test-Loss: 0.2413 / Time taken: 0:01:10 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 3 / Train-Loss: 0.2405 / Val-Loss: 0.2447 / Test-Loss: 0.2412 / Time taken: 0:01:25 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 4 / Train-Loss: 0.2404 / Val-Loss: 0.2449 / Test-Loss: 0.2413 / Time taken: 0:01:47 / ---- Currently Best Val-Epoch: 3 \n","Ensemble: 00/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 5 / Train-Loss: 0.2403 / Val-Loss: 0.2452 / Test-Loss: 0.2416 / Time taken: 0:02:00 / ---- Currently Best Val-Epoch: 3 \n","Ensemble: 00/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 6 / Train-Loss: 0.2398 / Val-Loss: 0.2443 / Test-Loss: 0.2404 / Time taken: 0:02:13 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 7 / Train-Loss: 0.2395 / Val-Loss: 0.2441 / Test-Loss: 0.2401 / Time taken: 0:02:29 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 8 / Train-Loss: 0.2393 / Val-Loss: 0.2441 / Test-Loss: 0.2400 / Time taken: 0:02:43 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 9 / Train-Loss: 0.2391 / Val-Loss: 0.2439 / Test-Loss: 0.2398 / Time taken: 0:02:59 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 10 / Train-Loss: 0.2390 / Val-Loss: 0.2436 / Test-Loss: 0.2397 / Time taken: 0:03:22 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 00/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 11 / Train-Loss: 0.2388 / Val-Loss: 0.2436 / Test-Loss: 0.2397 / Time taken: 0:03:44 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 12 / Train-Loss: 0.2387 / Val-Loss: 0.2434 / Test-Loss: 0.2395 / Time taken: 0:03:59 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 13 / Train-Loss: 0.2386 / Val-Loss: 0.2432 / Test-Loss: 0.2394 / Time taken: 0:04:13 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 14 / Train-Loss: 0.2385 / Val-Loss: 0.2433 / Test-Loss: 0.2395 / Time taken: 0:04:28 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 00/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 15 / Train-Loss: 0.2384 / Val-Loss: 0.2430 / Test-Loss: 0.2393 / Time taken: 0:04:41 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 16 / Train-Loss: 0.2384 / Val-Loss: 0.2428 / Test-Loss: 0.2391 / Time taken: 0:05:03 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 17 / Train-Loss: 0.2382 / Val-Loss: 0.2428 / Test-Loss: 0.2390 / Time taken: 0:05:26 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 18 / Train-Loss: 0.2382 / Val-Loss: 0.2427 / Test-Loss: 0.2391 / Time taken: 0:05:41 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 19 / Train-Loss: 0.2382 / Val-Loss: 0.2427 / Test-Loss: 0.2391 / Time taken: 0:06:03 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 20 / Train-Loss: 0.2381 / Val-Loss: 0.2427 / Test-Loss: 0.2391 / Time taken: 0:06:18 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 00/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 21 / Train-Loss: 0.2381 / Val-Loss: 0.2426 / Test-Loss: 0.2391 / Time taken: 0:06:31 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 22 / Train-Loss: 0.2380 / Val-Loss: 0.2426 / Test-Loss: 0.2390 / Time taken: 0:06:46 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 00/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 23 / Train-Loss: 0.2380 / Val-Loss: 0.2424 / Test-Loss: 0.2389 / Time taken: 0:07:07 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 24 / Train-Loss: 0.2379 / Val-Loss: 0.2425 / Test-Loss: 0.2389 / Time taken: 0:07:31 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 00/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 25 / Train-Loss: 0.2379 / Val-Loss: 0.2425 / Test-Loss: 0.2389 / Time taken: 0:07:45 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 00/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 26 / Train-Loss: 0.2378 / Val-Loss: 0.2425 / Test-Loss: 0.2388 / Time taken: 0:07:59 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 00/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 27 / Train-Loss: 0.2378 / Val-Loss: 0.2425 / Test-Loss: 0.2388 / Time taken: 0:08:12 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 00/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 28 / Train-Loss: 0.2377 / Val-Loss: 0.2423 / Test-Loss: 0.2386 / Time taken: 0:08:26 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 29 / Train-Loss: 0.2377 / Val-Loss: 0.2423 / Test-Loss: 0.2387 / Time taken: 0:08:41 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 30 / Train-Loss: 0.2377 / Val-Loss: 0.2423 / Test-Loss: 0.2386 / Time taken: 0:08:55 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 31 / Train-Loss: 0.2376 / Val-Loss: 0.2422 / Test-Loss: 0.2387 / Time taken: 0:09:09 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 32 / Train-Loss: 0.2376 / Val-Loss: 0.2423 / Test-Loss: 0.2387 / Time taken: 0:09:24 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 00/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 33 / Train-Loss: 0.2375 / Val-Loss: 0.2420 / Test-Loss: 0.2383 / Time taken: 0:09:37 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 34 / Train-Loss: 0.2375 / Val-Loss: 0.2422 / Test-Loss: 0.2385 / Time taken: 0:09:51 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 00/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 35 / Train-Loss: 0.2374 / Val-Loss: 0.2420 / Test-Loss: 0.2384 / Time taken: 0:10:05 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 36 / Train-Loss: 0.2374 / Val-Loss: 0.2419 / Test-Loss: 0.2382 / Time taken: 0:10:19 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 37 / Train-Loss: 0.2373 / Val-Loss: 0.2422 / Test-Loss: 0.2384 / Time taken: 0:10:32 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 00/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 38 / Train-Loss: 0.2371 / Val-Loss: 0.2421 / Test-Loss: 0.2385 / Time taken: 0:10:47 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 00/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 39 / Train-Loss: 0.2372 / Val-Loss: 0.2421 / Test-Loss: 0.2382 / Time taken: 0:11:01 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 00/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 40 / Train-Loss: 0.2371 / Val-Loss: 0.2420 / Test-Loss: 0.2383 / Time taken: 0:11:15 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 00/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 41 / Train-Loss: 0.2370 / Val-Loss: 0.2420 / Test-Loss: 0.2384 / Time taken: 0:11:28 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 00/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 42 / Train-Loss: 0.2371 / Val-Loss: 0.2416 / Test-Loss: 0.2381 / Time taken: 0:11:42 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 43 / Train-Loss: 0.2370 / Val-Loss: 0.2419 / Test-Loss: 0.2385 / Time taken: 0:11:56 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 44 / Train-Loss: 0.2369 / Val-Loss: 0.2421 / Test-Loss: 0.2382 / Time taken: 0:12:10 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 45 / Train-Loss: 0.2370 / Val-Loss: 0.2417 / Test-Loss: 0.2381 / Time taken: 0:12:23 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 46 / Train-Loss: 0.2367 / Val-Loss: 0.2424 / Test-Loss: 0.2388 / Time taken: 0:12:37 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 47 / Train-Loss: 0.2368 / Val-Loss: 0.2418 / Test-Loss: 0.2382 / Time taken: 0:12:50 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 48 / Train-Loss: 0.2368 / Val-Loss: 0.2417 / Test-Loss: 0.2380 / Time taken: 0:13:05 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 49 / Train-Loss: 0.2366 / Val-Loss: 0.2420 / Test-Loss: 0.2383 / Time taken: 0:13:18 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 50 / Train-Loss: 0.2367 / Val-Loss: 0.2417 / Test-Loss: 0.2380 / Time taken: 0:13:32 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 51 / Train-Loss: 0.2365 / Val-Loss: 0.2418 / Test-Loss: 0.2381 / Time taken: 0:13:45 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 52 / Train-Loss: 0.2365 / Val-Loss: 0.2423 / Test-Loss: 0.2384 / Time taken: 0:13:59 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 53 / Train-Loss: 0.2365 / Val-Loss: 0.2419 / Test-Loss: 0.2382 / Time taken: 0:14:13 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 54 / Train-Loss: 0.2364 / Val-Loss: 0.2418 / Test-Loss: 0.2380 / Time taken: 0:14:26 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 55 / Train-Loss: 0.2365 / Val-Loss: 0.2419 / Test-Loss: 0.2381 / Time taken: 0:14:48 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 56 / Train-Loss: 0.2365 / Val-Loss: 0.2418 / Test-Loss: 0.2379 / Time taken: 0:15:02 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 57 / Train-Loss: 0.2364 / Val-Loss: 0.2419 / Test-Loss: 0.2380 / Time taken: 0:15:16 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 00/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 58 / Train-Loss: 0.2363 / Val-Loss: 0.2418 / Test-Loss: 0.2379 / Time taken: 0:15:30 / ---- Currently Best Val-Epoch: 42 \n","596/596 [==============================] - 11s 18ms/step\n","67/67 [==============================] - 1s 15ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-c17bcf63-6350-4925-bde1-290d13fb3f8c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>FT_transformer (run: 11)</td>\n","      <td>86</td>\n","      <td>1705.731414</td>\n","      <td>27133</td>\n","      <td>0.236645</td>\n","      <td>0.238818</td>\n","      <td>0.062893</td>\n","      <td>0.063125</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>FT_transformer (run: 12)</td>\n","      <td>68</td>\n","      <td>1463.326831</td>\n","      <td>27133</td>\n","      <td>0.238008</td>\n","      <td>0.239344</td>\n","      <td>0.061057</td>\n","      <td>0.061140</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>FT_transformer (run: 13)</td>\n","      <td>100</td>\n","      <td>1992.376854</td>\n","      <td>27133</td>\n","      <td>0.237393</td>\n","      <td>0.239739</td>\n","      <td>0.060784</td>\n","      <td>0.060886</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>FT_transformer (run: 14)</td>\n","      <td>89</td>\n","      <td>1749.585324</td>\n","      <td>27133</td>\n","      <td>0.238085</td>\n","      <td>0.240123</td>\n","      <td>0.061349</td>\n","      <td>0.061344</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>CAFTT (run: 0)</td>\n","      <td>42</td>\n","      <td>930.150725</td>\n","      <td>27133</td>\n","      <td>0.237616</td>\n","      <td>0.238094</td>\n","      <td>0.066199</td>\n","      <td>0.066450</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>136 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c17bcf63-6350-4925-bde1-290d13fb3f8c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c17bcf63-6350-4925-bde1-290d13fb3f8c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c17bcf63-6350-4925-bde1-290d13fb3f8c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-aefbca41-ab6e-4bff-98d5-1a74d9c55cd5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aefbca41-ab6e-4bff-98d5-1a74d9c55cd5')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-aefbca41-ab6e-4bff-98d5-1a74d9c55cd5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","131    FT_transformer (run: 11)      86  1705.731414          27133   \n","132    FT_transformer (run: 12)      68  1463.326831          27133   \n","133    FT_transformer (run: 13)     100  1992.376854          27133   \n","134    FT_transformer (run: 14)      89  1749.585324          27133   \n","135              CAFTT (run: 0)      42   930.150725          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","131    0.236645   0.238818             0.062893            0.063125  \n","132    0.238008   0.239344             0.061057            0.061140  \n","133    0.237393   0.239739             0.060784            0.060886  \n","134    0.238085   0.240123             0.061349            0.061344  \n","135    0.237616   0.238094             0.066199            0.066450  \n","\n","[136 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 01-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 01/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.007   : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 0 / Train-Loss: 0.2402 / Val-Loss: 0.2458 / Test-Loss: 0.2413 / Time taken: 0:00:44 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.007   : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 1 / Train-Loss: 0.2404 / Val-Loss: 0.2457 / Test-Loss: 0.2413 / Time taken: 0:00:57 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0071  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 2 / Train-Loss: 0.2404 / Val-Loss: 0.2456 / Test-Loss: 0.2412 / Time taken: 0:01:11 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.007   : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 3 / Train-Loss: 0.2404 / Val-Loss: 0.2459 / Test-Loss: 0.2414 / Time taken: 0:01:26 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 01/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0068  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 4 / Train-Loss: 0.2402 / Val-Loss: 0.2459 / Test-Loss: 0.2414 / Time taken: 0:01:47 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 01/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0068  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 5 / Train-Loss: 0.2396 / Val-Loss: 0.2454 / Test-Loss: 0.2409 / Time taken: 0:02:00 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0069  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 6 / Train-Loss: 0.2393 / Val-Loss: 0.2446 / Test-Loss: 0.2401 / Time taken: 0:02:14 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0068  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 7 / Train-Loss: 0.2391 / Val-Loss: 0.2446 / Test-Loss: 0.2402 / Time taken: 0:02:27 / ---- Currently Best Val-Epoch: 6 \n","Ensemble: 01/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0069  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 8 / Train-Loss: 0.2388 / Val-Loss: 0.2444 / Test-Loss: 0.2400 / Time taken: 0:02:42 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0068  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 9 / Train-Loss: 0.2388 / Val-Loss: 0.2446 / Test-Loss: 0.2401 / Time taken: 0:02:55 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 01/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 10 / Train-Loss: 0.2386 / Val-Loss: 0.2442 / Test-Loss: 0.2397 / Time taken: 0:03:09 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 11 / Batch: 1 / Train-Loss (Batch): 0.1707   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 01/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 11 / Train-Loss: 0.2385 / Val-Loss: 0.2441 / Test-Loss: 0.2395 / Time taken: 0:03:22 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 12 / Train-Loss: 0.2384 / Val-Loss: 0.2438 / Test-Loss: 0.2393 / Time taken: 0:03:44 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 13 / Train-Loss: 0.2383 / Val-Loss: 0.2440 / Test-Loss: 0.2394 / Time taken: 0:04:06 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 01/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 14 / Train-Loss: 0.2383 / Val-Loss: 0.2439 / Test-Loss: 0.2393 / Time taken: 0:04:20 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 01/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 15 / Train-Loss: 0.2381 / Val-Loss: 0.2438 / Test-Loss: 0.2391 / Time taken: 0:04:33 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 16 / Train-Loss: 0.2381 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:04:48 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 17 / Train-Loss: 0.2379 / Val-Loss: 0.2439 / Test-Loss: 0.2392 / Time taken: 0:05:01 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 01/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 18 / Train-Loss: 0.2380 / Val-Loss: 0.2435 / Test-Loss: 0.2390 / Time taken: 0:05:14 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 19 / Train-Loss: 0.2378 / Val-Loss: 0.2434 / Test-Loss: 0.2389 / Time taken: 0:05:28 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 20 / Train-Loss: 0.2377 / Val-Loss: 0.2436 / Test-Loss: 0.2389 / Time taken: 0:05:42 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 01/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 21 / Train-Loss: 0.2377 / Val-Loss: 0.2433 / Test-Loss: 0.2388 / Time taken: 0:05:56 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 22 / Train-Loss: 0.2376 / Val-Loss: 0.2434 / Test-Loss: 0.2388 / Time taken: 0:06:10 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 01/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 23 / Train-Loss: 0.2375 / Val-Loss: 0.2434 / Test-Loss: 0.2388 / Time taken: 0:06:23 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 01/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 24 / Train-Loss: 0.2374 / Val-Loss: 0.2430 / Test-Loss: 0.2385 / Time taken: 0:06:37 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 25 / Train-Loss: 0.2374 / Val-Loss: 0.2428 / Test-Loss: 0.2384 / Time taken: 0:06:51 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 26 / Train-Loss: 0.2373 / Val-Loss: 0.2435 / Test-Loss: 0.2389 / Time taken: 0:07:13 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 01/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 27 / Train-Loss: 0.2373 / Val-Loss: 0.2433 / Test-Loss: 0.2387 / Time taken: 0:07:34 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 01/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 28 / Train-Loss: 0.2372 / Val-Loss: 0.2430 / Test-Loss: 0.2385 / Time taken: 0:07:57 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 01/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 29 / Train-Loss: 0.2371 / Val-Loss: 0.2427 / Test-Loss: 0.2383 / Time taken: 0:08:13 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 30 / Train-Loss: 0.2371 / Val-Loss: 0.2426 / Test-Loss: 0.2383 / Time taken: 0:08:27 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 31 / Train-Loss: 0.2370 / Val-Loss: 0.2428 / Test-Loss: 0.2384 / Time taken: 0:08:40 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 01/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 32 / Train-Loss: 0.2370 / Val-Loss: 0.2427 / Test-Loss: 0.2383 / Time taken: 0:08:54 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 01/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 33 / Train-Loss: 0.2369 / Val-Loss: 0.2433 / Test-Loss: 0.2388 / Time taken: 0:09:09 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 01/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 34 / Train-Loss: 0.2369 / Val-Loss: 0.2430 / Test-Loss: 0.2386 / Time taken: 0:09:23 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 01/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 35 / Train-Loss: 0.2368 / Val-Loss: 0.2429 / Test-Loss: 0.2384 / Time taken: 0:09:37 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 01/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 36 / Train-Loss: 0.2367 / Val-Loss: 0.2428 / Test-Loss: 0.2386 / Time taken: 0:09:51 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 01/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 37 / Train-Loss: 0.2367 / Val-Loss: 0.2428 / Test-Loss: 0.2384 / Time taken: 0:10:04 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 01/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 38 / Train-Loss: 0.2367 / Val-Loss: 0.2424 / Test-Loss: 0.2381 / Time taken: 0:10:19 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 39 / Train-Loss: 0.2366 / Val-Loss: 0.2424 / Test-Loss: 0.2382 / Time taken: 0:10:41 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 40 / Train-Loss: 0.2366 / Val-Loss: 0.2424 / Test-Loss: 0.2382 / Time taken: 0:11:03 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 41 / Train-Loss: 0.2366 / Val-Loss: 0.2425 / Test-Loss: 0.2382 / Time taken: 0:11:19 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 01/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 42 / Train-Loss: 0.2366 / Val-Loss: 0.2426 / Test-Loss: 0.2383 / Time taken: 0:11:33 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 01/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 43 / Train-Loss: 0.2365 / Val-Loss: 0.2424 / Test-Loss: 0.2381 / Time taken: 0:11:47 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 01/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 44 / Train-Loss: 0.2364 / Val-Loss: 0.2427 / Test-Loss: 0.2383 / Time taken: 0:12:01 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 01/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 45 / Train-Loss: 0.2365 / Val-Loss: 0.2424 / Test-Loss: 0.2381 / Time taken: 0:12:15 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 01/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 46 / Train-Loss: 0.2364 / Val-Loss: 0.2425 / Test-Loss: 0.2383 / Time taken: 0:12:30 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 01/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 47 / Train-Loss: 0.2363 / Val-Loss: 0.2425 / Test-Loss: 0.2382 / Time taken: 0:12:42 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 01/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 48 / Train-Loss: 0.2363 / Val-Loss: 0.2424 / Test-Loss: 0.2381 / Time taken: 0:12:56 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 01/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 49 / Train-Loss: 0.2363 / Val-Loss: 0.2423 / Test-Loss: 0.2380 / Time taken: 0:13:09 / ---- Currently Best Val-Epoch: 49 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 50 / Train-Loss: 0.2363 / Val-Loss: 0.2426 / Test-Loss: 0.2382 / Time taken: 0:13:23 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 51 / Train-Loss: 0.2361 / Val-Loss: 0.2426 / Test-Loss: 0.2382 / Time taken: 0:13:37 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 52 / Train-Loss: 0.2361 / Val-Loss: 0.2424 / Test-Loss: 0.2380 / Time taken: 0:13:51 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 53 / Train-Loss: 0.2362 / Val-Loss: 0.2424 / Test-Loss: 0.2379 / Time taken: 0:14:05 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 54 / Train-Loss: 0.2361 / Val-Loss: 0.2424 / Test-Loss: 0.2381 / Time taken: 0:14:18 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 55 / Train-Loss: 0.2361 / Val-Loss: 0.2426 / Test-Loss: 0.2381 / Time taken: 0:14:32 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 56 / Train-Loss: 0.2362 / Val-Loss: 0.2425 / Test-Loss: 0.2380 / Time taken: 0:14:47 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 57 / Train-Loss: 0.2361 / Val-Loss: 0.2425 / Test-Loss: 0.2380 / Time taken: 0:15:00 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 58 / Train-Loss: 0.2361 / Val-Loss: 0.2425 / Test-Loss: 0.2380 / Time taken: 0:15:22 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 59 / Train-Loss: 0.2360 / Val-Loss: 0.2424 / Test-Loss: 0.2380 / Time taken: 0:15:35 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 60 / Train-Loss: 0.2360 / Val-Loss: 0.2425 / Test-Loss: 0.2379 / Time taken: 0:15:51 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 61 / Train-Loss: 0.2360 / Val-Loss: 0.2425 / Test-Loss: 0.2381 / Time taken: 0:16:05 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 62 / Train-Loss: 0.2360 / Val-Loss: 0.2426 / Test-Loss: 0.2381 / Time taken: 0:16:28 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 63 / Train-Loss: 0.2359 / Val-Loss: 0.2426 / Test-Loss: 0.2381 / Time taken: 0:16:41 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 64 / Train-Loss: 0.2360 / Val-Loss: 0.2425 / Test-Loss: 0.2380 / Time taken: 0:16:56 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 01/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 65 / Train-Loss: 0.2360 / Val-Loss: 0.2424 / Test-Loss: 0.2380 / Time taken: 0:17:10 / ---- Currently Best Val-Epoch: 49 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 20ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-5105e65e-4a90-47af-a6a2-da97f115e7da\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>FT_transformer (run: 12)</td>\n","      <td>68</td>\n","      <td>1463.326831</td>\n","      <td>27133</td>\n","      <td>0.238008</td>\n","      <td>0.239344</td>\n","      <td>0.061057</td>\n","      <td>0.061140</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>FT_transformer (run: 13)</td>\n","      <td>100</td>\n","      <td>1992.376854</td>\n","      <td>27133</td>\n","      <td>0.237393</td>\n","      <td>0.239739</td>\n","      <td>0.060784</td>\n","      <td>0.060886</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>FT_transformer (run: 14)</td>\n","      <td>89</td>\n","      <td>1749.585324</td>\n","      <td>27133</td>\n","      <td>0.238085</td>\n","      <td>0.240123</td>\n","      <td>0.061349</td>\n","      <td>0.061344</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>CAFTT (run: 0)</td>\n","      <td>42</td>\n","      <td>930.150725</td>\n","      <td>27133</td>\n","      <td>0.237616</td>\n","      <td>0.238094</td>\n","      <td>0.066199</td>\n","      <td>0.066450</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>CAFTT (run: 1)</td>\n","      <td>49</td>\n","      <td>1030.421487</td>\n","      <td>27133</td>\n","      <td>0.237010</td>\n","      <td>0.237976</td>\n","      <td>0.065635</td>\n","      <td>0.065934</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>137 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5105e65e-4a90-47af-a6a2-da97f115e7da')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5105e65e-4a90-47af-a6a2-da97f115e7da button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5105e65e-4a90-47af-a6a2-da97f115e7da');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-54b4501a-014c-43b3-988c-4259714d8324\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54b4501a-014c-43b3-988c-4259714d8324')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-54b4501a-014c-43b3-988c-4259714d8324 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","132    FT_transformer (run: 12)      68  1463.326831          27133   \n","133    FT_transformer (run: 13)     100  1992.376854          27133   \n","134    FT_transformer (run: 14)      89  1749.585324          27133   \n","135              CAFTT (run: 0)      42   930.150725          27133   \n","136              CAFTT (run: 1)      49  1030.421487          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","132    0.238008   0.239344             0.061057            0.061140  \n","133    0.237393   0.239739             0.060784            0.060886  \n","134    0.238085   0.240123             0.061349            0.061344  \n","135    0.237616   0.238094             0.066199            0.066450  \n","136    0.237010   0.237976             0.065635            0.065934  \n","\n","[137 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 02-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 02/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 0 / Train-Loss: 0.2409 / Val-Loss: 0.2400 / Test-Loss: 0.2413 / Time taken: 0:00:30 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 1 / Train-Loss: 0.2410 / Val-Loss: 0.2400 / Test-Loss: 0.2413 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 02/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 2 / Train-Loss: 0.2410 / Val-Loss: 0.2399 / Test-Loss: 0.2413 / Time taken: 0:00:56 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 3 / Train-Loss: 0.2410 / Val-Loss: 0.2399 / Test-Loss: 0.2412 / Time taken: 0:01:10 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 4 / Train-Loss: 0.2410 / Val-Loss: 0.2398 / Test-Loss: 0.2412 / Time taken: 0:01:24 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 5 / Train-Loss: 0.2410 / Val-Loss: 0.2399 / Test-Loss: 0.2412 / Time taken: 0:01:38 / ---- Currently Best Val-Epoch: 4 \n","Ensemble: 02/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 6 / Train-Loss: 0.2407 / Val-Loss: 0.2398 / Test-Loss: 0.2410 / Time taken: 0:01:52 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 7 / Train-Loss: 0.2402 / Val-Loss: 0.2393 / Test-Loss: 0.2405 / Time taken: 0:02:05 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 8 / Train-Loss: 0.2399 / Val-Loss: 0.2390 / Test-Loss: 0.2402 / Time taken: 0:02:19 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 9 / Train-Loss: 0.2396 / Val-Loss: 0.2390 / Test-Loss: 0.2401 / Time taken: 0:02:33 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 10 / Train-Loss: 0.2394 / Val-Loss: 0.2388 / Test-Loss: 0.2397 / Time taken: 0:02:47 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 02/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 11 / Train-Loss: 0.2391 / Val-Loss: 0.2388 / Test-Loss: 0.2396 / Time taken: 0:03:01 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 02/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 12 / Train-Loss: 0.2390 / Val-Loss: 0.2389 / Test-Loss: 0.2397 / Time taken: 0:03:16 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 02/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 13 / Train-Loss: 0.2388 / Val-Loss: 0.2387 / Test-Loss: 0.2394 / Time taken: 0:03:30 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 14 / Train-Loss: 0.2387 / Val-Loss: 0.2387 / Test-Loss: 0.2396 / Time taken: 0:03:45 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 15 / Train-Loss: 0.2387 / Val-Loss: 0.2384 / Test-Loss: 0.2393 / Time taken: 0:03:58 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 16 / Train-Loss: 0.2386 / Val-Loss: 0.2382 / Test-Loss: 0.2392 / Time taken: 0:04:12 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 17 / Train-Loss: 0.2386 / Val-Loss: 0.2382 / Test-Loss: 0.2392 / Time taken: 0:04:26 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 18 / Train-Loss: 0.2385 / Val-Loss: 0.2380 / Test-Loss: 0.2391 / Time taken: 0:04:42 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 19 / Train-Loss: 0.2385 / Val-Loss: 0.2379 / Test-Loss: 0.2390 / Time taken: 0:04:56 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 20 / Train-Loss: 0.2384 / Val-Loss: 0.2379 / Test-Loss: 0.2391 / Time taken: 0:05:10 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 21 / Train-Loss: 0.2384 / Val-Loss: 0.2377 / Test-Loss: 0.2389 / Time taken: 0:05:24 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 22 / Train-Loss: 0.2383 / Val-Loss: 0.2378 / Test-Loss: 0.2390 / Time taken: 0:05:40 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 02/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 23 / Train-Loss: 0.2383 / Val-Loss: 0.2376 / Test-Loss: 0.2389 / Time taken: 0:05:54 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 24 / Train-Loss: 0.2382 / Val-Loss: 0.2376 / Test-Loss: 0.2389 / Time taken: 0:06:08 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 02/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 25 / Train-Loss: 0.2383 / Val-Loss: 0.2377 / Test-Loss: 0.2391 / Time taken: 0:06:21 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 02/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 26 / Train-Loss: 0.2382 / Val-Loss: 0.2376 / Test-Loss: 0.2389 / Time taken: 0:06:35 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 27 / Train-Loss: 0.2382 / Val-Loss: 0.2375 / Test-Loss: 0.2388 / Time taken: 0:06:57 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 28 / Train-Loss: 0.2382 / Val-Loss: 0.2375 / Test-Loss: 0.2388 / Time taken: 0:07:13 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 02/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 29 / Train-Loss: 0.2381 / Val-Loss: 0.2375 / Test-Loss: 0.2388 / Time taken: 0:07:34 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 30 / Train-Loss: 0.2381 / Val-Loss: 0.2374 / Test-Loss: 0.2387 / Time taken: 0:07:51 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 31 / Train-Loss: 0.2380 / Val-Loss: 0.2378 / Test-Loss: 0.2390 / Time taken: 0:08:06 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 02/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 32 / Train-Loss: 0.2381 / Val-Loss: 0.2374 / Test-Loss: 0.2388 / Time taken: 0:08:20 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 02/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 33 / Train-Loss: 0.2380 / Val-Loss: 0.2372 / Test-Loss: 0.2386 / Time taken: 0:08:42 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 34 / Train-Loss: 0.2378 / Val-Loss: 0.2373 / Test-Loss: 0.2387 / Time taken: 0:08:59 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 02/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 35 / Train-Loss: 0.2379 / Val-Loss: 0.2372 / Test-Loss: 0.2386 / Time taken: 0:09:12 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 36 / Train-Loss: 0.2377 / Val-Loss: 0.2377 / Test-Loss: 0.2389 / Time taken: 0:09:26 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 02/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 37 / Train-Loss: 0.2376 / Val-Loss: 0.2371 / Test-Loss: 0.2385 / Time taken: 0:09:47 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 38 / Train-Loss: 0.2376 / Val-Loss: 0.2369 / Test-Loss: 0.2383 / Time taken: 0:10:04 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 39 / Train-Loss: 0.2375 / Val-Loss: 0.2372 / Test-Loss: 0.2387 / Time taken: 0:10:26 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 02/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 40 / Train-Loss: 0.2374 / Val-Loss: 0.2368 / Test-Loss: 0.2383 / Time taken: 0:10:40 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 41 / Train-Loss: 0.2374 / Val-Loss: 0.2376 / Test-Loss: 0.2390 / Time taken: 0:10:56 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 02/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 42 / Train-Loss: 0.2374 / Val-Loss: 0.2368 / Test-Loss: 0.2383 / Time taken: 0:11:18 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 02/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 43 / Train-Loss: 0.2373 / Val-Loss: 0.2370 / Test-Loss: 0.2387 / Time taken: 0:11:31 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 02/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 44 / Train-Loss: 0.2372 / Val-Loss: 0.2372 / Test-Loss: 0.2386 / Time taken: 0:11:45 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 02/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 45 / Train-Loss: 0.2374 / Val-Loss: 0.2367 / Test-Loss: 0.2383 / Time taken: 0:12:07 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 46 / Train-Loss: 0.2373 / Val-Loss: 0.2367 / Test-Loss: 0.2384 / Time taken: 0:12:22 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 02/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 47 / Train-Loss: 0.2371 / Val-Loss: 0.2375 / Test-Loss: 0.2387 / Time taken: 0:12:37 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 02/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 48 / Train-Loss: 0.2372 / Val-Loss: 0.2372 / Test-Loss: 0.2387 / Time taken: 0:12:51 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 02/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 49 / Train-Loss: 0.2372 / Val-Loss: 0.2376 / Test-Loss: 0.2387 / Time taken: 0:13:07 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 02/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 50 / Train-Loss: 0.2370 / Val-Loss: 0.2370 / Test-Loss: 0.2386 / Time taken: 0:13:29 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 02/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 51 / Train-Loss: 0.2370 / Val-Loss: 0.2366 / Test-Loss: 0.2383 / Time taken: 0:13:43 / ---- Currently Best Val-Epoch: 51 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 52 / Train-Loss: 0.2370 / Val-Loss: 0.2366 / Test-Loss: 0.2383 / Time taken: 0:14:06 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 02/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 53 / Train-Loss: 0.2369 / Val-Loss: 0.2367 / Test-Loss: 0.2384 / Time taken: 0:14:20 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 02/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 54 / Train-Loss: 0.2370 / Val-Loss: 0.2365 / Test-Loss: 0.2381 / Time taken: 0:14:35 / ---- Currently Best Val-Epoch: 54 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 55 / Train-Loss: 0.2369 / Val-Loss: 0.2364 / Test-Loss: 0.2382 / Time taken: 0:14:49 / ---- Currently Best Val-Epoch: 55 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 56 / Train-Loss: 0.2368 / Val-Loss: 0.2368 / Test-Loss: 0.2385 / Time taken: 0:15:04 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 57 / Train-Loss: 0.2368 / Val-Loss: 0.2364 / Test-Loss: 0.2381 / Time taken: 0:15:25 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 58 / Train-Loss: 0.2367 / Val-Loss: 0.2378 / Test-Loss: 0.2388 / Time taken: 0:15:46 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 59 / Train-Loss: 0.2368 / Val-Loss: 0.2366 / Test-Loss: 0.2383 / Time taken: 0:16:09 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 60 / Train-Loss: 0.2366 / Val-Loss: 0.2368 / Test-Loss: 0.2382 / Time taken: 0:16:24 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 61 / Train-Loss: 0.2367 / Val-Loss: 0.2366 / Test-Loss: 0.2381 / Time taken: 0:16:38 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 62 / Train-Loss: 0.2367 / Val-Loss: 0.2370 / Test-Loss: 0.2384 / Time taken: 0:16:53 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 63 / Train-Loss: 0.2367 / Val-Loss: 0.2367 / Test-Loss: 0.2381 / Time taken: 0:17:15 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 64 / Train-Loss: 0.2365 / Val-Loss: 0.2375 / Test-Loss: 0.2388 / Time taken: 0:17:37 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 65 / Train-Loss: 0.2366 / Val-Loss: 0.2367 / Test-Loss: 0.2382 / Time taken: 0:17:50 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 66 / Train-Loss: 0.2366 / Val-Loss: 0.2370 / Test-Loss: 0.2383 / Time taken: 0:18:04 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 67 / Train-Loss: 0.2366 / Val-Loss: 0.2365 / Test-Loss: 0.2380 / Time taken: 0:18:20 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 68 / Train-Loss: 0.2365 / Val-Loss: 0.2364 / Test-Loss: 0.2381 / Time taken: 0:18:34 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 69 / Train-Loss: 0.2366 / Val-Loss: 0.2367 / Test-Loss: 0.2383 / Time taken: 0:18:47 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 70 / Train-Loss: 0.2366 / Val-Loss: 0.2366 / Test-Loss: 0.2382 / Time taken: 0:19:02 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 02/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 71 / Train-Loss: 0.2365 / Val-Loss: 0.2372 / Test-Loss: 0.2385 / Time taken: 0:19:17 / ---- Currently Best Val-Epoch: 55 \n","596/596 [==============================] - 11s 17ms/step\n","67/67 [==============================] - 1s 19ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-3189174c-2568-40d7-a16b-48fb8d321b81\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>FT_transformer (run: 13)</td>\n","      <td>100</td>\n","      <td>1992.376854</td>\n","      <td>27133</td>\n","      <td>0.237393</td>\n","      <td>0.239739</td>\n","      <td>0.060784</td>\n","      <td>0.060886</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>FT_transformer (run: 14)</td>\n","      <td>89</td>\n","      <td>1749.585324</td>\n","      <td>27133</td>\n","      <td>0.238085</td>\n","      <td>0.240123</td>\n","      <td>0.061349</td>\n","      <td>0.061344</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>CAFTT (run: 0)</td>\n","      <td>42</td>\n","      <td>930.150725</td>\n","      <td>27133</td>\n","      <td>0.237616</td>\n","      <td>0.238094</td>\n","      <td>0.066199</td>\n","      <td>0.066450</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>CAFTT (run: 1)</td>\n","      <td>49</td>\n","      <td>1030.421487</td>\n","      <td>27133</td>\n","      <td>0.237010</td>\n","      <td>0.237976</td>\n","      <td>0.065635</td>\n","      <td>0.065934</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>CAFTT (run: 2)</td>\n","      <td>55</td>\n","      <td>1157.808053</td>\n","      <td>27133</td>\n","      <td>0.237262</td>\n","      <td>0.238194</td>\n","      <td>0.066101</td>\n","      <td>0.066402</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>138 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3189174c-2568-40d7-a16b-48fb8d321b81')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3189174c-2568-40d7-a16b-48fb8d321b81 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3189174c-2568-40d7-a16b-48fb8d321b81');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ae3c8782-c315-40eb-aae8-f944ae47f36f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae3c8782-c315-40eb-aae8-f944ae47f36f')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ae3c8782-c315-40eb-aae8-f944ae47f36f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","133    FT_transformer (run: 13)     100  1992.376854          27133   \n","134    FT_transformer (run: 14)      89  1749.585324          27133   \n","135              CAFTT (run: 0)      42   930.150725          27133   \n","136              CAFTT (run: 1)      49  1030.421487          27133   \n","137              CAFTT (run: 2)      55  1157.808053          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","133    0.237393   0.239739             0.060784            0.060886  \n","134    0.238085   0.240123             0.061349            0.061344  \n","135    0.237616   0.238094             0.066199            0.066450  \n","136    0.237010   0.237976             0.065635            0.065934  \n","137    0.237262   0.238194             0.066101            0.066402  \n","\n","[138 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 03-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 03/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 0 / Train-Loss: 0.2401 / Val-Loss: 0.2468 / Test-Loss: 0.2413 / Time taken: 0:00:44 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 1 / Train-Loss: 0.2402 / Val-Loss: 0.2469 / Test-Loss: 0.2414 / Time taken: 0:00:59 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 03/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 2 / Train-Loss: 0.2401 / Val-Loss: 0.2465 / Test-Loss: 0.2408 / Time taken: 0:01:21 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 3 / Train-Loss: 0.2396 / Val-Loss: 0.2463 / Test-Loss: 0.2404 / Time taken: 0:01:35 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 4 / Train-Loss: 0.2394 / Val-Loss: 0.2464 / Test-Loss: 0.2405 / Time taken: 0:01:56 / ---- Currently Best Val-Epoch: 3 \n","Ensemble: 03/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 5 / Train-Loss: 0.2392 / Val-Loss: 0.2460 / Test-Loss: 0.2401 / Time taken: 0:02:11 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 6 / Train-Loss: 0.2392 / Val-Loss: 0.2460 / Test-Loss: 0.2401 / Time taken: 0:02:26 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 7 / Train-Loss: 0.2390 / Val-Loss: 0.2460 / Test-Loss: 0.2400 / Time taken: 0:02:41 / ---- Currently Best Val-Epoch: 6 \n","Ensemble: 03/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0338  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 8 / Train-Loss: 0.2389 / Val-Loss: 0.2457 / Test-Loss: 0.2397 / Time taken: 0:02:56 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0338  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 9 / Train-Loss: 0.2387 / Val-Loss: 0.2457 / Test-Loss: 0.2396 / Time taken: 0:03:11 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 10 / Train-Loss: 0.2385 / Val-Loss: 0.2458 / Test-Loss: 0.2396 / Time taken: 0:03:26 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 03/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 11 / Train-Loss: 0.2385 / Val-Loss: 0.2458 / Test-Loss: 0.2396 / Time taken: 0:03:40 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 03/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 12 / Train-Loss: 0.2383 / Val-Loss: 0.2457 / Test-Loss: 0.2394 / Time taken: 0:03:56 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 13 / Batch: 1 / Train-Loss (Batch): 0.1758   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 03/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 13 / Train-Loss: 0.2382 / Val-Loss: 0.2457 / Test-Loss: 0.2395 / Time taken: 0:04:11 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 03/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 14 / Train-Loss: 0.2382 / Val-Loss: 0.2458 / Test-Loss: 0.2394 / Time taken: 0:04:25 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 03/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 15 / Train-Loss: 0.2382 / Val-Loss: 0.2456 / Test-Loss: 0.2393 / Time taken: 0:04:39 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 16 / Train-Loss: 0.2380 / Val-Loss: 0.2457 / Test-Loss: 0.2394 / Time taken: 0:05:01 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 03/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 17 / Train-Loss: 0.2379 / Val-Loss: 0.2457 / Test-Loss: 0.2393 / Time taken: 0:05:15 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 03/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 18 / Train-Loss: 0.2379 / Val-Loss: 0.2458 / Test-Loss: 0.2394 / Time taken: 0:05:29 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 03/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 19 / Train-Loss: 0.2378 / Val-Loss: 0.2457 / Test-Loss: 0.2392 / Time taken: 0:05:43 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 03/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 20 / Train-Loss: 0.2378 / Val-Loss: 0.2456 / Test-Loss: 0.2391 / Time taken: 0:06:05 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 03/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 21 / Train-Loss: 0.2378 / Val-Loss: 0.2458 / Test-Loss: 0.2393 / Time taken: 0:06:20 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 03/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 22 / Train-Loss: 0.2377 / Val-Loss: 0.2456 / Test-Loss: 0.2391 / Time taken: 0:06:41 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 03/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 23 / Train-Loss: 0.2377 / Val-Loss: 0.2455 / Test-Loss: 0.2390 / Time taken: 0:06:55 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 24 / Train-Loss: 0.2377 / Val-Loss: 0.2453 / Test-Loss: 0.2389 / Time taken: 0:07:10 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 25 / Train-Loss: 0.2376 / Val-Loss: 0.2456 / Test-Loss: 0.2391 / Time taken: 0:07:26 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 03/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 26 / Train-Loss: 0.2376 / Val-Loss: 0.2455 / Test-Loss: 0.2390 / Time taken: 0:07:40 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 03/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 27 / Train-Loss: 0.2375 / Val-Loss: 0.2452 / Test-Loss: 0.2389 / Time taken: 0:07:55 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 28 / Train-Loss: 0.2375 / Val-Loss: 0.2453 / Test-Loss: 0.2388 / Time taken: 0:08:10 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 03/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 29 / Train-Loss: 0.2375 / Val-Loss: 0.2452 / Test-Loss: 0.2387 / Time taken: 0:08:24 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 03/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 30 / Train-Loss: 0.2374 / Val-Loss: 0.2451 / Test-Loss: 0.2387 / Time taken: 0:08:39 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 31 / Train-Loss: 0.2374 / Val-Loss: 0.2452 / Test-Loss: 0.2389 / Time taken: 0:08:54 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 03/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 32 / Train-Loss: 0.2373 / Val-Loss: 0.2450 / Test-Loss: 0.2386 / Time taken: 0:09:09 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 33 / Train-Loss: 0.2372 / Val-Loss: 0.2448 / Test-Loss: 0.2386 / Time taken: 0:09:32 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 34 / Train-Loss: 0.2371 / Val-Loss: 0.2448 / Test-Loss: 0.2386 / Time taken: 0:09:46 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 35 / Train-Loss: 0.2371 / Val-Loss: 0.2448 / Test-Loss: 0.2385 / Time taken: 0:10:02 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 36 / Train-Loss: 0.2370 / Val-Loss: 0.2447 / Test-Loss: 0.2384 / Time taken: 0:10:16 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 37 / Train-Loss: 0.2369 / Val-Loss: 0.2445 / Test-Loss: 0.2383 / Time taken: 0:10:38 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 38 / Train-Loss: 0.2369 / Val-Loss: 0.2446 / Test-Loss: 0.2384 / Time taken: 0:11:00 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 03/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 39 / Train-Loss: 0.2368 / Val-Loss: 0.2443 / Test-Loss: 0.2383 / Time taken: 0:11:23 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 40 / Train-Loss: 0.2367 / Val-Loss: 0.2445 / Test-Loss: 0.2387 / Time taken: 0:11:38 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 03/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 41 / Train-Loss: 0.2367 / Val-Loss: 0.2442 / Test-Loss: 0.2382 / Time taken: 0:11:53 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 42 / Train-Loss: 0.2366 / Val-Loss: 0.2449 / Test-Loss: 0.2386 / Time taken: 0:12:09 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 03/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 43 / Train-Loss: 0.2366 / Val-Loss: 0.2440 / Test-Loss: 0.2380 / Time taken: 0:12:23 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 44 / Train-Loss: 0.2366 / Val-Loss: 0.2442 / Test-Loss: 0.2384 / Time taken: 0:12:38 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 03/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 45 / Train-Loss: 0.2366 / Val-Loss: 0.2440 / Test-Loss: 0.2381 / Time taken: 0:12:52 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 46 / Train-Loss: 0.2365 / Val-Loss: 0.2439 / Test-Loss: 0.2381 / Time taken: 0:13:06 / ---- Currently Best Val-Epoch: 46 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 47 / Train-Loss: 0.2365 / Val-Loss: 0.2439 / Test-Loss: 0.2380 / Time taken: 0:13:28 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 03/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 48 / Train-Loss: 0.2364 / Val-Loss: 0.2446 / Test-Loss: 0.2388 / Time taken: 0:13:42 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 03/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 49 / Train-Loss: 0.2364 / Val-Loss: 0.2444 / Test-Loss: 0.2385 / Time taken: 0:13:56 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 03/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 50 / Train-Loss: 0.2363 / Val-Loss: 0.2437 / Test-Loss: 0.2378 / Time taken: 0:14:12 / ---- Currently Best Val-Epoch: 50 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 51 / Train-Loss: 0.2364 / Val-Loss: 0.2439 / Test-Loss: 0.2380 / Time taken: 0:14:27 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 52 / Train-Loss: 0.2363 / Val-Loss: 0.2438 / Test-Loss: 0.2378 / Time taken: 0:14:48 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 53 / Train-Loss: 0.2363 / Val-Loss: 0.2439 / Test-Loss: 0.2380 / Time taken: 0:15:11 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 54 / Train-Loss: 0.2363 / Val-Loss: 0.2440 / Test-Loss: 0.2379 / Time taken: 0:15:27 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 55 / Train-Loss: 0.2362 / Val-Loss: 0.2439 / Test-Loss: 0.2379 / Time taken: 0:15:41 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 56 / Train-Loss: 0.2361 / Val-Loss: 0.2439 / Test-Loss: 0.2381 / Time taken: 0:15:55 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 57 / Train-Loss: 0.2361 / Val-Loss: 0.2439 / Test-Loss: 0.2381 / Time taken: 0:16:10 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 58 / Train-Loss: 0.2360 / Val-Loss: 0.2439 / Test-Loss: 0.2380 / Time taken: 0:16:25 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 59 / Train-Loss: 0.2361 / Val-Loss: 0.2441 / Test-Loss: 0.2384 / Time taken: 0:16:38 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 60 / Train-Loss: 0.2360 / Val-Loss: 0.2441 / Test-Loss: 0.2383 / Time taken: 0:16:52 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 61 / Train-Loss: 0.2360 / Val-Loss: 0.2437 / Test-Loss: 0.2379 / Time taken: 0:17:07 / ---- Currently Best Val-Epoch: 61 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 62 / Train-Loss: 0.2361 / Val-Loss: 0.2440 / Test-Loss: 0.2381 / Time taken: 0:17:22 / ---- Currently Best Val-Epoch: 61 \n","Ensemble: 03/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 63 / Train-Loss: 0.2360 / Val-Loss: 0.2439 / Test-Loss: 0.2380 / Time taken: 0:17:37 / ---- Currently Best Val-Epoch: 61 \n","Ensemble: 03/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 64 / Train-Loss: 0.2359 / Val-Loss: 0.2437 / Test-Loss: 0.2380 / Time taken: 0:17:51 / ---- Currently Best Val-Epoch: 64 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 65 / Train-Loss: 0.2358 / Val-Loss: 0.2438 / Test-Loss: 0.2381 / Time taken: 0:18:13 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 66 / Train-Loss: 0.2358 / Val-Loss: 0.2441 / Test-Loss: 0.2384 / Time taken: 0:18:28 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 67 / Train-Loss: 0.2359 / Val-Loss: 0.2437 / Test-Loss: 0.2380 / Time taken: 0:18:42 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 68 / Train-Loss: 0.2358 / Val-Loss: 0.2437 / Test-Loss: 0.2379 / Time taken: 0:19:04 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 69 / Train-Loss: 0.2357 / Val-Loss: 0.2439 / Test-Loss: 0.2380 / Time taken: 0:19:18 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 70 / Train-Loss: 0.2358 / Val-Loss: 0.2438 / Test-Loss: 0.2381 / Time taken: 0:19:32 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 71 / Train-Loss: 0.2358 / Val-Loss: 0.2438 / Test-Loss: 0.2381 / Time taken: 0:19:46 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 72 / Train-Loss: 0.2358 / Val-Loss: 0.2437 / Test-Loss: 0.2381 / Time taken: 0:20:00 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 73 / Train-Loss: 0.2357 / Val-Loss: 0.2439 / Test-Loss: 0.2381 / Time taken: 0:20:14 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 74 / Train-Loss: 0.2357 / Val-Loss: 0.2443 / Test-Loss: 0.2384 / Time taken: 0:20:28 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 75 / Train-Loss: 0.2357 / Val-Loss: 0.2438 / Test-Loss: 0.2380 / Time taken: 0:20:42 / ---- Currently Best Val-Epoch: 64 \n","Ensemble: 03/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 76 / Train-Loss: 0.2357 / Val-Loss: 0.2436 / Test-Loss: 0.2379 / Time taken: 0:20:56 / ---- Currently Best Val-Epoch: 76 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 77 / Train-Loss: 0.2356 / Val-Loss: 0.2439 / Test-Loss: 0.2382 / Time taken: 0:21:11 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 78 / Train-Loss: 0.2357 / Val-Loss: 0.2439 / Test-Loss: 0.2382 / Time taken: 0:21:25 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 79 / Train-Loss: 0.2357 / Val-Loss: 0.2439 / Test-Loss: 0.2382 / Time taken: 0:21:41 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 80 / Train-Loss: 0.2356 / Val-Loss: 0.2438 / Test-Loss: 0.2382 / Time taken: 0:21:55 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 81 / Train-Loss: 0.2356 / Val-Loss: 0.2437 / Test-Loss: 0.2380 / Time taken: 0:22:09 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 82 / Train-Loss: 0.2356 / Val-Loss: 0.2437 / Test-Loss: 0.2380 / Time taken: 0:22:23 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 83 / Train-Loss: 0.2355 / Val-Loss: 0.2437 / Test-Loss: 0.2382 / Time taken: 0:22:44 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 84 / Train-Loss: 0.2355 / Val-Loss: 0.2439 / Test-Loss: 0.2382 / Time taken: 0:22:58 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 85 / Train-Loss: 0.2355 / Val-Loss: 0.2441 / Test-Loss: 0.2383 / Time taken: 0:23:13 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 86 / Train-Loss: 0.2355 / Val-Loss: 0.2438 / Test-Loss: 0.2381 / Time taken: 0:23:29 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 87 / Train-Loss: 0.2355 / Val-Loss: 0.2441 / Test-Loss: 0.2383 / Time taken: 0:23:43 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 88 / Train-Loss: 0.2354 / Val-Loss: 0.2438 / Test-Loss: 0.2383 / Time taken: 0:23:58 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 89 / Train-Loss: 0.2354 / Val-Loss: 0.2440 / Test-Loss: 0.2385 / Time taken: 0:24:12 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 90 / Train-Loss: 0.2354 / Val-Loss: 0.2437 / Test-Loss: 0.2382 / Time taken: 0:24:28 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 91 / Train-Loss: 0.2352 / Val-Loss: 0.2441 / Test-Loss: 0.2385 / Time taken: 0:24:50 / ---- Currently Best Val-Epoch: 76 \n","Ensemble: 03/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 92 / Train-Loss: 0.2353 / Val-Loss: 0.2442 / Test-Loss: 0.2384 / Time taken: 0:25:03 / ---- Currently Best Val-Epoch: 76 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 2s 22ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-34681855-5ec8-4f69-8e94-9e0d08f220ef\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>FT_transformer (run: 14)</td>\n","      <td>89</td>\n","      <td>1749.585324</td>\n","      <td>27133</td>\n","      <td>0.238085</td>\n","      <td>0.240123</td>\n","      <td>0.061349</td>\n","      <td>0.061344</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>CAFTT (run: 0)</td>\n","      <td>42</td>\n","      <td>930.150725</td>\n","      <td>27133</td>\n","      <td>0.237616</td>\n","      <td>0.238094</td>\n","      <td>0.066199</td>\n","      <td>0.066450</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>CAFTT (run: 1)</td>\n","      <td>49</td>\n","      <td>1030.421487</td>\n","      <td>27133</td>\n","      <td>0.237010</td>\n","      <td>0.237976</td>\n","      <td>0.065635</td>\n","      <td>0.065934</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>CAFTT (run: 2)</td>\n","      <td>55</td>\n","      <td>1157.808053</td>\n","      <td>27133</td>\n","      <td>0.237262</td>\n","      <td>0.238194</td>\n","      <td>0.066101</td>\n","      <td>0.066402</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>CAFTT (run: 3)</td>\n","      <td>76</td>\n","      <td>1503.508472</td>\n","      <td>27133</td>\n","      <td>0.236652</td>\n","      <td>0.237869</td>\n","      <td>0.065459</td>\n","      <td>0.065667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>139 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34681855-5ec8-4f69-8e94-9e0d08f220ef')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-34681855-5ec8-4f69-8e94-9e0d08f220ef button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-34681855-5ec8-4f69-8e94-9e0d08f220ef');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5c50165c-9af9-4918-8475-4c3fd0e0406b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c50165c-9af9-4918-8475-4c3fd0e0406b')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5c50165c-9af9-4918-8475-4c3fd0e0406b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","134    FT_transformer (run: 14)      89  1749.585324          27133   \n","135              CAFTT (run: 0)      42   930.150725          27133   \n","136              CAFTT (run: 1)      49  1030.421487          27133   \n","137              CAFTT (run: 2)      55  1157.808053          27133   \n","138              CAFTT (run: 3)      76  1503.508472          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","134    0.238085   0.240123             0.061349            0.061344  \n","135    0.237616   0.238094             0.066199            0.066450  \n","136    0.237010   0.237976             0.065635            0.065934  \n","137    0.237262   0.238194             0.066101            0.066402  \n","138    0.236652   0.237869             0.065459            0.065667  \n","\n","[139 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 04-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 04/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 0 / Train-Loss: 0.2412 / Val-Loss: 0.2374 / Test-Loss: 0.2412 / Time taken: 0:00:30 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 1 / Train-Loss: 0.2413 / Val-Loss: 0.2373 / Test-Loss: 0.2412 / Time taken: 0:00:44 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 2 / Train-Loss: 0.2413 / Val-Loss: 0.2373 / Test-Loss: 0.2412 / Time taken: 0:00:58 / ---- Currently Best Val-Epoch: 1 \n","Ensemble: 04/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 3 / Train-Loss: 0.2411 / Val-Loss: 0.2369 / Test-Loss: 0.2407 / Time taken: 0:01:19 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 4 / Train-Loss: 0.2405 / Val-Loss: 0.2365 / Test-Loss: 0.2402 / Time taken: 0:01:33 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 5 / Train-Loss: 0.2402 / Val-Loss: 0.2365 / Test-Loss: 0.2401 / Time taken: 0:01:48 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0336  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 6 / Train-Loss: 0.2401 / Val-Loss: 0.2362 / Test-Loss: 0.2398 / Time taken: 0:02:09 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0337  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 7 / Train-Loss: 0.2400 / Val-Loss: 0.2362 / Test-Loss: 0.2397 / Time taken: 0:02:24 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0339  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 8 / Train-Loss: 0.2399 / Val-Loss: 0.2361 / Test-Loss: 0.2396 / Time taken: 0:02:38 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0339  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 9 / Train-Loss: 0.2398 / Val-Loss: 0.2360 / Test-Loss: 0.2394 / Time taken: 0:02:51 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 10 / Train-Loss: 0.2397 / Val-Loss: 0.2359 / Test-Loss: 0.2393 / Time taken: 0:03:05 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 11 / Batch: 1 / Train-Loss (Batch): 0.1672   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 04/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 11 / Train-Loss: 0.2396 / Val-Loss: 0.2358 / Test-Loss: 0.2392 / Time taken: 0:03:21 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 12 / Train-Loss: 0.2394 / Val-Loss: 0.2357 / Test-Loss: 0.2390 / Time taken: 0:03:35 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 13 / Train-Loss: 0.2393 / Val-Loss: 0.2358 / Test-Loss: 0.2392 / Time taken: 0:03:57 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 04/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 14 / Train-Loss: 0.2391 / Val-Loss: 0.2356 / Test-Loss: 0.2390 / Time taken: 0:04:18 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 15 / Train-Loss: 0.2391 / Val-Loss: 0.2357 / Test-Loss: 0.2390 / Time taken: 0:04:34 / ---- Currently Best Val-Epoch: 14 \n","Ensemble: 04/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 16 / Train-Loss: 0.2390 / Val-Loss: 0.2355 / Test-Loss: 0.2389 / Time taken: 0:04:57 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 17 / Train-Loss: 0.2390 / Val-Loss: 0.2353 / Test-Loss: 0.2388 / Time taken: 0:05:12 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 18 / Train-Loss: 0.2389 / Val-Loss: 0.2352 / Test-Loss: 0.2387 / Time taken: 0:05:26 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 19 / Train-Loss: 0.2388 / Val-Loss: 0.2354 / Test-Loss: 0.2388 / Time taken: 0:05:40 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 04/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 20 / Train-Loss: 0.2387 / Val-Loss: 0.2357 / Test-Loss: 0.2390 / Time taken: 0:05:54 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 04/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 21 / Train-Loss: 0.2385 / Val-Loss: 0.2350 / Test-Loss: 0.2385 / Time taken: 0:06:08 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 22 / Train-Loss: 0.2386 / Val-Loss: 0.2351 / Test-Loss: 0.2386 / Time taken: 0:06:30 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 04/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 23 / Train-Loss: 0.2385 / Val-Loss: 0.2352 / Test-Loss: 0.2387 / Time taken: 0:06:52 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 04/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 24 / Train-Loss: 0.2384 / Val-Loss: 0.2347 / Test-Loss: 0.2384 / Time taken: 0:07:13 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 25 / Train-Loss: 0.2383 / Val-Loss: 0.2350 / Test-Loss: 0.2387 / Time taken: 0:07:28 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 04/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 26 / Train-Loss: 0.2383 / Val-Loss: 0.2357 / Test-Loss: 0.2390 / Time taken: 0:07:49 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 04/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 27 / Train-Loss: 0.2383 / Val-Loss: 0.2356 / Test-Loss: 0.2389 / Time taken: 0:08:02 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 04/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 28 / Train-Loss: 0.2383 / Val-Loss: 0.2355 / Test-Loss: 0.2390 / Time taken: 0:08:17 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 04/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 29 / Train-Loss: 0.2382 / Val-Loss: 0.2357 / Test-Loss: 0.2390 / Time taken: 0:08:30 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 04/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 30 / Train-Loss: 0.2382 / Val-Loss: 0.2346 / Test-Loss: 0.2383 / Time taken: 0:08:43 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 31 / Train-Loss: 0.2381 / Val-Loss: 0.2354 / Test-Loss: 0.2388 / Time taken: 0:08:58 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 04/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 32 / Train-Loss: 0.2382 / Val-Loss: 0.2348 / Test-Loss: 0.2384 / Time taken: 0:09:12 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 04/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 33 / Train-Loss: 0.2381 / Val-Loss: 0.2346 / Test-Loss: 0.2383 / Time taken: 0:09:26 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 04/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 34 / Train-Loss: 0.2380 / Val-Loss: 0.2348 / Test-Loss: 0.2384 / Time taken: 0:09:40 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 04/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 35 / Train-Loss: 0.2380 / Val-Loss: 0.2346 / Test-Loss: 0.2383 / Time taken: 0:09:54 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 04/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 36 / Train-Loss: 0.2380 / Val-Loss: 0.2351 / Test-Loss: 0.2391 / Time taken: 0:10:09 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 04/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 37 / Train-Loss: 0.2380 / Val-Loss: 0.2347 / Test-Loss: 0.2384 / Time taken: 0:10:22 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 04/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 38 / Train-Loss: 0.2380 / Val-Loss: 0.2348 / Test-Loss: 0.2385 / Time taken: 0:10:36 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 04/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 39 / Train-Loss: 0.2378 / Val-Loss: 0.2345 / Test-Loss: 0.2383 / Time taken: 0:10:50 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 40 / Train-Loss: 0.2378 / Val-Loss: 0.2346 / Test-Loss: 0.2383 / Time taken: 0:11:05 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 04/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 41 / Train-Loss: 0.2377 / Val-Loss: 0.2355 / Test-Loss: 0.2391 / Time taken: 0:11:19 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 04/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 42 / Train-Loss: 0.2377 / Val-Loss: 0.2349 / Test-Loss: 0.2386 / Time taken: 0:11:33 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 04/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 43 / Train-Loss: 0.2378 / Val-Loss: 0.2343 / Test-Loss: 0.2382 / Time taken: 0:11:47 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 44 / Train-Loss: 0.2376 / Val-Loss: 0.2344 / Test-Loss: 0.2382 / Time taken: 0:12:02 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 45 / Train-Loss: 0.2377 / Val-Loss: 0.2349 / Test-Loss: 0.2385 / Time taken: 0:12:16 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 46 / Train-Loss: 0.2376 / Val-Loss: 0.2344 / Test-Loss: 0.2382 / Time taken: 0:12:30 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 47 / Train-Loss: 0.2376 / Val-Loss: 0.2346 / Test-Loss: 0.2382 / Time taken: 0:12:43 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 48 / Train-Loss: 0.2375 / Val-Loss: 0.2347 / Test-Loss: 0.2383 / Time taken: 0:12:59 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 49 / Train-Loss: 0.2375 / Val-Loss: 0.2351 / Test-Loss: 0.2385 / Time taken: 0:13:12 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 50 / Train-Loss: 0.2374 / Val-Loss: 0.2349 / Test-Loss: 0.2385 / Time taken: 0:13:26 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 51 / Train-Loss: 0.2376 / Val-Loss: 0.2344 / Test-Loss: 0.2380 / Time taken: 0:13:40 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 52 / Train-Loss: 0.2375 / Val-Loss: 0.2345 / Test-Loss: 0.2382 / Time taken: 0:13:55 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 53 / Train-Loss: 0.2374 / Val-Loss: 0.2341 / Test-Loss: 0.2382 / Time taken: 0:14:09 / ---- Currently Best Val-Epoch: 53 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 54 / Train-Loss: 0.2373 / Val-Loss: 0.2342 / Test-Loss: 0.2382 / Time taken: 0:14:23 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 04/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 55 / Train-Loss: 0.2373 / Val-Loss: 0.2342 / Test-Loss: 0.2382 / Time taken: 0:14:45 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 04/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 56 / Train-Loss: 0.2373 / Val-Loss: 0.2343 / Test-Loss: 0.2381 / Time taken: 0:14:59 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 04/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 57 / Train-Loss: 0.2372 / Val-Loss: 0.2342 / Test-Loss: 0.2382 / Time taken: 0:15:13 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 04/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 58 / Train-Loss: 0.2373 / Val-Loss: 0.2342 / Test-Loss: 0.2380 / Time taken: 0:15:28 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 04/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 59 / Train-Loss: 0.2372 / Val-Loss: 0.2342 / Test-Loss: 0.2381 / Time taken: 0:15:43 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 04/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 60 / Train-Loss: 0.2372 / Val-Loss: 0.2341 / Test-Loss: 0.2381 / Time taken: 0:15:57 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 04/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 61 / Train-Loss: 0.2371 / Val-Loss: 0.2341 / Test-Loss: 0.2383 / Time taken: 0:16:12 / ---- Currently Best Val-Epoch: 61 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 62 / Train-Loss: 0.2372 / Val-Loss: 0.2341 / Test-Loss: 0.2384 / Time taken: 0:16:27 / ---- Currently Best Val-Epoch: 61 \n","Ensemble: 04/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 63 / Train-Loss: 0.2371 / Val-Loss: 0.2343 / Test-Loss: 0.2385 / Time taken: 0:16:43 / ---- Currently Best Val-Epoch: 61 \n","Ensemble: 04/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 64 / Train-Loss: 0.2371 / Val-Loss: 0.2342 / Test-Loss: 0.2381 / Time taken: 0:16:58 / ---- Currently Best Val-Epoch: 61 \n","Ensemble: 04/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 65 / Train-Loss: 0.2372 / Val-Loss: 0.2341 / Test-Loss: 0.2381 / Time taken: 0:17:12 / ---- Currently Best Val-Epoch: 65 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 66 / Train-Loss: 0.2372 / Val-Loss: 0.2341 / Test-Loss: 0.2381 / Time taken: 0:17:34 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 04/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 67 / Train-Loss: 0.2371 / Val-Loss: 0.2342 / Test-Loss: 0.2381 / Time taken: 0:17:48 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 04/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 68 / Train-Loss: 0.2369 / Val-Loss: 0.2340 / Test-Loss: 0.2381 / Time taken: 0:18:09 / ---- Currently Best Val-Epoch: 68 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 69 / Train-Loss: 0.2370 / Val-Loss: 0.2342 / Test-Loss: 0.2382 / Time taken: 0:18:25 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 70 / Train-Loss: 0.2370 / Val-Loss: 0.2342 / Test-Loss: 0.2383 / Time taken: 0:18:39 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 71 / Train-Loss: 0.2370 / Val-Loss: 0.2341 / Test-Loss: 0.2381 / Time taken: 0:18:52 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 72 / Train-Loss: 0.2369 / Val-Loss: 0.2341 / Test-Loss: 0.2381 / Time taken: 0:19:07 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 73 / Train-Loss: 0.2369 / Val-Loss: 0.2341 / Test-Loss: 0.2382 / Time taken: 0:19:22 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 74 / Train-Loss: 0.2369 / Val-Loss: 0.2341 / Test-Loss: 0.2381 / Time taken: 0:19:37 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 75 / Train-Loss: 0.2368 / Val-Loss: 0.2341 / Test-Loss: 0.2381 / Time taken: 0:19:51 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 76 / Train-Loss: 0.2368 / Val-Loss: 0.2343 / Test-Loss: 0.2380 / Time taken: 0:20:06 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 77 / Train-Loss: 0.2368 / Val-Loss: 0.2342 / Test-Loss: 0.2382 / Time taken: 0:20:28 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 78 / Train-Loss: 0.2367 / Val-Loss: 0.2341 / Test-Loss: 0.2381 / Time taken: 0:20:42 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 79 / Train-Loss: 0.2368 / Val-Loss: 0.2342 / Test-Loss: 0.2383 / Time taken: 0:20:57 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 80 / Train-Loss: 0.2368 / Val-Loss: 0.2343 / Test-Loss: 0.2385 / Time taken: 0:21:18 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 81 / Train-Loss: 0.2368 / Val-Loss: 0.2342 / Test-Loss: 0.2382 / Time taken: 0:21:32 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 82 / Train-Loss: 0.2366 / Val-Loss: 0.2341 / Test-Loss: 0.2383 / Time taken: 0:21:47 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 83 / Train-Loss: 0.2367 / Val-Loss: 0.2342 / Test-Loss: 0.2383 / Time taken: 0:22:08 / ---- Currently Best Val-Epoch: 68 \n","Ensemble: 04/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 84 / Train-Loss: 0.2367 / Val-Loss: 0.2341 / Test-Loss: 0.2382 / Time taken: 0:22:22 / ---- Currently Best Val-Epoch: 68 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 21ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-5f764cbf-6f9d-46d9-bd26-5ac727f49dfd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>CAFTT (run: 0)</td>\n","      <td>42</td>\n","      <td>930.150725</td>\n","      <td>27133</td>\n","      <td>0.237616</td>\n","      <td>0.238094</td>\n","      <td>0.066199</td>\n","      <td>0.066450</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>CAFTT (run: 1)</td>\n","      <td>49</td>\n","      <td>1030.421487</td>\n","      <td>27133</td>\n","      <td>0.237010</td>\n","      <td>0.237976</td>\n","      <td>0.065635</td>\n","      <td>0.065934</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>CAFTT (run: 2)</td>\n","      <td>55</td>\n","      <td>1157.808053</td>\n","      <td>27133</td>\n","      <td>0.237262</td>\n","      <td>0.238194</td>\n","      <td>0.066101</td>\n","      <td>0.066402</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>CAFTT (run: 3)</td>\n","      <td>76</td>\n","      <td>1503.508472</td>\n","      <td>27133</td>\n","      <td>0.236652</td>\n","      <td>0.237869</td>\n","      <td>0.065459</td>\n","      <td>0.065667</td>\n","    </tr>\n","    <tr>\n","      <th>139</th>\n","      <td>CAFTT (run: 4)</td>\n","      <td>68</td>\n","      <td>1342.143729</td>\n","      <td>27133</td>\n","      <td>0.236980</td>\n","      <td>0.238098</td>\n","      <td>0.066915</td>\n","      <td>0.067137</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>140 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f764cbf-6f9d-46d9-bd26-5ac727f49dfd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5f764cbf-6f9d-46d9-bd26-5ac727f49dfd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5f764cbf-6f9d-46d9-bd26-5ac727f49dfd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-62ead022-cd77-481c-85bd-a03a89e1d465\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62ead022-cd77-481c-85bd-a03a89e1d465')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-62ead022-cd77-481c-85bd-a03a89e1d465 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","135              CAFTT (run: 0)      42   930.150725          27133   \n","136              CAFTT (run: 1)      49  1030.421487          27133   \n","137              CAFTT (run: 2)      55  1157.808053          27133   \n","138              CAFTT (run: 3)      76  1503.508472          27133   \n","139              CAFTT (run: 4)      68  1342.143729          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","135    0.237616   0.238094             0.066199            0.066450  \n","136    0.237010   0.237976             0.065635            0.065934  \n","137    0.237262   0.238194             0.066101            0.066402  \n","138    0.236652   0.237869             0.065459            0.065667  \n","139    0.236980   0.238098             0.066915            0.067137  \n","\n","[140 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 05-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 05/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 0 / Train-Loss: 0.2410 / Val-Loss: 0.2387 / Test-Loss: 0.2413 / Time taken: 0:00:29 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 1 / Train-Loss: 0.2411 / Val-Loss: 0.2387 / Test-Loss: 0.2413 / Time taken: 0:00:42 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 05/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 2 / Train-Loss: 0.2411 / Val-Loss: 0.2386 / Test-Loss: 0.2412 / Time taken: 0:00:55 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 3 / Train-Loss: 0.2408 / Val-Loss: 0.2382 / Test-Loss: 0.2407 / Time taken: 0:01:17 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 4 / Train-Loss: 0.2402 / Val-Loss: 0.2376 / Test-Loss: 0.2401 / Time taken: 0:01:38 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0337  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 5 / Train-Loss: 0.2399 / Val-Loss: 0.2376 / Test-Loss: 0.2399 / Time taken: 0:01:52 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 6 / Train-Loss: 0.2397 / Val-Loss: 0.2373 / Test-Loss: 0.2396 / Time taken: 0:02:06 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0337  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 7 / Train-Loss: 0.2395 / Val-Loss: 0.2374 / Test-Loss: 0.2395 / Time taken: 0:02:21 / ---- Currently Best Val-Epoch: 6 \n","Ensemble: 05/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 8 / Train-Loss: 0.2392 / Val-Loss: 0.2372 / Test-Loss: 0.2393 / Time taken: 0:02:35 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 9 / Train-Loss: 0.2392 / Val-Loss: 0.2372 / Test-Loss: 0.2393 / Time taken: 0:02:49 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 05/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 10 / Train-Loss: 0.2390 / Val-Loss: 0.2370 / Test-Loss: 0.2391 / Time taken: 0:03:10 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 11 / Batch: 2 / Train-Loss (Batch): 0.1475   : [------------------------------] 0.4%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 05/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 11 / Train-Loss: 0.2389 / Val-Loss: 0.2370 / Test-Loss: 0.2392 / Time taken: 0:03:25 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 05/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 12 / Train-Loss: 0.2388 / Val-Loss: 0.2369 / Test-Loss: 0.2390 / Time taken: 0:03:47 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 13 / Train-Loss: 0.2387 / Val-Loss: 0.2369 / Test-Loss: 0.2389 / Time taken: 0:04:01 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 14 / Train-Loss: 0.2387 / Val-Loss: 0.2370 / Test-Loss: 0.2389 / Time taken: 0:04:14 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 05/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 15 / Train-Loss: 0.2387 / Val-Loss: 0.2369 / Test-Loss: 0.2388 / Time taken: 0:04:37 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 16 / Train-Loss: 0.2386 / Val-Loss: 0.2370 / Test-Loss: 0.2388 / Time taken: 0:04:52 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 05/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 17 / Train-Loss: 0.2386 / Val-Loss: 0.2369 / Test-Loss: 0.2388 / Time taken: 0:05:05 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 05/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 18 / Train-Loss: 0.2385 / Val-Loss: 0.2370 / Test-Loss: 0.2388 / Time taken: 0:05:19 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 05/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 19 / Train-Loss: 0.2385 / Val-Loss: 0.2369 / Test-Loss: 0.2386 / Time taken: 0:05:34 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 05/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 20 / Train-Loss: 0.2384 / Val-Loss: 0.2369 / Test-Loss: 0.2386 / Time taken: 0:05:48 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 05/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 21 / Train-Loss: 0.2383 / Val-Loss: 0.2368 / Test-Loss: 0.2384 / Time taken: 0:06:02 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 22 / Train-Loss: 0.2383 / Val-Loss: 0.2367 / Test-Loss: 0.2386 / Time taken: 0:06:17 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 23 / Train-Loss: 0.2382 / Val-Loss: 0.2366 / Test-Loss: 0.2383 / Time taken: 0:06:33 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 24 / Train-Loss: 0.2381 / Val-Loss: 0.2367 / Test-Loss: 0.2385 / Time taken: 0:06:47 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 05/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 25 / Train-Loss: 0.2379 / Val-Loss: 0.2383 / Test-Loss: 0.2401 / Time taken: 0:07:10 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 05/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 26 / Train-Loss: 0.2379 / Val-Loss: 0.2368 / Test-Loss: 0.2387 / Time taken: 0:07:24 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 05/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 27 / Train-Loss: 0.2379 / Val-Loss: 0.2365 / Test-Loss: 0.2383 / Time taken: 0:07:38 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 28 / Train-Loss: 0.2378 / Val-Loss: 0.2366 / Test-Loss: 0.2385 / Time taken: 0:07:53 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 05/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 29 / Train-Loss: 0.2377 / Val-Loss: 0.2366 / Test-Loss: 0.2386 / Time taken: 0:08:08 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 05/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 30 / Train-Loss: 0.2378 / Val-Loss: 0.2365 / Test-Loss: 0.2384 / Time taken: 0:08:29 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 31 / Train-Loss: 0.2376 / Val-Loss: 0.2368 / Test-Loss: 0.2388 / Time taken: 0:08:43 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 05/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 32 / Train-Loss: 0.2376 / Val-Loss: 0.2366 / Test-Loss: 0.2385 / Time taken: 0:08:59 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 05/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 33 / Train-Loss: 0.2376 / Val-Loss: 0.2368 / Test-Loss: 0.2387 / Time taken: 0:09:13 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 05/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 34 / Train-Loss: 0.2375 / Val-Loss: 0.2369 / Test-Loss: 0.2388 / Time taken: 0:09:27 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 05/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 35 / Train-Loss: 0.2376 / Val-Loss: 0.2367 / Test-Loss: 0.2387 / Time taken: 0:09:42 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 05/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 36 / Train-Loss: 0.2374 / Val-Loss: 0.2368 / Test-Loss: 0.2387 / Time taken: 0:09:55 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 05/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 37 / Train-Loss: 0.2375 / Val-Loss: 0.2365 / Test-Loss: 0.2385 / Time taken: 0:10:08 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 05/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 38 / Train-Loss: 0.2374 / Val-Loss: 0.2367 / Test-Loss: 0.2387 / Time taken: 0:10:22 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 05/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 39 / Train-Loss: 0.2374 / Val-Loss: 0.2365 / Test-Loss: 0.2382 / Time taken: 0:10:44 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 40 / Train-Loss: 0.2374 / Val-Loss: 0.2363 / Test-Loss: 0.2383 / Time taken: 0:10:58 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 41 / Train-Loss: 0.2373 / Val-Loss: 0.2363 / Test-Loss: 0.2381 / Time taken: 0:11:13 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 42 / Train-Loss: 0.2372 / Val-Loss: 0.2369 / Test-Loss: 0.2389 / Time taken: 0:11:29 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 43 / Train-Loss: 0.2372 / Val-Loss: 0.2365 / Test-Loss: 0.2385 / Time taken: 0:11:52 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 44 / Train-Loss: 0.2372 / Val-Loss: 0.2365 / Test-Loss: 0.2385 / Time taken: 0:12:06 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 45 / Train-Loss: 0.2372 / Val-Loss: 0.2368 / Test-Loss: 0.2385 / Time taken: 0:12:22 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 46 / Train-Loss: 0.2372 / Val-Loss: 0.2366 / Test-Loss: 0.2384 / Time taken: 0:12:36 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 47 / Train-Loss: 0.2371 / Val-Loss: 0.2371 / Test-Loss: 0.2389 / Time taken: 0:12:50 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 48 / Train-Loss: 0.2371 / Val-Loss: 0.2365 / Test-Loss: 0.2384 / Time taken: 0:13:05 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 49 / Train-Loss: 0.2371 / Val-Loss: 0.2364 / Test-Loss: 0.2383 / Time taken: 0:13:18 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 50 / Train-Loss: 0.2370 / Val-Loss: 0.2367 / Test-Loss: 0.2387 / Time taken: 0:13:32 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 51 / Train-Loss: 0.2371 / Val-Loss: 0.2365 / Test-Loss: 0.2382 / Time taken: 0:13:47 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 52 / Train-Loss: 0.2370 / Val-Loss: 0.2364 / Test-Loss: 0.2381 / Time taken: 0:14:08 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 53 / Train-Loss: 0.2370 / Val-Loss: 0.2365 / Test-Loss: 0.2383 / Time taken: 0:14:22 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 54 / Train-Loss: 0.2369 / Val-Loss: 0.2368 / Test-Loss: 0.2383 / Time taken: 0:14:38 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 55 / Train-Loss: 0.2369 / Val-Loss: 0.2365 / Test-Loss: 0.2382 / Time taken: 0:14:51 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 56 / Train-Loss: 0.2369 / Val-Loss: 0.2365 / Test-Loss: 0.2382 / Time taken: 0:15:04 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 05/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 57 / Train-Loss: 0.2370 / Val-Loss: 0.2362 / Test-Loss: 0.2380 / Time taken: 0:15:18 / ---- Currently Best Val-Epoch: 57 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 58 / Train-Loss: 0.2369 / Val-Loss: 0.2364 / Test-Loss: 0.2382 / Time taken: 0:15:33 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 59 / Train-Loss: 0.2369 / Val-Loss: 0.2365 / Test-Loss: 0.2383 / Time taken: 0:15:47 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 60 / Train-Loss: 0.2367 / Val-Loss: 0.2363 / Test-Loss: 0.2382 / Time taken: 0:16:02 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 61 / Train-Loss: 0.2368 / Val-Loss: 0.2365 / Test-Loss: 0.2382 / Time taken: 0:16:17 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 62 / Train-Loss: 0.2367 / Val-Loss: 0.2364 / Test-Loss: 0.2381 / Time taken: 0:16:38 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 63 / Train-Loss: 0.2368 / Val-Loss: 0.2366 / Test-Loss: 0.2385 / Time taken: 0:16:54 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 64 / Train-Loss: 0.2367 / Val-Loss: 0.2364 / Test-Loss: 0.2383 / Time taken: 0:17:08 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 65 / Train-Loss: 0.2367 / Val-Loss: 0.2363 / Test-Loss: 0.2383 / Time taken: 0:17:23 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 66 / Train-Loss: 0.2367 / Val-Loss: 0.2363 / Test-Loss: 0.2382 / Time taken: 0:17:44 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 67 / Train-Loss: 0.2367 / Val-Loss: 0.2364 / Test-Loss: 0.2383 / Time taken: 0:17:58 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 68 / Train-Loss: 0.2365 / Val-Loss: 0.2365 / Test-Loss: 0.2383 / Time taken: 0:18:11 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 69 / Train-Loss: 0.2365 / Val-Loss: 0.2364 / Test-Loss: 0.2383 / Time taken: 0:18:33 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 70 / Train-Loss: 0.2367 / Val-Loss: 0.2365 / Test-Loss: 0.2381 / Time taken: 0:18:48 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 71 / Train-Loss: 0.2365 / Val-Loss: 0.2367 / Test-Loss: 0.2384 / Time taken: 0:19:02 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 72 / Train-Loss: 0.2366 / Val-Loss: 0.2363 / Test-Loss: 0.2384 / Time taken: 0:19:17 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 05/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 73 / Train-Loss: 0.2366 / Val-Loss: 0.2364 / Test-Loss: 0.2383 / Time taken: 0:19:30 / ---- Currently Best Val-Epoch: 57 \n","596/596 [==============================] - 11s 17ms/step\n","67/67 [==============================] - 1s 22ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-3b6e975f-7678-4eb6-9a15-15300bfee575\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>CAFTT (run: 1)</td>\n","      <td>49</td>\n","      <td>1030.421487</td>\n","      <td>27133</td>\n","      <td>0.237010</td>\n","      <td>0.237976</td>\n","      <td>0.065635</td>\n","      <td>0.065934</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>CAFTT (run: 2)</td>\n","      <td>55</td>\n","      <td>1157.808053</td>\n","      <td>27133</td>\n","      <td>0.237262</td>\n","      <td>0.238194</td>\n","      <td>0.066101</td>\n","      <td>0.066402</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>CAFTT (run: 3)</td>\n","      <td>76</td>\n","      <td>1503.508472</td>\n","      <td>27133</td>\n","      <td>0.236652</td>\n","      <td>0.237869</td>\n","      <td>0.065459</td>\n","      <td>0.065667</td>\n","    </tr>\n","    <tr>\n","      <th>139</th>\n","      <td>CAFTT (run: 4)</td>\n","      <td>68</td>\n","      <td>1342.143729</td>\n","      <td>27133</td>\n","      <td>0.236980</td>\n","      <td>0.238098</td>\n","      <td>0.066915</td>\n","      <td>0.067137</td>\n","    </tr>\n","    <tr>\n","      <th>140</th>\n","      <td>CAFTT (run: 5)</td>\n","      <td>57</td>\n","      <td>1170.775908</td>\n","      <td>27133</td>\n","      <td>0.237184</td>\n","      <td>0.238024</td>\n","      <td>0.066190</td>\n","      <td>0.066403</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>141 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b6e975f-7678-4eb6-9a15-15300bfee575')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3b6e975f-7678-4eb6-9a15-15300bfee575 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3b6e975f-7678-4eb6-9a15-15300bfee575');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9410df5d-7a25-4cd6-84ed-b77be6ce17ed\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9410df5d-7a25-4cd6-84ed-b77be6ce17ed')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9410df5d-7a25-4cd6-84ed-b77be6ce17ed button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","136              CAFTT (run: 1)      49  1030.421487          27133   \n","137              CAFTT (run: 2)      55  1157.808053          27133   \n","138              CAFTT (run: 3)      76  1503.508472          27133   \n","139              CAFTT (run: 4)      68  1342.143729          27133   \n","140              CAFTT (run: 5)      57  1170.775908          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","136    0.237010   0.237976             0.065635            0.065934  \n","137    0.237262   0.238194             0.066101            0.066402  \n","138    0.236652   0.237869             0.065459            0.065667  \n","139    0.236980   0.238098             0.066915            0.067137  \n","140    0.237184   0.238024             0.066190            0.066403  \n","\n","[141 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 06-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 06/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 0 / Train-Loss: 0.2408 / Val-Loss: 0.2409 / Test-Loss: 0.2413 / Time taken: 0:00:30 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 1 / Train-Loss: 0.2409 / Val-Loss: 0.2408 / Test-Loss: 0.2413 / Time taken: 0:00:44 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 2 / Train-Loss: 0.2409 / Val-Loss: 0.2408 / Test-Loss: 0.2413 / Time taken: 0:00:59 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 3 / Train-Loss: 0.2409 / Val-Loss: 0.2409 / Test-Loss: 0.2413 / Time taken: 0:01:13 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 06/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 4 / Train-Loss: 0.2407 / Val-Loss: 0.2404 / Test-Loss: 0.2408 / Time taken: 0:01:35 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 5 / Train-Loss: 0.2401 / Val-Loss: 0.2402 / Test-Loss: 0.2406 / Time taken: 0:01:49 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 6 / Train-Loss: 0.2399 / Val-Loss: 0.2399 / Test-Loss: 0.2403 / Time taken: 0:02:02 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 7 / Train-Loss: 0.2397 / Val-Loss: 0.2397 / Test-Loss: 0.2400 / Time taken: 0:02:17 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0337  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 8 / Train-Loss: 0.2395 / Val-Loss: 0.2397 / Test-Loss: 0.2401 / Time taken: 0:02:31 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 9 / Train-Loss: 0.2394 / Val-Loss: 0.2395 / Test-Loss: 0.2398 / Time taken: 0:02:45 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 10 / Train-Loss: 0.2393 / Val-Loss: 0.2391 / Test-Loss: 0.2395 / Time taken: 0:03:00 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 06/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 11 / Train-Loss: 0.2392 / Val-Loss: 0.2392 / Test-Loss: 0.2396 / Time taken: 0:03:22 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 06/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 12 / Train-Loss: 0.2390 / Val-Loss: 0.2389 / Test-Loss: 0.2393 / Time taken: 0:03:36 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 13 / Train-Loss: 0.2390 / Val-Loss: 0.2390 / Test-Loss: 0.2395 / Time taken: 0:03:59 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 06/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 14 / Train-Loss: 0.2389 / Val-Loss: 0.2389 / Test-Loss: 0.2393 / Time taken: 0:04:14 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 15 / Train-Loss: 0.2388 / Val-Loss: 0.2389 / Test-Loss: 0.2393 / Time taken: 0:04:30 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 16 / Train-Loss: 0.2387 / Val-Loss: 0.2387 / Test-Loss: 0.2392 / Time taken: 0:04:44 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 17 / Train-Loss: 0.2387 / Val-Loss: 0.2387 / Test-Loss: 0.2391 / Time taken: 0:04:58 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 18 / Train-Loss: 0.2387 / Val-Loss: 0.2386 / Test-Loss: 0.2391 / Time taken: 0:05:14 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 19 / Train-Loss: 0.2386 / Val-Loss: 0.2387 / Test-Loss: 0.2391 / Time taken: 0:05:28 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 06/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 20 / Train-Loss: 0.2386 / Val-Loss: 0.2386 / Test-Loss: 0.2392 / Time taken: 0:05:42 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 06/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 21 / Train-Loss: 0.2386 / Val-Loss: 0.2387 / Test-Loss: 0.2392 / Time taken: 0:05:57 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 06/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 22 / Train-Loss: 0.2385 / Val-Loss: 0.2386 / Test-Loss: 0.2390 / Time taken: 0:06:10 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 23 / Train-Loss: 0.2385 / Val-Loss: 0.2386 / Test-Loss: 0.2392 / Time taken: 0:06:25 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 06/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 24 / Train-Loss: 0.2384 / Val-Loss: 0.2387 / Test-Loss: 0.2391 / Time taken: 0:06:40 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 06/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 25 / Train-Loss: 0.2384 / Val-Loss: 0.2385 / Test-Loss: 0.2390 / Time taken: 0:06:54 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 26 / Train-Loss: 0.2383 / Val-Loss: 0.2384 / Test-Loss: 0.2390 / Time taken: 0:07:08 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 27 / Train-Loss: 0.2383 / Val-Loss: 0.2385 / Test-Loss: 0.2390 / Time taken: 0:07:30 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 06/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 28 / Train-Loss: 0.2383 / Val-Loss: 0.2384 / Test-Loss: 0.2390 / Time taken: 0:07:44 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 06/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 29 / Train-Loss: 0.2382 / Val-Loss: 0.2385 / Test-Loss: 0.2390 / Time taken: 0:08:00 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 06/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 30 / Train-Loss: 0.2382 / Val-Loss: 0.2384 / Test-Loss: 0.2389 / Time taken: 0:08:14 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 31 / Train-Loss: 0.2381 / Val-Loss: 0.2383 / Test-Loss: 0.2388 / Time taken: 0:08:30 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 32 / Train-Loss: 0.2381 / Val-Loss: 0.2382 / Test-Loss: 0.2387 / Time taken: 0:08:46 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 33 / Train-Loss: 0.2380 / Val-Loss: 0.2382 / Test-Loss: 0.2388 / Time taken: 0:09:01 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 06/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 34 / Train-Loss: 0.2380 / Val-Loss: 0.2384 / Test-Loss: 0.2389 / Time taken: 0:09:15 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 06/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 35 / Train-Loss: 0.2379 / Val-Loss: 0.2382 / Test-Loss: 0.2387 / Time taken: 0:09:31 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 06/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 36 / Train-Loss: 0.2378 / Val-Loss: 0.2381 / Test-Loss: 0.2385 / Time taken: 0:09:53 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 37 / Train-Loss: 0.2377 / Val-Loss: 0.2381 / Test-Loss: 0.2384 / Time taken: 0:10:09 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 06/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 38 / Train-Loss: 0.2378 / Val-Loss: 0.2380 / Test-Loss: 0.2384 / Time taken: 0:10:22 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 39 / Train-Loss: 0.2377 / Val-Loss: 0.2381 / Test-Loss: 0.2386 / Time taken: 0:10:37 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 06/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 40 / Train-Loss: 0.2377 / Val-Loss: 0.2387 / Test-Loss: 0.2389 / Time taken: 0:10:52 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 06/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 41 / Train-Loss: 0.2375 / Val-Loss: 0.2381 / Test-Loss: 0.2384 / Time taken: 0:11:06 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 06/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 42 / Train-Loss: 0.2374 / Val-Loss: 0.2378 / Test-Loss: 0.2384 / Time taken: 0:11:20 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 43 / Train-Loss: 0.2374 / Val-Loss: 0.2381 / Test-Loss: 0.2383 / Time taken: 0:11:35 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 44 / Train-Loss: 0.2374 / Val-Loss: 0.2381 / Test-Loss: 0.2383 / Time taken: 0:11:49 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 45 / Train-Loss: 0.2374 / Val-Loss: 0.2377 / Test-Loss: 0.2383 / Time taken: 0:12:04 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 46 / Train-Loss: 0.2374 / Val-Loss: 0.2379 / Test-Loss: 0.2383 / Time taken: 0:12:19 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 06/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 47 / Train-Loss: 0.2373 / Val-Loss: 0.2379 / Test-Loss: 0.2382 / Time taken: 0:12:34 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 06/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 48 / Train-Loss: 0.2373 / Val-Loss: 0.2380 / Test-Loss: 0.2382 / Time taken: 0:12:49 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 06/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 49 / Train-Loss: 0.2373 / Val-Loss: 0.2382 / Test-Loss: 0.2384 / Time taken: 0:13:03 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 06/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 50 / Train-Loss: 0.2372 / Val-Loss: 0.2379 / Test-Loss: 0.2382 / Time taken: 0:13:17 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 06/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 51 / Train-Loss: 0.2372 / Val-Loss: 0.2376 / Test-Loss: 0.2382 / Time taken: 0:13:33 / ---- Currently Best Val-Epoch: 51 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 52 / Train-Loss: 0.2370 / Val-Loss: 0.2384 / Test-Loss: 0.2385 / Time taken: 0:13:47 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 06/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 53 / Train-Loss: 0.2370 / Val-Loss: 0.2380 / Test-Loss: 0.2383 / Time taken: 0:14:01 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 06/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 54 / Train-Loss: 0.2371 / Val-Loss: 0.2378 / Test-Loss: 0.2382 / Time taken: 0:14:17 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 06/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 55 / Train-Loss: 0.2370 / Val-Loss: 0.2376 / Test-Loss: 0.2382 / Time taken: 0:14:32 / ---- Currently Best Val-Epoch: 55 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 56 / Train-Loss: 0.2370 / Val-Loss: 0.2379 / Test-Loss: 0.2381 / Time taken: 0:14:48 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 06/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 57 / Train-Loss: 0.2370 / Val-Loss: 0.2376 / Test-Loss: 0.2381 / Time taken: 0:15:02 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 06/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 58 / Train-Loss: 0.2371 / Val-Loss: 0.2376 / Test-Loss: 0.2382 / Time taken: 0:15:23 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 06/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 59 / Train-Loss: 0.2369 / Val-Loss: 0.2377 / Test-Loss: 0.2379 / Time taken: 0:15:39 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 06/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 60 / Train-Loss: 0.2369 / Val-Loss: 0.2377 / Test-Loss: 0.2383 / Time taken: 0:15:54 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 06/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 61 / Train-Loss: 0.2370 / Val-Loss: 0.2379 / Test-Loss: 0.2380 / Time taken: 0:16:11 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 06/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 62 / Train-Loss: 0.2369 / Val-Loss: 0.2375 / Test-Loss: 0.2380 / Time taken: 0:16:32 / ---- Currently Best Val-Epoch: 62 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 63 / Train-Loss: 0.2369 / Val-Loss: 0.2374 / Test-Loss: 0.2380 / Time taken: 0:16:49 / ---- Currently Best Val-Epoch: 63 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 64 / Train-Loss: 0.2368 / Val-Loss: 0.2375 / Test-Loss: 0.2379 / Time taken: 0:17:11 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 65 / Train-Loss: 0.2368 / Val-Loss: 0.2378 / Test-Loss: 0.2381 / Time taken: 0:17:27 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 66 / Train-Loss: 0.2367 / Val-Loss: 0.2375 / Test-Loss: 0.2383 / Time taken: 0:17:41 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 67 / Train-Loss: 0.2367 / Val-Loss: 0.2378 / Test-Loss: 0.2383 / Time taken: 0:17:57 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 68 / Train-Loss: 0.2367 / Val-Loss: 0.2376 / Test-Loss: 0.2382 / Time taken: 0:18:12 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 69 / Train-Loss: 0.2366 / Val-Loss: 0.2376 / Test-Loss: 0.2383 / Time taken: 0:18:27 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 70 / Train-Loss: 0.2368 / Val-Loss: 0.2377 / Test-Loss: 0.2384 / Time taken: 0:18:42 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 71 / Train-Loss: 0.2367 / Val-Loss: 0.2375 / Test-Loss: 0.2382 / Time taken: 0:18:58 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 72 / Train-Loss: 0.2367 / Val-Loss: 0.2375 / Test-Loss: 0.2380 / Time taken: 0:19:12 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 73 / Train-Loss: 0.2365 / Val-Loss: 0.2375 / Test-Loss: 0.2381 / Time taken: 0:19:34 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 74 / Train-Loss: 0.2365 / Val-Loss: 0.2379 / Test-Loss: 0.2383 / Time taken: 0:19:48 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 75 / Train-Loss: 0.2365 / Val-Loss: 0.2377 / Test-Loss: 0.2381 / Time taken: 0:20:11 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 76 / Train-Loss: 0.2364 / Val-Loss: 0.2376 / Test-Loss: 0.2382 / Time taken: 0:20:27 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 77 / Train-Loss: 0.2364 / Val-Loss: 0.2375 / Test-Loss: 0.2379 / Time taken: 0:20:48 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 78 / Train-Loss: 0.2365 / Val-Loss: 0.2377 / Test-Loss: 0.2381 / Time taken: 0:21:03 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 06/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 79 / Train-Loss: 0.2364 / Val-Loss: 0.2376 / Test-Loss: 0.2381 / Time taken: 0:21:25 / ---- Currently Best Val-Epoch: 63 \n","596/596 [==============================] - 12s 19ms/step\n","67/67 [==============================] - 1s 22ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-b1fc5ffc-73a6-4ed1-b46b-e3f3d414280d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>CAFTT (run: 2)</td>\n","      <td>55</td>\n","      <td>1157.808053</td>\n","      <td>27133</td>\n","      <td>0.237262</td>\n","      <td>0.238194</td>\n","      <td>0.066101</td>\n","      <td>0.066402</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>CAFTT (run: 3)</td>\n","      <td>76</td>\n","      <td>1503.508472</td>\n","      <td>27133</td>\n","      <td>0.236652</td>\n","      <td>0.237869</td>\n","      <td>0.065459</td>\n","      <td>0.065667</td>\n","    </tr>\n","    <tr>\n","      <th>139</th>\n","      <td>CAFTT (run: 4)</td>\n","      <td>68</td>\n","      <td>1342.143729</td>\n","      <td>27133</td>\n","      <td>0.236980</td>\n","      <td>0.238098</td>\n","      <td>0.066915</td>\n","      <td>0.067137</td>\n","    </tr>\n","    <tr>\n","      <th>140</th>\n","      <td>CAFTT (run: 5)</td>\n","      <td>57</td>\n","      <td>1170.775908</td>\n","      <td>27133</td>\n","      <td>0.237184</td>\n","      <td>0.238024</td>\n","      <td>0.066190</td>\n","      <td>0.066403</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>CAFTT (run: 6)</td>\n","      <td>63</td>\n","      <td>1285.190307</td>\n","      <td>27133</td>\n","      <td>0.237250</td>\n","      <td>0.237963</td>\n","      <td>0.065993</td>\n","      <td>0.066259</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>142 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1fc5ffc-73a6-4ed1-b46b-e3f3d414280d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b1fc5ffc-73a6-4ed1-b46b-e3f3d414280d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b1fc5ffc-73a6-4ed1-b46b-e3f3d414280d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6af1d9e7-570c-4e46-acfa-dc937a5aaffb\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6af1d9e7-570c-4e46-acfa-dc937a5aaffb')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6af1d9e7-570c-4e46-acfa-dc937a5aaffb button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","137              CAFTT (run: 2)      55  1157.808053          27133   \n","138              CAFTT (run: 3)      76  1503.508472          27133   \n","139              CAFTT (run: 4)      68  1342.143729          27133   \n","140              CAFTT (run: 5)      57  1170.775908          27133   \n","141              CAFTT (run: 6)      63  1285.190307          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","137    0.237262   0.238194             0.066101            0.066402  \n","138    0.236652   0.237869             0.065459            0.065667  \n","139    0.236980   0.238098             0.066915            0.067137  \n","140    0.237184   0.238024             0.066190            0.066403  \n","141    0.237250   0.237963             0.065993            0.066259  \n","\n","[142 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 07-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 07/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 0 / Train-Loss: 0.2404 / Val-Loss: 0.2449 / Test-Loss: 0.2413 / Time taken: 0:00:33 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 1 / Train-Loss: 0.2404 / Val-Loss: 0.2448 / Test-Loss: 0.2412 / Time taken: 0:00:49 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 2 / Train-Loss: 0.2404 / Val-Loss: 0.2447 / Test-Loss: 0.2411 / Time taken: 0:01:03 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 3 / Train-Loss: 0.2401 / Val-Loss: 0.2449 / Test-Loss: 0.2411 / Time taken: 0:01:19 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 07/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 4 / Train-Loss: 0.2397 / Val-Loss: 0.2446 / Test-Loss: 0.2405 / Time taken: 0:01:40 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 5 / Train-Loss: 0.2395 / Val-Loss: 0.2444 / Test-Loss: 0.2402 / Time taken: 0:02:02 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 6 / Train-Loss: 0.2393 / Val-Loss: 0.2444 / Test-Loss: 0.2401 / Time taken: 0:02:15 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 7 / Train-Loss: 0.2392 / Val-Loss: 0.2442 / Test-Loss: 0.2400 / Time taken: 0:02:29 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 8 / Train-Loss: 0.2390 / Val-Loss: 0.2442 / Test-Loss: 0.2401 / Time taken: 0:02:43 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 9 / Train-Loss: 0.2390 / Val-Loss: 0.2440 / Test-Loss: 0.2399 / Time taken: 0:02:57 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 10 / Train-Loss: 0.2388 / Val-Loss: 0.2438 / Test-Loss: 0.2396 / Time taken: 0:03:11 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 11 / Batch: 1 / Train-Loss (Batch): 0.1553   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 07/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 11 / Train-Loss: 0.2386 / Val-Loss: 0.2439 / Test-Loss: 0.2397 / Time taken: 0:03:25 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 07/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 12 / Train-Loss: 0.2386 / Val-Loss: 0.2437 / Test-Loss: 0.2396 / Time taken: 0:03:39 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 13 / Train-Loss: 0.2384 / Val-Loss: 0.2438 / Test-Loss: 0.2396 / Time taken: 0:03:53 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 07/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 14 / Train-Loss: 0.2384 / Val-Loss: 0.2436 / Test-Loss: 0.2394 / Time taken: 0:04:07 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 15 / Train-Loss: 0.2383 / Val-Loss: 0.2435 / Test-Loss: 0.2394 / Time taken: 0:04:22 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 16 / Train-Loss: 0.2382 / Val-Loss: 0.2435 / Test-Loss: 0.2394 / Time taken: 0:04:36 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 17 / Train-Loss: 0.2381 / Val-Loss: 0.2433 / Test-Loss: 0.2393 / Time taken: 0:04:50 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 18 / Train-Loss: 0.2381 / Val-Loss: 0.2434 / Test-Loss: 0.2393 / Time taken: 0:05:05 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 07/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 19 / Train-Loss: 0.2380 / Val-Loss: 0.2433 / Test-Loss: 0.2392 / Time taken: 0:05:18 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 07/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 20 / Train-Loss: 0.2380 / Val-Loss: 0.2433 / Test-Loss: 0.2392 / Time taken: 0:05:33 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 07/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 21 / Train-Loss: 0.2379 / Val-Loss: 0.2432 / Test-Loss: 0.2391 / Time taken: 0:05:46 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 22 / Train-Loss: 0.2379 / Val-Loss: 0.2432 / Test-Loss: 0.2392 / Time taken: 0:06:01 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 07/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 23 / Train-Loss: 0.2379 / Val-Loss: 0.2431 / Test-Loss: 0.2390 / Time taken: 0:06:14 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 24 / Train-Loss: 0.2378 / Val-Loss: 0.2431 / Test-Loss: 0.2390 / Time taken: 0:06:29 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 07/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 25 / Train-Loss: 0.2377 / Val-Loss: 0.2433 / Test-Loss: 0.2391 / Time taken: 0:06:43 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 07/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 26 / Train-Loss: 0.2377 / Val-Loss: 0.2431 / Test-Loss: 0.2390 / Time taken: 0:06:57 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 07/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 27 / Train-Loss: 0.2376 / Val-Loss: 0.2433 / Test-Loss: 0.2391 / Time taken: 0:07:11 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 07/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 28 / Train-Loss: 0.2376 / Val-Loss: 0.2430 / Test-Loss: 0.2389 / Time taken: 0:07:25 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 29 / Train-Loss: 0.2376 / Val-Loss: 0.2432 / Test-Loss: 0.2390 / Time taken: 0:07:39 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 07/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 30 / Train-Loss: 0.2375 / Val-Loss: 0.2432 / Test-Loss: 0.2389 / Time taken: 0:07:53 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 07/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 31 / Train-Loss: 0.2375 / Val-Loss: 0.2432 / Test-Loss: 0.2389 / Time taken: 0:08:07 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 07/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 32 / Train-Loss: 0.2375 / Val-Loss: 0.2428 / Test-Loss: 0.2388 / Time taken: 0:08:22 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 33 / Train-Loss: 0.2375 / Val-Loss: 0.2429 / Test-Loss: 0.2389 / Time taken: 0:08:36 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 07/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 34 / Train-Loss: 0.2374 / Val-Loss: 0.2428 / Test-Loss: 0.2387 / Time taken: 0:08:50 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 07/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 35 / Train-Loss: 0.2374 / Val-Loss: 0.2426 / Test-Loss: 0.2386 / Time taken: 0:09:04 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 36 / Train-Loss: 0.2373 / Val-Loss: 0.2428 / Test-Loss: 0.2386 / Time taken: 0:09:19 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 07/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 37 / Train-Loss: 0.2372 / Val-Loss: 0.2426 / Test-Loss: 0.2386 / Time taken: 0:09:33 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 07/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 38 / Train-Loss: 0.2371 / Val-Loss: 0.2423 / Test-Loss: 0.2384 / Time taken: 0:09:47 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 39 / Train-Loss: 0.2371 / Val-Loss: 0.2422 / Test-Loss: 0.2382 / Time taken: 0:10:01 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 40 / Train-Loss: 0.2370 / Val-Loss: 0.2422 / Test-Loss: 0.2383 / Time taken: 0:10:16 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 41 / Train-Loss: 0.2369 / Val-Loss: 0.2420 / Test-Loss: 0.2382 / Time taken: 0:10:30 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 42 / Train-Loss: 0.2368 / Val-Loss: 0.2422 / Test-Loss: 0.2382 / Time taken: 0:10:45 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 07/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 43 / Train-Loss: 0.2368 / Val-Loss: 0.2422 / Test-Loss: 0.2381 / Time taken: 0:10:59 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 07/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 44 / Train-Loss: 0.2367 / Val-Loss: 0.2421 / Test-Loss: 0.2381 / Time taken: 0:11:13 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 07/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 45 / Train-Loss: 0.2367 / Val-Loss: 0.2417 / Test-Loss: 0.2379 / Time taken: 0:11:27 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 46 / Train-Loss: 0.2366 / Val-Loss: 0.2419 / Test-Loss: 0.2379 / Time taken: 0:11:42 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 47 / Train-Loss: 0.2366 / Val-Loss: 0.2420 / Test-Loss: 0.2379 / Time taken: 0:11:56 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 48 / Train-Loss: 0.2366 / Val-Loss: 0.2422 / Test-Loss: 0.2382 / Time taken: 0:12:10 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 49 / Train-Loss: 0.2365 / Val-Loss: 0.2418 / Test-Loss: 0.2379 / Time taken: 0:12:24 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 50 / Train-Loss: 0.2364 / Val-Loss: 0.2420 / Test-Loss: 0.2380 / Time taken: 0:12:38 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 51 / Train-Loss: 0.2364 / Val-Loss: 0.2424 / Test-Loss: 0.2384 / Time taken: 0:12:53 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 52 / Train-Loss: 0.2364 / Val-Loss: 0.2418 / Test-Loss: 0.2381 / Time taken: 0:13:07 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 53 / Train-Loss: 0.2364 / Val-Loss: 0.2418 / Test-Loss: 0.2379 / Time taken: 0:13:21 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 54 / Train-Loss: 0.2364 / Val-Loss: 0.2420 / Test-Loss: 0.2380 / Time taken: 0:13:35 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 55 / Train-Loss: 0.2363 / Val-Loss: 0.2417 / Test-Loss: 0.2379 / Time taken: 0:13:50 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 56 / Train-Loss: 0.2364 / Val-Loss: 0.2417 / Test-Loss: 0.2379 / Time taken: 0:14:04 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 57 / Train-Loss: 0.2363 / Val-Loss: 0.2421 / Test-Loss: 0.2382 / Time taken: 0:14:18 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 58 / Train-Loss: 0.2363 / Val-Loss: 0.2420 / Test-Loss: 0.2382 / Time taken: 0:14:32 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 07/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 59 / Train-Loss: 0.2363 / Val-Loss: 0.2417 / Test-Loss: 0.2378 / Time taken: 0:14:46 / ---- Currently Best Val-Epoch: 59 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 60 / Train-Loss: 0.2362 / Val-Loss: 0.2419 / Test-Loss: 0.2381 / Time taken: 0:15:01 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 07/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0314 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 61 / Train-Loss: 0.2362 / Val-Loss: 0.2417 / Test-Loss: 0.2380 / Time taken: 0:15:15 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 07/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 62 / Train-Loss: 0.2362 / Val-Loss: 0.2417 / Test-Loss: 0.2381 / Time taken: 0:15:29 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 07/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 63 / Train-Loss: 0.2362 / Val-Loss: 0.2418 / Test-Loss: 0.2380 / Time taken: 0:15:44 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 07/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 64 / Train-Loss: 0.2361 / Val-Loss: 0.2417 / Test-Loss: 0.2380 / Time taken: 0:15:58 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 07/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 65 / Train-Loss: 0.2360 / Val-Loss: 0.2418 / Test-Loss: 0.2380 / Time taken: 0:16:12 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 07/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 66 / Train-Loss: 0.2360 / Val-Loss: 0.2419 / Test-Loss: 0.2381 / Time taken: 0:16:26 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 07/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 67 / Train-Loss: 0.2360 / Val-Loss: 0.2416 / Test-Loss: 0.2380 / Time taken: 0:16:41 / ---- Currently Best Val-Epoch: 67 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 68 / Train-Loss: 0.2360 / Val-Loss: 0.2417 / Test-Loss: 0.2381 / Time taken: 0:16:55 / ---- Currently Best Val-Epoch: 67 \n","Ensemble: 07/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 69 / Train-Loss: 0.2360 / Val-Loss: 0.2416 / Test-Loss: 0.2381 / Time taken: 0:17:10 / ---- Currently Best Val-Epoch: 69 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0316 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 70 / Train-Loss: 0.2360 / Val-Loss: 0.2416 / Test-Loss: 0.2379 / Time taken: 0:17:25 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 71 / Train-Loss: 0.2359 / Val-Loss: 0.2417 / Test-Loss: 0.2380 / Time taken: 0:17:39 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 72 / Train-Loss: 0.2359 / Val-Loss: 0.2417 / Test-Loss: 0.2380 / Time taken: 0:17:54 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0313 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 73 / Train-Loss: 0.2359 / Val-Loss: 0.2417 / Test-Loss: 0.2380 / Time taken: 0:18:08 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 74 / Train-Loss: 0.2357 / Val-Loss: 0.2418 / Test-Loss: 0.2382 / Time taken: 0:18:22 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 75 / Train-Loss: 0.2358 / Val-Loss: 0.2416 / Test-Loss: 0.2381 / Time taken: 0:18:37 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 76 / Train-Loss: 0.2358 / Val-Loss: 0.2418 / Test-Loss: 0.2382 / Time taken: 0:18:51 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0314 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 77 / Train-Loss: 0.2358 / Val-Loss: 0.2419 / Test-Loss: 0.2383 / Time taken: 0:19:05 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0311 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 78 / Train-Loss: 0.2358 / Val-Loss: 0.2417 / Test-Loss: 0.2381 / Time taken: 0:19:19 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 79 / Train-Loss: 0.2358 / Val-Loss: 0.2418 / Test-Loss: 0.2381 / Time taken: 0:19:33 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 80 / Train-Loss: 0.2358 / Val-Loss: 0.2417 / Test-Loss: 0.2381 / Time taken: 0:19:47 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0313 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 81 / Train-Loss: 0.2357 / Val-Loss: 0.2416 / Test-Loss: 0.2380 / Time taken: 0:20:02 / ---- Currently Best Val-Epoch: 69 \n","Ensemble: 07/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0314 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 82 / Train-Loss: 0.2357 / Val-Loss: 0.2415 / Test-Loss: 0.2381 / Time taken: 0:20:16 / ---- Currently Best Val-Epoch: 82 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 83 / Train-Loss: 0.2357 / Val-Loss: 0.2416 / Test-Loss: 0.2380 / Time taken: 0:20:31 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0313 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 84 / Train-Loss: 0.2355 / Val-Loss: 0.2417 / Test-Loss: 0.2382 / Time taken: 0:20:45 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.031  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 85 / Train-Loss: 0.2356 / Val-Loss: 0.2419 / Test-Loss: 0.2384 / Time taken: 0:20:59 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 86 / Train-Loss: 0.2356 / Val-Loss: 0.2417 / Test-Loss: 0.2382 / Time taken: 0:21:13 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 87 / Train-Loss: 0.2356 / Val-Loss: 0.2417 / Test-Loss: 0.2384 / Time taken: 0:21:28 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 88 / Train-Loss: 0.2355 / Val-Loss: 0.2418 / Test-Loss: 0.2383 / Time taken: 0:21:42 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 89 / Train-Loss: 0.2356 / Val-Loss: 0.2416 / Test-Loss: 0.2383 / Time taken: 0:21:56 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 90 / Train-Loss: 0.2356 / Val-Loss: 0.2419 / Test-Loss: 0.2384 / Time taken: 0:22:10 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 91 / Train-Loss: 0.2355 / Val-Loss: 0.2416 / Test-Loss: 0.2381 / Time taken: 0:22:25 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 92 / Train-Loss: 0.2354 / Val-Loss: 0.2417 / Test-Loss: 0.2382 / Time taken: 0:22:39 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0311 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 93 / Train-Loss: 0.2355 / Val-Loss: 0.2421 / Test-Loss: 0.2385 / Time taken: 0:22:54 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 94 / Train-Loss: 0.2355 / Val-Loss: 0.2419 / Test-Loss: 0.2383 / Time taken: 0:23:08 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.0304 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 95 / Train-Loss: 0.2354 / Val-Loss: 0.2420 / Test-Loss: 0.2383 / Time taken: 0:23:22 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0316 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 96 / Train-Loss: 0.2355 / Val-Loss: 0.2419 / Test-Loss: 0.2384 / Time taken: 0:23:37 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 97 / Train-Loss: 0.2355 / Val-Loss: 0.2417 / Test-Loss: 0.2382 / Time taken: 0:23:51 / ---- Currently Best Val-Epoch: 82 \n","Ensemble: 07/14 / Epoch: 98 / Batch: 536 / Train-Loss (Batch): 0.0313 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 98 / Train-Loss: 0.2353 / Val-Loss: 0.2420 / Test-Loss: 0.2383 / Time taken: 0:24:05 / ---- Currently Best Val-Epoch: 82 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 2s 22ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-2d354939-302f-4e65-86e8-9d0f82728adf\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>CAFTT (run: 3)</td>\n","      <td>76</td>\n","      <td>1503.508472</td>\n","      <td>27133</td>\n","      <td>0.236652</td>\n","      <td>0.237869</td>\n","      <td>0.065459</td>\n","      <td>0.065667</td>\n","    </tr>\n","    <tr>\n","      <th>139</th>\n","      <td>CAFTT (run: 4)</td>\n","      <td>68</td>\n","      <td>1342.143729</td>\n","      <td>27133</td>\n","      <td>0.236980</td>\n","      <td>0.238098</td>\n","      <td>0.066915</td>\n","      <td>0.067137</td>\n","    </tr>\n","    <tr>\n","      <th>140</th>\n","      <td>CAFTT (run: 5)</td>\n","      <td>57</td>\n","      <td>1170.775908</td>\n","      <td>27133</td>\n","      <td>0.237184</td>\n","      <td>0.238024</td>\n","      <td>0.066190</td>\n","      <td>0.066403</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>CAFTT (run: 6)</td>\n","      <td>63</td>\n","      <td>1285.190307</td>\n","      <td>27133</td>\n","      <td>0.237250</td>\n","      <td>0.237963</td>\n","      <td>0.065993</td>\n","      <td>0.066259</td>\n","    </tr>\n","    <tr>\n","      <th>142</th>\n","      <td>CAFTT (run: 7)</td>\n","      <td>82</td>\n","      <td>1445.914973</td>\n","      <td>27133</td>\n","      <td>0.236267</td>\n","      <td>0.238129</td>\n","      <td>0.066620</td>\n","      <td>0.066841</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>143 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d354939-302f-4e65-86e8-9d0f82728adf')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2d354939-302f-4e65-86e8-9d0f82728adf button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2d354939-302f-4e65-86e8-9d0f82728adf');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-810ef2b9-d8fa-4742-b460-69e929657dc8\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-810ef2b9-d8fa-4742-b460-69e929657dc8')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-810ef2b9-d8fa-4742-b460-69e929657dc8 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","138              CAFTT (run: 3)      76  1503.508472          27133   \n","139              CAFTT (run: 4)      68  1342.143729          27133   \n","140              CAFTT (run: 5)      57  1170.775908          27133   \n","141              CAFTT (run: 6)      63  1285.190307          27133   \n","142              CAFTT (run: 7)      82  1445.914973          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","138    0.236652   0.237869             0.065459            0.065667  \n","139    0.236980   0.238098             0.066915            0.067137  \n","140    0.237184   0.238024             0.066190            0.066403  \n","141    0.237250   0.237963             0.065993            0.066259  \n","142    0.236267   0.238129             0.066620            0.066841  \n","\n","[143 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 08-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 08/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 0 / Train-Loss: 0.2399 / Val-Loss: 0.2494 / Test-Loss: 0.2413 / Time taken: 0:00:44 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 1 / Train-Loss: 0.2399 / Val-Loss: 0.2494 / Test-Loss: 0.2413 / Time taken: 0:01:06 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 2 / Train-Loss: 0.2399 / Val-Loss: 0.2491 / Test-Loss: 0.2409 / Time taken: 0:01:20 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 3 / Train-Loss: 0.2394 / Val-Loss: 0.2486 / Test-Loss: 0.2402 / Time taken: 0:01:34 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0336  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 4 / Train-Loss: 0.2391 / Val-Loss: 0.2486 / Test-Loss: 0.2401 / Time taken: 0:01:49 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0337  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 5 / Train-Loss: 0.2389 / Val-Loss: 0.2486 / Test-Loss: 0.2401 / Time taken: 0:02:02 / ---- Currently Best Val-Epoch: 4 \n","Ensemble: 08/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0339  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 6 / Train-Loss: 0.2388 / Val-Loss: 0.2484 / Test-Loss: 0.2400 / Time taken: 0:02:16 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.034   : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 7 / Train-Loss: 0.2387 / Val-Loss: 0.2482 / Test-Loss: 0.2398 / Time taken: 0:02:31 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0339  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 8 / Train-Loss: 0.2386 / Val-Loss: 0.2483 / Test-Loss: 0.2397 / Time taken: 0:02:45 / ---- Currently Best Val-Epoch: 7 \n","Ensemble: 08/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.034   : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 9 / Train-Loss: 0.2384 / Val-Loss: 0.2482 / Test-Loss: 0.2396 / Time taken: 0:02:59 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 10 / Train-Loss: 0.2382 / Val-Loss: 0.2479 / Test-Loss: 0.2395 / Time taken: 0:03:13 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 11 / Batch: 1 / Train-Loss (Batch): 0.1782   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 08/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 11 / Train-Loss: 0.2381 / Val-Loss: 0.2479 / Test-Loss: 0.2395 / Time taken: 0:03:28 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 12 / Train-Loss: 0.2380 / Val-Loss: 0.2476 / Test-Loss: 0.2393 / Time taken: 0:03:42 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 13 / Train-Loss: 0.2379 / Val-Loss: 0.2476 / Test-Loss: 0.2393 / Time taken: 0:03:56 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 14 / Train-Loss: 0.2378 / Val-Loss: 0.2475 / Test-Loss: 0.2392 / Time taken: 0:04:11 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 15 / Train-Loss: 0.2377 / Val-Loss: 0.2476 / Test-Loss: 0.2392 / Time taken: 0:04:25 / ---- Currently Best Val-Epoch: 14 \n","Ensemble: 08/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 16 / Train-Loss: 0.2376 / Val-Loss: 0.2475 / Test-Loss: 0.2392 / Time taken: 0:04:39 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 17 / Train-Loss: 0.2375 / Val-Loss: 0.2477 / Test-Loss: 0.2392 / Time taken: 0:05:01 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 08/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 18 / Train-Loss: 0.2375 / Val-Loss: 0.2476 / Test-Loss: 0.2392 / Time taken: 0:05:23 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 08/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 19 / Train-Loss: 0.2374 / Val-Loss: 0.2475 / Test-Loss: 0.2391 / Time taken: 0:05:36 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 20 / Train-Loss: 0.2374 / Val-Loss: 0.2475 / Test-Loss: 0.2390 / Time taken: 0:05:51 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 08/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 21 / Train-Loss: 0.2374 / Val-Loss: 0.2475 / Test-Loss: 0.2390 / Time taken: 0:06:05 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 22 / Train-Loss: 0.2373 / Val-Loss: 0.2476 / Test-Loss: 0.2392 / Time taken: 0:06:19 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 08/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 23 / Train-Loss: 0.2374 / Val-Loss: 0.2475 / Test-Loss: 0.2390 / Time taken: 0:06:33 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 24 / Train-Loss: 0.2372 / Val-Loss: 0.2474 / Test-Loss: 0.2390 / Time taken: 0:06:48 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 25 / Train-Loss: 0.2371 / Val-Loss: 0.2477 / Test-Loss: 0.2390 / Time taken: 0:07:03 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 08/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 26 / Train-Loss: 0.2371 / Val-Loss: 0.2475 / Test-Loss: 0.2390 / Time taken: 0:07:18 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 08/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 27 / Train-Loss: 0.2372 / Val-Loss: 0.2473 / Test-Loss: 0.2386 / Time taken: 0:07:32 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 28 / Train-Loss: 0.2370 / Val-Loss: 0.2475 / Test-Loss: 0.2387 / Time taken: 0:07:46 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 08/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 29 / Train-Loss: 0.2371 / Val-Loss: 0.2472 / Test-Loss: 0.2385 / Time taken: 0:08:00 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 30 / Train-Loss: 0.2370 / Val-Loss: 0.2473 / Test-Loss: 0.2385 / Time taken: 0:08:15 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 08/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 31 / Train-Loss: 0.2368 / Val-Loss: 0.2471 / Test-Loss: 0.2384 / Time taken: 0:08:29 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 32 / Train-Loss: 0.2368 / Val-Loss: 0.2473 / Test-Loss: 0.2385 / Time taken: 0:08:43 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 33 / Train-Loss: 0.2366 / Val-Loss: 0.2473 / Test-Loss: 0.2383 / Time taken: 0:08:58 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 34 / Train-Loss: 0.2365 / Val-Loss: 0.2469 / Test-Loss: 0.2382 / Time taken: 0:09:13 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 35 / Train-Loss: 0.2365 / Val-Loss: 0.2471 / Test-Loss: 0.2383 / Time taken: 0:09:35 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 08/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 36 / Train-Loss: 0.2364 / Val-Loss: 0.2472 / Test-Loss: 0.2384 / Time taken: 0:09:56 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 08/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 37 / Train-Loss: 0.2363 / Val-Loss: 0.2475 / Test-Loss: 0.2383 / Time taken: 0:10:10 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 08/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 38 / Train-Loss: 0.2363 / Val-Loss: 0.2470 / Test-Loss: 0.2383 / Time taken: 0:10:24 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 08/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 39 / Train-Loss: 0.2364 / Val-Loss: 0.2473 / Test-Loss: 0.2383 / Time taken: 0:10:38 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 08/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 40 / Train-Loss: 0.2362 / Val-Loss: 0.2475 / Test-Loss: 0.2383 / Time taken: 0:10:53 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 08/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 41 / Train-Loss: 0.2362 / Val-Loss: 0.2469 / Test-Loss: 0.2381 / Time taken: 0:11:07 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 42 / Train-Loss: 0.2361 / Val-Loss: 0.2472 / Test-Loss: 0.2383 / Time taken: 0:11:22 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 08/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 43 / Train-Loss: 0.2361 / Val-Loss: 0.2469 / Test-Loss: 0.2381 / Time taken: 0:11:36 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 08/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 44 / Train-Loss: 0.2361 / Val-Loss: 0.2473 / Test-Loss: 0.2385 / Time taken: 0:11:50 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 08/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 45 / Train-Loss: 0.2361 / Val-Loss: 0.2468 / Test-Loss: 0.2380 / Time taken: 0:12:04 / ---- Currently Best Val-Epoch: 45 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 46 / Train-Loss: 0.2361 / Val-Loss: 0.2471 / Test-Loss: 0.2381 / Time taken: 0:12:19 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 08/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 47 / Train-Loss: 0.2360 / Val-Loss: 0.2470 / Test-Loss: 0.2380 / Time taken: 0:12:33 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 08/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 48 / Train-Loss: 0.2359 / Val-Loss: 0.2469 / Test-Loss: 0.2382 / Time taken: 0:12:47 / ---- Currently Best Val-Epoch: 45 \n","Ensemble: 08/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 49 / Train-Loss: 0.2360 / Val-Loss: 0.2467 / Test-Loss: 0.2380 / Time taken: 0:13:09 / ---- Currently Best Val-Epoch: 49 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 50 / Train-Loss: 0.2360 / Val-Loss: 0.2473 / Test-Loss: 0.2382 / Time taken: 0:13:31 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 08/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 51 / Train-Loss: 0.2359 / Val-Loss: 0.2469 / Test-Loss: 0.2381 / Time taken: 0:13:44 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 08/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 52 / Train-Loss: 0.2358 / Val-Loss: 0.2471 / Test-Loss: 0.2382 / Time taken: 0:13:59 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 08/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 53 / Train-Loss: 0.2359 / Val-Loss: 0.2467 / Test-Loss: 0.2380 / Time taken: 0:14:12 / ---- Currently Best Val-Epoch: 53 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 54 / Train-Loss: 0.2358 / Val-Loss: 0.2471 / Test-Loss: 0.2381 / Time taken: 0:14:27 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 55 / Train-Loss: 0.2358 / Val-Loss: 0.2469 / Test-Loss: 0.2380 / Time taken: 0:14:41 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 56 / Train-Loss: 0.2358 / Val-Loss: 0.2471 / Test-Loss: 0.2379 / Time taken: 0:14:56 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 57 / Train-Loss: 0.2358 / Val-Loss: 0.2470 / Test-Loss: 0.2381 / Time taken: 0:15:10 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 58 / Train-Loss: 0.2357 / Val-Loss: 0.2470 / Test-Loss: 0.2381 / Time taken: 0:15:24 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 59 / Train-Loss: 0.2357 / Val-Loss: 0.2469 / Test-Loss: 0.2379 / Time taken: 0:15:38 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 60 / Train-Loss: 0.2357 / Val-Loss: 0.2468 / Test-Loss: 0.2379 / Time taken: 0:15:52 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 61 / Train-Loss: 0.2356 / Val-Loss: 0.2471 / Test-Loss: 0.2382 / Time taken: 0:16:07 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 08/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 62 / Train-Loss: 0.2357 / Val-Loss: 0.2466 / Test-Loss: 0.2379 / Time taken: 0:16:21 / ---- Currently Best Val-Epoch: 62 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 63 / Train-Loss: 0.2355 / Val-Loss: 0.2470 / Test-Loss: 0.2380 / Time taken: 0:16:36 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 64 / Train-Loss: 0.2356 / Val-Loss: 0.2467 / Test-Loss: 0.2377 / Time taken: 0:16:50 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 65 / Train-Loss: 0.2356 / Val-Loss: 0.2470 / Test-Loss: 0.2379 / Time taken: 0:17:04 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 66 / Train-Loss: 0.2354 / Val-Loss: 0.2469 / Test-Loss: 0.2381 / Time taken: 0:17:18 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 67 / Train-Loss: 0.2355 / Val-Loss: 0.2469 / Test-Loss: 0.2379 / Time taken: 0:17:32 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 68 / Train-Loss: 0.2354 / Val-Loss: 0.2470 / Test-Loss: 0.2381 / Time taken: 0:17:47 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 69 / Train-Loss: 0.2355 / Val-Loss: 0.2469 / Test-Loss: 0.2378 / Time taken: 0:18:01 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 70 / Train-Loss: 0.2354 / Val-Loss: 0.2468 / Test-Loss: 0.2379 / Time taken: 0:18:15 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 71 / Train-Loss: 0.2355 / Val-Loss: 0.2466 / Test-Loss: 0.2378 / Time taken: 0:18:30 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 72 / Train-Loss: 0.2354 / Val-Loss: 0.2468 / Test-Loss: 0.2379 / Time taken: 0:18:44 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 73 / Train-Loss: 0.2353 / Val-Loss: 0.2467 / Test-Loss: 0.2380 / Time taken: 0:18:59 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 08/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 74 / Train-Loss: 0.2354 / Val-Loss: 0.2463 / Test-Loss: 0.2377 / Time taken: 0:19:13 / ---- Currently Best Val-Epoch: 74 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 75 / Train-Loss: 0.2353 / Val-Loss: 0.2466 / Test-Loss: 0.2381 / Time taken: 0:19:28 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 76 / Train-Loss: 0.2354 / Val-Loss: 0.2464 / Test-Loss: 0.2378 / Time taken: 0:19:42 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 77 / Train-Loss: 0.2351 / Val-Loss: 0.2469 / Test-Loss: 0.2380 / Time taken: 0:19:57 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 78 / Train-Loss: 0.2353 / Val-Loss: 0.2468 / Test-Loss: 0.2380 / Time taken: 0:20:11 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 79 / Train-Loss: 0.2353 / Val-Loss: 0.2465 / Test-Loss: 0.2378 / Time taken: 0:20:25 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 80 / Train-Loss: 0.2352 / Val-Loss: 0.2468 / Test-Loss: 0.2380 / Time taken: 0:20:40 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 81 / Train-Loss: 0.2352 / Val-Loss: 0.2467 / Test-Loss: 0.2382 / Time taken: 0:20:55 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0349 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 82 / Train-Loss: 0.2352 / Val-Loss: 0.2466 / Test-Loss: 0.2379 / Time taken: 0:21:09 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 83 / Train-Loss: 0.2351 / Val-Loss: 0.2467 / Test-Loss: 0.2380 / Time taken: 0:21:24 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 84 / Train-Loss: 0.2351 / Val-Loss: 0.2468 / Test-Loss: 0.2380 / Time taken: 0:21:38 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 85 / Train-Loss: 0.2350 / Val-Loss: 0.2469 / Test-Loss: 0.2382 / Time taken: 0:21:52 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 86 / Train-Loss: 0.2350 / Val-Loss: 0.2466 / Test-Loss: 0.2379 / Time taken: 0:22:13 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 87 / Train-Loss: 0.2349 / Val-Loss: 0.2467 / Test-Loss: 0.2381 / Time taken: 0:22:35 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 88 / Train-Loss: 0.2350 / Val-Loss: 0.2465 / Test-Loss: 0.2381 / Time taken: 0:22:49 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 89 / Train-Loss: 0.2350 / Val-Loss: 0.2468 / Test-Loss: 0.2381 / Time taken: 0:23:03 / ---- Currently Best Val-Epoch: 74 \n","Ensemble: 08/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 90 / Train-Loss: 0.2349 / Val-Loss: 0.2466 / Test-Loss: 0.2380 / Time taken: 0:23:17 / ---- Currently Best Val-Epoch: 74 \n","596/596 [==============================] - 11s 17ms/step\n","67/67 [==============================] - 2s 25ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-a67304a9-51e9-4b1d-9d60-eb0501bd55d0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>139</th>\n","      <td>CAFTT (run: 4)</td>\n","      <td>68</td>\n","      <td>1342.143729</td>\n","      <td>27133</td>\n","      <td>0.236980</td>\n","      <td>0.238098</td>\n","      <td>0.066915</td>\n","      <td>0.067137</td>\n","    </tr>\n","    <tr>\n","      <th>140</th>\n","      <td>CAFTT (run: 5)</td>\n","      <td>57</td>\n","      <td>1170.775908</td>\n","      <td>27133</td>\n","      <td>0.237184</td>\n","      <td>0.238024</td>\n","      <td>0.066190</td>\n","      <td>0.066403</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>CAFTT (run: 6)</td>\n","      <td>63</td>\n","      <td>1285.190307</td>\n","      <td>27133</td>\n","      <td>0.237250</td>\n","      <td>0.237963</td>\n","      <td>0.065993</td>\n","      <td>0.066259</td>\n","    </tr>\n","    <tr>\n","      <th>142</th>\n","      <td>CAFTT (run: 7)</td>\n","      <td>82</td>\n","      <td>1445.914973</td>\n","      <td>27133</td>\n","      <td>0.236267</td>\n","      <td>0.238129</td>\n","      <td>0.066620</td>\n","      <td>0.066841</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>CAFTT (run: 8)</td>\n","      <td>74</td>\n","      <td>1397.400270</td>\n","      <td>27133</td>\n","      <td>0.236362</td>\n","      <td>0.237732</td>\n","      <td>0.066140</td>\n","      <td>0.066352</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>144 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a67304a9-51e9-4b1d-9d60-eb0501bd55d0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a67304a9-51e9-4b1d-9d60-eb0501bd55d0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a67304a9-51e9-4b1d-9d60-eb0501bd55d0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b8703d90-e949-4be3-b226-70bfd35baa3e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8703d90-e949-4be3-b226-70bfd35baa3e')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b8703d90-e949-4be3-b226-70bfd35baa3e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","139              CAFTT (run: 4)      68  1342.143729          27133   \n","140              CAFTT (run: 5)      57  1170.775908          27133   \n","141              CAFTT (run: 6)      63  1285.190307          27133   \n","142              CAFTT (run: 7)      82  1445.914973          27133   \n","143              CAFTT (run: 8)      74  1397.400270          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","139    0.236980   0.238098             0.066915            0.067137  \n","140    0.237184   0.238024             0.066190            0.066403  \n","141    0.237250   0.237963             0.065993            0.066259  \n","142    0.236267   0.238129             0.066620            0.066841  \n","143    0.236362   0.237732             0.066140            0.066352  \n","\n","[144 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 09-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 09/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0072  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 0 / Train-Loss: 0.2402 / Val-Loss: 0.2459 / Test-Loss: 0.2413 / Time taken: 0:00:28 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0071  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 1 / Train-Loss: 0.2404 / Val-Loss: 0.2460 / Test-Loss: 0.2414 / Time taken: 0:00:49 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 09/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0072  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 2 / Train-Loss: 0.2403 / Val-Loss: 0.2459 / Test-Loss: 0.2413 / Time taken: 0:01:04 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0071  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 3 / Train-Loss: 0.2403 / Val-Loss: 0.2459 / Test-Loss: 0.2413 / Time taken: 0:01:18 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 09/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0069  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 4 / Train-Loss: 0.2400 / Val-Loss: 0.2457 / Test-Loss: 0.2410 / Time taken: 0:01:40 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0069  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 5 / Train-Loss: 0.2393 / Val-Loss: 0.2454 / Test-Loss: 0.2405 / Time taken: 0:01:53 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0069  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 6 / Train-Loss: 0.2391 / Val-Loss: 0.2450 / Test-Loss: 0.2401 / Time taken: 0:02:08 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0069  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 7 / Train-Loss: 0.2389 / Val-Loss: 0.2448 / Test-Loss: 0.2398 / Time taken: 0:02:21 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0069  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 8 / Train-Loss: 0.2385 / Val-Loss: 0.2448 / Test-Loss: 0.2397 / Time taken: 0:02:36 / ---- Currently Best Val-Epoch: 7 \n","Ensemble: 09/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0068  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 9 / Train-Loss: 0.2384 / Val-Loss: 0.2446 / Test-Loss: 0.2395 / Time taken: 0:02:58 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 10 / Train-Loss: 0.2381 / Val-Loss: 0.2447 / Test-Loss: 0.2395 / Time taken: 0:03:13 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 09/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 11 / Train-Loss: 0.2381 / Val-Loss: 0.2443 / Test-Loss: 0.2392 / Time taken: 0:03:27 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 12 / Batch: 1 / Train-Loss (Batch): 0.1544   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 09/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 12 / Train-Loss: 0.2380 / Val-Loss: 0.2443 / Test-Loss: 0.2391 / Time taken: 0:03:42 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 13 / Train-Loss: 0.2379 / Val-Loss: 0.2443 / Test-Loss: 0.2391 / Time taken: 0:03:56 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 14 / Train-Loss: 0.2379 / Val-Loss: 0.2443 / Test-Loss: 0.2391 / Time taken: 0:04:10 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 09/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 15 / Train-Loss: 0.2378 / Val-Loss: 0.2444 / Test-Loss: 0.2392 / Time taken: 0:04:25 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 09/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 16 / Train-Loss: 0.2377 / Val-Loss: 0.2442 / Test-Loss: 0.2390 / Time taken: 0:04:39 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 17 / Train-Loss: 0.2377 / Val-Loss: 0.2443 / Test-Loss: 0.2391 / Time taken: 0:04:53 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 09/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 18 / Train-Loss: 0.2377 / Val-Loss: 0.2441 / Test-Loss: 0.2389 / Time taken: 0:05:07 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 19 / Train-Loss: 0.2376 / Val-Loss: 0.2442 / Test-Loss: 0.2390 / Time taken: 0:05:21 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 09/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 20 / Train-Loss: 0.2376 / Val-Loss: 0.2441 / Test-Loss: 0.2389 / Time taken: 0:05:36 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 21 / Train-Loss: 0.2374 / Val-Loss: 0.2440 / Test-Loss: 0.2387 / Time taken: 0:05:50 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 22 / Train-Loss: 0.2375 / Val-Loss: 0.2439 / Test-Loss: 0.2388 / Time taken: 0:06:04 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 23 / Train-Loss: 0.2374 / Val-Loss: 0.2441 / Test-Loss: 0.2388 / Time taken: 0:06:18 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 09/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0064 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 24 / Train-Loss: 0.2373 / Val-Loss: 0.2438 / Test-Loss: 0.2387 / Time taken: 0:06:32 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 25 / Train-Loss: 0.2372 / Val-Loss: 0.2439 / Test-Loss: 0.2387 / Time taken: 0:06:46 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 09/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 26 / Train-Loss: 0.2371 / Val-Loss: 0.2437 / Test-Loss: 0.2384 / Time taken: 0:07:00 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 27 / Train-Loss: 0.2371 / Val-Loss: 0.2441 / Test-Loss: 0.2388 / Time taken: 0:07:14 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 09/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 28 / Train-Loss: 0.2370 / Val-Loss: 0.2438 / Test-Loss: 0.2385 / Time taken: 0:07:28 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 09/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 29 / Train-Loss: 0.2369 / Val-Loss: 0.2435 / Test-Loss: 0.2384 / Time taken: 0:07:42 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 30 / Train-Loss: 0.2368 / Val-Loss: 0.2436 / Test-Loss: 0.2383 / Time taken: 0:07:56 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 31 / Train-Loss: 0.2368 / Val-Loss: 0.2439 / Test-Loss: 0.2386 / Time taken: 0:08:10 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 32 / Train-Loss: 0.2369 / Val-Loss: 0.2439 / Test-Loss: 0.2385 / Time taken: 0:08:24 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 33 / Train-Loss: 0.2368 / Val-Loss: 0.2439 / Test-Loss: 0.2385 / Time taken: 0:08:38 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 34 / Train-Loss: 0.2367 / Val-Loss: 0.2436 / Test-Loss: 0.2383 / Time taken: 0:08:52 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 35 / Train-Loss: 0.2367 / Val-Loss: 0.2437 / Test-Loss: 0.2385 / Time taken: 0:09:06 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 36 / Train-Loss: 0.2366 / Val-Loss: 0.2436 / Test-Loss: 0.2386 / Time taken: 0:09:20 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 37 / Train-Loss: 0.2365 / Val-Loss: 0.2437 / Test-Loss: 0.2384 / Time taken: 0:09:34 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0065 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 38 / Train-Loss: 0.2366 / Val-Loss: 0.2439 / Test-Loss: 0.2386 / Time taken: 0:09:48 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 39 / Train-Loss: 0.2365 / Val-Loss: 0.2435 / Test-Loss: 0.2383 / Time taken: 0:10:02 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 40 / Train-Loss: 0.2364 / Val-Loss: 0.2438 / Test-Loss: 0.2389 / Time taken: 0:10:16 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 41 / Train-Loss: 0.2365 / Val-Loss: 0.2436 / Test-Loss: 0.2384 / Time taken: 0:10:30 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 42 / Train-Loss: 0.2364 / Val-Loss: 0.2437 / Test-Loss: 0.2384 / Time taken: 0:10:44 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 43 / Train-Loss: 0.2363 / Val-Loss: 0.2437 / Test-Loss: 0.2384 / Time taken: 0:10:58 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 44 / Train-Loss: 0.2364 / Val-Loss: 0.2437 / Test-Loss: 0.2384 / Time taken: 0:11:13 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 45 / Train-Loss: 0.2363 / Val-Loss: 0.2437 / Test-Loss: 0.2383 / Time taken: 0:11:27 / ---- Currently Best Val-Epoch: 29 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 2s 26ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-aa1153d0-e322-4cd8-a9cc-56e0d3f3e5b3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>140</th>\n","      <td>CAFTT (run: 5)</td>\n","      <td>57</td>\n","      <td>1170.775908</td>\n","      <td>27133</td>\n","      <td>0.237184</td>\n","      <td>0.238024</td>\n","      <td>0.066190</td>\n","      <td>0.066403</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>CAFTT (run: 6)</td>\n","      <td>63</td>\n","      <td>1285.190307</td>\n","      <td>27133</td>\n","      <td>0.237250</td>\n","      <td>0.237963</td>\n","      <td>0.065993</td>\n","      <td>0.066259</td>\n","    </tr>\n","    <tr>\n","      <th>142</th>\n","      <td>CAFTT (run: 7)</td>\n","      <td>82</td>\n","      <td>1445.914973</td>\n","      <td>27133</td>\n","      <td>0.236267</td>\n","      <td>0.238129</td>\n","      <td>0.066620</td>\n","      <td>0.066841</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>CAFTT (run: 8)</td>\n","      <td>74</td>\n","      <td>1397.400270</td>\n","      <td>27133</td>\n","      <td>0.236362</td>\n","      <td>0.237732</td>\n","      <td>0.066140</td>\n","      <td>0.066352</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>CAFTT (run: 9)</td>\n","      <td>29</td>\n","      <td>687.138017</td>\n","      <td>27133</td>\n","      <td>0.238057</td>\n","      <td>0.238411</td>\n","      <td>0.065254</td>\n","      <td>0.065593</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>145 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa1153d0-e322-4cd8-a9cc-56e0d3f3e5b3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-aa1153d0-e322-4cd8-a9cc-56e0d3f3e5b3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-aa1153d0-e322-4cd8-a9cc-56e0d3f3e5b3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-09292ecd-bda0-4f89-9c38-c60825edec4a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09292ecd-bda0-4f89-9c38-c60825edec4a')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-09292ecd-bda0-4f89-9c38-c60825edec4a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","140              CAFTT (run: 5)      57  1170.775908          27133   \n","141              CAFTT (run: 6)      63  1285.190307          27133   \n","142              CAFTT (run: 7)      82  1445.914973          27133   \n","143              CAFTT (run: 8)      74  1397.400270          27133   \n","144              CAFTT (run: 9)      29   687.138017          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","140    0.237184   0.238024             0.066190            0.066403  \n","141    0.237250   0.237963             0.065993            0.066259  \n","142    0.236267   0.238129             0.066620            0.066841  \n","143    0.236362   0.237732             0.066140            0.066352  \n","144    0.238057   0.238411             0.065254            0.065593  \n","\n","[145 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 10-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 10/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 0 / Train-Loss: 0.2407 / Val-Loss: 0.2414 / Test-Loss: 0.2413 / Time taken: 0:00:28 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 1 / Train-Loss: 0.2408 / Val-Loss: 0.2414 / Test-Loss: 0.2413 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 2 / Train-Loss: 0.2408 / Val-Loss: 0.2413 / Test-Loss: 0.2412 / Time taken: 0:00:56 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 3 / Train-Loss: 0.2408 / Val-Loss: 0.2413 / Test-Loss: 0.2412 / Time taken: 0:01:10 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 10/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 4 / Train-Loss: 0.2405 / Val-Loss: 0.2415 / Test-Loss: 0.2411 / Time taken: 0:01:24 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 10/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 5 / Train-Loss: 0.2400 / Val-Loss: 0.2411 / Test-Loss: 0.2406 / Time taken: 0:01:45 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 6 / Train-Loss: 0.2395 / Val-Loss: 0.2409 / Test-Loss: 0.2402 / Time taken: 0:02:00 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 7 / Train-Loss: 0.2394 / Val-Loss: 0.2408 / Test-Loss: 0.2400 / Time taken: 0:02:14 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 8 / Train-Loss: 0.2392 / Val-Loss: 0.2405 / Test-Loss: 0.2398 / Time taken: 0:02:28 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 9 / Train-Loss: 0.2390 / Val-Loss: 0.2403 / Test-Loss: 0.2396 / Time taken: 0:02:43 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 10 / Train-Loss: 0.2388 / Val-Loss: 0.2400 / Test-Loss: 0.2395 / Time taken: 0:02:57 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 11 / Batch: 1 / Train-Loss (Batch): 0.1736   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 10/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 11 / Train-Loss: 0.2386 / Val-Loss: 0.2401 / Test-Loss: 0.2394 / Time taken: 0:03:12 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 10/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 12 / Train-Loss: 0.2387 / Val-Loss: 0.2399 / Test-Loss: 0.2393 / Time taken: 0:03:34 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 13 / Train-Loss: 0.2386 / Val-Loss: 0.2400 / Test-Loss: 0.2393 / Time taken: 0:03:49 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 10/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 14 / Train-Loss: 0.2385 / Val-Loss: 0.2399 / Test-Loss: 0.2392 / Time taken: 0:04:03 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 15 / Train-Loss: 0.2384 / Val-Loss: 0.2396 / Test-Loss: 0.2390 / Time taken: 0:04:18 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 16 / Train-Loss: 0.2384 / Val-Loss: 0.2399 / Test-Loss: 0.2393 / Time taken: 0:04:33 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 10/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 17 / Train-Loss: 0.2383 / Val-Loss: 0.2399 / Test-Loss: 0.2392 / Time taken: 0:04:48 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 10/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 18 / Train-Loss: 0.2383 / Val-Loss: 0.2397 / Test-Loss: 0.2391 / Time taken: 0:05:02 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 10/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 19 / Train-Loss: 0.2383 / Val-Loss: 0.2397 / Test-Loss: 0.2390 / Time taken: 0:05:24 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 10/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 20 / Train-Loss: 0.2382 / Val-Loss: 0.2396 / Test-Loss: 0.2389 / Time taken: 0:05:38 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 21 / Train-Loss: 0.2382 / Val-Loss: 0.2397 / Test-Loss: 0.2391 / Time taken: 0:05:53 / ---- Currently Best Val-Epoch: 20 \n","Ensemble: 10/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 22 / Train-Loss: 0.2381 / Val-Loss: 0.2396 / Test-Loss: 0.2390 / Time taken: 0:06:06 / ---- Currently Best Val-Epoch: 20 \n","Ensemble: 10/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 23 / Train-Loss: 0.2380 / Val-Loss: 0.2397 / Test-Loss: 0.2390 / Time taken: 0:06:20 / ---- Currently Best Val-Epoch: 20 \n","Ensemble: 10/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 24 / Train-Loss: 0.2380 / Val-Loss: 0.2396 / Test-Loss: 0.2389 / Time taken: 0:06:34 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 25 / Train-Loss: 0.2380 / Val-Loss: 0.2396 / Test-Loss: 0.2389 / Time taken: 0:06:49 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 10/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 26 / Train-Loss: 0.2379 / Val-Loss: 0.2394 / Test-Loss: 0.2388 / Time taken: 0:07:03 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 27 / Train-Loss: 0.2378 / Val-Loss: 0.2395 / Test-Loss: 0.2387 / Time taken: 0:07:18 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 10/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 28 / Train-Loss: 0.2377 / Val-Loss: 0.2392 / Test-Loss: 0.2385 / Time taken: 0:07:39 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 29 / Train-Loss: 0.2377 / Val-Loss: 0.2392 / Test-Loss: 0.2384 / Time taken: 0:07:54 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 30 / Train-Loss: 0.2376 / Val-Loss: 0.2391 / Test-Loss: 0.2385 / Time taken: 0:08:09 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 31 / Train-Loss: 0.2374 / Val-Loss: 0.2390 / Test-Loss: 0.2384 / Time taken: 0:08:31 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 32 / Train-Loss: 0.2374 / Val-Loss: 0.2390 / Test-Loss: 0.2383 / Time taken: 0:08:46 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 33 / Train-Loss: 0.2374 / Val-Loss: 0.2391 / Test-Loss: 0.2384 / Time taken: 0:09:02 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 10/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 34 / Train-Loss: 0.2374 / Val-Loss: 0.2390 / Test-Loss: 0.2384 / Time taken: 0:09:16 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 10/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 35 / Train-Loss: 0.2372 / Val-Loss: 0.2388 / Test-Loss: 0.2383 / Time taken: 0:09:30 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 36 / Train-Loss: 0.2372 / Val-Loss: 0.2391 / Test-Loss: 0.2385 / Time taken: 0:09:45 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 10/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 37 / Train-Loss: 0.2371 / Val-Loss: 0.2389 / Test-Loss: 0.2384 / Time taken: 0:10:01 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 10/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 38 / Train-Loss: 0.2371 / Val-Loss: 0.2390 / Test-Loss: 0.2384 / Time taken: 0:10:16 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 10/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 39 / Train-Loss: 0.2372 / Val-Loss: 0.2391 / Test-Loss: 0.2384 / Time taken: 0:10:31 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 10/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 40 / Train-Loss: 0.2370 / Val-Loss: 0.2395 / Test-Loss: 0.2387 / Time taken: 0:10:46 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 10/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 41 / Train-Loss: 0.2370 / Val-Loss: 0.2387 / Test-Loss: 0.2383 / Time taken: 0:11:01 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 42 / Train-Loss: 0.2370 / Val-Loss: 0.2390 / Test-Loss: 0.2385 / Time taken: 0:11:23 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 10/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 43 / Train-Loss: 0.2370 / Val-Loss: 0.2388 / Test-Loss: 0.2383 / Time taken: 0:11:45 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 10/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 44 / Train-Loss: 0.2370 / Val-Loss: 0.2389 / Test-Loss: 0.2383 / Time taken: 0:12:00 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 10/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 45 / Train-Loss: 0.2370 / Val-Loss: 0.2390 / Test-Loss: 0.2385 / Time taken: 0:12:15 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 10/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 46 / Train-Loss: 0.2369 / Val-Loss: 0.2385 / Test-Loss: 0.2382 / Time taken: 0:12:36 / ---- Currently Best Val-Epoch: 46 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 47 / Train-Loss: 0.2368 / Val-Loss: 0.2386 / Test-Loss: 0.2382 / Time taken: 0:12:51 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 10/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 48 / Train-Loss: 0.2368 / Val-Loss: 0.2386 / Test-Loss: 0.2383 / Time taken: 0:13:06 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 10/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 49 / Train-Loss: 0.2368 / Val-Loss: 0.2387 / Test-Loss: 0.2382 / Time taken: 0:13:22 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 10/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 50 / Train-Loss: 0.2368 / Val-Loss: 0.2387 / Test-Loss: 0.2382 / Time taken: 0:13:36 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 10/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 51 / Train-Loss: 0.2367 / Val-Loss: 0.2385 / Test-Loss: 0.2382 / Time taken: 0:13:51 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 10/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 52 / Train-Loss: 0.2367 / Val-Loss: 0.2386 / Test-Loss: 0.2382 / Time taken: 0:14:05 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 10/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 53 / Train-Loss: 0.2366 / Val-Loss: 0.2386 / Test-Loss: 0.2382 / Time taken: 0:14:22 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 10/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 54 / Train-Loss: 0.2366 / Val-Loss: 0.2386 / Test-Loss: 0.2381 / Time taken: 0:14:37 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 10/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 55 / Train-Loss: 0.2366 / Val-Loss: 0.2389 / Test-Loss: 0.2384 / Time taken: 0:14:51 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 10/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 56 / Train-Loss: 0.2367 / Val-Loss: 0.2385 / Test-Loss: 0.2381 / Time taken: 0:15:06 / ---- Currently Best Val-Epoch: 56 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 57 / Train-Loss: 0.2366 / Val-Loss: 0.2386 / Test-Loss: 0.2384 / Time taken: 0:15:20 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 10/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 58 / Train-Loss: 0.2366 / Val-Loss: 0.2383 / Test-Loss: 0.2382 / Time taken: 0:15:34 / ---- Currently Best Val-Epoch: 58 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 59 / Train-Loss: 0.2365 / Val-Loss: 0.2386 / Test-Loss: 0.2383 / Time taken: 0:15:48 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 60 / Train-Loss: 0.2365 / Val-Loss: 0.2384 / Test-Loss: 0.2382 / Time taken: 0:16:02 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 61 / Train-Loss: 0.2365 / Val-Loss: 0.2387 / Test-Loss: 0.2384 / Time taken: 0:16:17 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 62 / Train-Loss: 0.2365 / Val-Loss: 0.2384 / Test-Loss: 0.2382 / Time taken: 0:16:38 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 63 / Train-Loss: 0.2363 / Val-Loss: 0.2387 / Test-Loss: 0.2384 / Time taken: 0:17:00 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 64 / Train-Loss: 0.2365 / Val-Loss: 0.2386 / Test-Loss: 0.2385 / Time taken: 0:17:14 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 65 / Train-Loss: 0.2364 / Val-Loss: 0.2386 / Test-Loss: 0.2385 / Time taken: 0:17:28 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 66 / Train-Loss: 0.2363 / Val-Loss: 0.2387 / Test-Loss: 0.2385 / Time taken: 0:17:42 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 67 / Train-Loss: 0.2363 / Val-Loss: 0.2387 / Test-Loss: 0.2386 / Time taken: 0:17:56 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 68 / Train-Loss: 0.2363 / Val-Loss: 0.2384 / Test-Loss: 0.2383 / Time taken: 0:18:10 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 69 / Train-Loss: 0.2363 / Val-Loss: 0.2386 / Test-Loss: 0.2386 / Time taken: 0:18:24 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 70 / Train-Loss: 0.2364 / Val-Loss: 0.2384 / Test-Loss: 0.2384 / Time taken: 0:18:38 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 71 / Train-Loss: 0.2362 / Val-Loss: 0.2385 / Test-Loss: 0.2385 / Time taken: 0:18:52 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 72 / Train-Loss: 0.2363 / Val-Loss: 0.2385 / Test-Loss: 0.2385 / Time taken: 0:19:06 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 73 / Train-Loss: 0.2363 / Val-Loss: 0.2385 / Test-Loss: 0.2386 / Time taken: 0:19:21 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 10/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 74 / Train-Loss: 0.2362 / Val-Loss: 0.2384 / Test-Loss: 0.2384 / Time taken: 0:19:35 / ---- Currently Best Val-Epoch: 58 \n","596/596 [==============================] - 11s 17ms/step\n","67/67 [==============================] - 2s 23ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-f58e036f-b4f6-4cbe-9f73-8e860b219f58\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>CAFTT (run: 6)</td>\n","      <td>63</td>\n","      <td>1285.190307</td>\n","      <td>27133</td>\n","      <td>0.237250</td>\n","      <td>0.237963</td>\n","      <td>0.065993</td>\n","      <td>0.066259</td>\n","    </tr>\n","    <tr>\n","      <th>142</th>\n","      <td>CAFTT (run: 7)</td>\n","      <td>82</td>\n","      <td>1445.914973</td>\n","      <td>27133</td>\n","      <td>0.236267</td>\n","      <td>0.238129</td>\n","      <td>0.066620</td>\n","      <td>0.066841</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>CAFTT (run: 8)</td>\n","      <td>74</td>\n","      <td>1397.400270</td>\n","      <td>27133</td>\n","      <td>0.236362</td>\n","      <td>0.237732</td>\n","      <td>0.066140</td>\n","      <td>0.066352</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>CAFTT (run: 9)</td>\n","      <td>29</td>\n","      <td>687.138017</td>\n","      <td>27133</td>\n","      <td>0.238057</td>\n","      <td>0.238411</td>\n","      <td>0.065254</td>\n","      <td>0.065593</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>CAFTT (run: 10)</td>\n","      <td>58</td>\n","      <td>1175.236680</td>\n","      <td>27133</td>\n","      <td>0.237128</td>\n","      <td>0.238169</td>\n","      <td>0.065283</td>\n","      <td>0.065611</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>146 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f58e036f-b4f6-4cbe-9f73-8e860b219f58')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f58e036f-b4f6-4cbe-9f73-8e860b219f58 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f58e036f-b4f6-4cbe-9f73-8e860b219f58');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3adca6aa-3e1c-45c2-9f1d-d8b8ca96aa3d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3adca6aa-3e1c-45c2-9f1d-d8b8ca96aa3d')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3adca6aa-3e1c-45c2-9f1d-d8b8ca96aa3d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","141              CAFTT (run: 6)      63  1285.190307          27133   \n","142              CAFTT (run: 7)      82  1445.914973          27133   \n","143              CAFTT (run: 8)      74  1397.400270          27133   \n","144              CAFTT (run: 9)      29   687.138017          27133   \n","145             CAFTT (run: 10)      58  1175.236680          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","141    0.237250   0.237963             0.065993            0.066259  \n","142    0.236267   0.238129             0.066620            0.066841  \n","143    0.236362   0.237732             0.066140            0.066352  \n","144    0.238057   0.238411             0.065254            0.065593  \n","145    0.237128   0.238169             0.065283            0.065611  \n","\n","[146 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 11-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 11/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 0 / Train-Loss: 0.2417 / Val-Loss: 0.2327 / Test-Loss: 0.2413 / Time taken: 0:00:28 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 1 / Train-Loss: 0.2418 / Val-Loss: 0.2326 / Test-Loss: 0.2412 / Time taken: 0:00:42 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 2 / Train-Loss: 0.2418 / Val-Loss: 0.2326 / Test-Loss: 0.2413 / Time taken: 0:01:04 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 3 / Train-Loss: 0.2416 / Val-Loss: 0.2326 / Test-Loss: 0.2412 / Time taken: 0:01:19 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0336  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 4 / Train-Loss: 0.2412 / Val-Loss: 0.2325 / Test-Loss: 0.2413 / Time taken: 0:01:40 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0337  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 5 / Train-Loss: 0.2407 / Val-Loss: 0.2315 / Test-Loss: 0.2402 / Time taken: 0:01:56 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0339  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 6 / Train-Loss: 0.2404 / Val-Loss: 0.2314 / Test-Loss: 0.2401 / Time taken: 0:02:11 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.034   : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 7 / Train-Loss: 0.2403 / Val-Loss: 0.2313 / Test-Loss: 0.2400 / Time taken: 0:02:25 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0341  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 8 / Train-Loss: 0.2402 / Val-Loss: 0.2315 / Test-Loss: 0.2401 / Time taken: 0:02:40 / ---- Currently Best Val-Epoch: 7 \n","Ensemble: 11/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0341  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 9 / Train-Loss: 0.2401 / Val-Loss: 0.2308 / Test-Loss: 0.2395 / Time taken: 0:02:55 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 10 / Train-Loss: 0.2400 / Val-Loss: 0.2310 / Test-Loss: 0.2397 / Time taken: 0:03:17 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 11/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 11 / Train-Loss: 0.2399 / Val-Loss: 0.2308 / Test-Loss: 0.2396 / Time taken: 0:03:32 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 11/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 12 / Train-Loss: 0.2398 / Val-Loss: 0.2309 / Test-Loss: 0.2396 / Time taken: 0:03:46 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 11/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 13 / Train-Loss: 0.2399 / Val-Loss: 0.2307 / Test-Loss: 0.2394 / Time taken: 0:04:00 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 14 / Batch: 1 / Train-Loss (Batch): 0.1776   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 11/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 14 / Train-Loss: 0.2397 / Val-Loss: 0.2305 / Test-Loss: 0.2394 / Time taken: 0:04:14 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 15 / Train-Loss: 0.2397 / Val-Loss: 0.2304 / Test-Loss: 0.2393 / Time taken: 0:04:29 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 16 / Train-Loss: 0.2396 / Val-Loss: 0.2303 / Test-Loss: 0.2392 / Time taken: 0:04:44 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 17 / Train-Loss: 0.2394 / Val-Loss: 0.2304 / Test-Loss: 0.2392 / Time taken: 0:04:58 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 11/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 18 / Train-Loss: 0.2395 / Val-Loss: 0.2304 / Test-Loss: 0.2392 / Time taken: 0:05:12 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 11/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 19 / Train-Loss: 0.2395 / Val-Loss: 0.2303 / Test-Loss: 0.2391 / Time taken: 0:05:27 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 20 / Train-Loss: 0.2393 / Val-Loss: 0.2304 / Test-Loss: 0.2392 / Time taken: 0:05:41 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 11/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 21 / Train-Loss: 0.2393 / Val-Loss: 0.2302 / Test-Loss: 0.2391 / Time taken: 0:06:02 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 22 / Train-Loss: 0.2392 / Val-Loss: 0.2302 / Test-Loss: 0.2390 / Time taken: 0:06:18 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 23 / Train-Loss: 0.2392 / Val-Loss: 0.2301 / Test-Loss: 0.2390 / Time taken: 0:06:34 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 24 / Train-Loss: 0.2391 / Val-Loss: 0.2303 / Test-Loss: 0.2391 / Time taken: 0:06:49 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 11/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 25 / Train-Loss: 0.2391 / Val-Loss: 0.2303 / Test-Loss: 0.2391 / Time taken: 0:07:03 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 11/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 26 / Train-Loss: 0.2391 / Val-Loss: 0.2301 / Test-Loss: 0.2389 / Time taken: 0:07:17 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 11/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 27 / Train-Loss: 0.2391 / Val-Loss: 0.2300 / Test-Loss: 0.2389 / Time taken: 0:07:31 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 28 / Train-Loss: 0.2390 / Val-Loss: 0.2300 / Test-Loss: 0.2387 / Time taken: 0:07:46 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 29 / Train-Loss: 0.2390 / Val-Loss: 0.2299 / Test-Loss: 0.2388 / Time taken: 0:08:01 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 30 / Train-Loss: 0.2389 / Val-Loss: 0.2299 / Test-Loss: 0.2388 / Time taken: 0:08:17 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 31 / Train-Loss: 0.2388 / Val-Loss: 0.2298 / Test-Loss: 0.2386 / Time taken: 0:08:32 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 32 / Train-Loss: 0.2388 / Val-Loss: 0.2297 / Test-Loss: 0.2387 / Time taken: 0:08:54 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 33 / Train-Loss: 0.2387 / Val-Loss: 0.2298 / Test-Loss: 0.2386 / Time taken: 0:09:16 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 11/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 34 / Train-Loss: 0.2386 / Val-Loss: 0.2295 / Test-Loss: 0.2384 / Time taken: 0:09:32 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 35 / Train-Loss: 0.2385 / Val-Loss: 0.2296 / Test-Loss: 0.2384 / Time taken: 0:09:48 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 11/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 36 / Train-Loss: 0.2385 / Val-Loss: 0.2296 / Test-Loss: 0.2384 / Time taken: 0:10:09 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 11/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 37 / Train-Loss: 0.2385 / Val-Loss: 0.2298 / Test-Loss: 0.2384 / Time taken: 0:10:24 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 11/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 38 / Train-Loss: 0.2383 / Val-Loss: 0.2296 / Test-Loss: 0.2383 / Time taken: 0:10:46 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 11/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 39 / Train-Loss: 0.2384 / Val-Loss: 0.2295 / Test-Loss: 0.2384 / Time taken: 0:11:01 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 11/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 40 / Train-Loss: 0.2383 / Val-Loss: 0.2296 / Test-Loss: 0.2383 / Time taken: 0:11:23 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 11/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 41 / Train-Loss: 0.2383 / Val-Loss: 0.2296 / Test-Loss: 0.2383 / Time taken: 0:11:38 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 11/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 42 / Train-Loss: 0.2381 / Val-Loss: 0.2296 / Test-Loss: 0.2384 / Time taken: 0:11:54 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 11/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 43 / Train-Loss: 0.2381 / Val-Loss: 0.2293 / Test-Loss: 0.2381 / Time taken: 0:12:09 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 44 / Train-Loss: 0.2381 / Val-Loss: 0.2296 / Test-Loss: 0.2383 / Time taken: 0:12:27 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 11/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 45 / Train-Loss: 0.2381 / Val-Loss: 0.2294 / Test-Loss: 0.2384 / Time taken: 0:12:41 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 11/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 46 / Train-Loss: 0.2381 / Val-Loss: 0.2294 / Test-Loss: 0.2382 / Time taken: 0:13:03 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 11/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 47 / Train-Loss: 0.2379 / Val-Loss: 0.2298 / Test-Loss: 0.2385 / Time taken: 0:13:18 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 11/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 48 / Train-Loss: 0.2380 / Val-Loss: 0.2294 / Test-Loss: 0.2383 / Time taken: 0:13:33 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 11/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 49 / Train-Loss: 0.2379 / Val-Loss: 0.2296 / Test-Loss: 0.2383 / Time taken: 0:13:48 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 11/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 50 / Train-Loss: 0.2379 / Val-Loss: 0.2294 / Test-Loss: 0.2383 / Time taken: 0:14:03 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 11/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 51 / Train-Loss: 0.2378 / Val-Loss: 0.2291 / Test-Loss: 0.2383 / Time taken: 0:14:18 / ---- Currently Best Val-Epoch: 51 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 52 / Train-Loss: 0.2379 / Val-Loss: 0.2293 / Test-Loss: 0.2382 / Time taken: 0:14:33 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 11/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 53 / Train-Loss: 0.2378 / Val-Loss: 0.2294 / Test-Loss: 0.2383 / Time taken: 0:14:48 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 11/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 54 / Train-Loss: 0.2378 / Val-Loss: 0.2294 / Test-Loss: 0.2382 / Time taken: 0:15:03 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 11/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 55 / Train-Loss: 0.2378 / Val-Loss: 0.2299 / Test-Loss: 0.2387 / Time taken: 0:15:18 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 11/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 56 / Train-Loss: 0.2378 / Val-Loss: 0.2294 / Test-Loss: 0.2382 / Time taken: 0:15:40 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 11/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 57 / Train-Loss: 0.2376 / Val-Loss: 0.2294 / Test-Loss: 0.2384 / Time taken: 0:15:54 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 11/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 58 / Train-Loss: 0.2377 / Val-Loss: 0.2295 / Test-Loss: 0.2383 / Time taken: 0:16:10 / ---- Currently Best Val-Epoch: 51 \n","Ensemble: 11/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 59 / Train-Loss: 0.2377 / Val-Loss: 0.2290 / Test-Loss: 0.2382 / Time taken: 0:16:25 / ---- Currently Best Val-Epoch: 59 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 60 / Train-Loss: 0.2376 / Val-Loss: 0.2291 / Test-Loss: 0.2382 / Time taken: 0:16:47 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 61 / Train-Loss: 0.2376 / Val-Loss: 0.2293 / Test-Loss: 0.2384 / Time taken: 0:17:01 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 62 / Train-Loss: 0.2376 / Val-Loss: 0.2292 / Test-Loss: 0.2382 / Time taken: 0:17:22 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 63 / Train-Loss: 0.2377 / Val-Loss: 0.2305 / Test-Loss: 0.2386 / Time taken: 0:17:37 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 64 / Train-Loss: 0.2376 / Val-Loss: 0.2295 / Test-Loss: 0.2382 / Time taken: 0:17:52 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 65 / Train-Loss: 0.2375 / Val-Loss: 0.2291 / Test-Loss: 0.2382 / Time taken: 0:18:07 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 66 / Train-Loss: 0.2375 / Val-Loss: 0.2295 / Test-Loss: 0.2384 / Time taken: 0:18:22 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 67 / Train-Loss: 0.2375 / Val-Loss: 0.2293 / Test-Loss: 0.2385 / Time taken: 0:18:37 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 68 / Train-Loss: 0.2375 / Val-Loss: 0.2293 / Test-Loss: 0.2384 / Time taken: 0:18:52 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 69 / Train-Loss: 0.2375 / Val-Loss: 0.2293 / Test-Loss: 0.2381 / Time taken: 0:19:07 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 70 / Train-Loss: 0.2374 / Val-Loss: 0.2294 / Test-Loss: 0.2382 / Time taken: 0:19:28 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 71 / Train-Loss: 0.2375 / Val-Loss: 0.2294 / Test-Loss: 0.2383 / Time taken: 0:19:43 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 72 / Train-Loss: 0.2374 / Val-Loss: 0.2293 / Test-Loss: 0.2382 / Time taken: 0:19:57 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 73 / Train-Loss: 0.2374 / Val-Loss: 0.2297 / Test-Loss: 0.2384 / Time taken: 0:20:11 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 74 / Train-Loss: 0.2373 / Val-Loss: 0.2294 / Test-Loss: 0.2383 / Time taken: 0:20:33 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 11/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 75 / Train-Loss: 0.2373 / Val-Loss: 0.2296 / Test-Loss: 0.2383 / Time taken: 0:20:48 / ---- Currently Best Val-Epoch: 59 \n","596/596 [==============================] - 12s 19ms/step\n","67/67 [==============================] - 1s 17ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-69305645-eb68-4a0f-b7fc-db4a15feb173\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>142</th>\n","      <td>CAFTT (run: 7)</td>\n","      <td>82</td>\n","      <td>1445.914973</td>\n","      <td>27133</td>\n","      <td>0.236267</td>\n","      <td>0.238129</td>\n","      <td>0.066620</td>\n","      <td>0.066841</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>CAFTT (run: 8)</td>\n","      <td>74</td>\n","      <td>1397.400270</td>\n","      <td>27133</td>\n","      <td>0.236362</td>\n","      <td>0.237732</td>\n","      <td>0.066140</td>\n","      <td>0.066352</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>CAFTT (run: 9)</td>\n","      <td>29</td>\n","      <td>687.138017</td>\n","      <td>27133</td>\n","      <td>0.238057</td>\n","      <td>0.238411</td>\n","      <td>0.065254</td>\n","      <td>0.065593</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>CAFTT (run: 10)</td>\n","      <td>58</td>\n","      <td>1175.236680</td>\n","      <td>27133</td>\n","      <td>0.237128</td>\n","      <td>0.238169</td>\n","      <td>0.065283</td>\n","      <td>0.065611</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>CAFTT (run: 11)</td>\n","      <td>59</td>\n","      <td>1248.218261</td>\n","      <td>27133</td>\n","      <td>0.237067</td>\n","      <td>0.238216</td>\n","      <td>0.065540</td>\n","      <td>0.065780</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>147 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69305645-eb68-4a0f-b7fc-db4a15feb173')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-69305645-eb68-4a0f-b7fc-db4a15feb173 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-69305645-eb68-4a0f-b7fc-db4a15feb173');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-96e0cdb0-93c4-46d7-abdd-0b4b016040c8\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96e0cdb0-93c4-46d7-abdd-0b4b016040c8')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-96e0cdb0-93c4-46d7-abdd-0b4b016040c8 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","142              CAFTT (run: 7)      82  1445.914973          27133   \n","143              CAFTT (run: 8)      74  1397.400270          27133   \n","144              CAFTT (run: 9)      29   687.138017          27133   \n","145             CAFTT (run: 10)      58  1175.236680          27133   \n","146             CAFTT (run: 11)      59  1248.218261          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","142    0.236267   0.238129             0.066620            0.066841  \n","143    0.236362   0.237732             0.066140            0.066352  \n","144    0.238057   0.238411             0.065254            0.065593  \n","145    0.237128   0.238169             0.065283            0.065611  \n","146    0.237067   0.238216             0.065540            0.065780  \n","\n","[147 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 12-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 12/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 0 / Train-Loss: 0.2407 / Val-Loss: 0.2418 / Test-Loss: 0.2413 / Time taken: 0:00:30 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 1 / Train-Loss: 0.2408 / Val-Loss: 0.2418 / Test-Loss: 0.2413 / Time taken: 0:00:45 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 12/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 2 / Train-Loss: 0.2408 / Val-Loss: 0.2419 / Test-Loss: 0.2413 / Time taken: 0:01:00 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 12/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 3 / Train-Loss: 0.2407 / Val-Loss: 0.2419 / Test-Loss: 0.2414 / Time taken: 0:01:14 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 12/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 4 / Train-Loss: 0.2403 / Val-Loss: 0.2414 / Test-Loss: 0.2404 / Time taken: 0:01:35 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 5 / Train-Loss: 0.2398 / Val-Loss: 0.2415 / Test-Loss: 0.2403 / Time taken: 0:01:57 / ---- Currently Best Val-Epoch: 4 \n","Ensemble: 12/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 6 / Train-Loss: 0.2397 / Val-Loss: 0.2414 / Test-Loss: 0.2403 / Time taken: 0:02:11 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 7 / Train-Loss: 0.2396 / Val-Loss: 0.2413 / Test-Loss: 0.2403 / Time taken: 0:02:25 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0336  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 8 / Train-Loss: 0.2394 / Val-Loss: 0.2413 / Test-Loss: 0.2401 / Time taken: 0:02:38 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0336  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 9 / Train-Loss: 0.2391 / Val-Loss: 0.2412 / Test-Loss: 0.2399 / Time taken: 0:02:53 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 10 / Train-Loss: 0.2389 / Val-Loss: 0.2412 / Test-Loss: 0.2399 / Time taken: 0:03:07 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 12/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 11 / Train-Loss: 0.2389 / Val-Loss: 0.2409 / Test-Loss: 0.2395 / Time taken: 0:03:21 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 12 / Batch: 1 / Train-Loss (Batch): 0.1759   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 12/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 12 / Train-Loss: 0.2387 / Val-Loss: 0.2409 / Test-Loss: 0.2395 / Time taken: 0:03:43 / ---- Currently Best Val-Epoch: 11 \n","Ensemble: 12/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 13 / Train-Loss: 0.2386 / Val-Loss: 0.2408 / Test-Loss: 0.2394 / Time taken: 0:04:04 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 14 / Train-Loss: 0.2385 / Val-Loss: 0.2407 / Test-Loss: 0.2392 / Time taken: 0:04:19 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 15 / Train-Loss: 0.2385 / Val-Loss: 0.2406 / Test-Loss: 0.2391 / Time taken: 0:04:34 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 16 / Train-Loss: 0.2383 / Val-Loss: 0.2405 / Test-Loss: 0.2390 / Time taken: 0:04:49 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 17 / Train-Loss: 0.2383 / Val-Loss: 0.2405 / Test-Loss: 0.2390 / Time taken: 0:05:05 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 12/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 18 / Train-Loss: 0.2383 / Val-Loss: 0.2404 / Test-Loss: 0.2390 / Time taken: 0:05:20 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 19 / Train-Loss: 0.2382 / Val-Loss: 0.2404 / Test-Loss: 0.2390 / Time taken: 0:05:42 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 12/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 20 / Train-Loss: 0.2382 / Val-Loss: 0.2404 / Test-Loss: 0.2390 / Time taken: 0:05:55 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 12/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 21 / Train-Loss: 0.2381 / Val-Loss: 0.2402 / Test-Loss: 0.2388 / Time taken: 0:06:10 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 22 / Train-Loss: 0.2381 / Val-Loss: 0.2403 / Test-Loss: 0.2387 / Time taken: 0:06:24 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 12/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 23 / Train-Loss: 0.2381 / Val-Loss: 0.2402 / Test-Loss: 0.2386 / Time taken: 0:06:39 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 24 / Train-Loss: 0.2380 / Val-Loss: 0.2401 / Test-Loss: 0.2386 / Time taken: 0:06:53 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 25 / Train-Loss: 0.2379 / Val-Loss: 0.2401 / Test-Loss: 0.2386 / Time taken: 0:07:07 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 12/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 26 / Train-Loss: 0.2378 / Val-Loss: 0.2401 / Test-Loss: 0.2385 / Time taken: 0:07:29 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 27 / Train-Loss: 0.2379 / Val-Loss: 0.2401 / Test-Loss: 0.2387 / Time taken: 0:07:44 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 28 / Train-Loss: 0.2376 / Val-Loss: 0.2400 / Test-Loss: 0.2383 / Time taken: 0:07:59 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 29 / Train-Loss: 0.2376 / Val-Loss: 0.2400 / Test-Loss: 0.2383 / Time taken: 0:08:15 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 30 / Train-Loss: 0.2376 / Val-Loss: 0.2400 / Test-Loss: 0.2384 / Time taken: 0:08:31 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 12/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 31 / Train-Loss: 0.2375 / Val-Loss: 0.2398 / Test-Loss: 0.2383 / Time taken: 0:08:52 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 32 / Train-Loss: 0.2373 / Val-Loss: 0.2398 / Test-Loss: 0.2382 / Time taken: 0:09:08 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 33 / Train-Loss: 0.2373 / Val-Loss: 0.2398 / Test-Loss: 0.2382 / Time taken: 0:09:29 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 34 / Train-Loss: 0.2373 / Val-Loss: 0.2398 / Test-Loss: 0.2382 / Time taken: 0:09:43 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 35 / Train-Loss: 0.2373 / Val-Loss: 0.2401 / Test-Loss: 0.2385 / Time taken: 0:10:05 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 36 / Train-Loss: 0.2371 / Val-Loss: 0.2399 / Test-Loss: 0.2384 / Time taken: 0:10:26 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 37 / Train-Loss: 0.2371 / Val-Loss: 0.2398 / Test-Loss: 0.2382 / Time taken: 0:10:42 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 38 / Train-Loss: 0.2370 / Val-Loss: 0.2399 / Test-Loss: 0.2381 / Time taken: 0:10:56 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 39 / Train-Loss: 0.2371 / Val-Loss: 0.2398 / Test-Loss: 0.2382 / Time taken: 0:11:11 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 40 / Train-Loss: 0.2369 / Val-Loss: 0.2400 / Test-Loss: 0.2384 / Time taken: 0:11:25 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 41 / Train-Loss: 0.2370 / Val-Loss: 0.2398 / Test-Loss: 0.2382 / Time taken: 0:11:40 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 42 / Train-Loss: 0.2370 / Val-Loss: 0.2399 / Test-Loss: 0.2382 / Time taken: 0:11:55 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 12/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 43 / Train-Loss: 0.2369 / Val-Loss: 0.2398 / Test-Loss: 0.2381 / Time taken: 0:12:09 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 44 / Train-Loss: 0.2368 / Val-Loss: 0.2397 / Test-Loss: 0.2381 / Time taken: 0:12:24 / ---- Currently Best Val-Epoch: 44 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 45 / Train-Loss: 0.2368 / Val-Loss: 0.2398 / Test-Loss: 0.2382 / Time taken: 0:12:39 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 12/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 46 / Train-Loss: 0.2367 / Val-Loss: 0.2399 / Test-Loss: 0.2382 / Time taken: 0:13:02 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 12/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 47 / Train-Loss: 0.2367 / Val-Loss: 0.2400 / Test-Loss: 0.2384 / Time taken: 0:13:17 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 12/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 48 / Train-Loss: 0.2367 / Val-Loss: 0.2399 / Test-Loss: 0.2382 / Time taken: 0:13:32 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 12/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 49 / Train-Loss: 0.2366 / Val-Loss: 0.2398 / Test-Loss: 0.2381 / Time taken: 0:13:46 / ---- Currently Best Val-Epoch: 44 \n","Ensemble: 12/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 50 / Train-Loss: 0.2367 / Val-Loss: 0.2397 / Test-Loss: 0.2380 / Time taken: 0:14:00 / ---- Currently Best Val-Epoch: 50 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 51 / Train-Loss: 0.2366 / Val-Loss: 0.2397 / Test-Loss: 0.2380 / Time taken: 0:14:22 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 52 / Train-Loss: 0.2366 / Val-Loss: 0.2398 / Test-Loss: 0.2381 / Time taken: 0:14:37 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 53 / Train-Loss: 0.2366 / Val-Loss: 0.2398 / Test-Loss: 0.2380 / Time taken: 0:14:59 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 54 / Train-Loss: 0.2366 / Val-Loss: 0.2398 / Test-Loss: 0.2380 / Time taken: 0:15:13 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 55 / Train-Loss: 0.2365 / Val-Loss: 0.2399 / Test-Loss: 0.2380 / Time taken: 0:15:35 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 56 / Train-Loss: 0.2366 / Val-Loss: 0.2399 / Test-Loss: 0.2380 / Time taken: 0:15:49 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 57 / Train-Loss: 0.2365 / Val-Loss: 0.2399 / Test-Loss: 0.2380 / Time taken: 0:16:05 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 58 / Train-Loss: 0.2365 / Val-Loss: 0.2397 / Test-Loss: 0.2379 / Time taken: 0:16:21 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 59 / Train-Loss: 0.2363 / Val-Loss: 0.2402 / Test-Loss: 0.2381 / Time taken: 0:16:35 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 60 / Train-Loss: 0.2364 / Val-Loss: 0.2398 / Test-Loss: 0.2379 / Time taken: 0:16:50 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 61 / Train-Loss: 0.2364 / Val-Loss: 0.2399 / Test-Loss: 0.2380 / Time taken: 0:17:04 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 62 / Train-Loss: 0.2364 / Val-Loss: 0.2399 / Test-Loss: 0.2380 / Time taken: 0:17:19 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 63 / Train-Loss: 0.2364 / Val-Loss: 0.2398 / Test-Loss: 0.2379 / Time taken: 0:17:33 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 64 / Train-Loss: 0.2363 / Val-Loss: 0.2400 / Test-Loss: 0.2380 / Time taken: 0:17:47 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 65 / Train-Loss: 0.2361 / Val-Loss: 0.2400 / Test-Loss: 0.2383 / Time taken: 0:18:02 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 66 / Train-Loss: 0.2362 / Val-Loss: 0.2400 / Test-Loss: 0.2382 / Time taken: 0:18:16 / ---- Currently Best Val-Epoch: 50 \n","596/596 [==============================] - 11s 17ms/step\n","67/67 [==============================] - 1s 18ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-b491506c-78d1-47f0-a006-224dec2b06d3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>CAFTT (run: 8)</td>\n","      <td>74</td>\n","      <td>1397.400270</td>\n","      <td>27133</td>\n","      <td>0.236362</td>\n","      <td>0.237732</td>\n","      <td>0.066140</td>\n","      <td>0.066352</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>CAFTT (run: 9)</td>\n","      <td>29</td>\n","      <td>687.138017</td>\n","      <td>27133</td>\n","      <td>0.238057</td>\n","      <td>0.238411</td>\n","      <td>0.065254</td>\n","      <td>0.065593</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>CAFTT (run: 10)</td>\n","      <td>58</td>\n","      <td>1175.236680</td>\n","      <td>27133</td>\n","      <td>0.237128</td>\n","      <td>0.238169</td>\n","      <td>0.065283</td>\n","      <td>0.065611</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>CAFTT (run: 11)</td>\n","      <td>59</td>\n","      <td>1248.218261</td>\n","      <td>27133</td>\n","      <td>0.237067</td>\n","      <td>0.238216</td>\n","      <td>0.065540</td>\n","      <td>0.065780</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>CAFTT (run: 12)</td>\n","      <td>50</td>\n","      <td>1096.780236</td>\n","      <td>27133</td>\n","      <td>0.237433</td>\n","      <td>0.237963</td>\n","      <td>0.065774</td>\n","      <td>0.066086</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>148 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b491506c-78d1-47f0-a006-224dec2b06d3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b491506c-78d1-47f0-a006-224dec2b06d3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b491506c-78d1-47f0-a006-224dec2b06d3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-71c9067e-a65c-4bd1-b081-a0911bb08aab\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71c9067e-a65c-4bd1-b081-a0911bb08aab')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-71c9067e-a65c-4bd1-b081-a0911bb08aab button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","143              CAFTT (run: 8)      74  1397.400270          27133   \n","144              CAFTT (run: 9)      29   687.138017          27133   \n","145             CAFTT (run: 10)      58  1175.236680          27133   \n","146             CAFTT (run: 11)      59  1248.218261          27133   \n","147             CAFTT (run: 12)      50  1096.780236          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","143    0.236362   0.237732             0.066140            0.066352  \n","144    0.238057   0.238411             0.065254            0.065593  \n","145    0.237128   0.238169             0.065283            0.065611  \n","146    0.237067   0.238216             0.065540            0.065780  \n","147    0.237433   0.237963             0.065774            0.066086  \n","\n","[148 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 13-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 13/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 0 / Train-Loss: 0.2409 / Val-Loss: 0.2400 / Test-Loss: 0.2413 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 1 / Train-Loss: 0.2410 / Val-Loss: 0.2400 / Test-Loss: 0.2412 / Time taken: 0:00:58 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 2 / Train-Loss: 0.2410 / Val-Loss: 0.2399 / Test-Loss: 0.2412 / Time taken: 0:01:12 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 3 / Train-Loss: 0.2410 / Val-Loss: 0.2401 / Test-Loss: 0.2413 / Time taken: 0:01:27 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 13/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 4 / Train-Loss: 0.2410 / Val-Loss: 0.2400 / Test-Loss: 0.2412 / Time taken: 0:01:42 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 13/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 5 / Train-Loss: 0.2409 / Val-Loss: 0.2400 / Test-Loss: 0.2412 / Time taken: 0:01:56 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 13/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 6 / Train-Loss: 0.2404 / Val-Loss: 0.2397 / Test-Loss: 0.2408 / Time taken: 0:02:11 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 7 / Train-Loss: 0.2401 / Val-Loss: 0.2395 / Test-Loss: 0.2406 / Time taken: 0:02:32 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 8 / Train-Loss: 0.2399 / Val-Loss: 0.2391 / Test-Loss: 0.2402 / Time taken: 0:02:46 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 9 / Train-Loss: 0.2397 / Val-Loss: 0.2389 / Test-Loss: 0.2399 / Time taken: 0:03:00 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 10 / Train-Loss: 0.2395 / Val-Loss: 0.2387 / Test-Loss: 0.2399 / Time taken: 0:03:14 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 11 / Batch: 1 / Train-Loss (Batch): 0.1562   : [------------------------------] 0.2%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 13/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 11 / Train-Loss: 0.2394 / Val-Loss: 0.2386 / Test-Loss: 0.2396 / Time taken: 0:03:29 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 12 / Train-Loss: 0.2392 / Val-Loss: 0.2384 / Test-Loss: 0.2395 / Time taken: 0:03:43 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 13 / Train-Loss: 0.2390 / Val-Loss: 0.2383 / Test-Loss: 0.2393 / Time taken: 0:03:58 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 14 / Train-Loss: 0.2389 / Val-Loss: 0.2383 / Test-Loss: 0.2394 / Time taken: 0:04:12 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 15 / Train-Loss: 0.2388 / Val-Loss: 0.2383 / Test-Loss: 0.2393 / Time taken: 0:04:27 / ---- Currently Best Val-Epoch: 14 \n","Ensemble: 13/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 16 / Train-Loss: 0.2387 / Val-Loss: 0.2381 / Test-Loss: 0.2391 / Time taken: 0:04:41 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 17 / Train-Loss: 0.2387 / Val-Loss: 0.2380 / Test-Loss: 0.2391 / Time taken: 0:04:56 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 18 / Train-Loss: 0.2386 / Val-Loss: 0.2380 / Test-Loss: 0.2391 / Time taken: 0:05:10 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 13/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 19 / Train-Loss: 0.2386 / Val-Loss: 0.2381 / Test-Loss: 0.2391 / Time taken: 0:05:24 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 13/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 20 / Train-Loss: 0.2384 / Val-Loss: 0.2381 / Test-Loss: 0.2391 / Time taken: 0:05:38 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 13/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 21 / Train-Loss: 0.2384 / Val-Loss: 0.2380 / Test-Loss: 0.2390 / Time taken: 0:05:53 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 22 / Train-Loss: 0.2384 / Val-Loss: 0.2379 / Test-Loss: 0.2390 / Time taken: 0:06:07 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 23 / Train-Loss: 0.2383 / Val-Loss: 0.2379 / Test-Loss: 0.2389 / Time taken: 0:06:22 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 24 / Train-Loss: 0.2383 / Val-Loss: 0.2380 / Test-Loss: 0.2390 / Time taken: 0:06:37 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 13/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 25 / Train-Loss: 0.2383 / Val-Loss: 0.2379 / Test-Loss: 0.2389 / Time taken: 0:06:51 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 26 / Train-Loss: 0.2382 / Val-Loss: 0.2378 / Test-Loss: 0.2389 / Time taken: 0:07:06 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 27 / Train-Loss: 0.2382 / Val-Loss: 0.2379 / Test-Loss: 0.2389 / Time taken: 0:07:21 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 13/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 28 / Train-Loss: 0.2381 / Val-Loss: 0.2378 / Test-Loss: 0.2387 / Time taken: 0:07:35 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 29 / Train-Loss: 0.2380 / Val-Loss: 0.2379 / Test-Loss: 0.2388 / Time taken: 0:07:50 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 13/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 30 / Train-Loss: 0.2380 / Val-Loss: 0.2378 / Test-Loss: 0.2387 / Time taken: 0:08:05 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 31 / Train-Loss: 0.2380 / Val-Loss: 0.2378 / Test-Loss: 0.2388 / Time taken: 0:08:20 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 32 / Train-Loss: 0.2378 / Val-Loss: 0.2378 / Test-Loss: 0.2388 / Time taken: 0:08:35 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 13/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 33 / Train-Loss: 0.2379 / Val-Loss: 0.2376 / Test-Loss: 0.2386 / Time taken: 0:08:49 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 34 / Train-Loss: 0.2377 / Val-Loss: 0.2375 / Test-Loss: 0.2385 / Time taken: 0:09:04 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 35 / Train-Loss: 0.2376 / Val-Loss: 0.2376 / Test-Loss: 0.2385 / Time taken: 0:09:18 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 13/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 36 / Train-Loss: 0.2376 / Val-Loss: 0.2375 / Test-Loss: 0.2385 / Time taken: 0:09:33 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 13/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 37 / Train-Loss: 0.2376 / Val-Loss: 0.2375 / Test-Loss: 0.2385 / Time taken: 0:09:47 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 38 / Train-Loss: 0.2375 / Val-Loss: 0.2378 / Test-Loss: 0.2386 / Time taken: 0:10:02 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 13/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 39 / Train-Loss: 0.2375 / Val-Loss: 0.2374 / Test-Loss: 0.2385 / Time taken: 0:10:16 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 40 / Train-Loss: 0.2374 / Val-Loss: 0.2375 / Test-Loss: 0.2385 / Time taken: 0:10:31 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 13/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 41 / Train-Loss: 0.2374 / Val-Loss: 0.2374 / Test-Loss: 0.2383 / Time taken: 0:10:45 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 42 / Train-Loss: 0.2374 / Val-Loss: 0.2374 / Test-Loss: 0.2385 / Time taken: 0:11:00 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 43 / Train-Loss: 0.2373 / Val-Loss: 0.2374 / Test-Loss: 0.2385 / Time taken: 0:11:14 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 44 / Train-Loss: 0.2373 / Val-Loss: 0.2375 / Test-Loss: 0.2384 / Time taken: 0:11:36 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 45 / Train-Loss: 0.2373 / Val-Loss: 0.2374 / Test-Loss: 0.2385 / Time taken: 0:11:51 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 46 / Train-Loss: 0.2373 / Val-Loss: 0.2374 / Test-Loss: 0.2384 / Time taken: 0:12:06 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 47 / Train-Loss: 0.2372 / Val-Loss: 0.2375 / Test-Loss: 0.2386 / Time taken: 0:12:28 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 48 / Train-Loss: 0.2371 / Val-Loss: 0.2375 / Test-Loss: 0.2386 / Time taken: 0:12:43 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 49 / Train-Loss: 0.2371 / Val-Loss: 0.2375 / Test-Loss: 0.2385 / Time taken: 0:12:57 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 50 / Train-Loss: 0.2370 / Val-Loss: 0.2374 / Test-Loss: 0.2386 / Time taken: 0:13:12 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 51 / Train-Loss: 0.2370 / Val-Loss: 0.2374 / Test-Loss: 0.2384 / Time taken: 0:13:27 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 52 / Train-Loss: 0.2370 / Val-Loss: 0.2374 / Test-Loss: 0.2384 / Time taken: 0:13:41 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 53 / Train-Loss: 0.2370 / Val-Loss: 0.2376 / Test-Loss: 0.2385 / Time taken: 0:13:55 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 54 / Train-Loss: 0.2370 / Val-Loss: 0.2375 / Test-Loss: 0.2387 / Time taken: 0:14:10 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 55 / Train-Loss: 0.2369 / Val-Loss: 0.2374 / Test-Loss: 0.2386 / Time taken: 0:14:24 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 56 / Train-Loss: 0.2368 / Val-Loss: 0.2374 / Test-Loss: 0.2386 / Time taken: 0:14:39 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 57 / Train-Loss: 0.2368 / Val-Loss: 0.2376 / Test-Loss: 0.2384 / Time taken: 0:14:53 / ---- Currently Best Val-Epoch: 41 \n","596/596 [==============================] - 11s 18ms/step\n","67/67 [==============================] - 1s 17ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-89d90b01-8913-4c99-9a15-0bb36ddae723\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>CAFTT (run: 9)</td>\n","      <td>29</td>\n","      <td>687.138017</td>\n","      <td>27133</td>\n","      <td>0.238057</td>\n","      <td>0.238411</td>\n","      <td>0.065254</td>\n","      <td>0.065593</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>CAFTT (run: 10)</td>\n","      <td>58</td>\n","      <td>1175.236680</td>\n","      <td>27133</td>\n","      <td>0.237128</td>\n","      <td>0.238169</td>\n","      <td>0.065283</td>\n","      <td>0.065611</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>CAFTT (run: 11)</td>\n","      <td>59</td>\n","      <td>1248.218261</td>\n","      <td>27133</td>\n","      <td>0.237067</td>\n","      <td>0.238216</td>\n","      <td>0.065540</td>\n","      <td>0.065780</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>CAFTT (run: 12)</td>\n","      <td>50</td>\n","      <td>1096.780236</td>\n","      <td>27133</td>\n","      <td>0.237433</td>\n","      <td>0.237963</td>\n","      <td>0.065774</td>\n","      <td>0.066086</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>CAFTT (run: 13)</td>\n","      <td>41</td>\n","      <td>893.841639</td>\n","      <td>27133</td>\n","      <td>0.237690</td>\n","      <td>0.238301</td>\n","      <td>0.065890</td>\n","      <td>0.066175</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>149 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89d90b01-8913-4c99-9a15-0bb36ddae723')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-89d90b01-8913-4c99-9a15-0bb36ddae723 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-89d90b01-8913-4c99-9a15-0bb36ddae723');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9885e3f7-9d3d-43f5-a3e0-f2cbc5faee50\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9885e3f7-9d3d-43f5-a3e0-f2cbc5faee50')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9885e3f7-9d3d-43f5-a3e0-f2cbc5faee50 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","144              CAFTT (run: 9)      29   687.138017          27133   \n","145             CAFTT (run: 10)      58  1175.236680          27133   \n","146             CAFTT (run: 11)      59  1248.218261          27133   \n","147             CAFTT (run: 12)      50  1096.780236          27133   \n","148             CAFTT (run: 13)      41   893.841639          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","144    0.238057   0.238411             0.065254            0.065593  \n","145    0.237128   0.238169             0.065283            0.065611  \n","146    0.237067   0.238216             0.065540            0.065780  \n","147    0.237433   0.237963             0.065774            0.066086  \n","148    0.237690   0.238301             0.065890            0.066175  \n","\n","[149 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 14-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 14/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 0 / Train-Loss: 0.2410 / Val-Loss: 0.2388 / Test-Loss: 0.2413 / Time taken: 0:00:28 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 1 / Train-Loss: 0.2411 / Val-Loss: 0.2387 / Test-Loss: 0.2413 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 2 / Train-Loss: 0.2411 / Val-Loss: 0.2387 / Test-Loss: 0.2412 / Time taken: 0:00:57 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0336  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 3 / Train-Loss: 0.2406 / Val-Loss: 0.2384 / Test-Loss: 0.2409 / Time taken: 0:01:12 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0339  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 4 / Train-Loss: 0.2402 / Val-Loss: 0.2380 / Test-Loss: 0.2403 / Time taken: 0:01:26 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0339  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 5 / Train-Loss: 0.2400 / Val-Loss: 0.2378 / Test-Loss: 0.2401 / Time taken: 0:01:47 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.034   : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 6 / Train-Loss: 0.2398 / Val-Loss: 0.2376 / Test-Loss: 0.2400 / Time taken: 0:02:02 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0341  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 7 / Train-Loss: 0.2396 / Val-Loss: 0.2374 / Test-Loss: 0.2398 / Time taken: 0:02:23 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0342  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 8 / Train-Loss: 0.2396 / Val-Loss: 0.2372 / Test-Loss: 0.2395 / Time taken: 0:02:38 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0342  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 9 / Train-Loss: 0.2394 / Val-Loss: 0.2371 / Test-Loss: 0.2395 / Time taken: 0:02:52 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 10 / Train-Loss: 0.2394 / Val-Loss: 0.2369 / Test-Loss: 0.2393 / Time taken: 0:03:15 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 14/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 11 / Train-Loss: 0.2392 / Val-Loss: 0.2370 / Test-Loss: 0.2395 / Time taken: 0:03:31 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 14/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 12 / Train-Loss: 0.2390 / Val-Loss: 0.2370 / Test-Loss: 0.2393 / Time taken: 0:03:45 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 14/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 13 / Train-Loss: 0.2390 / Val-Loss: 0.2367 / Test-Loss: 0.2390 / Time taken: 0:03:59 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 14 / Train-Loss: 0.2389 / Val-Loss: 0.2365 / Test-Loss: 0.2388 / Time taken: 0:04:14 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 15 / Train-Loss: 0.2388 / Val-Loss: 0.2366 / Test-Loss: 0.2388 / Time taken: 0:04:28 / ---- Currently Best Val-Epoch: 14 \n","Ensemble: 14/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 16 / Train-Loss: 0.2386 / Val-Loss: 0.2370 / Test-Loss: 0.2393 / Time taken: 0:04:43 / ---- Currently Best Val-Epoch: 14 \n","Ensemble: 14/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 17 / Train-Loss: 0.2386 / Val-Loss: 0.2364 / Test-Loss: 0.2389 / Time taken: 0:04:57 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 18 / Train-Loss: 0.2385 / Val-Loss: 0.2371 / Test-Loss: 0.2393 / Time taken: 0:05:12 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 14/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 19 / Train-Loss: 0.2384 / Val-Loss: 0.2361 / Test-Loss: 0.2383 / Time taken: 0:05:26 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 20 / Train-Loss: 0.2384 / Val-Loss: 0.2363 / Test-Loss: 0.2389 / Time taken: 0:05:41 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 14/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 21 / Train-Loss: 0.2384 / Val-Loss: 0.2370 / Test-Loss: 0.2392 / Time taken: 0:05:55 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 14/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 22 / Train-Loss: 0.2384 / Val-Loss: 0.2364 / Test-Loss: 0.2386 / Time taken: 0:06:09 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 14/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 23 / Train-Loss: 0.2382 / Val-Loss: 0.2360 / Test-Loss: 0.2386 / Time taken: 0:06:23 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 24 / Train-Loss: 0.2381 / Val-Loss: 0.2361 / Test-Loss: 0.2385 / Time taken: 0:06:38 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 14/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 25 / Train-Loss: 0.2381 / Val-Loss: 0.2364 / Test-Loss: 0.2387 / Time taken: 0:06:52 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 14/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 26 / Train-Loss: 0.2381 / Val-Loss: 0.2367 / Test-Loss: 0.2391 / Time taken: 0:07:07 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 14/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 27 / Train-Loss: 0.2381 / Val-Loss: 0.2359 / Test-Loss: 0.2383 / Time taken: 0:07:21 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 28 / Train-Loss: 0.2380 / Val-Loss: 0.2365 / Test-Loss: 0.2388 / Time taken: 0:07:35 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 14/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 29 / Train-Loss: 0.2380 / Val-Loss: 0.2360 / Test-Loss: 0.2383 / Time taken: 0:07:50 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 14/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 30 / Train-Loss: 0.2379 / Val-Loss: 0.2359 / Test-Loss: 0.2383 / Time taken: 0:08:04 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 31 / Train-Loss: 0.2379 / Val-Loss: 0.2359 / Test-Loss: 0.2382 / Time taken: 0:08:19 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 32 / Train-Loss: 0.2378 / Val-Loss: 0.2359 / Test-Loss: 0.2383 / Time taken: 0:08:34 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 14/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 33 / Train-Loss: 0.2379 / Val-Loss: 0.2359 / Test-Loss: 0.2381 / Time taken: 0:08:48 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 14/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 34 / Train-Loss: 0.2378 / Val-Loss: 0.2358 / Test-Loss: 0.2382 / Time taken: 0:09:02 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 35 / Train-Loss: 0.2378 / Val-Loss: 0.2359 / Test-Loss: 0.2382 / Time taken: 0:09:17 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 14/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 36 / Train-Loss: 0.2378 / Val-Loss: 0.2363 / Test-Loss: 0.2384 / Time taken: 0:09:31 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 14/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 37 / Train-Loss: 0.2378 / Val-Loss: 0.2358 / Test-Loss: 0.2383 / Time taken: 0:09:46 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 38 / Train-Loss: 0.2377 / Val-Loss: 0.2360 / Test-Loss: 0.2382 / Time taken: 0:10:08 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 14/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 39 / Train-Loss: 0.2376 / Val-Loss: 0.2358 / Test-Loss: 0.2381 / Time taken: 0:10:29 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 40 / Train-Loss: 0.2377 / Val-Loss: 0.2360 / Test-Loss: 0.2382 / Time taken: 0:10:52 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 41 / Train-Loss: 0.2376 / Val-Loss: 0.2359 / Test-Loss: 0.2382 / Time taken: 0:11:08 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 42 / Train-Loss: 0.2375 / Val-Loss: 0.2361 / Test-Loss: 0.2383 / Time taken: 0:11:22 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 43 / Train-Loss: 0.2375 / Val-Loss: 0.2359 / Test-Loss: 0.2380 / Time taken: 0:11:37 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 44 / Train-Loss: 0.2375 / Val-Loss: 0.2359 / Test-Loss: 0.2380 / Time taken: 0:11:51 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 45 / Train-Loss: 0.2374 / Val-Loss: 0.2360 / Test-Loss: 0.2381 / Time taken: 0:12:05 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 46 / Train-Loss: 0.2374 / Val-Loss: 0.2359 / Test-Loss: 0.2382 / Time taken: 0:12:20 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 47 / Train-Loss: 0.2374 / Val-Loss: 0.2359 / Test-Loss: 0.2382 / Time taken: 0:12:35 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 48 / Train-Loss: 0.2375 / Val-Loss: 0.2358 / Test-Loss: 0.2380 / Time taken: 0:12:49 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 14/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 49 / Train-Loss: 0.2373 / Val-Loss: 0.2358 / Test-Loss: 0.2383 / Time taken: 0:13:04 / ---- Currently Best Val-Epoch: 49 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 50 / Train-Loss: 0.2374 / Val-Loss: 0.2359 / Test-Loss: 0.2379 / Time taken: 0:13:19 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 14/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 51 / Train-Loss: 0.2373 / Val-Loss: 0.2359 / Test-Loss: 0.2384 / Time taken: 0:13:34 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 14/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 52 / Train-Loss: 0.2373 / Val-Loss: 0.2357 / Test-Loss: 0.2381 / Time taken: 0:13:48 / ---- Currently Best Val-Epoch: 52 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 53 / Train-Loss: 0.2373 / Val-Loss: 0.2358 / Test-Loss: 0.2380 / Time taken: 0:14:03 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 14/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 54 / Train-Loss: 0.2372 / Val-Loss: 0.2358 / Test-Loss: 0.2379 / Time taken: 0:14:17 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 14/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 55 / Train-Loss: 0.2373 / Val-Loss: 0.2358 / Test-Loss: 0.2380 / Time taken: 0:14:31 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 14/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 56 / Train-Loss: 0.2371 / Val-Loss: 0.2358 / Test-Loss: 0.2381 / Time taken: 0:14:45 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 14/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 57 / Train-Loss: 0.2372 / Val-Loss: 0.2357 / Test-Loss: 0.2379 / Time taken: 0:15:00 / ---- Currently Best Val-Epoch: 57 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 58 / Train-Loss: 0.2371 / Val-Loss: 0.2358 / Test-Loss: 0.2380 / Time taken: 0:15:15 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 59 / Train-Loss: 0.2370 / Val-Loss: 0.2358 / Test-Loss: 0.2381 / Time taken: 0:15:30 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 60 / Train-Loss: 0.2371 / Val-Loss: 0.2359 / Test-Loss: 0.2382 / Time taken: 0:15:45 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 61 / Train-Loss: 0.2370 / Val-Loss: 0.2359 / Test-Loss: 0.2380 / Time taken: 0:16:06 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 62 / Train-Loss: 0.2371 / Val-Loss: 0.2359 / Test-Loss: 0.2381 / Time taken: 0:16:28 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 63 / Train-Loss: 0.2370 / Val-Loss: 0.2360 / Test-Loss: 0.2379 / Time taken: 0:16:42 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 64 / Train-Loss: 0.2370 / Val-Loss: 0.2359 / Test-Loss: 0.2378 / Time taken: 0:16:57 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 65 / Train-Loss: 0.2370 / Val-Loss: 0.2360 / Test-Loss: 0.2382 / Time taken: 0:17:12 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 66 / Train-Loss: 0.2369 / Val-Loss: 0.2360 / Test-Loss: 0.2383 / Time taken: 0:17:34 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 67 / Train-Loss: 0.2369 / Val-Loss: 0.2360 / Test-Loss: 0.2382 / Time taken: 0:17:51 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 68 / Train-Loss: 0.2370 / Val-Loss: 0.2360 / Test-Loss: 0.2379 / Time taken: 0:18:13 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 69 / Train-Loss: 0.2369 / Val-Loss: 0.2360 / Test-Loss: 0.2380 / Time taken: 0:18:28 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 70 / Train-Loss: 0.2369 / Val-Loss: 0.2359 / Test-Loss: 0.2377 / Time taken: 0:18:49 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 71 / Train-Loss: 0.2368 / Val-Loss: 0.2361 / Test-Loss: 0.2382 / Time taken: 0:19:11 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 72 / Train-Loss: 0.2368 / Val-Loss: 0.2359 / Test-Loss: 0.2379 / Time taken: 0:19:26 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 73 / Train-Loss: 0.2367 / Val-Loss: 0.2361 / Test-Loss: 0.2381 / Time taken: 0:19:47 / ---- Currently Best Val-Epoch: 57 \n","596/596 [==============================] - 12s 19ms/step\n","67/67 [==============================] - 1s 16ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-35f47b77-189b-48da-8fcd-c8b8c07c69c8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>CAFTT (run: 10)</td>\n","      <td>58</td>\n","      <td>1175.236680</td>\n","      <td>27133</td>\n","      <td>0.237128</td>\n","      <td>0.238169</td>\n","      <td>0.065283</td>\n","      <td>0.065611</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>CAFTT (run: 11)</td>\n","      <td>59</td>\n","      <td>1248.218261</td>\n","      <td>27133</td>\n","      <td>0.237067</td>\n","      <td>0.238216</td>\n","      <td>0.065540</td>\n","      <td>0.065780</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>CAFTT (run: 12)</td>\n","      <td>50</td>\n","      <td>1096.780236</td>\n","      <td>27133</td>\n","      <td>0.237433</td>\n","      <td>0.237963</td>\n","      <td>0.065774</td>\n","      <td>0.066086</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>CAFTT (run: 13)</td>\n","      <td>41</td>\n","      <td>893.841639</td>\n","      <td>27133</td>\n","      <td>0.237690</td>\n","      <td>0.238301</td>\n","      <td>0.065890</td>\n","      <td>0.066175</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>CAFTT (run: 14)</td>\n","      <td>57</td>\n","      <td>1187.882093</td>\n","      <td>27133</td>\n","      <td>0.237231</td>\n","      <td>0.237943</td>\n","      <td>0.066632</td>\n","      <td>0.066834</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35f47b77-189b-48da-8fcd-c8b8c07c69c8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-35f47b77-189b-48da-8fcd-c8b8c07c69c8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-35f47b77-189b-48da-8fcd-c8b8c07c69c8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bb4cc48e-1d60-4365-8196-8eb72236c622\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb4cc48e-1d60-4365-8196-8eb72236c622')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bb4cc48e-1d60-4365-8196-8eb72236c622 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","145             CAFTT (run: 10)      58  1175.236680          27133   \n","146             CAFTT (run: 11)      59  1248.218261          27133   \n","147             CAFTT (run: 12)      50  1096.780236          27133   \n","148             CAFTT (run: 13)      41   893.841639          27133   \n","149             CAFTT (run: 14)      57  1187.882093          27133   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","145    0.237128   0.238169             0.065283            0.065611  \n","146    0.237067   0.238216             0.065540            0.065780  \n","147    0.237433   0.237963             0.065774            0.066086  \n","148    0.237690   0.238301             0.065890            0.066175  \n","149    0.237231   0.237943             0.066632            0.066834  \n","\n","[150 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# Create the dataframes needed for evaluation:\n","# --------------------\n","# NOTE: in the 2021 Gorishniy et al paper the batch size is different for the different Datasets\n","# but is not hyperparameter tuned. Bigger datasets they used a batch size of 1024 and\n","# for smaller datasets a batch size of (256/512).\n","batch_size = 1024\n","learn_data = df_to_tensor(df_freq_prep_nn[bool_in_learn], feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size)\n","test_data = df_to_tensor(df_freq_prep_nn[bool_in_test], feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","# NOTE we use at first just a fraction of the data to test the code:\n","learn_train_dummy_data = df_to_tensor(df_freq_prep_nn[bool_in_learn_train_dummy], feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size,\n","                                      dummy_data_for_build=True)\n","\n","for run_index in range(15):\n","    # Create the dataframes needed for training:\n","    learn_train_data = df_to_tensor(df_freq_prep_nn[train_val_split[f\"learn_train_{run_index}\"]],\n","                                    feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size)\n","    learn_val_data = df_to_tensor(df_freq_prep_nn[train_val_split[f\"learn_val_{run_index}\"]],\n","                                  feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------We are at Model: {str(run_index).zfill(2)}-----------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    # Define FT-Transformer Models:\n","    # ----------------------\n","    # NOTE: we use here tensorflow/keras model subclasses (not the functional or sequential api)\n","    # NOTE: we use here instead of the .fit function a costum training loop\n","\n","    # create the model:\n","    # ----------------------\n","    set_random_seeds(int(random_seeds[run_index]))\n","\n","    FT_transformer = EnhActuar.Feature_Tokenizer_Transformer(\n","            emb_dim = 32, # NOTE: In the default setting for the 2021 Gorishniy paper they used emb_dim = 192 (but the parameter size would here go trough the roof, so we use something smaller)\n","            nr_features = nr_col,\n","            cat_features = cat_col,\n","            cat_vocabulary = cat_vocabulary,\n","            count_transformer_blocks = 3,\n","            attention_n_heads = 8,\n","            attention_dropout = 0.2,\n","            ffn_d_hidden = None, # NOTE: change to None if ReGLU should be used -> None uses default value (4/3*emb_dim), they write that they used 2*emb_dim if not ReGLU.\n","            ffn_activation_ReGLU = True, # NOTE: set True if ReGLU should be used\n","            ffn_dropout = 0.1,\n","            prenormalization = True,\n","            output_dim = 1,\n","            last_activation = 'exponential',\n","            exposure_name = \"Exposure_x_GLM3_pred\",\n","            last_layer_initial_weights = \"zeros\",\n","            last_layer_initial_bias = \"zeros\",\n","            seed_nr = int(random_seeds[run_index])\n","    )\n","\n","    # See here regarding costum training loop: https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch\n","\n","    # Instantiate an optimizer to train the model.\n","    # ----------------------\n","    # create an optimizer AdamW with learning rate 1e-4, weight decay 1e-5:\n","    optimizer = tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5)\n","\n","    # Instantiate a loss function\n","    # ----------------------\n","    # we use our own loss function here\n","    # because it is not included in tensorflow in the same way (see section loss function for more details):\n","    loss_fn = Poisson_loss_for_tf_Wrapped()\n","\n","    # Prepare the metrics.\n","    # ----------------------\n","    # we use a costume metric here (because it is not included in tensorflow in the same way):\n","    train_acc_metric = Poisson_Metric_for_tf()\n","    val_acc_metric = Poisson_Metric_for_tf()\n","    test_acc_metric = Poisson_Metric_for_tf()\n","\n","    @tf.function\n","    def train_step(x, y):\n","        # Open a GradientTape to record the operations run during the forward pass, which enables auto-differentiation.\n","        with tf.GradientTape() as tape:\n","            # Run the forward pass of the layer. The operations that the layer applies to its inputs are going to be recorded on the GradientTape.\n","            y_pred = FT_transformer(x, training=True)[\"output\"]  # prediction for this minibatch\n","            # Compute the loss value for this minibatch.\n","            loss_value = loss_fn(y, y_pred)\n","        # Use the gradient tape to automatically retrieve the gradients of the trainable variables with respect to the loss.\n","        grads = tape.gradient(loss_value, FT_transformer.trainable_weights)\n","        # Run one step of gradient descent by updating the value of the variables to minimize the loss.\n","        optimizer.apply_gradients(zip(grads, FT_transformer.trainable_weights))\n","        # Update training metric.\n","        train_acc_metric.update_state(y, y_pred)\n","        return loss_value\n","\n","    @tf.function\n","    def val_step(x, y):\n","        # Run the forward pass of the layer.\n","        # (note: training=False is needed because the layers have different behavior during training versus inference (e.g. Dropout))\n","        y_pred = FT_transformer(x, training=False)[\"output\"]\n","        # Update val metrics\n","        val_acc_metric.update_state(y, y_pred)\n","\n","    @tf.function\n","    def test_step(x, y):\n","        # Run the forward pass of the layer.\n","        # (note: training=False is needed because the layers have different behavior during training versus inference (e.g. Dropout))\n","        y_pred = FT_transformer(x, training=False)[\"output\"]\n","        # Update val metrics\n","        test_acc_metric.update_state(y, y_pred)\n","\n","    # model fitting:\n","    # ----------------------\n","    start_time = time.time()\n","    Val_Progress = helper.Easy_ProgressTracker(patience=15)\n","    epochs = 500\n","\n","    for epoch in range(epochs):\n","        # Iterate over the batches of the dataset.\n","        for step, (x_batch_train, y_batch_train) in enumerate(learn_train_data):\n","            loss_value = train_step(x_batch_train, y_batch_train)\n","            helper.costume_progress_bar(f\"Ensemble: {str(run_index).zfill(2)}/{14} / Epoch: {epoch} / Batch: {step} / Train-Loss (Batch): {round(float(loss_value),4)}\",step,len(learn_train_data), 30)\n","\n","        # Display metrics at the end of each epoch.\n","        print_train_loss = train_acc_metric.result()\n","        # Reset training metrics at the end of each epoch\n","        train_acc_metric.reset_states()\n","\n","        # Run a validation at the end of each epoch.\n","        for x_batch_val, y_batch_val in learn_val_data:\n","            val_step(x_batch_val, y_batch_val)\n","        print_val_loss = val_acc_metric.result()\n","        val_acc_metric.reset_states()\n","        for x_batch_test, y_batch_test in test_data:\n","            test_step(x_batch_test, y_batch_test)\n","        print_test_loss = test_acc_metric.result()\n","        test_acc_metric.reset_states()\n","\n","        Val_Progress(current_epoch=epoch, current_score = print_val_loss)\n","\n","        print(f\"\\nEnsemble: {str(run_index).zfill(2)}/{14} / Epoch: {epoch} / Train-Loss: %.4f / Val-Loss: %.4f / Test-Loss: %.4f / Time taken: %s / ---- Currently Best Val-Epoch: %d\" % (\n","            # str(run_index).zfill(2),\n","            float(print_train_loss),\n","            float(print_val_loss),\n","            float(print_test_loss),\n","            datetime.timedelta(seconds=int(time.time() - start_time)),\n","            Val_Progress.best_epoch\n","            ), end = \" \")\n","        if Val_Progress.progress == True:\n","            print(\"<------- Best VAL Epoch so far\")\n","        else:\n","            print(\"\\r\")\n","\n","\n","        # Callback: save best model / early stopping:\n","        # ----------------------\n","        earliest_epoch2save = 10\n","        if Val_Progress.progress and Val_Progress.current_epoch >= earliest_epoch2save:\n","            FT_transformer.save_weights(f'{storage_path}/saved_models/Poisson_CAFTT_{run_index}.weights.h5')\n","        if Val_Progress.patience_over:\n","            break\n","\n","    # create some metrics after the loop\n","    best_epoch_FT_transformer = Val_Progress.best_epoch\n","    execution_time_FT_transformer = time.time() - start_time\n","\n","    # load the best saved model and epochs_and_time from the pickle file:\n","    # ----------------------\n","    FT_transformer.load_weights(f'{storage_path}/saved_models/Poisson_CAFTT_{run_index}.weights.h5')\n","\n","    # predict with the model:\n","    # ----------------------\n","    y_pred[\"train\"][f\"CAFTT\"] = np.array([x for [x] in FT_transformer.predict(learn_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                )[\"output\"]])\n","    y_pred[\"test\"][f\"CAFTT\"] = np.array([x for [x] in FT_transformer.predict(test_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                )[\"output\"]])\n","\n","    # evaluate the model:\n","    # ----------------------\n","    CAFTT_results = Results(model=f\"CAFTT (run: {run_index})\",\n","                                epochs=best_epoch_FT_transformer,\n","                                run_time=execution_time_FT_transformer,\n","                                nr_parameters=[np.sum([np.prod(v.get_shape().as_list()) for v in FT_transformer.trainable_weights])],\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"CAFTT\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"CAFTT\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"CAFTT\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"CAFTT\"].sum()/exposure[\"test\"].sum())\n","    # store the results in the dataframe:\n","    store_results_in_df(CAFTT_results)\n","    display(df_results)\n","    # save the results:\n","    with open(f'{storage_path}/Data/df_results.pickle', 'wb') as handle:\n","        pickle.dump(df_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZrvIt_sNKw2z"},"outputs":[],"source":["# # save the results:\n","# with open(f'{storage_path}/Data/df_results.pickle', 'wb') as handle:\n","#     pickle.dump(df_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# load the results:\n","with open(f'{storage_path}/Data/df_results.pickle', 'rb') as handle:\n","    df_results = pickle.load(handle)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3IPmjCg5jymw"},"source":["## 4.3 LocalGLM-FT-Transformer:  "]},{"cell_type":"markdown","metadata":{"id":"-zCJQSTNitmf"},"source":["Note: we run the code 15 times on different seeds (to calc the avg and std of runtime and results)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4556795,"status":"ok","timestamp":1699187117556,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"NWgC23RMjPC9","outputId":"ba37b8c1-8110-41d3-b84a-6ebdf9571e60"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 00-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 00/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 0 / Train-Loss: 0.2414 / Val-Loss: 0.2455 / Test-Loss: 0.2424 / Time taken: 0:00:44 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 1 / Train-Loss: 0.2413 / Val-Loss: 0.2454 / Test-Loss: 0.2422 / Time taken: 0:00:58 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 2 / Train-Loss: 0.2412 / Val-Loss: 0.2453 / Test-Loss: 0.2420 / Time taken: 0:01:17 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 3 / Train-Loss: 0.2410 / Val-Loss: 0.2453 / Test-Loss: 0.2418 / Time taken: 0:01:31 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 4 / Train-Loss: 0.2409 / Val-Loss: 0.2452 / Test-Loss: 0.2417 / Time taken: 0:01:45 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 5 / Train-Loss: 0.2408 / Val-Loss: 0.2451 / Test-Loss: 0.2415 / Time taken: 0:01:59 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 6 / Train-Loss: 0.2406 / Val-Loss: 0.2450 / Test-Loss: 0.2414 / Time taken: 0:02:12 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 7 / Train-Loss: 0.2405 / Val-Loss: 0.2449 / Test-Loss: 0.2412 / Time taken: 0:02:26 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 8 / Train-Loss: 0.2403 / Val-Loss: 0.2446 / Test-Loss: 0.2408 / Time taken: 0:02:40 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 9 / Train-Loss: 0.2401 / Val-Loss: 0.2446 / Test-Loss: 0.2407 / Time taken: 0:03:02 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 10 / Train-Loss: 0.2399 / Val-Loss: 0.2443 / Test-Loss: 0.2404 / Time taken: 0:03:23 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 00/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 11 / Train-Loss: 0.2397 / Val-Loss: 0.2441 / Test-Loss: 0.2402 / Time taken: 0:03:37 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 12 / Train-Loss: 0.2395 / Val-Loss: 0.2439 / Test-Loss: 0.2399 / Time taken: 0:04:00 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 13 / Train-Loss: 0.2393 / Val-Loss: 0.2437 / Test-Loss: 0.2397 / Time taken: 0:04:15 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 14 / Train-Loss: 0.2391 / Val-Loss: 0.2436 / Test-Loss: 0.2397 / Time taken: 0:04:29 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 15 / Train-Loss: 0.2390 / Val-Loss: 0.2434 / Test-Loss: 0.2396 / Time taken: 0:04:51 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 16 / Train-Loss: 0.2389 / Val-Loss: 0.2433 / Test-Loss: 0.2395 / Time taken: 0:05:05 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 17 / Train-Loss: 0.2387 / Val-Loss: 0.2432 / Test-Loss: 0.2394 / Time taken: 0:05:27 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 18 / Train-Loss: 0.2386 / Val-Loss: 0.2432 / Test-Loss: 0.2395 / Time taken: 0:05:41 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 00/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 19 / Train-Loss: 0.2385 / Val-Loss: 0.2427 / Test-Loss: 0.2391 / Time taken: 0:06:04 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 20 / Train-Loss: 0.2385 / Val-Loss: 0.2429 / Test-Loss: 0.2390 / Time taken: 0:06:26 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 00/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 21 / Train-Loss: 0.2383 / Val-Loss: 0.2428 / Test-Loss: 0.2392 / Time taken: 0:06:40 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 00/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 22 / Train-Loss: 0.2383 / Val-Loss: 0.2426 / Test-Loss: 0.2390 / Time taken: 0:07:02 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 23 / Train-Loss: 0.2382 / Val-Loss: 0.2428 / Test-Loss: 0.2391 / Time taken: 0:07:25 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 00/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 24 / Train-Loss: 0.2381 / Val-Loss: 0.2427 / Test-Loss: 0.2390 / Time taken: 0:07:38 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 00/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 25 / Train-Loss: 0.2381 / Val-Loss: 0.2427 / Test-Loss: 0.2390 / Time taken: 0:08:00 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 00/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 26 / Train-Loss: 0.2380 / Val-Loss: 0.2428 / Test-Loss: 0.2390 / Time taken: 0:08:14 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 00/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 27 / Train-Loss: 0.2380 / Val-Loss: 0.2425 / Test-Loss: 0.2389 / Time taken: 0:08:35 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 28 / Train-Loss: 0.2379 / Val-Loss: 0.2425 / Test-Loss: 0.2389 / Time taken: 0:08:58 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 00/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 29 / Train-Loss: 0.2378 / Val-Loss: 0.2426 / Test-Loss: 0.2390 / Time taken: 0:09:13 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 00/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 30 / Train-Loss: 0.2379 / Val-Loss: 0.2425 / Test-Loss: 0.2389 / Time taken: 0:09:27 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 31 / Train-Loss: 0.2377 / Val-Loss: 0.2426 / Test-Loss: 0.2389 / Time taken: 0:09:41 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 00/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 32 / Train-Loss: 0.2377 / Val-Loss: 0.2424 / Test-Loss: 0.2388 / Time taken: 0:09:54 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 33 / Train-Loss: 0.2376 / Val-Loss: 0.2426 / Test-Loss: 0.2389 / Time taken: 0:10:09 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 00/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 34 / Train-Loss: 0.2376 / Val-Loss: 0.2425 / Test-Loss: 0.2389 / Time taken: 0:10:22 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 00/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 35 / Train-Loss: 0.2375 / Val-Loss: 0.2424 / Test-Loss: 0.2389 / Time taken: 0:10:36 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 36 / Train-Loss: 0.2375 / Val-Loss: 0.2424 / Test-Loss: 0.2387 / Time taken: 0:10:50 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 00/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 37 / Train-Loss: 0.2375 / Val-Loss: 0.2424 / Test-Loss: 0.2388 / Time taken: 0:11:04 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 00/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 38 / Train-Loss: 0.2375 / Val-Loss: 0.2424 / Test-Loss: 0.2387 / Time taken: 0:11:18 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 39 / Train-Loss: 0.2374 / Val-Loss: 0.2425 / Test-Loss: 0.2389 / Time taken: 0:11:32 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 40 / Train-Loss: 0.2373 / Val-Loss: 0.2426 / Test-Loss: 0.2388 / Time taken: 0:11:46 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 41 / Train-Loss: 0.2373 / Val-Loss: 0.2426 / Test-Loss: 0.2388 / Time taken: 0:11:59 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 42 / Train-Loss: 0.2372 / Val-Loss: 0.2425 / Test-Loss: 0.2387 / Time taken: 0:12:13 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 43 / Train-Loss: 0.2373 / Val-Loss: 0.2424 / Test-Loss: 0.2387 / Time taken: 0:12:27 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 44 / Train-Loss: 0.2372 / Val-Loss: 0.2426 / Test-Loss: 0.2388 / Time taken: 0:12:41 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 45 / Train-Loss: 0.2371 / Val-Loss: 0.2425 / Test-Loss: 0.2387 / Time taken: 0:12:55 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 46 / Train-Loss: 0.2370 / Val-Loss: 0.2426 / Test-Loss: 0.2388 / Time taken: 0:13:09 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 47 / Train-Loss: 0.2370 / Val-Loss: 0.2426 / Test-Loss: 0.2390 / Time taken: 0:13:23 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 48 / Train-Loss: 0.2371 / Val-Loss: 0.2427 / Test-Loss: 0.2390 / Time taken: 0:13:36 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 49 / Train-Loss: 0.2370 / Val-Loss: 0.2424 / Test-Loss: 0.2387 / Time taken: 0:13:50 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 50 / Train-Loss: 0.2370 / Val-Loss: 0.2426 / Test-Loss: 0.2389 / Time taken: 0:14:04 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 51 / Train-Loss: 0.2369 / Val-Loss: 0.2425 / Test-Loss: 0.2388 / Time taken: 0:14:18 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 52 / Train-Loss: 0.2369 / Val-Loss: 0.2424 / Test-Loss: 0.2388 / Time taken: 0:14:32 / ---- Currently Best Val-Epoch: 37 \n","Ensemble: 00/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 00/14 / Epoch: 53 / Train-Loss: 0.2369 / Val-Loss: 0.2426 / Test-Loss: 0.2388 / Time taken: 0:14:46 / ---- Currently Best Val-Epoch: 37 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 16ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-b57cd0ae-7a9c-4b6f-afde-8dcbe46e7db5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>CAFTT (run: 11)</td>\n","      <td>59</td>\n","      <td>1248.218261</td>\n","      <td>27133</td>\n","      <td>0.237067</td>\n","      <td>0.238216</td>\n","      <td>0.065540</td>\n","      <td>0.065780</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>CAFTT (run: 12)</td>\n","      <td>50</td>\n","      <td>1096.780236</td>\n","      <td>27133</td>\n","      <td>0.237433</td>\n","      <td>0.237963</td>\n","      <td>0.065774</td>\n","      <td>0.066086</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>CAFTT (run: 13)</td>\n","      <td>41</td>\n","      <td>893.841639</td>\n","      <td>27133</td>\n","      <td>0.237690</td>\n","      <td>0.238301</td>\n","      <td>0.065890</td>\n","      <td>0.066175</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>CAFTT (run: 14)</td>\n","      <td>57</td>\n","      <td>1187.882093</td>\n","      <td>27133</td>\n","      <td>0.237231</td>\n","      <td>0.237943</td>\n","      <td>0.066632</td>\n","      <td>0.066834</td>\n","    </tr>\n","    <tr>\n","      <th>150</th>\n","      <td>LocalGLMftt (run: 0)</td>\n","      <td>37</td>\n","      <td>886.447916</td>\n","      <td>27430</td>\n","      <td>0.238011</td>\n","      <td>0.238797</td>\n","      <td>0.068197</td>\n","      <td>0.068621</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>151 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b57cd0ae-7a9c-4b6f-afde-8dcbe46e7db5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b57cd0ae-7a9c-4b6f-afde-8dcbe46e7db5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b57cd0ae-7a9c-4b6f-afde-8dcbe46e7db5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bf8061c8-5492-4a30-8aa8-9277f5e3a8cd\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf8061c8-5492-4a30-8aa8-9277f5e3a8cd')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bf8061c8-5492-4a30-8aa8-9277f5e3a8cd button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","146             CAFTT (run: 11)      59  1248.218261          27133   \n","147             CAFTT (run: 12)      50  1096.780236          27133   \n","148             CAFTT (run: 13)      41   893.841639          27133   \n","149             CAFTT (run: 14)      57  1187.882093          27133   \n","150        LocalGLMftt (run: 0)      37   886.447916          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","146    0.237067   0.238216             0.065540            0.065780  \n","147    0.237433   0.237963             0.065774            0.066086  \n","148    0.237690   0.238301             0.065890            0.066175  \n","149    0.237231   0.237943             0.066632            0.066834  \n","150    0.238011   0.238797             0.068197            0.068621  \n","\n","[151 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 01-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 01/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0075  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 0 / Train-Loss: 0.2413 / Val-Loss: 0.2461 / Test-Loss: 0.2424 / Time taken: 0:00:30 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0071  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 1 / Train-Loss: 0.2413 / Val-Loss: 0.2464 / Test-Loss: 0.2426 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 01/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0068  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 2 / Train-Loss: 0.2412 / Val-Loss: 0.2462 / Test-Loss: 0.2422 / Time taken: 0:01:06 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 01/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0067  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 3 / Train-Loss: 0.2410 / Val-Loss: 0.2460 / Test-Loss: 0.2419 / Time taken: 0:01:20 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0067  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 4 / Train-Loss: 0.2408 / Val-Loss: 0.2458 / Test-Loss: 0.2416 / Time taken: 0:01:34 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0066  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 5 / Train-Loss: 0.2406 / Val-Loss: 0.2457 / Test-Loss: 0.2415 / Time taken: 0:01:48 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0067  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 6 / Train-Loss: 0.2405 / Val-Loss: 0.2456 / Test-Loss: 0.2413 / Time taken: 0:02:01 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0067  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 7 / Train-Loss: 0.2404 / Val-Loss: 0.2456 / Test-Loss: 0.2413 / Time taken: 0:02:15 / ---- Currently Best Val-Epoch: 6 \n","Ensemble: 01/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0066  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 8 / Train-Loss: 0.2403 / Val-Loss: 0.2454 / Test-Loss: 0.2409 / Time taken: 0:02:29 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0067  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 9 / Train-Loss: 0.2402 / Val-Loss: 0.2452 / Test-Loss: 0.2407 / Time taken: 0:02:43 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 10 / Train-Loss: 0.2400 / Val-Loss: 0.2451 / Test-Loss: 0.2405 / Time taken: 0:02:57 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 01/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 11 / Train-Loss: 0.2399 / Val-Loss: 0.2450 / Test-Loss: 0.2404 / Time taken: 0:03:10 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 12 / Train-Loss: 0.2398 / Val-Loss: 0.2448 / Test-Loss: 0.2402 / Time taken: 0:03:25 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 13 / Train-Loss: 0.2396 / Val-Loss: 0.2447 / Test-Loss: 0.2400 / Time taken: 0:03:38 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 14 / Train-Loss: 0.2394 / Val-Loss: 0.2445 / Test-Loss: 0.2398 / Time taken: 0:03:52 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 15 / Train-Loss: 0.2393 / Val-Loss: 0.2445 / Test-Loss: 0.2398 / Time taken: 0:04:06 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 16 / Train-Loss: 0.2391 / Val-Loss: 0.2443 / Test-Loss: 0.2396 / Time taken: 0:04:20 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 17 / Train-Loss: 0.2390 / Val-Loss: 0.2443 / Test-Loss: 0.2397 / Time taken: 0:04:34 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 18 / Train-Loss: 0.2388 / Val-Loss: 0.2442 / Test-Loss: 0.2395 / Time taken: 0:04:48 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 19 / Train-Loss: 0.2386 / Val-Loss: 0.2441 / Test-Loss: 0.2395 / Time taken: 0:05:02 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 20 / Train-Loss: 0.2385 / Val-Loss: 0.2442 / Test-Loss: 0.2395 / Time taken: 0:05:16 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 01/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 21 / Train-Loss: 0.2384 / Val-Loss: 0.2439 / Test-Loss: 0.2394 / Time taken: 0:05:29 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 22 / Train-Loss: 0.2383 / Val-Loss: 0.2438 / Test-Loss: 0.2391 / Time taken: 0:05:43 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 23 / Train-Loss: 0.2382 / Val-Loss: 0.2439 / Test-Loss: 0.2392 / Time taken: 0:05:57 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 01/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 24 / Train-Loss: 0.2381 / Val-Loss: 0.2436 / Test-Loss: 0.2391 / Time taken: 0:06:11 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 25 / Train-Loss: 0.2381 / Val-Loss: 0.2438 / Test-Loss: 0.2392 / Time taken: 0:06:25 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 01/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 26 / Train-Loss: 0.2380 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:06:38 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 27 / Train-Loss: 0.2379 / Val-Loss: 0.2437 / Test-Loss: 0.2390 / Time taken: 0:06:53 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 01/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 28 / Train-Loss: 0.2378 / Val-Loss: 0.2437 / Test-Loss: 0.2391 / Time taken: 0:07:06 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 01/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 29 / Train-Loss: 0.2377 / Val-Loss: 0.2435 / Test-Loss: 0.2390 / Time taken: 0:07:20 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 30 / Train-Loss: 0.2376 / Val-Loss: 0.2436 / Test-Loss: 0.2391 / Time taken: 0:07:34 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 01/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 31 / Train-Loss: 0.2376 / Val-Loss: 0.2434 / Test-Loss: 0.2390 / Time taken: 0:07:48 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 32 / Train-Loss: 0.2376 / Val-Loss: 0.2434 / Test-Loss: 0.2391 / Time taken: 0:08:02 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 01/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 33 / Train-Loss: 0.2374 / Val-Loss: 0.2433 / Test-Loss: 0.2389 / Time taken: 0:08:15 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 34 / Train-Loss: 0.2375 / Val-Loss: 0.2433 / Test-Loss: 0.2388 / Time taken: 0:08:30 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 35 / Train-Loss: 0.2373 / Val-Loss: 0.2433 / Test-Loss: 0.2389 / Time taken: 0:08:43 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 01/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 36 / Train-Loss: 0.2373 / Val-Loss: 0.2433 / Test-Loss: 0.2389 / Time taken: 0:08:57 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 37 / Train-Loss: 0.2373 / Val-Loss: 0.2433 / Test-Loss: 0.2390 / Time taken: 0:09:11 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 01/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 38 / Train-Loss: 0.2372 / Val-Loss: 0.2432 / Test-Loss: 0.2389 / Time taken: 0:09:25 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 39 / Train-Loss: 0.2371 / Val-Loss: 0.2434 / Test-Loss: 0.2389 / Time taken: 0:09:39 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 01/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 40 / Train-Loss: 0.2371 / Val-Loss: 0.2432 / Test-Loss: 0.2389 / Time taken: 0:09:53 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 41 / Train-Loss: 0.2371 / Val-Loss: 0.2432 / Test-Loss: 0.2388 / Time taken: 0:10:07 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 42 / Train-Loss: 0.2371 / Val-Loss: 0.2431 / Test-Loss: 0.2388 / Time taken: 0:10:21 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 01/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 43 / Train-Loss: 0.2370 / Val-Loss: 0.2431 / Test-Loss: 0.2388 / Time taken: 0:10:35 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 44 / Train-Loss: 0.2369 / Val-Loss: 0.2431 / Test-Loss: 0.2389 / Time taken: 0:10:49 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 45 / Train-Loss: 0.2368 / Val-Loss: 0.2432 / Test-Loss: 0.2389 / Time taken: 0:11:03 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 46 / Train-Loss: 0.2370 / Val-Loss: 0.2432 / Test-Loss: 0.2388 / Time taken: 0:11:17 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 47 / Train-Loss: 0.2368 / Val-Loss: 0.2432 / Test-Loss: 0.2388 / Time taken: 0:11:30 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 48 / Train-Loss: 0.2368 / Val-Loss: 0.2431 / Test-Loss: 0.2388 / Time taken: 0:11:44 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 49 / Train-Loss: 0.2366 / Val-Loss: 0.2431 / Test-Loss: 0.2389 / Time taken: 0:12:06 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 50 / Train-Loss: 0.2367 / Val-Loss: 0.2431 / Test-Loss: 0.2387 / Time taken: 0:12:27 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 51 / Train-Loss: 0.2367 / Val-Loss: 0.2432 / Test-Loss: 0.2388 / Time taken: 0:12:50 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 52 / Train-Loss: 0.2367 / Val-Loss: 0.2431 / Test-Loss: 0.2387 / Time taken: 0:13:05 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 53 / Train-Loss: 0.2366 / Val-Loss: 0.2432 / Test-Loss: 0.2388 / Time taken: 0:13:19 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 54 / Train-Loss: 0.2366 / Val-Loss: 0.2432 / Test-Loss: 0.2388 / Time taken: 0:13:33 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 55 / Train-Loss: 0.2365 / Val-Loss: 0.2433 / Test-Loss: 0.2388 / Time taken: 0:13:47 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 56 / Train-Loss: 0.2365 / Val-Loss: 0.2433 / Test-Loss: 0.2388 / Time taken: 0:14:00 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 57 / Train-Loss: 0.2365 / Val-Loss: 0.2431 / Test-Loss: 0.2388 / Time taken: 0:14:14 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 01/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 01/14 / Epoch: 58 / Train-Loss: 0.2364 / Val-Loss: 0.2433 / Test-Loss: 0.2388 / Time taken: 0:14:28 / ---- Currently Best Val-Epoch: 42 \n","596/596 [==============================] - 9s 14ms/step\n","67/67 [==============================] - 1s 17ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-f3043051-6d35-4b70-8cd8-06d1bb5059ec\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>CAFTT (run: 12)</td>\n","      <td>50</td>\n","      <td>1096.780236</td>\n","      <td>27133</td>\n","      <td>0.237433</td>\n","      <td>0.237963</td>\n","      <td>0.065774</td>\n","      <td>0.066086</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>CAFTT (run: 13)</td>\n","      <td>41</td>\n","      <td>893.841639</td>\n","      <td>27133</td>\n","      <td>0.237690</td>\n","      <td>0.238301</td>\n","      <td>0.065890</td>\n","      <td>0.066175</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>CAFTT (run: 14)</td>\n","      <td>57</td>\n","      <td>1187.882093</td>\n","      <td>27133</td>\n","      <td>0.237231</td>\n","      <td>0.237943</td>\n","      <td>0.066632</td>\n","      <td>0.066834</td>\n","    </tr>\n","    <tr>\n","      <th>150</th>\n","      <td>LocalGLMftt (run: 0)</td>\n","      <td>37</td>\n","      <td>886.447916</td>\n","      <td>27430</td>\n","      <td>0.238011</td>\n","      <td>0.238797</td>\n","      <td>0.068197</td>\n","      <td>0.068621</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>LocalGLMftt (run: 1)</td>\n","      <td>42</td>\n","      <td>868.665794</td>\n","      <td>27430</td>\n","      <td>0.237444</td>\n","      <td>0.238771</td>\n","      <td>0.067885</td>\n","      <td>0.068379</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>152 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3043051-6d35-4b70-8cd8-06d1bb5059ec')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f3043051-6d35-4b70-8cd8-06d1bb5059ec button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f3043051-6d35-4b70-8cd8-06d1bb5059ec');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0ada72fd-8d4d-474f-b078-2d64cb41ec0e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ada72fd-8d4d-474f-b078-2d64cb41ec0e')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0ada72fd-8d4d-474f-b078-2d64cb41ec0e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","147             CAFTT (run: 12)      50  1096.780236          27133   \n","148             CAFTT (run: 13)      41   893.841639          27133   \n","149             CAFTT (run: 14)      57  1187.882093          27133   \n","150        LocalGLMftt (run: 0)      37   886.447916          27430   \n","151        LocalGLMftt (run: 1)      42   868.665794          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","147    0.237433   0.237963             0.065774            0.066086  \n","148    0.237690   0.238301             0.065890            0.066175  \n","149    0.237231   0.237943             0.066632            0.066834  \n","150    0.238011   0.238797             0.068197            0.068621  \n","151    0.237444   0.238771             0.067885            0.068379  \n","\n","[152 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 02-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 02/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 0 / Train-Loss: 0.2419 / Val-Loss: 0.2407 / Test-Loss: 0.2426 / Time taken: 0:00:31 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 1 / Train-Loss: 0.2418 / Val-Loss: 0.2405 / Test-Loss: 0.2422 / Time taken: 0:00:45 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 2 / Train-Loss: 0.2416 / Val-Loss: 0.2403 / Test-Loss: 0.2418 / Time taken: 0:00:59 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 3 / Train-Loss: 0.2414 / Val-Loss: 0.2401 / Test-Loss: 0.2415 / Time taken: 0:01:13 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 4 / Train-Loss: 0.2412 / Val-Loss: 0.2399 / Test-Loss: 0.2413 / Time taken: 0:01:35 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 5 / Train-Loss: 0.2410 / Val-Loss: 0.2396 / Test-Loss: 0.2411 / Time taken: 0:01:49 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 6 / Train-Loss: 0.2408 / Val-Loss: 0.2394 / Test-Loss: 0.2409 / Time taken: 0:02:03 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 7 / Train-Loss: 0.2407 / Val-Loss: 0.2393 / Test-Loss: 0.2407 / Time taken: 0:02:17 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 8 / Train-Loss: 0.2404 / Val-Loss: 0.2390 / Test-Loss: 0.2405 / Time taken: 0:02:31 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 9 / Train-Loss: 0.2402 / Val-Loss: 0.2389 / Test-Loss: 0.2403 / Time taken: 0:02:44 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 10 / Train-Loss: 0.2400 / Val-Loss: 0.2388 / Test-Loss: 0.2401 / Time taken: 0:03:06 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 11 / Batch: 0 / Train-Loss (Batch): 0.1865   : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 02/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 11 / Train-Loss: 0.2399 / Val-Loss: 0.2387 / Test-Loss: 0.2399 / Time taken: 0:03:20 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 12 / Train-Loss: 0.2398 / Val-Loss: 0.2385 / Test-Loss: 0.2398 / Time taken: 0:03:35 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 13 / Train-Loss: 0.2395 / Val-Loss: 0.2383 / Test-Loss: 0.2396 / Time taken: 0:03:50 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 14 / Train-Loss: 0.2394 / Val-Loss: 0.2382 / Test-Loss: 0.2394 / Time taken: 0:04:06 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 15 / Train-Loss: 0.2392 / Val-Loss: 0.2380 / Test-Loss: 0.2394 / Time taken: 0:04:21 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 16 / Train-Loss: 0.2392 / Val-Loss: 0.2379 / Test-Loss: 0.2392 / Time taken: 0:04:36 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 17 / Train-Loss: 0.2389 / Val-Loss: 0.2377 / Test-Loss: 0.2391 / Time taken: 0:04:50 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 18 / Train-Loss: 0.2389 / Val-Loss: 0.2378 / Test-Loss: 0.2391 / Time taken: 0:05:12 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 02/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 19 / Train-Loss: 0.2387 / Val-Loss: 0.2374 / Test-Loss: 0.2389 / Time taken: 0:05:26 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 20 / Train-Loss: 0.2386 / Val-Loss: 0.2376 / Test-Loss: 0.2392 / Time taken: 0:05:41 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 02/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 21 / Train-Loss: 0.2386 / Val-Loss: 0.2374 / Test-Loss: 0.2390 / Time taken: 0:05:56 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 02/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 22 / Train-Loss: 0.2385 / Val-Loss: 0.2374 / Test-Loss: 0.2391 / Time taken: 0:06:17 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 02/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 23 / Train-Loss: 0.2383 / Val-Loss: 0.2371 / Test-Loss: 0.2387 / Time taken: 0:06:40 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 24 / Train-Loss: 0.2382 / Val-Loss: 0.2375 / Test-Loss: 0.2390 / Time taken: 0:06:54 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 02/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 25 / Train-Loss: 0.2382 / Val-Loss: 0.2372 / Test-Loss: 0.2387 / Time taken: 0:07:08 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 02/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 26 / Train-Loss: 0.2381 / Val-Loss: 0.2370 / Test-Loss: 0.2385 / Time taken: 0:07:23 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 27 / Train-Loss: 0.2380 / Val-Loss: 0.2370 / Test-Loss: 0.2386 / Time taken: 0:07:38 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 02/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 28 / Train-Loss: 0.2379 / Val-Loss: 0.2372 / Test-Loss: 0.2388 / Time taken: 0:07:53 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 02/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 29 / Train-Loss: 0.2379 / Val-Loss: 0.2372 / Test-Loss: 0.2388 / Time taken: 0:08:08 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 02/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 30 / Train-Loss: 0.2379 / Val-Loss: 0.2373 / Test-Loss: 0.2388 / Time taken: 0:08:23 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 02/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 31 / Train-Loss: 0.2378 / Val-Loss: 0.2370 / Test-Loss: 0.2387 / Time taken: 0:08:38 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 02/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 32 / Train-Loss: 0.2378 / Val-Loss: 0.2371 / Test-Loss: 0.2388 / Time taken: 0:08:54 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 02/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 33 / Train-Loss: 0.2377 / Val-Loss: 0.2371 / Test-Loss: 0.2388 / Time taken: 0:09:15 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 02/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 34 / Train-Loss: 0.2377 / Val-Loss: 0.2369 / Test-Loss: 0.2386 / Time taken: 0:09:38 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 02/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 35 / Train-Loss: 0.2376 / Val-Loss: 0.2372 / Test-Loss: 0.2389 / Time taken: 0:09:54 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 36 / Train-Loss: 0.2376 / Val-Loss: 0.2372 / Test-Loss: 0.2388 / Time taken: 0:10:09 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 37 / Train-Loss: 0.2375 / Val-Loss: 0.2372 / Test-Loss: 0.2389 / Time taken: 0:10:23 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 38 / Train-Loss: 0.2375 / Val-Loss: 0.2372 / Test-Loss: 0.2389 / Time taken: 0:10:39 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 39 / Train-Loss: 0.2374 / Val-Loss: 0.2375 / Test-Loss: 0.2392 / Time taken: 0:11:00 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 40 / Train-Loss: 0.2374 / Val-Loss: 0.2372 / Test-Loss: 0.2390 / Time taken: 0:11:22 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 41 / Train-Loss: 0.2375 / Val-Loss: 0.2371 / Test-Loss: 0.2387 / Time taken: 0:11:37 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 42 / Train-Loss: 0.2374 / Val-Loss: 0.2371 / Test-Loss: 0.2388 / Time taken: 0:11:53 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 43 / Train-Loss: 0.2373 / Val-Loss: 0.2373 / Test-Loss: 0.2389 / Time taken: 0:12:09 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 44 / Train-Loss: 0.2373 / Val-Loss: 0.2372 / Test-Loss: 0.2389 / Time taken: 0:12:25 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 45 / Train-Loss: 0.2373 / Val-Loss: 0.2371 / Test-Loss: 0.2389 / Time taken: 0:12:41 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 46 / Train-Loss: 0.2372 / Val-Loss: 0.2371 / Test-Loss: 0.2390 / Time taken: 0:12:56 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 47 / Train-Loss: 0.2372 / Val-Loss: 0.2370 / Test-Loss: 0.2388 / Time taken: 0:13:11 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 48 / Train-Loss: 0.2371 / Val-Loss: 0.2372 / Test-Loss: 0.2391 / Time taken: 0:13:25 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 49 / Train-Loss: 0.2371 / Val-Loss: 0.2372 / Test-Loss: 0.2390 / Time taken: 0:13:40 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 02/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 02/14 / Epoch: 50 / Train-Loss: 0.2371 / Val-Loss: 0.2371 / Test-Loss: 0.2388 / Time taken: 0:14:02 / ---- Currently Best Val-Epoch: 34 \n","596/596 [==============================] - 11s 16ms/step\n","67/67 [==============================] - 2s 24ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-d2e89334-7509-40fb-8090-656bcff5d2ed\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>CAFTT (run: 13)</td>\n","      <td>41</td>\n","      <td>893.841639</td>\n","      <td>27133</td>\n","      <td>0.237690</td>\n","      <td>0.238301</td>\n","      <td>0.065890</td>\n","      <td>0.066175</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>CAFTT (run: 14)</td>\n","      <td>57</td>\n","      <td>1187.882093</td>\n","      <td>27133</td>\n","      <td>0.237231</td>\n","      <td>0.237943</td>\n","      <td>0.066632</td>\n","      <td>0.066834</td>\n","    </tr>\n","    <tr>\n","      <th>150</th>\n","      <td>LocalGLMftt (run: 0)</td>\n","      <td>37</td>\n","      <td>886.447916</td>\n","      <td>27430</td>\n","      <td>0.238011</td>\n","      <td>0.238797</td>\n","      <td>0.068197</td>\n","      <td>0.068621</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>LocalGLMftt (run: 1)</td>\n","      <td>42</td>\n","      <td>868.665794</td>\n","      <td>27430</td>\n","      <td>0.237444</td>\n","      <td>0.238771</td>\n","      <td>0.067885</td>\n","      <td>0.068379</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>LocalGLMftt (run: 2)</td>\n","      <td>34</td>\n","      <td>842.569307</td>\n","      <td>27430</td>\n","      <td>0.237727</td>\n","      <td>0.238600</td>\n","      <td>0.067902</td>\n","      <td>0.068265</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>153 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2e89334-7509-40fb-8090-656bcff5d2ed')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d2e89334-7509-40fb-8090-656bcff5d2ed button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d2e89334-7509-40fb-8090-656bcff5d2ed');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cb545814-15fc-4209-9890-0e2607175b4b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb545814-15fc-4209-9890-0e2607175b4b')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cb545814-15fc-4209-9890-0e2607175b4b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","148             CAFTT (run: 13)      41   893.841639          27133   \n","149             CAFTT (run: 14)      57  1187.882093          27133   \n","150        LocalGLMftt (run: 0)      37   886.447916          27430   \n","151        LocalGLMftt (run: 1)      42   868.665794          27430   \n","152        LocalGLMftt (run: 2)      34   842.569307          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","148    0.237690   0.238301             0.065890            0.066175  \n","149    0.237231   0.237943             0.066632            0.066834  \n","150    0.238011   0.238797             0.068197            0.068621  \n","151    0.237444   0.238771             0.067885            0.068379  \n","152    0.237727   0.238600             0.067902            0.068265  \n","\n","[153 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 03-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 03/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0336  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 0 / Train-Loss: 0.2411 / Val-Loss: 0.2476 / Test-Loss: 0.2424 / Time taken: 0:00:31 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 1 / Train-Loss: 0.2410 / Val-Loss: 0.2477 / Test-Loss: 0.2420 / Time taken: 0:00:54 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 03/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 2 / Train-Loss: 0.2408 / Val-Loss: 0.2477 / Test-Loss: 0.2419 / Time taken: 0:01:09 / ---- Currently Best Val-Epoch: 0 \n","Ensemble: 03/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 3 / Train-Loss: 0.2406 / Val-Loss: 0.2476 / Test-Loss: 0.2417 / Time taken: 0:01:23 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 4 / Train-Loss: 0.2404 / Val-Loss: 0.2475 / Test-Loss: 0.2416 / Time taken: 0:01:38 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 5 / Train-Loss: 0.2403 / Val-Loss: 0.2474 / Test-Loss: 0.2413 / Time taken: 0:01:53 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 6 / Train-Loss: 0.2401 / Val-Loss: 0.2473 / Test-Loss: 0.2412 / Time taken: 0:02:07 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0324  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 7 / Train-Loss: 0.2399 / Val-Loss: 0.2471 / Test-Loss: 0.2410 / Time taken: 0:02:22 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 8 / Train-Loss: 0.2397 / Val-Loss: 0.2469 / Test-Loss: 0.2407 / Time taken: 0:02:37 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0323  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 9 / Train-Loss: 0.2395 / Val-Loss: 0.2466 / Test-Loss: 0.2405 / Time taken: 0:03:00 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 10 / Train-Loss: 0.2393 / Val-Loss: 0.2464 / Test-Loss: 0.2403 / Time taken: 0:03:14 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 11 / Batch: 0 / Train-Loss (Batch): 0.1926   : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 03/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 11 / Train-Loss: 0.2390 / Val-Loss: 0.2462 / Test-Loss: 0.2401 / Time taken: 0:03:29 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 12 / Train-Loss: 0.2389 / Val-Loss: 0.2461 / Test-Loss: 0.2399 / Time taken: 0:03:51 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 13 / Train-Loss: 0.2387 / Val-Loss: 0.2459 / Test-Loss: 0.2398 / Time taken: 0:04:08 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 14 / Train-Loss: 0.2386 / Val-Loss: 0.2459 / Test-Loss: 0.2398 / Time taken: 0:04:23 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 03/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 15 / Train-Loss: 0.2386 / Val-Loss: 0.2457 / Test-Loss: 0.2396 / Time taken: 0:04:45 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 16 / Train-Loss: 0.2384 / Val-Loss: 0.2455 / Test-Loss: 0.2394 / Time taken: 0:05:07 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 17 / Train-Loss: 0.2382 / Val-Loss: 0.2456 / Test-Loss: 0.2395 / Time taken: 0:05:30 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 03/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 18 / Train-Loss: 0.2381 / Val-Loss: 0.2456 / Test-Loss: 0.2395 / Time taken: 0:05:45 / ---- Currently Best Val-Epoch: 16 \n","Ensemble: 03/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 19 / Train-Loss: 0.2380 / Val-Loss: 0.2455 / Test-Loss: 0.2393 / Time taken: 0:06:00 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 20 / Train-Loss: 0.2380 / Val-Loss: 0.2456 / Test-Loss: 0.2395 / Time taken: 0:06:22 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 03/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 21 / Train-Loss: 0.2379 / Val-Loss: 0.2456 / Test-Loss: 0.2395 / Time taken: 0:06:39 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 03/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 22 / Train-Loss: 0.2378 / Val-Loss: 0.2453 / Test-Loss: 0.2393 / Time taken: 0:06:54 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 23 / Train-Loss: 0.2377 / Val-Loss: 0.2456 / Test-Loss: 0.2395 / Time taken: 0:07:09 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 03/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 24 / Train-Loss: 0.2377 / Val-Loss: 0.2454 / Test-Loss: 0.2394 / Time taken: 0:07:24 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 03/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 25 / Train-Loss: 0.2376 / Val-Loss: 0.2453 / Test-Loss: 0.2393 / Time taken: 0:07:39 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 03/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 26 / Train-Loss: 0.2376 / Val-Loss: 0.2454 / Test-Loss: 0.2394 / Time taken: 0:07:53 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 03/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 27 / Train-Loss: 0.2375 / Val-Loss: 0.2457 / Test-Loss: 0.2396 / Time taken: 0:08:16 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 03/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 28 / Train-Loss: 0.2374 / Val-Loss: 0.2455 / Test-Loss: 0.2394 / Time taken: 0:08:31 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 03/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 29 / Train-Loss: 0.2374 / Val-Loss: 0.2454 / Test-Loss: 0.2394 / Time taken: 0:08:46 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 03/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 30 / Train-Loss: 0.2373 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:09:01 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0315 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 31 / Train-Loss: 0.2373 / Val-Loss: 0.2455 / Test-Loss: 0.2395 / Time taken: 0:09:23 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 03/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 32 / Train-Loss: 0.2373 / Val-Loss: 0.2452 / Test-Loss: 0.2391 / Time taken: 0:09:38 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 33 / Train-Loss: 0.2372 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:09:54 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 03/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 34 / Train-Loss: 0.2371 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:10:09 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 03/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 35 / Train-Loss: 0.2372 / Val-Loss: 0.2453 / Test-Loss: 0.2393 / Time taken: 0:10:24 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 03/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 36 / Train-Loss: 0.2370 / Val-Loss: 0.2454 / Test-Loss: 0.2392 / Time taken: 0:10:38 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 03/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 37 / Train-Loss: 0.2370 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:10:53 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 03/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 38 / Train-Loss: 0.2370 / Val-Loss: 0.2455 / Test-Loss: 0.2394 / Time taken: 0:11:08 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 03/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 39 / Train-Loss: 0.2369 / Val-Loss: 0.2453 / Test-Loss: 0.2393 / Time taken: 0:11:22 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 03/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 40 / Train-Loss: 0.2369 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:11:44 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 03/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 41 / Train-Loss: 0.2369 / Val-Loss: 0.2452 / Test-Loss: 0.2391 / Time taken: 0:12:00 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 42 / Train-Loss: 0.2367 / Val-Loss: 0.2453 / Test-Loss: 0.2393 / Time taken: 0:12:15 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 03/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 43 / Train-Loss: 0.2368 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:12:30 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 03/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 44 / Train-Loss: 0.2367 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:12:44 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 03/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 45 / Train-Loss: 0.2367 / Val-Loss: 0.2453 / Test-Loss: 0.2394 / Time taken: 0:13:06 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 03/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 46 / Train-Loss: 0.2367 / Val-Loss: 0.2454 / Test-Loss: 0.2395 / Time taken: 0:13:27 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 03/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 47 / Train-Loss: 0.2367 / Val-Loss: 0.2452 / Test-Loss: 0.2391 / Time taken: 0:13:50 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 03/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0312 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 48 / Train-Loss: 0.2366 / Val-Loss: 0.2454 / Test-Loss: 0.2393 / Time taken: 0:14:05 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 03/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 49 / Train-Loss: 0.2366 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:14:20 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 03/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 50 / Train-Loss: 0.2366 / Val-Loss: 0.2452 / Test-Loss: 0.2391 / Time taken: 0:14:35 / ---- Currently Best Val-Epoch: 50 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 51 / Train-Loss: 0.2365 / Val-Loss: 0.2454 / Test-Loss: 0.2393 / Time taken: 0:14:58 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 52 / Train-Loss: 0.2365 / Val-Loss: 0.2453 / Test-Loss: 0.2393 / Time taken: 0:15:14 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 03/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 53 / Train-Loss: 0.2364 / Val-Loss: 0.2451 / Test-Loss: 0.2392 / Time taken: 0:15:30 / ---- Currently Best Val-Epoch: 53 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 54 / Train-Loss: 0.2365 / Val-Loss: 0.2452 / Test-Loss: 0.2390 / Time taken: 0:15:45 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 03/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 55 / Train-Loss: 0.2364 / Val-Loss: 0.2453 / Test-Loss: 0.2391 / Time taken: 0:16:07 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 03/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 56 / Train-Loss: 0.2363 / Val-Loss: 0.2454 / Test-Loss: 0.2394 / Time taken: 0:16:22 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 03/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 57 / Train-Loss: 0.2363 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:16:38 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 03/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 58 / Train-Loss: 0.2363 / Val-Loss: 0.2452 / Test-Loss: 0.2393 / Time taken: 0:16:55 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 03/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 59 / Train-Loss: 0.2363 / Val-Loss: 0.2452 / Test-Loss: 0.2393 / Time taken: 0:17:10 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 03/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 60 / Train-Loss: 0.2362 / Val-Loss: 0.2454 / Test-Loss: 0.2393 / Time taken: 0:17:24 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 03/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 61 / Train-Loss: 0.2362 / Val-Loss: 0.2451 / Test-Loss: 0.2392 / Time taken: 0:17:46 / ---- Currently Best Val-Epoch: 61 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 62 / Train-Loss: 0.2360 / Val-Loss: 0.2451 / Test-Loss: 0.2391 / Time taken: 0:18:08 / ---- Currently Best Val-Epoch: 62 <------- Best VAL Epoch so far\n","Ensemble: 03/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 63 / Train-Loss: 0.2360 / Val-Loss: 0.2452 / Test-Loss: 0.2392 / Time taken: 0:18:31 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 64 / Train-Loss: 0.2360 / Val-Loss: 0.2453 / Test-Loss: 0.2393 / Time taken: 0:18:46 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 65 / Train-Loss: 0.2360 / Val-Loss: 0.2453 / Test-Loss: 0.2393 / Time taken: 0:19:02 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0316 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 66 / Train-Loss: 0.2359 / Val-Loss: 0.2452 / Test-Loss: 0.2392 / Time taken: 0:19:16 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 67 / Train-Loss: 0.2359 / Val-Loss: 0.2456 / Test-Loss: 0.2396 / Time taken: 0:19:31 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 68 / Train-Loss: 0.2358 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:19:45 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 69 / Train-Loss: 0.2360 / Val-Loss: 0.2454 / Test-Loss: 0.2393 / Time taken: 0:20:00 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 70 / Train-Loss: 0.2358 / Val-Loss: 0.2455 / Test-Loss: 0.2394 / Time taken: 0:20:22 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 71 / Train-Loss: 0.2358 / Val-Loss: 0.2454 / Test-Loss: 0.2392 / Time taken: 0:20:44 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 72 / Train-Loss: 0.2358 / Val-Loss: 0.2453 / Test-Loss: 0.2393 / Time taken: 0:20:59 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 73 / Train-Loss: 0.2359 / Val-Loss: 0.2452 / Test-Loss: 0.2393 / Time taken: 0:21:20 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0305 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 74 / Train-Loss: 0.2357 / Val-Loss: 0.2453 / Test-Loss: 0.2393 / Time taken: 0:21:42 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 75 / Train-Loss: 0.2357 / Val-Loss: 0.2453 / Test-Loss: 0.2392 / Time taken: 0:22:04 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 76 / Train-Loss: 0.2357 / Val-Loss: 0.2453 / Test-Loss: 0.2394 / Time taken: 0:22:26 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 77 / Train-Loss: 0.2358 / Val-Loss: 0.2455 / Test-Loss: 0.2395 / Time taken: 0:22:42 / ---- Currently Best Val-Epoch: 62 \n","Ensemble: 03/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 03/14 / Epoch: 78 / Train-Loss: 0.2357 / Val-Loss: 0.2452 / Test-Loss: 0.2393 / Time taken: 0:22:57 / ---- Currently Best Val-Epoch: 62 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 2s 23ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-237a1341-8c6b-46a9-9e75-88cf9ea2423d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>CAFTT (run: 14)</td>\n","      <td>57</td>\n","      <td>1187.882093</td>\n","      <td>27133</td>\n","      <td>0.237231</td>\n","      <td>0.237943</td>\n","      <td>0.066632</td>\n","      <td>0.066834</td>\n","    </tr>\n","    <tr>\n","      <th>150</th>\n","      <td>LocalGLMftt (run: 0)</td>\n","      <td>37</td>\n","      <td>886.447916</td>\n","      <td>27430</td>\n","      <td>0.238011</td>\n","      <td>0.238797</td>\n","      <td>0.068197</td>\n","      <td>0.068621</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>LocalGLMftt (run: 1)</td>\n","      <td>42</td>\n","      <td>868.665794</td>\n","      <td>27430</td>\n","      <td>0.237444</td>\n","      <td>0.238771</td>\n","      <td>0.067885</td>\n","      <td>0.068379</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>LocalGLMftt (run: 2)</td>\n","      <td>34</td>\n","      <td>842.569307</td>\n","      <td>27430</td>\n","      <td>0.237727</td>\n","      <td>0.238600</td>\n","      <td>0.067902</td>\n","      <td>0.068265</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>LocalGLMftt (run: 3)</td>\n","      <td>62</td>\n","      <td>1377.378268</td>\n","      <td>27430</td>\n","      <td>0.237049</td>\n","      <td>0.239091</td>\n","      <td>0.067171</td>\n","      <td>0.067539</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-237a1341-8c6b-46a9-9e75-88cf9ea2423d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-237a1341-8c6b-46a9-9e75-88cf9ea2423d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-237a1341-8c6b-46a9-9e75-88cf9ea2423d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-18b8cac4-7f13-456e-96f7-abad8e57071d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18b8cac4-7f13-456e-96f7-abad8e57071d')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-18b8cac4-7f13-456e-96f7-abad8e57071d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","149             CAFTT (run: 14)      57  1187.882093          27133   \n","150        LocalGLMftt (run: 0)      37   886.447916          27430   \n","151        LocalGLMftt (run: 1)      42   868.665794          27430   \n","152        LocalGLMftt (run: 2)      34   842.569307          27430   \n","153        LocalGLMftt (run: 3)      62  1377.378268          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","149    0.237231   0.237943             0.066632            0.066834  \n","150    0.238011   0.238797             0.068197            0.068621  \n","151    0.237444   0.238771             0.067885            0.068379  \n","152    0.237727   0.238600             0.067902            0.068265  \n","153    0.237049   0.239091             0.067171            0.067539  \n","\n","[154 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 04-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 04/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0336  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 0 / Train-Loss: 0.2422 / Val-Loss: 0.2384 / Test-Loss: 0.2424 / Time taken: 0:00:31 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 1 / Train-Loss: 0.2421 / Val-Loss: 0.2382 / Test-Loss: 0.2420 / Time taken: 0:00:46 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 2 / Train-Loss: 0.2419 / Val-Loss: 0.2379 / Test-Loss: 0.2418 / Time taken: 0:01:01 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 3 / Train-Loss: 0.2418 / Val-Loss: 0.2378 / Test-Loss: 0.2417 / Time taken: 0:01:22 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 4 / Train-Loss: 0.2416 / Val-Loss: 0.2377 / Test-Loss: 0.2416 / Time taken: 0:01:37 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 5 / Train-Loss: 0.2416 / Val-Loss: 0.2377 / Test-Loss: 0.2415 / Time taken: 0:01:52 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 6 / Train-Loss: 0.2415 / Val-Loss: 0.2376 / Test-Loss: 0.2414 / Time taken: 0:02:07 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 7 / Train-Loss: 0.2414 / Val-Loss: 0.2374 / Test-Loss: 0.2412 / Time taken: 0:02:29 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 8 / Train-Loss: 0.2413 / Val-Loss: 0.2374 / Test-Loss: 0.2410 / Time taken: 0:02:45 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 9 / Train-Loss: 0.2412 / Val-Loss: 0.2374 / Test-Loss: 0.2411 / Time taken: 0:03:00 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 04/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 10 / Train-Loss: 0.2411 / Val-Loss: 0.2372 / Test-Loss: 0.2409 / Time taken: 0:03:14 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 11 / Batch: 0 / Train-Loss (Batch): 0.1828   : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 04/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 11 / Train-Loss: 0.2410 / Val-Loss: 0.2370 / Test-Loss: 0.2406 / Time taken: 0:03:29 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 12 / Train-Loss: 0.2408 / Val-Loss: 0.2369 / Test-Loss: 0.2405 / Time taken: 0:03:51 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 13 / Train-Loss: 0.2407 / Val-Loss: 0.2367 / Test-Loss: 0.2403 / Time taken: 0:04:08 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 14 / Train-Loss: 0.2406 / Val-Loss: 0.2365 / Test-Loss: 0.2401 / Time taken: 0:04:23 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 15 / Train-Loss: 0.2404 / Val-Loss: 0.2363 / Test-Loss: 0.2399 / Time taken: 0:04:38 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 16 / Train-Loss: 0.2403 / Val-Loss: 0.2362 / Test-Loss: 0.2399 / Time taken: 0:04:52 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 17 / Train-Loss: 0.2401 / Val-Loss: 0.2362 / Test-Loss: 0.2397 / Time taken: 0:05:15 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 18 / Train-Loss: 0.2400 / Val-Loss: 0.2362 / Test-Loss: 0.2398 / Time taken: 0:05:32 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 04/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 19 / Train-Loss: 0.2399 / Val-Loss: 0.2359 / Test-Loss: 0.2395 / Time taken: 0:05:46 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 20 / Train-Loss: 0.2396 / Val-Loss: 0.2359 / Test-Loss: 0.2394 / Time taken: 0:06:01 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 04/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 21 / Train-Loss: 0.2396 / Val-Loss: 0.2358 / Test-Loss: 0.2393 / Time taken: 0:06:16 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 22 / Train-Loss: 0.2394 / Val-Loss: 0.2357 / Test-Loss: 0.2392 / Time taken: 0:06:31 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 23 / Train-Loss: 0.2393 / Val-Loss: 0.2358 / Test-Loss: 0.2394 / Time taken: 0:06:46 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 04/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 24 / Train-Loss: 0.2391 / Val-Loss: 0.2356 / Test-Loss: 0.2391 / Time taken: 0:07:08 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 25 / Train-Loss: 0.2391 / Val-Loss: 0.2354 / Test-Loss: 0.2390 / Time taken: 0:07:24 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 26 / Train-Loss: 0.2390 / Val-Loss: 0.2351 / Test-Loss: 0.2389 / Time taken: 0:07:39 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 27 / Train-Loss: 0.2388 / Val-Loss: 0.2353 / Test-Loss: 0.2390 / Time taken: 0:07:54 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 04/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 28 / Train-Loss: 0.2388 / Val-Loss: 0.2351 / Test-Loss: 0.2389 / Time taken: 0:08:08 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 29 / Train-Loss: 0.2387 / Val-Loss: 0.2352 / Test-Loss: 0.2390 / Time taken: 0:08:31 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 04/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 30 / Train-Loss: 0.2386 / Val-Loss: 0.2351 / Test-Loss: 0.2388 / Time taken: 0:08:46 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 04/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 31 / Train-Loss: 0.2385 / Val-Loss: 0.2349 / Test-Loss: 0.2389 / Time taken: 0:09:03 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 32 / Train-Loss: 0.2386 / Val-Loss: 0.2350 / Test-Loss: 0.2389 / Time taken: 0:09:17 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 04/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 33 / Train-Loss: 0.2384 / Val-Loss: 0.2350 / Test-Loss: 0.2389 / Time taken: 0:09:32 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 04/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 34 / Train-Loss: 0.2384 / Val-Loss: 0.2349 / Test-Loss: 0.2389 / Time taken: 0:09:54 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 35 / Train-Loss: 0.2384 / Val-Loss: 0.2351 / Test-Loss: 0.2390 / Time taken: 0:10:16 / ---- Currently Best Val-Epoch: 34 \n","Ensemble: 04/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 36 / Train-Loss: 0.2383 / Val-Loss: 0.2348 / Test-Loss: 0.2388 / Time taken: 0:10:31 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 37 / Train-Loss: 0.2382 / Val-Loss: 0.2350 / Test-Loss: 0.2389 / Time taken: 0:10:47 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 04/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 38 / Train-Loss: 0.2382 / Val-Loss: 0.2348 / Test-Loss: 0.2388 / Time taken: 0:11:03 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 04/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 39 / Train-Loss: 0.2382 / Val-Loss: 0.2347 / Test-Loss: 0.2388 / Time taken: 0:11:24 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 40 / Train-Loss: 0.2380 / Val-Loss: 0.2350 / Test-Loss: 0.2389 / Time taken: 0:11:47 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 04/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 41 / Train-Loss: 0.2379 / Val-Loss: 0.2350 / Test-Loss: 0.2391 / Time taken: 0:12:04 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 04/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 42 / Train-Loss: 0.2380 / Val-Loss: 0.2347 / Test-Loss: 0.2388 / Time taken: 0:12:18 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 04/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 43 / Train-Loss: 0.2379 / Val-Loss: 0.2347 / Test-Loss: 0.2387 / Time taken: 0:12:40 / ---- Currently Best Val-Epoch: 43 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 44 / Train-Loss: 0.2379 / Val-Loss: 0.2349 / Test-Loss: 0.2389 / Time taken: 0:12:56 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 45 / Train-Loss: 0.2379 / Val-Loss: 0.2349 / Test-Loss: 0.2389 / Time taken: 0:13:17 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 46 / Train-Loss: 0.2378 / Val-Loss: 0.2351 / Test-Loss: 0.2390 / Time taken: 0:13:40 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 47 / Train-Loss: 0.2378 / Val-Loss: 0.2347 / Test-Loss: 0.2388 / Time taken: 0:13:55 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 48 / Train-Loss: 0.2377 / Val-Loss: 0.2350 / Test-Loss: 0.2390 / Time taken: 0:14:10 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 49 / Train-Loss: 0.2377 / Val-Loss: 0.2348 / Test-Loss: 0.2389 / Time taken: 0:14:25 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 50 / Train-Loss: 0.2377 / Val-Loss: 0.2348 / Test-Loss: 0.2388 / Time taken: 0:14:39 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 51 / Train-Loss: 0.2375 / Val-Loss: 0.2348 / Test-Loss: 0.2389 / Time taken: 0:14:54 / ---- Currently Best Val-Epoch: 43 \n","Ensemble: 04/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 52 / Train-Loss: 0.2376 / Val-Loss: 0.2345 / Test-Loss: 0.2388 / Time taken: 0:15:08 / ---- Currently Best Val-Epoch: 52 <------- Best VAL Epoch so far\n","Ensemble: 04/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 53 / Train-Loss: 0.2376 / Val-Loss: 0.2346 / Test-Loss: 0.2387 / Time taken: 0:15:24 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0313 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 54 / Train-Loss: 0.2374 / Val-Loss: 0.2349 / Test-Loss: 0.2388 / Time taken: 0:15:47 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0315 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 55 / Train-Loss: 0.2375 / Val-Loss: 0.2347 / Test-Loss: 0.2389 / Time taken: 0:16:02 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 56 / Train-Loss: 0.2375 / Val-Loss: 0.2347 / Test-Loss: 0.2389 / Time taken: 0:16:17 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 57 / Train-Loss: 0.2374 / Val-Loss: 0.2349 / Test-Loss: 0.2389 / Time taken: 0:16:32 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 58 / Train-Loss: 0.2374 / Val-Loss: 0.2351 / Test-Loss: 0.2390 / Time taken: 0:16:47 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 59 / Train-Loss: 0.2373 / Val-Loss: 0.2349 / Test-Loss: 0.2389 / Time taken: 0:17:01 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 60 / Train-Loss: 0.2372 / Val-Loss: 0.2349 / Test-Loss: 0.2389 / Time taken: 0:17:16 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 61 / Train-Loss: 0.2372 / Val-Loss: 0.2347 / Test-Loss: 0.2389 / Time taken: 0:17:31 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 62 / Train-Loss: 0.2371 / Val-Loss: 0.2347 / Test-Loss: 0.2389 / Time taken: 0:17:53 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 63 / Train-Loss: 0.2372 / Val-Loss: 0.2347 / Test-Loss: 0.2388 / Time taken: 0:18:09 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 64 / Train-Loss: 0.2371 / Val-Loss: 0.2348 / Test-Loss: 0.2388 / Time taken: 0:18:25 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 65 / Train-Loss: 0.2371 / Val-Loss: 0.2347 / Test-Loss: 0.2389 / Time taken: 0:18:41 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 66 / Train-Loss: 0.2371 / Val-Loss: 0.2345 / Test-Loss: 0.2388 / Time taken: 0:18:55 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 67 / Train-Loss: 0.2370 / Val-Loss: 0.2348 / Test-Loss: 0.2389 / Time taken: 0:19:17 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 04/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 04/14 / Epoch: 68 / Train-Loss: 0.2371 / Val-Loss: 0.2347 / Test-Loss: 0.2388 / Time taken: 0:19:32 / ---- Currently Best Val-Epoch: 52 \n","596/596 [==============================] - 12s 18ms/step\n","67/67 [==============================] - 1s 15ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-e49ca6fb-1791-4e18-8326-7f312d27b969\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>150</th>\n","      <td>LocalGLMftt (run: 0)</td>\n","      <td>37</td>\n","      <td>886.447916</td>\n","      <td>27430</td>\n","      <td>0.238011</td>\n","      <td>0.238797</td>\n","      <td>0.068197</td>\n","      <td>0.068621</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>LocalGLMftt (run: 1)</td>\n","      <td>42</td>\n","      <td>868.665794</td>\n","      <td>27430</td>\n","      <td>0.237444</td>\n","      <td>0.238771</td>\n","      <td>0.067885</td>\n","      <td>0.068379</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>LocalGLMftt (run: 2)</td>\n","      <td>34</td>\n","      <td>842.569307</td>\n","      <td>27430</td>\n","      <td>0.237727</td>\n","      <td>0.238600</td>\n","      <td>0.067902</td>\n","      <td>0.068265</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>LocalGLMftt (run: 3)</td>\n","      <td>62</td>\n","      <td>1377.378268</td>\n","      <td>27430</td>\n","      <td>0.237049</td>\n","      <td>0.239091</td>\n","      <td>0.067171</td>\n","      <td>0.067539</td>\n","    </tr>\n","    <tr>\n","      <th>154</th>\n","      <td>LocalGLMftt (run: 4)</td>\n","      <td>52</td>\n","      <td>1172.448311</td>\n","      <td>27430</td>\n","      <td>0.237175</td>\n","      <td>0.238773</td>\n","      <td>0.067236</td>\n","      <td>0.067723</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>155 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e49ca6fb-1791-4e18-8326-7f312d27b969')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e49ca6fb-1791-4e18-8326-7f312d27b969 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e49ca6fb-1791-4e18-8326-7f312d27b969');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a83fa0c6-ec3d-4943-99ac-b8e47af4d704\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a83fa0c6-ec3d-4943-99ac-b8e47af4d704')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a83fa0c6-ec3d-4943-99ac-b8e47af4d704 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","150        LocalGLMftt (run: 0)      37   886.447916          27430   \n","151        LocalGLMftt (run: 1)      42   868.665794          27430   \n","152        LocalGLMftt (run: 2)      34   842.569307          27430   \n","153        LocalGLMftt (run: 3)      62  1377.378268          27430   \n","154        LocalGLMftt (run: 4)      52  1172.448311          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","150    0.238011   0.238797             0.068197            0.068621  \n","151    0.237444   0.238771             0.067885            0.068379  \n","152    0.237727   0.238600             0.067902            0.068265  \n","153    0.237049   0.239091             0.067171            0.067539  \n","154    0.237175   0.238773             0.067236            0.067723  \n","\n","[155 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 05-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 05/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0337  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 0 / Train-Loss: 0.2420 / Val-Loss: 0.2395 / Test-Loss: 0.2423 / Time taken: 0:00:45 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 1 / Train-Loss: 0.2419 / Val-Loss: 0.2394 / Test-Loss: 0.2420 / Time taken: 0:00:59 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 2 / Train-Loss: 0.2417 / Val-Loss: 0.2393 / Test-Loss: 0.2418 / Time taken: 0:01:14 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 3 / Train-Loss: 0.2414 / Val-Loss: 0.2392 / Test-Loss: 0.2415 / Time taken: 0:01:36 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 4 / Train-Loss: 0.2413 / Val-Loss: 0.2391 / Test-Loss: 0.2413 / Time taken: 0:01:51 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 5 / Train-Loss: 0.2411 / Val-Loss: 0.2391 / Test-Loss: 0.2410 / Time taken: 0:02:13 / ---- Currently Best Val-Epoch: 4 \n","Ensemble: 05/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 6 / Train-Loss: 0.2409 / Val-Loss: 0.2390 / Test-Loss: 0.2407 / Time taken: 0:02:28 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 7 / Train-Loss: 0.2409 / Val-Loss: 0.2389 / Test-Loss: 0.2407 / Time taken: 0:02:43 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 8 / Train-Loss: 0.2408 / Val-Loss: 0.2389 / Test-Loss: 0.2405 / Time taken: 0:02:59 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 9 / Train-Loss: 0.2407 / Val-Loss: 0.2390 / Test-Loss: 0.2407 / Time taken: 0:03:14 / ---- Currently Best Val-Epoch: 8 \n","Ensemble: 05/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 10 / Train-Loss: 0.2405 / Val-Loss: 0.2388 / Test-Loss: 0.2403 / Time taken: 0:03:31 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 05/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 11 / Train-Loss: 0.2404 / Val-Loss: 0.2388 / Test-Loss: 0.2405 / Time taken: 0:03:47 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 05/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 12 / Train-Loss: 0.2403 / Val-Loss: 0.2388 / Test-Loss: 0.2406 / Time taken: 0:04:02 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 05/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 13 / Train-Loss: 0.2402 / Val-Loss: 0.2386 / Test-Loss: 0.2402 / Time taken: 0:04:16 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 14 / Train-Loss: 0.2401 / Val-Loss: 0.2386 / Test-Loss: 0.2401 / Time taken: 0:04:32 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 15 / Train-Loss: 0.2400 / Val-Loss: 0.2386 / Test-Loss: 0.2401 / Time taken: 0:04:46 / ---- Currently Best Val-Epoch: 14 \n","Ensemble: 05/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 16 / Train-Loss: 0.2399 / Val-Loss: 0.2384 / Test-Loss: 0.2400 / Time taken: 0:05:01 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 17 / Train-Loss: 0.2399 / Val-Loss: 0.2384 / Test-Loss: 0.2399 / Time taken: 0:05:25 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 18 / Train-Loss: 0.2398 / Val-Loss: 0.2381 / Test-Loss: 0.2397 / Time taken: 0:05:40 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 19 / Train-Loss: 0.2396 / Val-Loss: 0.2383 / Test-Loss: 0.2400 / Time taken: 0:05:55 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 05/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 20 / Train-Loss: 0.2395 / Val-Loss: 0.2381 / Test-Loss: 0.2398 / Time taken: 0:06:16 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 21 / Train-Loss: 0.2394 / Val-Loss: 0.2380 / Test-Loss: 0.2398 / Time taken: 0:06:38 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 22 / Train-Loss: 0.2393 / Val-Loss: 0.2380 / Test-Loss: 0.2398 / Time taken: 0:06:55 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 23 / Train-Loss: 0.2392 / Val-Loss: 0.2378 / Test-Loss: 0.2395 / Time taken: 0:07:11 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 24 / Train-Loss: 0.2391 / Val-Loss: 0.2379 / Test-Loss: 0.2397 / Time taken: 0:07:28 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 05/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 25 / Train-Loss: 0.2390 / Val-Loss: 0.2375 / Test-Loss: 0.2393 / Time taken: 0:07:43 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 26 / Train-Loss: 0.2388 / Val-Loss: 0.2376 / Test-Loss: 0.2395 / Time taken: 0:08:00 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 05/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 27 / Train-Loss: 0.2388 / Val-Loss: 0.2375 / Test-Loss: 0.2395 / Time taken: 0:08:15 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 05/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 28 / Train-Loss: 0.2388 / Val-Loss: 0.2374 / Test-Loss: 0.2393 / Time taken: 0:08:36 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 29 / Train-Loss: 0.2386 / Val-Loss: 0.2375 / Test-Loss: 0.2393 / Time taken: 0:08:58 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 05/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 30 / Train-Loss: 0.2385 / Val-Loss: 0.2373 / Test-Loss: 0.2392 / Time taken: 0:09:14 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 31 / Train-Loss: 0.2384 / Val-Loss: 0.2373 / Test-Loss: 0.2393 / Time taken: 0:09:29 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 32 / Train-Loss: 0.2384 / Val-Loss: 0.2372 / Test-Loss: 0.2391 / Time taken: 0:09:52 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 33 / Train-Loss: 0.2383 / Val-Loss: 0.2373 / Test-Loss: 0.2392 / Time taken: 0:10:07 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 05/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 34 / Train-Loss: 0.2382 / Val-Loss: 0.2373 / Test-Loss: 0.2392 / Time taken: 0:10:29 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 05/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 35 / Train-Loss: 0.2382 / Val-Loss: 0.2373 / Test-Loss: 0.2394 / Time taken: 0:10:44 / ---- Currently Best Val-Epoch: 32 \n","Ensemble: 05/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 36 / Train-Loss: 0.2381 / Val-Loss: 0.2370 / Test-Loss: 0.2390 / Time taken: 0:11:01 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 37 / Train-Loss: 0.2381 / Val-Loss: 0.2372 / Test-Loss: 0.2392 / Time taken: 0:11:16 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 05/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 38 / Train-Loss: 0.2380 / Val-Loss: 0.2370 / Test-Loss: 0.2390 / Time taken: 0:11:32 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 39 / Train-Loss: 0.2379 / Val-Loss: 0.2370 / Test-Loss: 0.2391 / Time taken: 0:11:54 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 05/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0316 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 40 / Train-Loss: 0.2379 / Val-Loss: 0.2369 / Test-Loss: 0.2390 / Time taken: 0:12:15 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 41 / Train-Loss: 0.2377 / Val-Loss: 0.2370 / Test-Loss: 0.2390 / Time taken: 0:12:39 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 05/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 42 / Train-Loss: 0.2377 / Val-Loss: 0.2369 / Test-Loss: 0.2389 / Time taken: 0:12:54 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 05/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 43 / Train-Loss: 0.2377 / Val-Loss: 0.2370 / Test-Loss: 0.2390 / Time taken: 0:13:09 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 05/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 44 / Train-Loss: 0.2376 / Val-Loss: 0.2370 / Test-Loss: 0.2390 / Time taken: 0:13:24 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 05/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 45 / Train-Loss: 0.2377 / Val-Loss: 0.2371 / Test-Loss: 0.2391 / Time taken: 0:13:39 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 05/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 46 / Train-Loss: 0.2376 / Val-Loss: 0.2368 / Test-Loss: 0.2388 / Time taken: 0:13:54 / ---- Currently Best Val-Epoch: 46 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 47 / Train-Loss: 0.2375 / Val-Loss: 0.2368 / Test-Loss: 0.2389 / Time taken: 0:14:09 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 05/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 48 / Train-Loss: 0.2375 / Val-Loss: 0.2369 / Test-Loss: 0.2390 / Time taken: 0:14:24 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 05/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 49 / Train-Loss: 0.2375 / Val-Loss: 0.2367 / Test-Loss: 0.2388 / Time taken: 0:14:39 / ---- Currently Best Val-Epoch: 49 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 50 / Train-Loss: 0.2375 / Val-Loss: 0.2370 / Test-Loss: 0.2389 / Time taken: 0:14:55 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 05/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 51 / Train-Loss: 0.2375 / Val-Loss: 0.2369 / Test-Loss: 0.2388 / Time taken: 0:15:11 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 05/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 52 / Train-Loss: 0.2373 / Val-Loss: 0.2368 / Test-Loss: 0.2390 / Time taken: 0:15:26 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 05/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 53 / Train-Loss: 0.2372 / Val-Loss: 0.2368 / Test-Loss: 0.2387 / Time taken: 0:15:42 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 05/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 54 / Train-Loss: 0.2372 / Val-Loss: 0.2370 / Test-Loss: 0.2390 / Time taken: 0:15:58 / ---- Currently Best Val-Epoch: 49 \n","Ensemble: 05/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 55 / Train-Loss: 0.2373 / Val-Loss: 0.2367 / Test-Loss: 0.2388 / Time taken: 0:16:15 / ---- Currently Best Val-Epoch: 55 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 56 / Train-Loss: 0.2373 / Val-Loss: 0.2368 / Test-Loss: 0.2388 / Time taken: 0:16:30 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 05/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 57 / Train-Loss: 0.2372 / Val-Loss: 0.2370 / Test-Loss: 0.2389 / Time taken: 0:16:45 / ---- Currently Best Val-Epoch: 55 \n","Ensemble: 05/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 58 / Train-Loss: 0.2372 / Val-Loss: 0.2366 / Test-Loss: 0.2387 / Time taken: 0:17:00 / ---- Currently Best Val-Epoch: 58 <------- Best VAL Epoch so far\n","Ensemble: 05/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 59 / Train-Loss: 0.2372 / Val-Loss: 0.2369 / Test-Loss: 0.2388 / Time taken: 0:17:22 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 60 / Train-Loss: 0.2371 / Val-Loss: 0.2368 / Test-Loss: 0.2388 / Time taken: 0:17:38 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 61 / Train-Loss: 0.2371 / Val-Loss: 0.2370 / Test-Loss: 0.2391 / Time taken: 0:17:54 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 62 / Train-Loss: 0.2372 / Val-Loss: 0.2369 / Test-Loss: 0.2390 / Time taken: 0:18:11 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 63 / Train-Loss: 0.2370 / Val-Loss: 0.2370 / Test-Loss: 0.2390 / Time taken: 0:18:26 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 64 / Train-Loss: 0.2370 / Val-Loss: 0.2368 / Test-Loss: 0.2389 / Time taken: 0:18:41 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 65 / Train-Loss: 0.2370 / Val-Loss: 0.2369 / Test-Loss: 0.2390 / Time taken: 0:18:55 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 66 / Train-Loss: 0.2369 / Val-Loss: 0.2367 / Test-Loss: 0.2388 / Time taken: 0:19:11 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 67 / Train-Loss: 0.2369 / Val-Loss: 0.2369 / Test-Loss: 0.2390 / Time taken: 0:19:25 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 68 / Train-Loss: 0.2368 / Val-Loss: 0.2369 / Test-Loss: 0.2391 / Time taken: 0:19:41 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 69 / Train-Loss: 0.2369 / Val-Loss: 0.2369 / Test-Loss: 0.2390 / Time taken: 0:19:56 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0346 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 70 / Train-Loss: 0.2369 / Val-Loss: 0.2369 / Test-Loss: 0.2389 / Time taken: 0:20:11 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 71 / Train-Loss: 0.2367 / Val-Loss: 0.2371 / Test-Loss: 0.2390 / Time taken: 0:20:34 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0344 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 72 / Train-Loss: 0.2368 / Val-Loss: 0.2371 / Test-Loss: 0.2390 / Time taken: 0:20:50 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 73 / Train-Loss: 0.2367 / Val-Loss: 0.2369 / Test-Loss: 0.2388 / Time taken: 0:21:11 / ---- Currently Best Val-Epoch: 58 \n","Ensemble: 05/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 05/14 / Epoch: 74 / Train-Loss: 0.2366 / Val-Loss: 0.2369 / Test-Loss: 0.2388 / Time taken: 0:21:29 / ---- Currently Best Val-Epoch: 58 \n","596/596 [==============================] - 13s 19ms/step\n","67/67 [==============================] - 1s 15ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-8af3c397-cc24-4f95-a4fb-063402750f50\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>LocalGLMftt (run: 1)</td>\n","      <td>42</td>\n","      <td>868.665794</td>\n","      <td>27430</td>\n","      <td>0.237444</td>\n","      <td>0.238771</td>\n","      <td>0.067885</td>\n","      <td>0.068379</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>LocalGLMftt (run: 2)</td>\n","      <td>34</td>\n","      <td>842.569307</td>\n","      <td>27430</td>\n","      <td>0.237727</td>\n","      <td>0.238600</td>\n","      <td>0.067902</td>\n","      <td>0.068265</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>LocalGLMftt (run: 3)</td>\n","      <td>62</td>\n","      <td>1377.378268</td>\n","      <td>27430</td>\n","      <td>0.237049</td>\n","      <td>0.239091</td>\n","      <td>0.067171</td>\n","      <td>0.067539</td>\n","    </tr>\n","    <tr>\n","      <th>154</th>\n","      <td>LocalGLMftt (run: 4)</td>\n","      <td>52</td>\n","      <td>1172.448311</td>\n","      <td>27430</td>\n","      <td>0.237175</td>\n","      <td>0.238773</td>\n","      <td>0.067236</td>\n","      <td>0.067723</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>LocalGLMftt (run: 5)</td>\n","      <td>58</td>\n","      <td>1289.168909</td>\n","      <td>27430</td>\n","      <td>0.237039</td>\n","      <td>0.238749</td>\n","      <td>0.068158</td>\n","      <td>0.068611</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>156 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8af3c397-cc24-4f95-a4fb-063402750f50')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8af3c397-cc24-4f95-a4fb-063402750f50 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8af3c397-cc24-4f95-a4fb-063402750f50');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6060455b-bfb0-4a15-888d-b94c523be747\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6060455b-bfb0-4a15-888d-b94c523be747')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6060455b-bfb0-4a15-888d-b94c523be747 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","151        LocalGLMftt (run: 1)      42   868.665794          27430   \n","152        LocalGLMftt (run: 2)      34   842.569307          27430   \n","153        LocalGLMftt (run: 3)      62  1377.378268          27430   \n","154        LocalGLMftt (run: 4)      52  1172.448311          27430   \n","155        LocalGLMftt (run: 5)      58  1289.168909          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","151    0.237444   0.238771             0.067885            0.068379  \n","152    0.237727   0.238600             0.067902            0.068265  \n","153    0.237049   0.239091             0.067171            0.067539  \n","154    0.237175   0.238773             0.067236            0.067723  \n","155    0.237039   0.238749             0.068158            0.068611  \n","\n","[156 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 06-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 06/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0338  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 0 / Train-Loss: 0.2418 / Val-Loss: 0.2416 / Test-Loss: 0.2422 / Time taken: 0:00:34 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 1 / Train-Loss: 0.2417 / Val-Loss: 0.2414 / Test-Loss: 0.2420 / Time taken: 0:00:49 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 2 / Train-Loss: 0.2414 / Val-Loss: 0.2411 / Test-Loss: 0.2416 / Time taken: 0:01:04 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 3 / Train-Loss: 0.2412 / Val-Loss: 0.2410 / Test-Loss: 0.2415 / Time taken: 0:01:25 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 4 / Train-Loss: 0.2411 / Val-Loss: 0.2408 / Test-Loss: 0.2414 / Time taken: 0:01:47 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 5 / Train-Loss: 0.2410 / Val-Loss: 0.2407 / Test-Loss: 0.2412 / Time taken: 0:02:09 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 6 / Train-Loss: 0.2409 / Val-Loss: 0.2404 / Test-Loss: 0.2410 / Time taken: 0:02:27 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 7 / Train-Loss: 0.2408 / Val-Loss: 0.2403 / Test-Loss: 0.2409 / Time taken: 0:02:42 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 8 / Train-Loss: 0.2406 / Val-Loss: 0.2403 / Test-Loss: 0.2408 / Time taken: 0:03:03 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 9 / Train-Loss: 0.2405 / Val-Loss: 0.2401 / Test-Loss: 0.2407 / Time taken: 0:03:19 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 10 / Train-Loss: 0.2404 / Val-Loss: 0.2399 / Test-Loss: 0.2405 / Time taken: 0:03:35 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 11 / Batch: 0 / Train-Loss (Batch): 0.178    : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 06/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 11 / Train-Loss: 0.2402 / Val-Loss: 0.2398 / Test-Loss: 0.2403 / Time taken: 0:03:51 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 12 / Train-Loss: 0.2401 / Val-Loss: 0.2399 / Test-Loss: 0.2403 / Time taken: 0:04:08 / ---- Currently Best Val-Epoch: 11 \n","Ensemble: 06/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 13 / Train-Loss: 0.2399 / Val-Loss: 0.2398 / Test-Loss: 0.2401 / Time taken: 0:04:24 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 14 / Train-Loss: 0.2398 / Val-Loss: 0.2397 / Test-Loss: 0.2399 / Time taken: 0:04:39 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 15 / Train-Loss: 0.2397 / Val-Loss: 0.2396 / Test-Loss: 0.2398 / Time taken: 0:04:56 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 16 / Train-Loss: 0.2396 / Val-Loss: 0.2395 / Test-Loss: 0.2397 / Time taken: 0:05:11 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 17 / Train-Loss: 0.2393 / Val-Loss: 0.2394 / Test-Loss: 0.2395 / Time taken: 0:05:26 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 18 / Train-Loss: 0.2392 / Val-Loss: 0.2393 / Test-Loss: 0.2395 / Time taken: 0:05:50 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 19 / Train-Loss: 0.2390 / Val-Loss: 0.2392 / Test-Loss: 0.2394 / Time taken: 0:06:05 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 20 / Train-Loss: 0.2390 / Val-Loss: 0.2390 / Test-Loss: 0.2392 / Time taken: 0:06:27 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 21 / Train-Loss: 0.2388 / Val-Loss: 0.2388 / Test-Loss: 0.2390 / Time taken: 0:06:43 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 22 / Train-Loss: 0.2385 / Val-Loss: 0.2389 / Test-Loss: 0.2391 / Time taken: 0:06:59 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 06/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 23 / Train-Loss: 0.2385 / Val-Loss: 0.2385 / Test-Loss: 0.2389 / Time taken: 0:07:16 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 24 / Train-Loss: 0.2384 / Val-Loss: 0.2383 / Test-Loss: 0.2387 / Time taken: 0:07:38 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0315 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 25 / Train-Loss: 0.2383 / Val-Loss: 0.2385 / Test-Loss: 0.2387 / Time taken: 0:08:00 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 06/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0316 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 26 / Train-Loss: 0.2381 / Val-Loss: 0.2384 / Test-Loss: 0.2387 / Time taken: 0:08:22 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 06/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 27 / Train-Loss: 0.2380 / Val-Loss: 0.2385 / Test-Loss: 0.2387 / Time taken: 0:08:39 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 06/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 28 / Train-Loss: 0.2381 / Val-Loss: 0.2383 / Test-Loss: 0.2385 / Time taken: 0:08:53 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 06/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 29 / Train-Loss: 0.2380 / Val-Loss: 0.2382 / Test-Loss: 0.2384 / Time taken: 0:09:08 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 30 / Train-Loss: 0.2380 / Val-Loss: 0.2383 / Test-Loss: 0.2386 / Time taken: 0:09:23 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 06/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 31 / Train-Loss: 0.2378 / Val-Loss: 0.2385 / Test-Loss: 0.2388 / Time taken: 0:09:38 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 06/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 32 / Train-Loss: 0.2378 / Val-Loss: 0.2384 / Test-Loss: 0.2388 / Time taken: 0:09:52 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 06/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 33 / Train-Loss: 0.2378 / Val-Loss: 0.2384 / Test-Loss: 0.2388 / Time taken: 0:10:14 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 06/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 34 / Train-Loss: 0.2378 / Val-Loss: 0.2383 / Test-Loss: 0.2388 / Time taken: 0:10:29 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 06/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 35 / Train-Loss: 0.2378 / Val-Loss: 0.2383 / Test-Loss: 0.2387 / Time taken: 0:10:51 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 06/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 36 / Train-Loss: 0.2378 / Val-Loss: 0.2382 / Test-Loss: 0.2385 / Time taken: 0:11:05 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 37 / Train-Loss: 0.2376 / Val-Loss: 0.2384 / Test-Loss: 0.2387 / Time taken: 0:11:29 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 06/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 38 / Train-Loss: 0.2375 / Val-Loss: 0.2383 / Test-Loss: 0.2386 / Time taken: 0:11:44 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 06/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 39 / Train-Loss: 0.2376 / Val-Loss: 0.2383 / Test-Loss: 0.2386 / Time taken: 0:11:59 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 06/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 40 / Train-Loss: 0.2375 / Val-Loss: 0.2382 / Test-Loss: 0.2387 / Time taken: 0:12:14 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 41 / Train-Loss: 0.2374 / Val-Loss: 0.2385 / Test-Loss: 0.2388 / Time taken: 0:12:36 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 06/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 42 / Train-Loss: 0.2374 / Val-Loss: 0.2381 / Test-Loss: 0.2387 / Time taken: 0:12:52 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 43 / Train-Loss: 0.2374 / Val-Loss: 0.2382 / Test-Loss: 0.2386 / Time taken: 0:13:08 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 44 / Train-Loss: 0.2374 / Val-Loss: 0.2383 / Test-Loss: 0.2387 / Time taken: 0:13:25 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 45 / Train-Loss: 0.2373 / Val-Loss: 0.2383 / Test-Loss: 0.2388 / Time taken: 0:13:40 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 46 / Train-Loss: 0.2373 / Val-Loss: 0.2381 / Test-Loss: 0.2388 / Time taken: 0:13:54 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 47 / Train-Loss: 0.2373 / Val-Loss: 0.2382 / Test-Loss: 0.2386 / Time taken: 0:14:09 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 48 / Train-Loss: 0.2372 / Val-Loss: 0.2383 / Test-Loss: 0.2389 / Time taken: 0:14:24 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 49 / Train-Loss: 0.2372 / Val-Loss: 0.2382 / Test-Loss: 0.2386 / Time taken: 0:14:38 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 50 / Train-Loss: 0.2372 / Val-Loss: 0.2383 / Test-Loss: 0.2388 / Time taken: 0:14:53 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 51 / Train-Loss: 0.2372 / Val-Loss: 0.2382 / Test-Loss: 0.2386 / Time taken: 0:15:07 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 06/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 52 / Train-Loss: 0.2371 / Val-Loss: 0.2381 / Test-Loss: 0.2386 / Time taken: 0:15:29 / ---- Currently Best Val-Epoch: 52 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 53 / Train-Loss: 0.2370 / Val-Loss: 0.2381 / Test-Loss: 0.2386 / Time taken: 0:15:45 / ---- Currently Best Val-Epoch: 53 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 54 / Train-Loss: 0.2371 / Val-Loss: 0.2382 / Test-Loss: 0.2387 / Time taken: 0:16:01 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 06/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 55 / Train-Loss: 0.2370 / Val-Loss: 0.2382 / Test-Loss: 0.2388 / Time taken: 0:16:17 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 06/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 56 / Train-Loss: 0.2370 / Val-Loss: 0.2383 / Test-Loss: 0.2388 / Time taken: 0:16:39 / ---- Currently Best Val-Epoch: 53 \n","Ensemble: 06/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 57 / Train-Loss: 0.2369 / Val-Loss: 0.2380 / Test-Loss: 0.2387 / Time taken: 0:16:54 / ---- Currently Best Val-Epoch: 57 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 58 / Train-Loss: 0.2369 / Val-Loss: 0.2382 / Test-Loss: 0.2388 / Time taken: 0:17:10 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 06/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 59 / Train-Loss: 0.2369 / Val-Loss: 0.2383 / Test-Loss: 0.2387 / Time taken: 0:17:32 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 06/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 60 / Train-Loss: 0.2370 / Val-Loss: 0.2380 / Test-Loss: 0.2388 / Time taken: 0:17:46 / ---- Currently Best Val-Epoch: 60 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 61 / Train-Loss: 0.2367 / Val-Loss: 0.2383 / Test-Loss: 0.2389 / Time taken: 0:18:02 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 06/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 62 / Train-Loss: 0.2368 / Val-Loss: 0.2381 / Test-Loss: 0.2387 / Time taken: 0:18:16 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 06/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 63 / Train-Loss: 0.2367 / Val-Loss: 0.2382 / Test-Loss: 0.2389 / Time taken: 0:18:31 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 06/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 64 / Train-Loss: 0.2367 / Val-Loss: 0.2381 / Test-Loss: 0.2386 / Time taken: 0:18:53 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 06/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 65 / Train-Loss: 0.2366 / Val-Loss: 0.2382 / Test-Loss: 0.2388 / Time taken: 0:19:09 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 06/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 66 / Train-Loss: 0.2366 / Val-Loss: 0.2381 / Test-Loss: 0.2388 / Time taken: 0:19:25 / ---- Currently Best Val-Epoch: 60 \n","Ensemble: 06/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 67 / Train-Loss: 0.2366 / Val-Loss: 0.2380 / Test-Loss: 0.2388 / Time taken: 0:19:41 / ---- Currently Best Val-Epoch: 67 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 68 / Train-Loss: 0.2367 / Val-Loss: 0.2382 / Test-Loss: 0.2387 / Time taken: 0:19:56 / ---- Currently Best Val-Epoch: 67 \n","Ensemble: 06/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 69 / Train-Loss: 0.2365 / Val-Loss: 0.2384 / Test-Loss: 0.2389 / Time taken: 0:20:10 / ---- Currently Best Val-Epoch: 67 \n","Ensemble: 06/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 70 / Train-Loss: 0.2366 / Val-Loss: 0.2380 / Test-Loss: 0.2387 / Time taken: 0:20:25 / ---- Currently Best Val-Epoch: 70 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 71 / Train-Loss: 0.2364 / Val-Loss: 0.2383 / Test-Loss: 0.2388 / Time taken: 0:20:40 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 06/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 72 / Train-Loss: 0.2364 / Val-Loss: 0.2383 / Test-Loss: 0.2390 / Time taken: 0:21:02 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 06/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 73 / Train-Loss: 0.2364 / Val-Loss: 0.2380 / Test-Loss: 0.2388 / Time taken: 0:21:17 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 06/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 74 / Train-Loss: 0.2364 / Val-Loss: 0.2381 / Test-Loss: 0.2387 / Time taken: 0:21:33 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 06/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 75 / Train-Loss: 0.2363 / Val-Loss: 0.2380 / Test-Loss: 0.2387 / Time taken: 0:21:48 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 06/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 76 / Train-Loss: 0.2364 / Val-Loss: 0.2383 / Test-Loss: 0.2389 / Time taken: 0:22:05 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 06/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 77 / Train-Loss: 0.2362 / Val-Loss: 0.2382 / Test-Loss: 0.2387 / Time taken: 0:22:21 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 06/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 78 / Train-Loss: 0.2362 / Val-Loss: 0.2383 / Test-Loss: 0.2390 / Time taken: 0:22:37 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 06/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 79 / Train-Loss: 0.2361 / Val-Loss: 0.2384 / Test-Loss: 0.2388 / Time taken: 0:22:52 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 06/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 80 / Train-Loss: 0.2361 / Val-Loss: 0.2382 / Test-Loss: 0.2389 / Time taken: 0:23:07 / ---- Currently Best Val-Epoch: 70 \n","Ensemble: 06/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 81 / Train-Loss: 0.2361 / Val-Loss: 0.2379 / Test-Loss: 0.2387 / Time taken: 0:23:22 / ---- Currently Best Val-Epoch: 81 <------- Best VAL Epoch so far\n","Ensemble: 06/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 82 / Train-Loss: 0.2361 / Val-Loss: 0.2383 / Test-Loss: 0.2390 / Time taken: 0:23:44 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 83 / Train-Loss: 0.2359 / Val-Loss: 0.2380 / Test-Loss: 0.2388 / Time taken: 0:24:06 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 84 / Train-Loss: 0.2359 / Val-Loss: 0.2380 / Test-Loss: 0.2389 / Time taken: 0:24:27 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 85 / Train-Loss: 0.2359 / Val-Loss: 0.2382 / Test-Loss: 0.2391 / Time taken: 0:24:49 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 86 / Train-Loss: 0.2358 / Val-Loss: 0.2381 / Test-Loss: 0.2391 / Time taken: 0:25:05 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 87 / Train-Loss: 0.2358 / Val-Loss: 0.2379 / Test-Loss: 0.2388 / Time taken: 0:25:20 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 88 / Train-Loss: 0.2357 / Val-Loss: 0.2383 / Test-Loss: 0.2390 / Time taken: 0:25:43 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 89 / Train-Loss: 0.2359 / Val-Loss: 0.2381 / Test-Loss: 0.2389 / Time taken: 0:25:58 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 90 / Train-Loss: 0.2358 / Val-Loss: 0.2382 / Test-Loss: 0.2388 / Time taken: 0:26:13 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 91 / Train-Loss: 0.2357 / Val-Loss: 0.2383 / Test-Loss: 0.2389 / Time taken: 0:26:28 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 92 / Train-Loss: 0.2357 / Val-Loss: 0.2380 / Test-Loss: 0.2389 / Time taken: 0:26:43 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 93 / Train-Loss: 0.2357 / Val-Loss: 0.2381 / Test-Loss: 0.2389 / Time taken: 0:26:58 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 94 / Train-Loss: 0.2355 / Val-Loss: 0.2385 / Test-Loss: 0.2390 / Time taken: 0:27:20 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 95 / Train-Loss: 0.2356 / Val-Loss: 0.2381 / Test-Loss: 0.2388 / Time taken: 0:27:36 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 96 / Train-Loss: 0.2355 / Val-Loss: 0.2382 / Test-Loss: 0.2388 / Time taken: 0:27:52 / ---- Currently Best Val-Epoch: 81 \n","Ensemble: 06/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 06/14 / Epoch: 97 / Train-Loss: 0.2354 / Val-Loss: 0.2380 / Test-Loss: 0.2389 / Time taken: 0:28:08 / ---- Currently Best Val-Epoch: 81 \n","596/596 [==============================] - 12s 18ms/step\n","67/67 [==============================] - 1s 16ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-46b8c0ba-582c-4c6d-b36c-40458810e442\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>LocalGLMftt (run: 2)</td>\n","      <td>34</td>\n","      <td>842.569307</td>\n","      <td>27430</td>\n","      <td>0.237727</td>\n","      <td>0.238600</td>\n","      <td>0.067902</td>\n","      <td>0.068265</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>LocalGLMftt (run: 3)</td>\n","      <td>62</td>\n","      <td>1377.378268</td>\n","      <td>27430</td>\n","      <td>0.237049</td>\n","      <td>0.239091</td>\n","      <td>0.067171</td>\n","      <td>0.067539</td>\n","    </tr>\n","    <tr>\n","      <th>154</th>\n","      <td>LocalGLMftt (run: 4)</td>\n","      <td>52</td>\n","      <td>1172.448311</td>\n","      <td>27430</td>\n","      <td>0.237175</td>\n","      <td>0.238773</td>\n","      <td>0.067236</td>\n","      <td>0.067723</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>LocalGLMftt (run: 5)</td>\n","      <td>58</td>\n","      <td>1289.168909</td>\n","      <td>27430</td>\n","      <td>0.237039</td>\n","      <td>0.238749</td>\n","      <td>0.068158</td>\n","      <td>0.068611</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>LocalGLMftt (run: 6)</td>\n","      <td>81</td>\n","      <td>1688.195204</td>\n","      <td>27430</td>\n","      <td>0.236139</td>\n","      <td>0.238735</td>\n","      <td>0.066555</td>\n","      <td>0.066987</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>157 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46b8c0ba-582c-4c6d-b36c-40458810e442')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-46b8c0ba-582c-4c6d-b36c-40458810e442 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-46b8c0ba-582c-4c6d-b36c-40458810e442');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d95dfce4-49dc-41d3-8059-ea60e0f58c35\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d95dfce4-49dc-41d3-8059-ea60e0f58c35')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d95dfce4-49dc-41d3-8059-ea60e0f58c35 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","152        LocalGLMftt (run: 2)      34   842.569307          27430   \n","153        LocalGLMftt (run: 3)      62  1377.378268          27430   \n","154        LocalGLMftt (run: 4)      52  1172.448311          27430   \n","155        LocalGLMftt (run: 5)      58  1289.168909          27430   \n","156        LocalGLMftt (run: 6)      81  1688.195204          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","152    0.237727   0.238600             0.067902            0.068265  \n","153    0.237049   0.239091             0.067171            0.067539  \n","154    0.237175   0.238773             0.067236            0.067723  \n","155    0.237039   0.238749             0.068158            0.068611  \n","156    0.236139   0.238735             0.066555            0.066987  \n","\n","[157 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 07-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 07/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 0 / Train-Loss: 0.2414 / Val-Loss: 0.2456 / Test-Loss: 0.2424 / Time taken: 0:00:34 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 1 / Train-Loss: 0.2412 / Val-Loss: 0.2456 / Test-Loss: 0.2422 / Time taken: 0:00:49 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 2 / Train-Loss: 0.2410 / Val-Loss: 0.2452 / Test-Loss: 0.2417 / Time taken: 0:01:04 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 3 / Train-Loss: 0.2408 / Val-Loss: 0.2452 / Test-Loss: 0.2415 / Time taken: 0:01:26 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 07/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 4 / Train-Loss: 0.2406 / Val-Loss: 0.2452 / Test-Loss: 0.2413 / Time taken: 0:01:48 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 07/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 5 / Train-Loss: 0.2405 / Val-Loss: 0.2452 / Test-Loss: 0.2411 / Time taken: 0:02:04 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 07/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 6 / Train-Loss: 0.2403 / Val-Loss: 0.2452 / Test-Loss: 0.2410 / Time taken: 0:02:19 / ---- Currently Best Val-Epoch: 2 \n","Ensemble: 07/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 7 / Train-Loss: 0.2402 / Val-Loss: 0.2451 / Test-Loss: 0.2409 / Time taken: 0:02:41 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 8 / Train-Loss: 0.2400 / Val-Loss: 0.2449 / Test-Loss: 0.2406 / Time taken: 0:03:02 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 9 / Train-Loss: 0.2398 / Val-Loss: 0.2448 / Test-Loss: 0.2404 / Time taken: 0:03:20 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 10 / Train-Loss: 0.2396 / Val-Loss: 0.2448 / Test-Loss: 0.2404 / Time taken: 0:03:35 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 07/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 11 / Train-Loss: 0.2395 / Val-Loss: 0.2447 / Test-Loss: 0.2401 / Time taken: 0:03:51 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 12 / Batch: 0 / Train-Loss (Batch): 0.1953   : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 07/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 12 / Train-Loss: 0.2393 / Val-Loss: 0.2446 / Test-Loss: 0.2399 / Time taken: 0:04:05 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 13 / Train-Loss: 0.2393 / Val-Loss: 0.2445 / Test-Loss: 0.2398 / Time taken: 0:04:20 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 14 / Train-Loss: 0.2391 / Val-Loss: 0.2445 / Test-Loss: 0.2398 / Time taken: 0:04:34 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 15 / Train-Loss: 0.2390 / Val-Loss: 0.2442 / Test-Loss: 0.2395 / Time taken: 0:04:56 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 16 / Train-Loss: 0.2388 / Val-Loss: 0.2443 / Test-Loss: 0.2394 / Time taken: 0:05:18 / ---- Currently Best Val-Epoch: 15 \n","Ensemble: 07/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 17 / Train-Loss: 0.2387 / Val-Loss: 0.2442 / Test-Loss: 0.2393 / Time taken: 0:05:33 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 18 / Train-Loss: 0.2387 / Val-Loss: 0.2441 / Test-Loss: 0.2393 / Time taken: 0:05:56 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 19 / Train-Loss: 0.2385 / Val-Loss: 0.2440 / Test-Loss: 0.2391 / Time taken: 0:06:12 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 20 / Train-Loss: 0.2385 / Val-Loss: 0.2439 / Test-Loss: 0.2392 / Time taken: 0:06:27 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 21 / Train-Loss: 0.2383 / Val-Loss: 0.2440 / Test-Loss: 0.2393 / Time taken: 0:06:42 / ---- Currently Best Val-Epoch: 20 \n","Ensemble: 07/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 22 / Train-Loss: 0.2384 / Val-Loss: 0.2438 / Test-Loss: 0.2391 / Time taken: 0:06:56 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 23 / Train-Loss: 0.2382 / Val-Loss: 0.2437 / Test-Loss: 0.2390 / Time taken: 0:07:11 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0313 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 24 / Train-Loss: 0.2382 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:07:26 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 25 / Train-Loss: 0.2381 / Val-Loss: 0.2435 / Test-Loss: 0.2389 / Time taken: 0:07:40 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 26 / Train-Loss: 0.2380 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:07:55 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 07/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 27 / Train-Loss: 0.2379 / Val-Loss: 0.2434 / Test-Loss: 0.2389 / Time taken: 0:08:09 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 28 / Train-Loss: 0.2378 / Val-Loss: 0.2434 / Test-Loss: 0.2389 / Time taken: 0:08:31 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 07/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 29 / Train-Loss: 0.2377 / Val-Loss: 0.2434 / Test-Loss: 0.2389 / Time taken: 0:08:47 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 30 / Train-Loss: 0.2377 / Val-Loss: 0.2432 / Test-Loss: 0.2389 / Time taken: 0:09:02 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 31 / Train-Loss: 0.2377 / Val-Loss: 0.2433 / Test-Loss: 0.2390 / Time taken: 0:09:17 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 07/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 32 / Train-Loss: 0.2377 / Val-Loss: 0.2432 / Test-Loss: 0.2390 / Time taken: 0:09:39 / ---- Currently Best Val-Epoch: 30 \n","Ensemble: 07/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 33 / Train-Loss: 0.2376 / Val-Loss: 0.2432 / Test-Loss: 0.2390 / Time taken: 0:09:54 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 34 / Train-Loss: 0.2375 / Val-Loss: 0.2432 / Test-Loss: 0.2389 / Time taken: 0:10:09 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 07/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 35 / Train-Loss: 0.2374 / Val-Loss: 0.2430 / Test-Loss: 0.2389 / Time taken: 0:10:32 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 36 / Train-Loss: 0.2374 / Val-Loss: 0.2430 / Test-Loss: 0.2389 / Time taken: 0:10:46 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 07/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 37 / Train-Loss: 0.2373 / Val-Loss: 0.2430 / Test-Loss: 0.2389 / Time taken: 0:11:01 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 07/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 38 / Train-Loss: 0.2373 / Val-Loss: 0.2430 / Test-Loss: 0.2390 / Time taken: 0:11:15 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 39 / Train-Loss: 0.2373 / Val-Loss: 0.2428 / Test-Loss: 0.2388 / Time taken: 0:11:31 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 07/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 40 / Train-Loss: 0.2372 / Val-Loss: 0.2429 / Test-Loss: 0.2389 / Time taken: 0:11:45 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 41 / Train-Loss: 0.2372 / Val-Loss: 0.2429 / Test-Loss: 0.2389 / Time taken: 0:12:00 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 42 / Train-Loss: 0.2371 / Val-Loss: 0.2430 / Test-Loss: 0.2389 / Time taken: 0:12:14 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 43 / Train-Loss: 0.2370 / Val-Loss: 0.2430 / Test-Loss: 0.2390 / Time taken: 0:12:29 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 44 / Train-Loss: 0.2371 / Val-Loss: 0.2430 / Test-Loss: 0.2390 / Time taken: 0:12:43 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 45 / Train-Loss: 0.2371 / Val-Loss: 0.2430 / Test-Loss: 0.2390 / Time taken: 0:12:59 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 46 / Train-Loss: 0.2369 / Val-Loss: 0.2430 / Test-Loss: 0.2390 / Time taken: 0:13:13 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 47 / Train-Loss: 0.2370 / Val-Loss: 0.2431 / Test-Loss: 0.2390 / Time taken: 0:13:28 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 48 / Train-Loss: 0.2369 / Val-Loss: 0.2430 / Test-Loss: 0.2390 / Time taken: 0:13:50 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 49 / Train-Loss: 0.2369 / Val-Loss: 0.2431 / Test-Loss: 0.2391 / Time taken: 0:14:05 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 50 / Train-Loss: 0.2369 / Val-Loss: 0.2430 / Test-Loss: 0.2390 / Time taken: 0:14:20 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 51 / Train-Loss: 0.2368 / Val-Loss: 0.2430 / Test-Loss: 0.2392 / Time taken: 0:14:36 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 52 / Train-Loss: 0.2367 / Val-Loss: 0.2430 / Test-Loss: 0.2391 / Time taken: 0:14:51 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 53 / Train-Loss: 0.2367 / Val-Loss: 0.2432 / Test-Loss: 0.2392 / Time taken: 0:15:06 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 54 / Train-Loss: 0.2369 / Val-Loss: 0.2429 / Test-Loss: 0.2390 / Time taken: 0:15:21 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 07/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 07/14 / Epoch: 55 / Train-Loss: 0.2367 / Val-Loss: 0.2429 / Test-Loss: 0.2390 / Time taken: 0:15:38 / ---- Currently Best Val-Epoch: 39 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 21ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-b7e96272-6539-4129-8d41-0ab2fa0d45b5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>LocalGLMftt (run: 3)</td>\n","      <td>62</td>\n","      <td>1377.378268</td>\n","      <td>27430</td>\n","      <td>0.237049</td>\n","      <td>0.239091</td>\n","      <td>0.067171</td>\n","      <td>0.067539</td>\n","    </tr>\n","    <tr>\n","      <th>154</th>\n","      <td>LocalGLMftt (run: 4)</td>\n","      <td>52</td>\n","      <td>1172.448311</td>\n","      <td>27430</td>\n","      <td>0.237175</td>\n","      <td>0.238773</td>\n","      <td>0.067236</td>\n","      <td>0.067723</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>LocalGLMftt (run: 5)</td>\n","      <td>58</td>\n","      <td>1289.168909</td>\n","      <td>27430</td>\n","      <td>0.237039</td>\n","      <td>0.238749</td>\n","      <td>0.068158</td>\n","      <td>0.068611</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>LocalGLMftt (run: 6)</td>\n","      <td>81</td>\n","      <td>1688.195204</td>\n","      <td>27430</td>\n","      <td>0.236139</td>\n","      <td>0.238735</td>\n","      <td>0.066555</td>\n","      <td>0.066987</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>LocalGLMftt (run: 7)</td>\n","      <td>39</td>\n","      <td>938.974456</td>\n","      <td>27430</td>\n","      <td>0.237802</td>\n","      <td>0.238847</td>\n","      <td>0.068716</td>\n","      <td>0.069133</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>158 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7e96272-6539-4129-8d41-0ab2fa0d45b5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b7e96272-6539-4129-8d41-0ab2fa0d45b5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b7e96272-6539-4129-8d41-0ab2fa0d45b5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8d60d69e-0906-4e21-af04-691ac82580f9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d60d69e-0906-4e21-af04-691ac82580f9')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8d60d69e-0906-4e21-af04-691ac82580f9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","153        LocalGLMftt (run: 3)      62  1377.378268          27430   \n","154        LocalGLMftt (run: 4)      52  1172.448311          27430   \n","155        LocalGLMftt (run: 5)      58  1289.168909          27430   \n","156        LocalGLMftt (run: 6)      81  1688.195204          27430   \n","157        LocalGLMftt (run: 7)      39   938.974456          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","153    0.237049   0.239091             0.067171            0.067539  \n","154    0.237175   0.238773             0.067236            0.067723  \n","155    0.237039   0.238749             0.068158            0.068611  \n","156    0.236139   0.238735             0.066555            0.066987  \n","157    0.237802   0.238847             0.068716            0.069133  \n","\n","[158 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 08-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 08/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.034   : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 0 / Train-Loss: 0.2409 / Val-Loss: 0.2500 / Test-Loss: 0.2423 / Time taken: 0:00:31 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 1 / Train-Loss: 0.2408 / Val-Loss: 0.2500 / Test-Loss: 0.2420 / Time taken: 0:00:45 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 2 / Train-Loss: 0.2406 / Val-Loss: 0.2497 / Test-Loss: 0.2417 / Time taken: 0:01:00 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 3 / Train-Loss: 0.2404 / Val-Loss: 0.2496 / Test-Loss: 0.2416 / Time taken: 0:01:23 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 4 / Train-Loss: 0.2402 / Val-Loss: 0.2496 / Test-Loss: 0.2414 / Time taken: 0:01:38 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 5 / Train-Loss: 0.2400 / Val-Loss: 0.2493 / Test-Loss: 0.2410 / Time taken: 0:01:52 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 6 / Train-Loss: 0.2398 / Val-Loss: 0.2492 / Test-Loss: 0.2408 / Time taken: 0:02:07 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 7 / Train-Loss: 0.2396 / Val-Loss: 0.2490 / Test-Loss: 0.2406 / Time taken: 0:02:21 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 8 / Train-Loss: 0.2395 / Val-Loss: 0.2487 / Test-Loss: 0.2404 / Time taken: 0:02:35 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 9 / Train-Loss: 0.2392 / Val-Loss: 0.2485 / Test-Loss: 0.2401 / Time taken: 0:02:50 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 10 / Train-Loss: 0.2390 / Val-Loss: 0.2483 / Test-Loss: 0.2399 / Time taken: 0:03:04 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 11 / Batch: 0 / Train-Loss (Batch): 0.1989   : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 08/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 11 / Train-Loss: 0.2389 / Val-Loss: 0.2482 / Test-Loss: 0.2398 / Time taken: 0:03:19 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 12 / Train-Loss: 0.2388 / Val-Loss: 0.2481 / Test-Loss: 0.2398 / Time taken: 0:03:33 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 13 / Train-Loss: 0.2386 / Val-Loss: 0.2478 / Test-Loss: 0.2395 / Time taken: 0:03:48 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 14 / Train-Loss: 0.2386 / Val-Loss: 0.2477 / Test-Loss: 0.2394 / Time taken: 0:04:03 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 15 / Train-Loss: 0.2384 / Val-Loss: 0.2479 / Test-Loss: 0.2396 / Time taken: 0:04:17 / ---- Currently Best Val-Epoch: 14 \n","Ensemble: 08/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 16 / Train-Loss: 0.2383 / Val-Loss: 0.2475 / Test-Loss: 0.2394 / Time taken: 0:04:32 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 17 / Train-Loss: 0.2382 / Val-Loss: 0.2474 / Test-Loss: 0.2394 / Time taken: 0:04:46 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 18 / Train-Loss: 0.2381 / Val-Loss: 0.2474 / Test-Loss: 0.2393 / Time taken: 0:05:01 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 19 / Train-Loss: 0.2380 / Val-Loss: 0.2473 / Test-Loss: 0.2394 / Time taken: 0:05:15 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 20 / Train-Loss: 0.2380 / Val-Loss: 0.2471 / Test-Loss: 0.2392 / Time taken: 0:05:30 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 21 / Train-Loss: 0.2379 / Val-Loss: 0.2473 / Test-Loss: 0.2394 / Time taken: 0:05:44 / ---- Currently Best Val-Epoch: 20 \n","Ensemble: 08/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 22 / Train-Loss: 0.2379 / Val-Loss: 0.2472 / Test-Loss: 0.2392 / Time taken: 0:05:59 / ---- Currently Best Val-Epoch: 20 \n","Ensemble: 08/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 23 / Train-Loss: 0.2378 / Val-Loss: 0.2471 / Test-Loss: 0.2391 / Time taken: 0:06:13 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 24 / Train-Loss: 0.2377 / Val-Loss: 0.2473 / Test-Loss: 0.2393 / Time taken: 0:06:28 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 08/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 25 / Train-Loss: 0.2377 / Val-Loss: 0.2472 / Test-Loss: 0.2392 / Time taken: 0:06:42 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 08/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 26 / Train-Loss: 0.2375 / Val-Loss: 0.2472 / Test-Loss: 0.2392 / Time taken: 0:06:56 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 08/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 27 / Train-Loss: 0.2375 / Val-Loss: 0.2473 / Test-Loss: 0.2394 / Time taken: 0:07:11 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 08/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 28 / Train-Loss: 0.2374 / Val-Loss: 0.2474 / Test-Loss: 0.2393 / Time taken: 0:07:25 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 08/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 29 / Train-Loss: 0.2373 / Val-Loss: 0.2473 / Test-Loss: 0.2394 / Time taken: 0:07:40 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 08/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 30 / Train-Loss: 0.2373 / Val-Loss: 0.2474 / Test-Loss: 0.2394 / Time taken: 0:07:55 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 08/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 31 / Train-Loss: 0.2373 / Val-Loss: 0.2469 / Test-Loss: 0.2391 / Time taken: 0:08:09 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 32 / Train-Loss: 0.2372 / Val-Loss: 0.2473 / Test-Loss: 0.2393 / Time taken: 0:08:24 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 33 / Train-Loss: 0.2371 / Val-Loss: 0.2470 / Test-Loss: 0.2391 / Time taken: 0:08:38 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 34 / Train-Loss: 0.2370 / Val-Loss: 0.2470 / Test-Loss: 0.2390 / Time taken: 0:08:52 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 35 / Train-Loss: 0.2370 / Val-Loss: 0.2471 / Test-Loss: 0.2391 / Time taken: 0:09:07 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 36 / Train-Loss: 0.2370 / Val-Loss: 0.2470 / Test-Loss: 0.2388 / Time taken: 0:09:21 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 37 / Train-Loss: 0.2369 / Val-Loss: 0.2470 / Test-Loss: 0.2390 / Time taken: 0:09:36 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 38 / Train-Loss: 0.2369 / Val-Loss: 0.2470 / Test-Loss: 0.2392 / Time taken: 0:09:58 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0316 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 39 / Train-Loss: 0.2369 / Val-Loss: 0.2471 / Test-Loss: 0.2391 / Time taken: 0:10:12 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 08/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 40 / Train-Loss: 0.2369 / Val-Loss: 0.2469 / Test-Loss: 0.2389 / Time taken: 0:10:34 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 41 / Train-Loss: 0.2367 / Val-Loss: 0.2471 / Test-Loss: 0.2391 / Time taken: 0:10:49 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 08/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 42 / Train-Loss: 0.2368 / Val-Loss: 0.2468 / Test-Loss: 0.2389 / Time taken: 0:11:10 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 08/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 43 / Train-Loss: 0.2366 / Val-Loss: 0.2473 / Test-Loss: 0.2392 / Time taken: 0:11:26 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 44 / Train-Loss: 0.2367 / Val-Loss: 0.2471 / Test-Loss: 0.2392 / Time taken: 0:11:47 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 45 / Train-Loss: 0.2366 / Val-Loss: 0.2470 / Test-Loss: 0.2391 / Time taken: 0:12:09 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 46 / Train-Loss: 0.2367 / Val-Loss: 0.2472 / Test-Loss: 0.2391 / Time taken: 0:12:24 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 47 / Train-Loss: 0.2365 / Val-Loss: 0.2471 / Test-Loss: 0.2391 / Time taken: 0:12:39 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 48 / Train-Loss: 0.2365 / Val-Loss: 0.2470 / Test-Loss: 0.2389 / Time taken: 0:12:54 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 49 / Train-Loss: 0.2364 / Val-Loss: 0.2469 / Test-Loss: 0.2389 / Time taken: 0:13:09 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 50 / Train-Loss: 0.2365 / Val-Loss: 0.2471 / Test-Loss: 0.2390 / Time taken: 0:13:24 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 51 / Train-Loss: 0.2363 / Val-Loss: 0.2473 / Test-Loss: 0.2394 / Time taken: 0:13:45 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 52 / Train-Loss: 0.2364 / Val-Loss: 0.2472 / Test-Loss: 0.2391 / Time taken: 0:14:07 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 53 / Train-Loss: 0.2363 / Val-Loss: 0.2473 / Test-Loss: 0.2392 / Time taken: 0:14:22 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 54 / Train-Loss: 0.2363 / Val-Loss: 0.2471 / Test-Loss: 0.2389 / Time taken: 0:14:43 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 55 / Train-Loss: 0.2362 / Val-Loss: 0.2470 / Test-Loss: 0.2389 / Time taken: 0:14:58 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 56 / Train-Loss: 0.2363 / Val-Loss: 0.2472 / Test-Loss: 0.2391 / Time taken: 0:15:13 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 57 / Train-Loss: 0.2362 / Val-Loss: 0.2470 / Test-Loss: 0.2389 / Time taken: 0:15:35 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 08/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 08/14 / Epoch: 58 / Train-Loss: 0.2362 / Val-Loss: 0.2471 / Test-Loss: 0.2391 / Time taken: 0:15:51 / ---- Currently Best Val-Epoch: 42 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 2s 23ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-b1faf7bd-17e8-4c62-8bdb-5f9e3e6babcd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>154</th>\n","      <td>LocalGLMftt (run: 4)</td>\n","      <td>52</td>\n","      <td>1172.448311</td>\n","      <td>27430</td>\n","      <td>0.237175</td>\n","      <td>0.238773</td>\n","      <td>0.067236</td>\n","      <td>0.067723</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>LocalGLMftt (run: 5)</td>\n","      <td>58</td>\n","      <td>1289.168909</td>\n","      <td>27430</td>\n","      <td>0.237039</td>\n","      <td>0.238749</td>\n","      <td>0.068158</td>\n","      <td>0.068611</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>LocalGLMftt (run: 6)</td>\n","      <td>81</td>\n","      <td>1688.195204</td>\n","      <td>27430</td>\n","      <td>0.236139</td>\n","      <td>0.238735</td>\n","      <td>0.066555</td>\n","      <td>0.066987</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>LocalGLMftt (run: 7)</td>\n","      <td>39</td>\n","      <td>938.974456</td>\n","      <td>27430</td>\n","      <td>0.237802</td>\n","      <td>0.238847</td>\n","      <td>0.068716</td>\n","      <td>0.069133</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>LocalGLMftt (run: 8)</td>\n","      <td>42</td>\n","      <td>951.956478</td>\n","      <td>27430</td>\n","      <td>0.237784</td>\n","      <td>0.238886</td>\n","      <td>0.068275</td>\n","      <td>0.068710</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>159 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1faf7bd-17e8-4c62-8bdb-5f9e3e6babcd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b1faf7bd-17e8-4c62-8bdb-5f9e3e6babcd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b1faf7bd-17e8-4c62-8bdb-5f9e3e6babcd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3e4505d8-4374-4343-84be-71fe08e2aee2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e4505d8-4374-4343-84be-71fe08e2aee2')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3e4505d8-4374-4343-84be-71fe08e2aee2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","154        LocalGLMftt (run: 4)      52  1172.448311          27430   \n","155        LocalGLMftt (run: 5)      58  1289.168909          27430   \n","156        LocalGLMftt (run: 6)      81  1688.195204          27430   \n","157        LocalGLMftt (run: 7)      39   938.974456          27430   \n","158        LocalGLMftt (run: 8)      42   951.956478          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","154    0.237175   0.238773             0.067236            0.067723  \n","155    0.237039   0.238749             0.068158            0.068611  \n","156    0.236139   0.238735             0.066555            0.066987  \n","157    0.237802   0.238847             0.068716            0.069133  \n","158    0.237784   0.238886             0.068275            0.068710  \n","\n","[159 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 09-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 09/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0075  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 0 / Train-Loss: 0.2413 / Val-Loss: 0.2462 / Test-Loss: 0.2424 / Time taken: 0:00:30 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.007   : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 1 / Train-Loss: 0.2412 / Val-Loss: 0.2461 / Test-Loss: 0.2422 / Time taken: 0:00:44 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0069  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 2 / Train-Loss: 0.2410 / Val-Loss: 0.2459 / Test-Loss: 0.2419 / Time taken: 0:00:58 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0069  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 3 / Train-Loss: 0.2408 / Val-Loss: 0.2458 / Test-Loss: 0.2417 / Time taken: 0:01:20 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0067  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 4 / Train-Loss: 0.2407 / Val-Loss: 0.2458 / Test-Loss: 0.2416 / Time taken: 0:01:35 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0068  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 5 / Train-Loss: 0.2406 / Val-Loss: 0.2457 / Test-Loss: 0.2415 / Time taken: 0:01:49 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0067  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 6 / Train-Loss: 0.2405 / Val-Loss: 0.2456 / Test-Loss: 0.2413 / Time taken: 0:02:04 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0068  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 7 / Train-Loss: 0.2403 / Val-Loss: 0.2455 / Test-Loss: 0.2410 / Time taken: 0:02:26 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0068  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 8 / Train-Loss: 0.2402 / Val-Loss: 0.2453 / Test-Loss: 0.2408 / Time taken: 0:02:40 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0068  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 9 / Train-Loss: 0.2399 / Val-Loss: 0.2452 / Test-Loss: 0.2406 / Time taken: 0:02:54 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 10 / Train-Loss: 0.2397 / Val-Loss: 0.2450 / Test-Loss: 0.2403 / Time taken: 0:03:09 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 11 / Batch: 0 / Train-Loss (Batch): 0.1899   : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 09/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 11 / Train-Loss: 0.2395 / Val-Loss: 0.2448 / Test-Loss: 0.2402 / Time taken: 0:03:23 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 12 / Train-Loss: 0.2393 / Val-Loss: 0.2446 / Test-Loss: 0.2399 / Time taken: 0:03:38 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 13 / Train-Loss: 0.2391 / Val-Loss: 0.2447 / Test-Loss: 0.2399 / Time taken: 0:03:53 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 09/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 14 / Train-Loss: 0.2390 / Val-Loss: 0.2446 / Test-Loss: 0.2397 / Time taken: 0:04:07 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 15 / Train-Loss: 0.2389 / Val-Loss: 0.2445 / Test-Loss: 0.2396 / Time taken: 0:04:22 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 16 / Train-Loss: 0.2387 / Val-Loss: 0.2444 / Test-Loss: 0.2395 / Time taken: 0:04:37 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 17 / Train-Loss: 0.2387 / Val-Loss: 0.2443 / Test-Loss: 0.2393 / Time taken: 0:04:52 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 18 / Train-Loss: 0.2385 / Val-Loss: 0.2443 / Test-Loss: 0.2393 / Time taken: 0:05:07 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 09/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 19 / Train-Loss: 0.2384 / Val-Loss: 0.2443 / Test-Loss: 0.2395 / Time taken: 0:05:21 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 20 / Train-Loss: 0.2382 / Val-Loss: 0.2443 / Test-Loss: 0.2395 / Time taken: 0:05:35 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 21 / Train-Loss: 0.2381 / Val-Loss: 0.2441 / Test-Loss: 0.2392 / Time taken: 0:05:50 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 22 / Train-Loss: 0.2381 / Val-Loss: 0.2440 / Test-Loss: 0.2393 / Time taken: 0:06:05 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 23 / Train-Loss: 0.2379 / Val-Loss: 0.2441 / Test-Loss: 0.2393 / Time taken: 0:06:19 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 09/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 24 / Train-Loss: 0.2379 / Val-Loss: 0.2440 / Test-Loss: 0.2392 / Time taken: 0:06:34 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0071 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 25 / Train-Loss: 0.2378 / Val-Loss: 0.2440 / Test-Loss: 0.2393 / Time taken: 0:06:49 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 09/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 26 / Train-Loss: 0.2377 / Val-Loss: 0.2439 / Test-Loss: 0.2391 / Time taken: 0:07:03 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 27 / Train-Loss: 0.2376 / Val-Loss: 0.2439 / Test-Loss: 0.2392 / Time taken: 0:07:18 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 09/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 28 / Train-Loss: 0.2376 / Val-Loss: 0.2440 / Test-Loss: 0.2392 / Time taken: 0:07:32 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 09/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 29 / Train-Loss: 0.2376 / Val-Loss: 0.2438 / Test-Loss: 0.2391 / Time taken: 0:07:47 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 30 / Train-Loss: 0.2374 / Val-Loss: 0.2438 / Test-Loss: 0.2391 / Time taken: 0:08:02 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 09/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 31 / Train-Loss: 0.2374 / Val-Loss: 0.2438 / Test-Loss: 0.2391 / Time taken: 0:08:23 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0071 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 32 / Train-Loss: 0.2375 / Val-Loss: 0.2438 / Test-Loss: 0.2391 / Time taken: 0:08:38 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 09/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 33 / Train-Loss: 0.2373 / Val-Loss: 0.2438 / Test-Loss: 0.2392 / Time taken: 0:08:53 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 09/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 34 / Train-Loss: 0.2372 / Val-Loss: 0.2437 / Test-Loss: 0.2391 / Time taken: 0:09:15 / ---- Currently Best Val-Epoch: 34 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0071 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 35 / Train-Loss: 0.2373 / Val-Loss: 0.2437 / Test-Loss: 0.2389 / Time taken: 0:09:29 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 36 / Train-Loss: 0.2371 / Val-Loss: 0.2438 / Test-Loss: 0.2391 / Time taken: 0:09:44 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 09/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 37 / Train-Loss: 0.2371 / Val-Loss: 0.2437 / Test-Loss: 0.2390 / Time taken: 0:09:58 / ---- Currently Best Val-Epoch: 37 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 38 / Train-Loss: 0.2370 / Val-Loss: 0.2436 / Test-Loss: 0.2389 / Time taken: 0:10:13 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 39 / Train-Loss: 0.2369 / Val-Loss: 0.2437 / Test-Loss: 0.2392 / Time taken: 0:10:28 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 09/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 40 / Train-Loss: 0.2369 / Val-Loss: 0.2438 / Test-Loss: 0.2392 / Time taken: 0:10:42 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 09/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 41 / Train-Loss: 0.2370 / Val-Loss: 0.2436 / Test-Loss: 0.2388 / Time taken: 0:10:57 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 42 / Train-Loss: 0.2369 / Val-Loss: 0.2437 / Test-Loss: 0.2390 / Time taken: 0:11:11 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 09/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 43 / Train-Loss: 0.2368 / Val-Loss: 0.2437 / Test-Loss: 0.2389 / Time taken: 0:11:26 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 09/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 44 / Train-Loss: 0.2368 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:11:40 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 09/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 45 / Train-Loss: 0.2368 / Val-Loss: 0.2436 / Test-Loss: 0.2389 / Time taken: 0:11:55 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 09/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 46 / Train-Loss: 0.2368 / Val-Loss: 0.2435 / Test-Loss: 0.2391 / Time taken: 0:12:09 / ---- Currently Best Val-Epoch: 46 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0071 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 47 / Train-Loss: 0.2367 / Val-Loss: 0.2435 / Test-Loss: 0.2390 / Time taken: 0:12:24 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 09/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 48 / Train-Loss: 0.2366 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:12:39 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 09/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 49 / Train-Loss: 0.2366 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:12:54 / ---- Currently Best Val-Epoch: 46 \n","Ensemble: 09/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 50 / Train-Loss: 0.2366 / Val-Loss: 0.2435 / Test-Loss: 0.2389 / Time taken: 0:13:08 / ---- Currently Best Val-Epoch: 50 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 51 / Train-Loss: 0.2365 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:13:23 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 52 / Train-Loss: 0.2365 / Val-Loss: 0.2435 / Test-Loss: 0.2388 / Time taken: 0:13:37 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 53 / Train-Loss: 0.2365 / Val-Loss: 0.2437 / Test-Loss: 0.2390 / Time taken: 0:13:52 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 54 / Train-Loss: 0.2363 / Val-Loss: 0.2435 / Test-Loss: 0.2391 / Time taken: 0:14:06 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 55 / Train-Loss: 0.2364 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:14:21 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 56 / Train-Loss: 0.2363 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:14:35 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 57 / Train-Loss: 0.2364 / Val-Loss: 0.2436 / Test-Loss: 0.2392 / Time taken: 0:14:50 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 58 / Train-Loss: 0.2363 / Val-Loss: 0.2436 / Test-Loss: 0.2391 / Time taken: 0:15:05 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 59 / Train-Loss: 0.2362 / Val-Loss: 0.2437 / Test-Loss: 0.2390 / Time taken: 0:15:19 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 60 / Train-Loss: 0.2363 / Val-Loss: 0.2437 / Test-Loss: 0.2392 / Time taken: 0:15:34 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 61 / Train-Loss: 0.2362 / Val-Loss: 0.2437 / Test-Loss: 0.2391 / Time taken: 0:15:49 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 62 / Train-Loss: 0.2361 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:16:03 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 09/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 63 / Train-Loss: 0.2361 / Val-Loss: 0.2435 / Test-Loss: 0.2390 / Time taken: 0:16:18 / ---- Currently Best Val-Epoch: 63 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 64 / Train-Loss: 0.2361 / Val-Loss: 0.2435 / Test-Loss: 0.2390 / Time taken: 0:16:33 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 09/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 65 / Train-Loss: 0.2360 / Val-Loss: 0.2435 / Test-Loss: 0.2389 / Time taken: 0:16:48 / ---- Currently Best Val-Epoch: 63 \n","Ensemble: 09/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 66 / Train-Loss: 0.2361 / Val-Loss: 0.2434 / Test-Loss: 0.2389 / Time taken: 0:17:02 / ---- Currently Best Val-Epoch: 66 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 67 / Train-Loss: 0.2359 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:17:17 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 09/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 68 / Train-Loss: 0.2359 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:17:32 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 09/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 69 / Train-Loss: 0.2359 / Val-Loss: 0.2436 / Test-Loss: 0.2389 / Time taken: 0:17:47 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 09/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 70 / Train-Loss: 0.2359 / Val-Loss: 0.2436 / Test-Loss: 0.2389 / Time taken: 0:18:01 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 09/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 71 / Train-Loss: 0.2358 / Val-Loss: 0.2436 / Test-Loss: 0.2389 / Time taken: 0:18:16 / ---- Currently Best Val-Epoch: 66 \n","Ensemble: 09/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 72 / Train-Loss: 0.2357 / Val-Loss: 0.2434 / Test-Loss: 0.2391 / Time taken: 0:18:31 / ---- Currently Best Val-Epoch: 72 <------- Best VAL Epoch so far\n","Ensemble: 09/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 73 / Train-Loss: 0.2358 / Val-Loss: 0.2434 / Test-Loss: 0.2389 / Time taken: 0:18:46 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 74 / Train-Loss: 0.2358 / Val-Loss: 0.2434 / Test-Loss: 0.2389 / Time taken: 0:19:01 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 75 / Train-Loss: 0.2358 / Val-Loss: 0.2435 / Test-Loss: 0.2390 / Time taken: 0:19:16 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 76 / Train-Loss: 0.2356 / Val-Loss: 0.2435 / Test-Loss: 0.2390 / Time taken: 0:19:38 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 77 / Train-Loss: 0.2357 / Val-Loss: 0.2435 / Test-Loss: 0.2389 / Time taken: 0:19:53 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 78 / Train-Loss: 0.2355 / Val-Loss: 0.2436 / Test-Loss: 0.2389 / Time taken: 0:20:09 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 79 / Train-Loss: 0.2354 / Val-Loss: 0.2436 / Test-Loss: 0.2390 / Time taken: 0:20:24 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 80 / Train-Loss: 0.2355 / Val-Loss: 0.2436 / Test-Loss: 0.2388 / Time taken: 0:20:39 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 81 / Train-Loss: 0.2354 / Val-Loss: 0.2435 / Test-Loss: 0.2389 / Time taken: 0:21:01 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0069 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 82 / Train-Loss: 0.2353 / Val-Loss: 0.2436 / Test-Loss: 0.2386 / Time taken: 0:21:22 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 83 / Train-Loss: 0.2353 / Val-Loss: 0.2436 / Test-Loss: 0.2387 / Time taken: 0:21:44 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.007  : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 84 / Train-Loss: 0.2353 / Val-Loss: 0.2436 / Test-Loss: 0.2387 / Time taken: 0:21:58 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 85 / Train-Loss: 0.2353 / Val-Loss: 0.2436 / Test-Loss: 0.2389 / Time taken: 0:22:13 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0066 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 86 / Train-Loss: 0.2351 / Val-Loss: 0.2436 / Test-Loss: 0.2388 / Time taken: 0:22:28 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0068 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 87 / Train-Loss: 0.2352 / Val-Loss: 0.2435 / Test-Loss: 0.2387 / Time taken: 0:22:42 / ---- Currently Best Val-Epoch: 72 \n","Ensemble: 09/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0067 : [##############################] 99.8%\n","Ensemble: 09/14 / Epoch: 88 / Train-Loss: 0.2350 / Val-Loss: 0.2435 / Test-Loss: 0.2388 / Time taken: 0:22:57 / ---- Currently Best Val-Epoch: 72 \n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 18ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-a09fd7ab-908b-4a5d-ba21-1536fa9a3dc5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>LocalGLMftt (run: 5)</td>\n","      <td>58</td>\n","      <td>1289.168909</td>\n","      <td>27430</td>\n","      <td>0.237039</td>\n","      <td>0.238749</td>\n","      <td>0.068158</td>\n","      <td>0.068611</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>LocalGLMftt (run: 6)</td>\n","      <td>81</td>\n","      <td>1688.195204</td>\n","      <td>27430</td>\n","      <td>0.236139</td>\n","      <td>0.238735</td>\n","      <td>0.066555</td>\n","      <td>0.066987</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>LocalGLMftt (run: 7)</td>\n","      <td>39</td>\n","      <td>938.974456</td>\n","      <td>27430</td>\n","      <td>0.237802</td>\n","      <td>0.238847</td>\n","      <td>0.068716</td>\n","      <td>0.069133</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>LocalGLMftt (run: 8)</td>\n","      <td>42</td>\n","      <td>951.956478</td>\n","      <td>27430</td>\n","      <td>0.237784</td>\n","      <td>0.238886</td>\n","      <td>0.068275</td>\n","      <td>0.068710</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>LocalGLMftt (run: 9)</td>\n","      <td>72</td>\n","      <td>1377.468203</td>\n","      <td>27430</td>\n","      <td>0.236593</td>\n","      <td>0.239080</td>\n","      <td>0.066974</td>\n","      <td>0.067353</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>160 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a09fd7ab-908b-4a5d-ba21-1536fa9a3dc5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a09fd7ab-908b-4a5d-ba21-1536fa9a3dc5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a09fd7ab-908b-4a5d-ba21-1536fa9a3dc5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a5f5fd2d-b765-497d-a3ea-2d1328bdd6b8\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5f5fd2d-b765-497d-a3ea-2d1328bdd6b8')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a5f5fd2d-b765-497d-a3ea-2d1328bdd6b8 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","155        LocalGLMftt (run: 5)      58  1289.168909          27430   \n","156        LocalGLMftt (run: 6)      81  1688.195204          27430   \n","157        LocalGLMftt (run: 7)      39   938.974456          27430   \n","158        LocalGLMftt (run: 8)      42   951.956478          27430   \n","159        LocalGLMftt (run: 9)      72  1377.468203          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","155    0.237039   0.238749             0.068158            0.068611  \n","156    0.236139   0.238735             0.066555            0.066987  \n","157    0.237802   0.238847             0.068716            0.069133  \n","158    0.237784   0.238886             0.068275            0.068710  \n","159    0.236593   0.239080             0.066974            0.067353  \n","\n","[160 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 10-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 10/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 0 / Train-Loss: 0.2417 / Val-Loss: 0.2423 / Test-Loss: 0.2423 / Time taken: 0:00:31 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 1 / Train-Loss: 0.2416 / Val-Loss: 0.2421 / Test-Loss: 0.2421 / Time taken: 0:00:46 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 2 / Train-Loss: 0.2414 / Val-Loss: 0.2418 / Test-Loss: 0.2418 / Time taken: 0:01:00 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 3 / Train-Loss: 0.2412 / Val-Loss: 0.2416 / Test-Loss: 0.2416 / Time taken: 0:01:15 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 4 / Train-Loss: 0.2411 / Val-Loss: 0.2414 / Test-Loss: 0.2415 / Time taken: 0:01:30 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 5 / Train-Loss: 0.2410 / Val-Loss: 0.2412 / Test-Loss: 0.2413 / Time taken: 0:01:53 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 6 / Train-Loss: 0.2409 / Val-Loss: 0.2411 / Test-Loss: 0.2412 / Time taken: 0:02:08 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 7 / Train-Loss: 0.2408 / Val-Loss: 0.2409 / Test-Loss: 0.2410 / Time taken: 0:02:23 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 8 / Train-Loss: 0.2406 / Val-Loss: 0.2408 / Test-Loss: 0.2408 / Time taken: 0:02:38 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 9 / Train-Loss: 0.2406 / Val-Loss: 0.2407 / Test-Loss: 0.2407 / Time taken: 0:02:52 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 10 / Train-Loss: 0.2403 / Val-Loss: 0.2407 / Test-Loss: 0.2407 / Time taken: 0:03:07 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 10/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 11 / Train-Loss: 0.2402 / Val-Loss: 0.2405 / Test-Loss: 0.2405 / Time taken: 0:03:22 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 12 / Batch: 0 / Train-Loss (Batch): 0.1809   : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 10/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 12 / Train-Loss: 0.2401 / Val-Loss: 0.2403 / Test-Loss: 0.2402 / Time taken: 0:03:36 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 13 / Train-Loss: 0.2399 / Val-Loss: 0.2401 / Test-Loss: 0.2400 / Time taken: 0:03:51 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 14 / Train-Loss: 0.2397 / Val-Loss: 0.2402 / Test-Loss: 0.2400 / Time taken: 0:04:06 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 10/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 15 / Train-Loss: 0.2395 / Val-Loss: 0.2400 / Test-Loss: 0.2398 / Time taken: 0:04:20 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 16 / Train-Loss: 0.2394 / Val-Loss: 0.2399 / Test-Loss: 0.2397 / Time taken: 0:04:35 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 17 / Train-Loss: 0.2393 / Val-Loss: 0.2398 / Test-Loss: 0.2395 / Time taken: 0:04:50 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 18 / Train-Loss: 0.2391 / Val-Loss: 0.2397 / Test-Loss: 0.2394 / Time taken: 0:05:05 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 19 / Train-Loss: 0.2389 / Val-Loss: 0.2396 / Test-Loss: 0.2393 / Time taken: 0:05:26 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 20 / Train-Loss: 0.2390 / Val-Loss: 0.2393 / Test-Loss: 0.2391 / Time taken: 0:05:42 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 21 / Train-Loss: 0.2387 / Val-Loss: 0.2392 / Test-Loss: 0.2391 / Time taken: 0:05:57 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 22 / Train-Loss: 0.2386 / Val-Loss: 0.2391 / Test-Loss: 0.2390 / Time taken: 0:06:13 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 23 / Train-Loss: 0.2385 / Val-Loss: 0.2391 / Test-Loss: 0.2390 / Time taken: 0:06:35 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 10/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 24 / Train-Loss: 0.2384 / Val-Loss: 0.2392 / Test-Loss: 0.2390 / Time taken: 0:06:49 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 10/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 25 / Train-Loss: 0.2384 / Val-Loss: 0.2389 / Test-Loss: 0.2388 / Time taken: 0:07:03 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 26 / Train-Loss: 0.2384 / Val-Loss: 0.2389 / Test-Loss: 0.2389 / Time taken: 0:07:18 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 10/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 27 / Train-Loss: 0.2382 / Val-Loss: 0.2390 / Test-Loss: 0.2390 / Time taken: 0:07:33 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 10/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 28 / Train-Loss: 0.2380 / Val-Loss: 0.2391 / Test-Loss: 0.2390 / Time taken: 0:07:54 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 10/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 29 / Train-Loss: 0.2381 / Val-Loss: 0.2389 / Test-Loss: 0.2388 / Time taken: 0:08:10 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 30 / Train-Loss: 0.2380 / Val-Loss: 0.2390 / Test-Loss: 0.2388 / Time taken: 0:08:25 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 10/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 31 / Train-Loss: 0.2380 / Val-Loss: 0.2390 / Test-Loss: 0.2389 / Time taken: 0:08:40 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 10/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 32 / Train-Loss: 0.2380 / Val-Loss: 0.2389 / Test-Loss: 0.2388 / Time taken: 0:08:55 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 10/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 33 / Train-Loss: 0.2379 / Val-Loss: 0.2388 / Test-Loss: 0.2388 / Time taken: 0:09:11 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 34 / Train-Loss: 0.2379 / Val-Loss: 0.2390 / Test-Loss: 0.2389 / Time taken: 0:09:32 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 10/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 35 / Train-Loss: 0.2377 / Val-Loss: 0.2388 / Test-Loss: 0.2388 / Time taken: 0:09:48 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 10/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 36 / Train-Loss: 0.2378 / Val-Loss: 0.2391 / Test-Loss: 0.2389 / Time taken: 0:10:03 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 10/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 37 / Train-Loss: 0.2377 / Val-Loss: 0.2389 / Test-Loss: 0.2389 / Time taken: 0:10:18 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 10/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 38 / Train-Loss: 0.2377 / Val-Loss: 0.2390 / Test-Loss: 0.2389 / Time taken: 0:10:32 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 10/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 39 / Train-Loss: 0.2375 / Val-Loss: 0.2389 / Test-Loss: 0.2390 / Time taken: 0:10:48 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 10/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 40 / Train-Loss: 0.2376 / Val-Loss: 0.2387 / Test-Loss: 0.2387 / Time taken: 0:11:03 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 10/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 41 / Train-Loss: 0.2376 / Val-Loss: 0.2389 / Test-Loss: 0.2389 / Time taken: 0:11:26 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 42 / Train-Loss: 0.2376 / Val-Loss: 0.2389 / Test-Loss: 0.2389 / Time taken: 0:11:42 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 43 / Train-Loss: 0.2375 / Val-Loss: 0.2389 / Test-Loss: 0.2388 / Time taken: 0:11:58 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 44 / Train-Loss: 0.2374 / Val-Loss: 0.2388 / Test-Loss: 0.2389 / Time taken: 0:12:13 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 45 / Train-Loss: 0.2374 / Val-Loss: 0.2388 / Test-Loss: 0.2388 / Time taken: 0:12:28 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 46 / Train-Loss: 0.2373 / Val-Loss: 0.2388 / Test-Loss: 0.2389 / Time taken: 0:12:43 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 47 / Train-Loss: 0.2372 / Val-Loss: 0.2390 / Test-Loss: 0.2390 / Time taken: 0:12:58 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 48 / Train-Loss: 0.2373 / Val-Loss: 0.2388 / Test-Loss: 0.2389 / Time taken: 0:13:13 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 49 / Train-Loss: 0.2373 / Val-Loss: 0.2390 / Test-Loss: 0.2389 / Time taken: 0:13:28 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 50 / Train-Loss: 0.2373 / Val-Loss: 0.2389 / Test-Loss: 0.2390 / Time taken: 0:13:43 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 51 / Train-Loss: 0.2372 / Val-Loss: 0.2389 / Test-Loss: 0.2390 / Time taken: 0:14:05 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 52 / Train-Loss: 0.2372 / Val-Loss: 0.2388 / Test-Loss: 0.2389 / Time taken: 0:14:20 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 53 / Train-Loss: 0.2371 / Val-Loss: 0.2388 / Test-Loss: 0.2389 / Time taken: 0:14:36 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 54 / Train-Loss: 0.2370 / Val-Loss: 0.2389 / Test-Loss: 0.2389 / Time taken: 0:14:52 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 55 / Train-Loss: 0.2371 / Val-Loss: 0.2389 / Test-Loss: 0.2389 / Time taken: 0:15:08 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 10/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 10/14 / Epoch: 56 / Train-Loss: 0.2370 / Val-Loss: 0.2389 / Test-Loss: 0.2391 / Time taken: 0:15:23 / ---- Currently Best Val-Epoch: 40 \n","596/596 [==============================] - 12s 18ms/step\n","67/67 [==============================] - 1s 15ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-af1c76f3-d6c6-4641-a447-9080187ffb5c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>LocalGLMftt (run: 6)</td>\n","      <td>81</td>\n","      <td>1688.195204</td>\n","      <td>27430</td>\n","      <td>0.236139</td>\n","      <td>0.238735</td>\n","      <td>0.066555</td>\n","      <td>0.066987</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>LocalGLMftt (run: 7)</td>\n","      <td>39</td>\n","      <td>938.974456</td>\n","      <td>27430</td>\n","      <td>0.237802</td>\n","      <td>0.238847</td>\n","      <td>0.068716</td>\n","      <td>0.069133</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>LocalGLMftt (run: 8)</td>\n","      <td>42</td>\n","      <td>951.956478</td>\n","      <td>27430</td>\n","      <td>0.237784</td>\n","      <td>0.238886</td>\n","      <td>0.068275</td>\n","      <td>0.068710</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>LocalGLMftt (run: 9)</td>\n","      <td>72</td>\n","      <td>1377.468203</td>\n","      <td>27430</td>\n","      <td>0.236593</td>\n","      <td>0.239080</td>\n","      <td>0.066974</td>\n","      <td>0.067353</td>\n","    </tr>\n","    <tr>\n","      <th>160</th>\n","      <td>LocalGLMftt (run: 10)</td>\n","      <td>40</td>\n","      <td>923.518332</td>\n","      <td>27430</td>\n","      <td>0.237557</td>\n","      <td>0.238749</td>\n","      <td>0.068609</td>\n","      <td>0.068993</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>161 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af1c76f3-d6c6-4641-a447-9080187ffb5c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-af1c76f3-d6c6-4641-a447-9080187ffb5c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-af1c76f3-d6c6-4641-a447-9080187ffb5c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-fa17959e-209a-4ff9-b560-0a0d6b6944c9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa17959e-209a-4ff9-b560-0a0d6b6944c9')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-fa17959e-209a-4ff9-b560-0a0d6b6944c9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","156        LocalGLMftt (run: 6)      81  1688.195204          27430   \n","157        LocalGLMftt (run: 7)      39   938.974456          27430   \n","158        LocalGLMftt (run: 8)      42   951.956478          27430   \n","159        LocalGLMftt (run: 9)      72  1377.468203          27430   \n","160       LocalGLMftt (run: 10)      40   923.518332          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","156    0.236139   0.238735             0.066555            0.066987  \n","157    0.237802   0.238847             0.068716            0.069133  \n","158    0.237784   0.238886             0.068275            0.068710  \n","159    0.236593   0.239080             0.066974            0.067353  \n","160    0.237557   0.238749             0.068609            0.068993  \n","\n","[161 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 11-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 11/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0336  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 0 / Train-Loss: 0.2427 / Val-Loss: 0.2339 / Test-Loss: 0.2424 / Time taken: 0:00:45 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 1 / Train-Loss: 0.2426 / Val-Loss: 0.2336 / Test-Loss: 0.2421 / Time taken: 0:01:00 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 2 / Train-Loss: 0.2424 / Val-Loss: 0.2334 / Test-Loss: 0.2418 / Time taken: 0:01:15 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 3 / Train-Loss: 0.2422 / Val-Loss: 0.2331 / Test-Loss: 0.2415 / Time taken: 0:01:29 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 4 / Train-Loss: 0.2420 / Val-Loss: 0.2328 / Test-Loss: 0.2413 / Time taken: 0:01:45 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 5 / Train-Loss: 0.2417 / Val-Loss: 0.2327 / Test-Loss: 0.2412 / Time taken: 0:02:00 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 6 / Train-Loss: 0.2415 / Val-Loss: 0.2324 / Test-Loss: 0.2409 / Time taken: 0:02:14 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 7 / Train-Loss: 0.2412 / Val-Loss: 0.2322 / Test-Loss: 0.2406 / Time taken: 0:02:29 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 8 / Train-Loss: 0.2411 / Val-Loss: 0.2322 / Test-Loss: 0.2404 / Time taken: 0:02:43 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 9 / Train-Loss: 0.2409 / Val-Loss: 0.2319 / Test-Loss: 0.2402 / Time taken: 0:02:58 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 10 / Train-Loss: 0.2407 / Val-Loss: 0.2317 / Test-Loss: 0.2399 / Time taken: 0:03:13 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 11 / Batch: 0 / Train-Loss (Batch): 0.2017   : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 11/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 11 / Train-Loss: 0.2405 / Val-Loss: 0.2317 / Test-Loss: 0.2398 / Time taken: 0:03:28 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 12 / Train-Loss: 0.2403 / Val-Loss: 0.2315 / Test-Loss: 0.2396 / Time taken: 0:03:43 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 13 / Train-Loss: 0.2403 / Val-Loss: 0.2312 / Test-Loss: 0.2395 / Time taken: 0:03:59 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 14 / Train-Loss: 0.2402 / Val-Loss: 0.2313 / Test-Loss: 0.2395 / Time taken: 0:04:14 / ---- Currently Best Val-Epoch: 13 \n","Ensemble: 11/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 15 / Train-Loss: 0.2400 / Val-Loss: 0.2311 / Test-Loss: 0.2393 / Time taken: 0:04:28 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 16 / Train-Loss: 0.2400 / Val-Loss: 0.2310 / Test-Loss: 0.2392 / Time taken: 0:04:44 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 17 / Train-Loss: 0.2399 / Val-Loss: 0.2310 / Test-Loss: 0.2392 / Time taken: 0:05:00 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 18 / Train-Loss: 0.2398 / Val-Loss: 0.2310 / Test-Loss: 0.2391 / Time taken: 0:05:24 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 19 / Train-Loss: 0.2397 / Val-Loss: 0.2309 / Test-Loss: 0.2391 / Time taken: 0:05:40 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 20 / Train-Loss: 0.2396 / Val-Loss: 0.2308 / Test-Loss: 0.2391 / Time taken: 0:06:02 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 21 / Train-Loss: 0.2396 / Val-Loss: 0.2307 / Test-Loss: 0.2391 / Time taken: 0:06:18 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 22 / Train-Loss: 0.2394 / Val-Loss: 0.2307 / Test-Loss: 0.2389 / Time taken: 0:06:34 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 23 / Train-Loss: 0.2394 / Val-Loss: 0.2306 / Test-Loss: 0.2390 / Time taken: 0:06:51 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 24 / Train-Loss: 0.2393 / Val-Loss: 0.2305 / Test-Loss: 0.2389 / Time taken: 0:07:08 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 25 / Train-Loss: 0.2391 / Val-Loss: 0.2305 / Test-Loss: 0.2389 / Time taken: 0:07:24 / ---- Currently Best Val-Epoch: 25 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 26 / Train-Loss: 0.2391 / Val-Loss: 0.2306 / Test-Loss: 0.2389 / Time taken: 0:07:40 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 11/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 27 / Train-Loss: 0.2390 / Val-Loss: 0.2305 / Test-Loss: 0.2388 / Time taken: 0:07:55 / ---- Currently Best Val-Epoch: 25 \n","Ensemble: 11/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 28 / Train-Loss: 0.2389 / Val-Loss: 0.2304 / Test-Loss: 0.2388 / Time taken: 0:08:10 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 29 / Train-Loss: 0.2389 / Val-Loss: 0.2303 / Test-Loss: 0.2387 / Time taken: 0:08:33 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 30 / Train-Loss: 0.2390 / Val-Loss: 0.2303 / Test-Loss: 0.2387 / Time taken: 0:08:50 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 31 / Train-Loss: 0.2389 / Val-Loss: 0.2304 / Test-Loss: 0.2387 / Time taken: 0:09:05 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 32 / Train-Loss: 0.2387 / Val-Loss: 0.2304 / Test-Loss: 0.2387 / Time taken: 0:09:20 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 33 / Train-Loss: 0.2387 / Val-Loss: 0.2304 / Test-Loss: 0.2386 / Time taken: 0:09:36 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 34 / Train-Loss: 0.2388 / Val-Loss: 0.2304 / Test-Loss: 0.2385 / Time taken: 0:09:57 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 35 / Train-Loss: 0.2386 / Val-Loss: 0.2305 / Test-Loss: 0.2388 / Time taken: 0:10:19 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 36 / Train-Loss: 0.2386 / Val-Loss: 0.2304 / Test-Loss: 0.2387 / Time taken: 0:10:41 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 37 / Train-Loss: 0.2385 / Val-Loss: 0.2303 / Test-Loss: 0.2386 / Time taken: 0:11:02 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 11/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 38 / Train-Loss: 0.2385 / Val-Loss: 0.2302 / Test-Loss: 0.2386 / Time taken: 0:11:17 / ---- Currently Best Val-Epoch: 38 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 39 / Train-Loss: 0.2385 / Val-Loss: 0.2304 / Test-Loss: 0.2387 / Time taken: 0:11:33 / ---- Currently Best Val-Epoch: 38 \n","Ensemble: 11/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 40 / Train-Loss: 0.2385 / Val-Loss: 0.2302 / Test-Loss: 0.2385 / Time taken: 0:11:48 / ---- Currently Best Val-Epoch: 40 <------- Best VAL Epoch so far\n","Ensemble: 11/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 41 / Train-Loss: 0.2384 / Val-Loss: 0.2303 / Test-Loss: 0.2387 / Time taken: 0:12:04 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 42 / Train-Loss: 0.2383 / Val-Loss: 0.2304 / Test-Loss: 0.2387 / Time taken: 0:12:19 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 43 / Train-Loss: 0.2384 / Val-Loss: 0.2302 / Test-Loss: 0.2386 / Time taken: 0:12:41 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 44 / Train-Loss: 0.2384 / Val-Loss: 0.2305 / Test-Loss: 0.2388 / Time taken: 0:12:58 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 45 / Train-Loss: 0.2384 / Val-Loss: 0.2303 / Test-Loss: 0.2387 / Time taken: 0:13:20 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0342 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 46 / Train-Loss: 0.2382 / Val-Loss: 0.2302 / Test-Loss: 0.2387 / Time taken: 0:13:35 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 47 / Train-Loss: 0.2383 / Val-Loss: 0.2303 / Test-Loss: 0.2387 / Time taken: 0:13:52 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 48 / Train-Loss: 0.2381 / Val-Loss: 0.2302 / Test-Loss: 0.2386 / Time taken: 0:14:07 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 49 / Train-Loss: 0.2382 / Val-Loss: 0.2303 / Test-Loss: 0.2386 / Time taken: 0:14:23 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 50 / Train-Loss: 0.2382 / Val-Loss: 0.2304 / Test-Loss: 0.2386 / Time taken: 0:14:39 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 51 / Train-Loss: 0.2381 / Val-Loss: 0.2304 / Test-Loss: 0.2388 / Time taken: 0:14:55 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 52 / Train-Loss: 0.2382 / Val-Loss: 0.2303 / Test-Loss: 0.2387 / Time taken: 0:15:17 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 53 / Train-Loss: 0.2380 / Val-Loss: 0.2305 / Test-Loss: 0.2388 / Time taken: 0:15:32 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 54 / Train-Loss: 0.2381 / Val-Loss: 0.2305 / Test-Loss: 0.2388 / Time taken: 0:15:48 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 55 / Train-Loss: 0.2380 / Val-Loss: 0.2304 / Test-Loss: 0.2388 / Time taken: 0:16:10 / ---- Currently Best Val-Epoch: 40 \n","Ensemble: 11/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 11/14 / Epoch: 56 / Train-Loss: 0.2379 / Val-Loss: 0.2303 / Test-Loss: 0.2387 / Time taken: 0:16:26 / ---- Currently Best Val-Epoch: 40 \n","596/596 [==============================] - 11s 18ms/step\n","67/67 [==============================] - 1s 20ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-0a526b99-9925-4075-a2ab-9b3f79574070\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>LocalGLMftt (run: 7)</td>\n","      <td>39</td>\n","      <td>938.974456</td>\n","      <td>27430</td>\n","      <td>0.237802</td>\n","      <td>0.238847</td>\n","      <td>0.068716</td>\n","      <td>0.069133</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>LocalGLMftt (run: 8)</td>\n","      <td>42</td>\n","      <td>951.956478</td>\n","      <td>27430</td>\n","      <td>0.237784</td>\n","      <td>0.238886</td>\n","      <td>0.068275</td>\n","      <td>0.068710</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>LocalGLMftt (run: 9)</td>\n","      <td>72</td>\n","      <td>1377.468203</td>\n","      <td>27430</td>\n","      <td>0.236593</td>\n","      <td>0.239080</td>\n","      <td>0.066974</td>\n","      <td>0.067353</td>\n","    </tr>\n","    <tr>\n","      <th>160</th>\n","      <td>LocalGLMftt (run: 10)</td>\n","      <td>40</td>\n","      <td>923.518332</td>\n","      <td>27430</td>\n","      <td>0.237557</td>\n","      <td>0.238749</td>\n","      <td>0.068609</td>\n","      <td>0.068993</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>LocalGLMftt (run: 11)</td>\n","      <td>40</td>\n","      <td>986.134145</td>\n","      <td>27430</td>\n","      <td>0.237617</td>\n","      <td>0.238476</td>\n","      <td>0.068948</td>\n","      <td>0.069450</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>162 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a526b99-9925-4075-a2ab-9b3f79574070')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0a526b99-9925-4075-a2ab-9b3f79574070 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0a526b99-9925-4075-a2ab-9b3f79574070');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0a1e007e-9dc2-4db1-860d-9839c5dd4baa\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a1e007e-9dc2-4db1-860d-9839c5dd4baa')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0a1e007e-9dc2-4db1-860d-9839c5dd4baa button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","157        LocalGLMftt (run: 7)      39   938.974456          27430   \n","158        LocalGLMftt (run: 8)      42   951.956478          27430   \n","159        LocalGLMftt (run: 9)      72  1377.468203          27430   \n","160       LocalGLMftt (run: 10)      40   923.518332          27430   \n","161       LocalGLMftt (run: 11)      40   986.134145          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","157    0.237802   0.238847             0.068716            0.069133  \n","158    0.237784   0.238886             0.068275            0.068710  \n","159    0.236593   0.239080             0.066974            0.067353  \n","160    0.237557   0.238749             0.068609            0.068993  \n","161    0.237617   0.238476             0.068948            0.069450  \n","\n","[162 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 12-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 12/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 0 / Train-Loss: 0.2417 / Val-Loss: 0.2423 / Test-Loss: 0.2424 / Time taken: 0:00:31 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 1 / Train-Loss: 0.2415 / Val-Loss: 0.2422 / Test-Loss: 0.2421 / Time taken: 0:00:47 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 2 / Train-Loss: 0.2414 / Val-Loss: 0.2421 / Test-Loss: 0.2419 / Time taken: 0:01:02 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 3 / Train-Loss: 0.2412 / Val-Loss: 0.2419 / Test-Loss: 0.2417 / Time taken: 0:01:18 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 4 / Train-Loss: 0.2410 / Val-Loss: 0.2417 / Test-Loss: 0.2415 / Time taken: 0:01:34 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 5 / Train-Loss: 0.2408 / Val-Loss: 0.2415 / Test-Loss: 0.2412 / Time taken: 0:01:49 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 6 / Train-Loss: 0.2406 / Val-Loss: 0.2414 / Test-Loss: 0.2410 / Time taken: 0:02:07 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 7 / Train-Loss: 0.2404 / Val-Loss: 0.2412 / Test-Loss: 0.2409 / Time taken: 0:02:28 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 8 / Train-Loss: 0.2402 / Val-Loss: 0.2412 / Test-Loss: 0.2408 / Time taken: 0:02:44 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0325  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 9 / Train-Loss: 0.2400 / Val-Loss: 0.2410 / Test-Loss: 0.2406 / Time taken: 0:03:05 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 10 / Train-Loss: 0.2398 / Val-Loss: 0.2410 / Test-Loss: 0.2405 / Time taken: 0:03:21 / ---- Currently Best Val-Epoch: 9 \n","Ensemble: 12/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 11 / Train-Loss: 0.2396 / Val-Loss: 0.2408 / Test-Loss: 0.2403 / Time taken: 0:03:38 / ---- Currently Best Val-Epoch: 11 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 12 / Batch: 0 / Train-Loss (Batch): 0.189    : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 12/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 12 / Train-Loss: 0.2395 / Val-Loss: 0.2406 / Test-Loss: 0.2401 / Time taken: 0:03:59 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 13 / Train-Loss: 0.2394 / Val-Loss: 0.2404 / Test-Loss: 0.2398 / Time taken: 0:04:22 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 14 / Train-Loss: 0.2392 / Val-Loss: 0.2404 / Test-Loss: 0.2397 / Time taken: 0:04:44 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 15 / Train-Loss: 0.2390 / Val-Loss: 0.2402 / Test-Loss: 0.2396 / Time taken: 0:05:06 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 16 / Train-Loss: 0.2390 / Val-Loss: 0.2402 / Test-Loss: 0.2395 / Time taken: 0:05:22 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 17 / Train-Loss: 0.2389 / Val-Loss: 0.2400 / Test-Loss: 0.2394 / Time taken: 0:05:44 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 18 / Train-Loss: 0.2388 / Val-Loss: 0.2400 / Test-Loss: 0.2394 / Time taken: 0:06:00 / ---- Currently Best Val-Epoch: 18 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 19 / Train-Loss: 0.2387 / Val-Loss: 0.2402 / Test-Loss: 0.2395 / Time taken: 0:06:23 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 12/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 20 / Train-Loss: 0.2387 / Val-Loss: 0.2402 / Test-Loss: 0.2395 / Time taken: 0:06:38 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 12/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 21 / Train-Loss: 0.2386 / Val-Loss: 0.2401 / Test-Loss: 0.2394 / Time taken: 0:06:53 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 12/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 22 / Train-Loss: 0.2385 / Val-Loss: 0.2401 / Test-Loss: 0.2393 / Time taken: 0:07:08 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 12/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 23 / Train-Loss: 0.2385 / Val-Loss: 0.2400 / Test-Loss: 0.2393 / Time taken: 0:07:23 / ---- Currently Best Val-Epoch: 18 \n","Ensemble: 12/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 24 / Train-Loss: 0.2384 / Val-Loss: 0.2399 / Test-Loss: 0.2391 / Time taken: 0:07:39 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 25 / Train-Loss: 0.2383 / Val-Loss: 0.2400 / Test-Loss: 0.2393 / Time taken: 0:07:55 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 12/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 26 / Train-Loss: 0.2382 / Val-Loss: 0.2399 / Test-Loss: 0.2392 / Time taken: 0:08:11 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 12/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 27 / Train-Loss: 0.2382 / Val-Loss: 0.2398 / Test-Loss: 0.2392 / Time taken: 0:08:27 / ---- Currently Best Val-Epoch: 27 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 28 / Train-Loss: 0.2382 / Val-Loss: 0.2398 / Test-Loss: 0.2392 / Time taken: 0:08:44 / ---- Currently Best Val-Epoch: 27 \n","Ensemble: 12/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 29 / Train-Loss: 0.2381 / Val-Loss: 0.2397 / Test-Loss: 0.2391 / Time taken: 0:09:05 / ---- Currently Best Val-Epoch: 29 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 30 / Train-Loss: 0.2381 / Val-Loss: 0.2398 / Test-Loss: 0.2391 / Time taken: 0:09:27 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 12/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 31 / Train-Loss: 0.2380 / Val-Loss: 0.2398 / Test-Loss: 0.2392 / Time taken: 0:09:50 / ---- Currently Best Val-Epoch: 29 \n","Ensemble: 12/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 32 / Train-Loss: 0.2381 / Val-Loss: 0.2396 / Test-Loss: 0.2390 / Time taken: 0:10:05 / ---- Currently Best Val-Epoch: 32 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 33 / Train-Loss: 0.2379 / Val-Loss: 0.2395 / Test-Loss: 0.2389 / Time taken: 0:10:21 / ---- Currently Best Val-Epoch: 33 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 34 / Train-Loss: 0.2379 / Val-Loss: 0.2398 / Test-Loss: 0.2392 / Time taken: 0:10:37 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 12/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 35 / Train-Loss: 0.2378 / Val-Loss: 0.2396 / Test-Loss: 0.2390 / Time taken: 0:10:52 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 12/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 36 / Train-Loss: 0.2379 / Val-Loss: 0.2396 / Test-Loss: 0.2391 / Time taken: 0:11:08 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 12/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 37 / Train-Loss: 0.2378 / Val-Loss: 0.2397 / Test-Loss: 0.2392 / Time taken: 0:11:29 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 12/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 38 / Train-Loss: 0.2377 / Val-Loss: 0.2395 / Test-Loss: 0.2390 / Time taken: 0:11:44 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 12/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 39 / Train-Loss: 0.2376 / Val-Loss: 0.2396 / Test-Loss: 0.2391 / Time taken: 0:11:59 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 12/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 40 / Train-Loss: 0.2376 / Val-Loss: 0.2395 / Test-Loss: 0.2391 / Time taken: 0:12:16 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 12/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 41 / Train-Loss: 0.2375 / Val-Loss: 0.2395 / Test-Loss: 0.2391 / Time taken: 0:12:32 / ---- Currently Best Val-Epoch: 33 \n","Ensemble: 12/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 42 / Train-Loss: 0.2375 / Val-Loss: 0.2395 / Test-Loss: 0.2390 / Time taken: 0:12:53 / ---- Currently Best Val-Epoch: 42 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 43 / Train-Loss: 0.2375 / Val-Loss: 0.2396 / Test-Loss: 0.2390 / Time taken: 0:13:16 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 12/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 44 / Train-Loss: 0.2374 / Val-Loss: 0.2396 / Test-Loss: 0.2390 / Time taken: 0:13:32 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 12/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 45 / Train-Loss: 0.2375 / Val-Loss: 0.2395 / Test-Loss: 0.2389 / Time taken: 0:13:54 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 12/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 46 / Train-Loss: 0.2374 / Val-Loss: 0.2396 / Test-Loss: 0.2390 / Time taken: 0:14:10 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 12/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 47 / Train-Loss: 0.2373 / Val-Loss: 0.2395 / Test-Loss: 0.2390 / Time taken: 0:14:26 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 12/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 48 / Train-Loss: 0.2372 / Val-Loss: 0.2398 / Test-Loss: 0.2392 / Time taken: 0:14:42 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 12/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 49 / Train-Loss: 0.2371 / Val-Loss: 0.2398 / Test-Loss: 0.2391 / Time taken: 0:15:04 / ---- Currently Best Val-Epoch: 42 \n","Ensemble: 12/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 50 / Train-Loss: 0.2373 / Val-Loss: 0.2395 / Test-Loss: 0.2389 / Time taken: 0:15:25 / ---- Currently Best Val-Epoch: 50 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 51 / Train-Loss: 0.2372 / Val-Loss: 0.2395 / Test-Loss: 0.2390 / Time taken: 0:15:42 / ---- Currently Best Val-Epoch: 50 \n","Ensemble: 12/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 52 / Train-Loss: 0.2372 / Val-Loss: 0.2395 / Test-Loss: 0.2389 / Time taken: 0:16:04 / ---- Currently Best Val-Epoch: 52 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 53 / Train-Loss: 0.2371 / Val-Loss: 0.2396 / Test-Loss: 0.2390 / Time taken: 0:16:19 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 12/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 54 / Train-Loss: 0.2370 / Val-Loss: 0.2396 / Test-Loss: 0.2390 / Time taken: 0:16:35 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 12/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 55 / Train-Loss: 0.2370 / Val-Loss: 0.2395 / Test-Loss: 0.2388 / Time taken: 0:16:57 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 12/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0339 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 56 / Train-Loss: 0.2370 / Val-Loss: 0.2394 / Test-Loss: 0.2389 / Time taken: 0:17:13 / ---- Currently Best Val-Epoch: 56 <------- Best VAL Epoch so far\n","Ensemble: 12/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 57 / Train-Loss: 0.2370 / Val-Loss: 0.2398 / Test-Loss: 0.2390 / Time taken: 0:17:29 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0338 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 58 / Train-Loss: 0.2369 / Val-Loss: 0.2397 / Test-Loss: 0.2389 / Time taken: 0:17:44 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0341 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 59 / Train-Loss: 0.2369 / Val-Loss: 0.2396 / Test-Loss: 0.2389 / Time taken: 0:18:07 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 60 / Train-Loss: 0.2370 / Val-Loss: 0.2396 / Test-Loss: 0.2387 / Time taken: 0:18:23 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 61 / Train-Loss: 0.2369 / Val-Loss: 0.2396 / Test-Loss: 0.2390 / Time taken: 0:18:44 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0343 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 62 / Train-Loss: 0.2368 / Val-Loss: 0.2398 / Test-Loss: 0.2389 / Time taken: 0:19:00 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 63 / Train-Loss: 0.2367 / Val-Loss: 0.2395 / Test-Loss: 0.2386 / Time taken: 0:19:18 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 64 / Train-Loss: 0.2366 / Val-Loss: 0.2397 / Test-Loss: 0.2387 / Time taken: 0:19:33 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 65 / Train-Loss: 0.2368 / Val-Loss: 0.2398 / Test-Loss: 0.2387 / Time taken: 0:19:48 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 66 / Train-Loss: 0.2367 / Val-Loss: 0.2396 / Test-Loss: 0.2387 / Time taken: 0:20:03 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 67 / Train-Loss: 0.2367 / Val-Loss: 0.2397 / Test-Loss: 0.2389 / Time taken: 0:20:25 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 68 / Train-Loss: 0.2366 / Val-Loss: 0.2398 / Test-Loss: 0.2388 / Time taken: 0:20:42 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 69 / Train-Loss: 0.2366 / Val-Loss: 0.2399 / Test-Loss: 0.2389 / Time taken: 0:21:03 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 70 / Train-Loss: 0.2366 / Val-Loss: 0.2396 / Test-Loss: 0.2387 / Time taken: 0:21:19 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 71 / Train-Loss: 0.2364 / Val-Loss: 0.2397 / Test-Loss: 0.2388 / Time taken: 0:21:36 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 12/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.034  : [##############################] 99.8%\n","Ensemble: 12/14 / Epoch: 72 / Train-Loss: 0.2364 / Val-Loss: 0.2398 / Test-Loss: 0.2388 / Time taken: 0:21:53 / ---- Currently Best Val-Epoch: 56 \n","596/596 [==============================] - 11s 18ms/step\n","67/67 [==============================] - 2s 25ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-dd5579f3-0bb2-4b2f-bd64-b7b3508e2c6b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>LocalGLMftt (run: 8)</td>\n","      <td>42</td>\n","      <td>951.956478</td>\n","      <td>27430</td>\n","      <td>0.237784</td>\n","      <td>0.238886</td>\n","      <td>0.068275</td>\n","      <td>0.068710</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>LocalGLMftt (run: 9)</td>\n","      <td>72</td>\n","      <td>1377.468203</td>\n","      <td>27430</td>\n","      <td>0.236593</td>\n","      <td>0.239080</td>\n","      <td>0.066974</td>\n","      <td>0.067353</td>\n","    </tr>\n","    <tr>\n","      <th>160</th>\n","      <td>LocalGLMftt (run: 10)</td>\n","      <td>40</td>\n","      <td>923.518332</td>\n","      <td>27430</td>\n","      <td>0.237557</td>\n","      <td>0.238749</td>\n","      <td>0.068609</td>\n","      <td>0.068993</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>LocalGLMftt (run: 11)</td>\n","      <td>40</td>\n","      <td>986.134145</td>\n","      <td>27430</td>\n","      <td>0.237617</td>\n","      <td>0.238476</td>\n","      <td>0.068948</td>\n","      <td>0.069450</td>\n","    </tr>\n","    <tr>\n","      <th>162</th>\n","      <td>LocalGLMftt (run: 12)</td>\n","      <td>56</td>\n","      <td>1313.066551</td>\n","      <td>27430</td>\n","      <td>0.237276</td>\n","      <td>0.238862</td>\n","      <td>0.067985</td>\n","      <td>0.068371</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>163 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd5579f3-0bb2-4b2f-bd64-b7b3508e2c6b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dd5579f3-0bb2-4b2f-bd64-b7b3508e2c6b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dd5579f3-0bb2-4b2f-bd64-b7b3508e2c6b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0b39042e-3c2d-45db-832a-a9b1a35f1f75\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b39042e-3c2d-45db-832a-a9b1a35f1f75')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0b39042e-3c2d-45db-832a-a9b1a35f1f75 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","158        LocalGLMftt (run: 8)      42   951.956478          27430   \n","159        LocalGLMftt (run: 9)      72  1377.468203          27430   \n","160       LocalGLMftt (run: 10)      40   923.518332          27430   \n","161       LocalGLMftt (run: 11)      40   986.134145          27430   \n","162       LocalGLMftt (run: 12)      56  1313.066551          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","158    0.237784   0.238886             0.068275            0.068710  \n","159    0.236593   0.239080             0.066974            0.067353  \n","160    0.237557   0.238749             0.068609            0.068993  \n","161    0.237617   0.238476             0.068948            0.069450  \n","162    0.237276   0.238862             0.067985            0.068371  \n","\n","[163 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 13-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 13/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.034   : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 0 / Train-Loss: 0.2419 / Val-Loss: 0.2408 / Test-Loss: 0.2422 / Time taken: 0:00:43 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0333  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 1 / Train-Loss: 0.2419 / Val-Loss: 0.2408 / Test-Loss: 0.2423 / Time taken: 0:00:59 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0332  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 2 / Train-Loss: 0.2416 / Val-Loss: 0.2404 / Test-Loss: 0.2418 / Time taken: 0:01:21 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 3 / Train-Loss: 0.2414 / Val-Loss: 0.2403 / Test-Loss: 0.2416 / Time taken: 0:01:36 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 4 / Train-Loss: 0.2412 / Val-Loss: 0.2403 / Test-Loss: 0.2415 / Time taken: 0:01:52 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0327  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 5 / Train-Loss: 0.2411 / Val-Loss: 0.2401 / Test-Loss: 0.2412 / Time taken: 0:02:08 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 6 / Train-Loss: 0.2409 / Val-Loss: 0.2401 / Test-Loss: 0.2411 / Time taken: 0:02:30 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0326  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 7 / Train-Loss: 0.2408 / Val-Loss: 0.2399 / Test-Loss: 0.2407 / Time taken: 0:02:45 / ---- Currently Best Val-Epoch: 7 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0328  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 8 / Train-Loss: 0.2406 / Val-Loss: 0.2399 / Test-Loss: 0.2406 / Time taken: 0:03:01 / ---- Currently Best Val-Epoch: 7 \n","Ensemble: 13/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.0329  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 9 / Train-Loss: 0.2405 / Val-Loss: 0.2398 / Test-Loss: 0.2406 / Time taken: 0:03:23 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 10 / Train-Loss: 0.2404 / Val-Loss: 0.2398 / Test-Loss: 0.2404 / Time taken: 0:03:45 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 11 / Batch: 0 / Train-Loss (Batch): 0.2009   : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 13/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 11 / Train-Loss: 0.2402 / Val-Loss: 0.2398 / Test-Loss: 0.2405 / Time taken: 0:04:02 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 13/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 12 / Train-Loss: 0.2401 / Val-Loss: 0.2396 / Test-Loss: 0.2402 / Time taken: 0:04:18 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 13 / Train-Loss: 0.2400 / Val-Loss: 0.2396 / Test-Loss: 0.2401 / Time taken: 0:04:33 / ---- Currently Best Val-Epoch: 13 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 14 / Train-Loss: 0.2398 / Val-Loss: 0.2394 / Test-Loss: 0.2400 / Time taken: 0:04:50 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 15 / Train-Loss: 0.2397 / Val-Loss: 0.2392 / Test-Loss: 0.2398 / Time taken: 0:05:07 / ---- Currently Best Val-Epoch: 15 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 16 / Train-Loss: 0.2396 / Val-Loss: 0.2391 / Test-Loss: 0.2397 / Time taken: 0:05:29 / ---- Currently Best Val-Epoch: 16 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 17 / Train-Loss: 0.2394 / Val-Loss: 0.2390 / Test-Loss: 0.2396 / Time taken: 0:05:45 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 18 / Train-Loss: 0.2393 / Val-Loss: 0.2391 / Test-Loss: 0.2399 / Time taken: 0:06:01 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 13/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 19 / Train-Loss: 0.2392 / Val-Loss: 0.2389 / Test-Loss: 0.2396 / Time taken: 0:06:23 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 20 / Train-Loss: 0.2390 / Val-Loss: 0.2388 / Test-Loss: 0.2395 / Time taken: 0:06:46 / ---- Currently Best Val-Epoch: 20 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 21 / Train-Loss: 0.2390 / Val-Loss: 0.2386 / Test-Loss: 0.2393 / Time taken: 0:07:02 / ---- Currently Best Val-Epoch: 21 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 22 / Train-Loss: 0.2389 / Val-Loss: 0.2386 / Test-Loss: 0.2393 / Time taken: 0:07:19 / ---- Currently Best Val-Epoch: 21 \n","Ensemble: 13/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 23 / Train-Loss: 0.2388 / Val-Loss: 0.2385 / Test-Loss: 0.2392 / Time taken: 0:07:35 / ---- Currently Best Val-Epoch: 23 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 24 / Train-Loss: 0.2387 / Val-Loss: 0.2385 / Test-Loss: 0.2394 / Time taken: 0:07:51 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 13/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 25 / Train-Loss: 0.2385 / Val-Loss: 0.2386 / Test-Loss: 0.2394 / Time taken: 0:08:13 / ---- Currently Best Val-Epoch: 23 \n","Ensemble: 13/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 26 / Train-Loss: 0.2385 / Val-Loss: 0.2383 / Test-Loss: 0.2390 / Time taken: 0:08:29 / ---- Currently Best Val-Epoch: 26 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 27 / Train-Loss: 0.2385 / Val-Loss: 0.2384 / Test-Loss: 0.2391 / Time taken: 0:08:45 / ---- Currently Best Val-Epoch: 26 \n","Ensemble: 13/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 28 / Train-Loss: 0.2383 / Val-Loss: 0.2383 / Test-Loss: 0.2390 / Time taken: 0:09:07 / ---- Currently Best Val-Epoch: 28 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 29 / Train-Loss: 0.2383 / Val-Loss: 0.2383 / Test-Loss: 0.2392 / Time taken: 0:09:23 / ---- Currently Best Val-Epoch: 28 \n","Ensemble: 13/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 30 / Train-Loss: 0.2382 / Val-Loss: 0.2382 / Test-Loss: 0.2390 / Time taken: 0:09:45 / ---- Currently Best Val-Epoch: 30 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 31 / Train-Loss: 0.2381 / Val-Loss: 0.2382 / Test-Loss: 0.2390 / Time taken: 0:10:01 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 32 / Train-Loss: 0.2381 / Val-Loss: 0.2382 / Test-Loss: 0.2391 / Time taken: 0:10:17 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 13/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 33 / Train-Loss: 0.2381 / Val-Loss: 0.2382 / Test-Loss: 0.2391 / Time taken: 0:10:33 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 13/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 34 / Train-Loss: 0.2380 / Val-Loss: 0.2382 / Test-Loss: 0.2392 / Time taken: 0:10:55 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 13/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 35 / Train-Loss: 0.2380 / Val-Loss: 0.2381 / Test-Loss: 0.2390 / Time taken: 0:11:10 / ---- Currently Best Val-Epoch: 35 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 36 / Train-Loss: 0.2379 / Val-Loss: 0.2382 / Test-Loss: 0.2390 / Time taken: 0:11:27 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 13/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 37 / Train-Loss: 0.2378 / Val-Loss: 0.2381 / Test-Loss: 0.2391 / Time taken: 0:11:49 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 13/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 38 / Train-Loss: 0.2378 / Val-Loss: 0.2382 / Test-Loss: 0.2390 / Time taken: 0:12:11 / ---- Currently Best Val-Epoch: 35 \n","Ensemble: 13/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 39 / Train-Loss: 0.2377 / Val-Loss: 0.2380 / Test-Loss: 0.2390 / Time taken: 0:12:27 / ---- Currently Best Val-Epoch: 39 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 40 / Train-Loss: 0.2377 / Val-Loss: 0.2381 / Test-Loss: 0.2389 / Time taken: 0:12:49 / ---- Currently Best Val-Epoch: 39 \n","Ensemble: 13/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 41 / Train-Loss: 0.2377 / Val-Loss: 0.2380 / Test-Loss: 0.2389 / Time taken: 0:13:05 / ---- Currently Best Val-Epoch: 41 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 42 / Train-Loss: 0.2376 / Val-Loss: 0.2380 / Test-Loss: 0.2390 / Time taken: 0:13:23 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 43 / Train-Loss: 0.2376 / Val-Loss: 0.2381 / Test-Loss: 0.2389 / Time taken: 0:13:38 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 44 / Train-Loss: 0.2375 / Val-Loss: 0.2380 / Test-Loss: 0.2389 / Time taken: 0:13:54 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 45 / Train-Loss: 0.2375 / Val-Loss: 0.2382 / Test-Loss: 0.2391 / Time taken: 0:14:09 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 46 / Train-Loss: 0.2374 / Val-Loss: 0.2380 / Test-Loss: 0.2390 / Time taken: 0:14:26 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0312 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 47 / Train-Loss: 0.2374 / Val-Loss: 0.2380 / Test-Loss: 0.2389 / Time taken: 0:14:42 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0312 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 48 / Train-Loss: 0.2373 / Val-Loss: 0.2381 / Test-Loss: 0.2389 / Time taken: 0:15:04 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0313 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 49 / Train-Loss: 0.2375 / Val-Loss: 0.2381 / Test-Loss: 0.2390 / Time taken: 0:15:19 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 50 / Train-Loss: 0.2373 / Val-Loss: 0.2382 / Test-Loss: 0.2390 / Time taken: 0:15:36 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 51 / Train-Loss: 0.2373 / Val-Loss: 0.2380 / Test-Loss: 0.2389 / Time taken: 0:15:52 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 52 / Train-Loss: 0.2373 / Val-Loss: 0.2382 / Test-Loss: 0.2390 / Time taken: 0:16:10 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0312 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 53 / Train-Loss: 0.2372 / Val-Loss: 0.2381 / Test-Loss: 0.2388 / Time taken: 0:16:25 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 54 / Train-Loss: 0.2371 / Val-Loss: 0.2381 / Test-Loss: 0.2389 / Time taken: 0:16:41 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 55 / Train-Loss: 0.2372 / Val-Loss: 0.2381 / Test-Loss: 0.2389 / Time taken: 0:16:57 / ---- Currently Best Val-Epoch: 41 \n","Ensemble: 13/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 56 / Train-Loss: 0.2371 / Val-Loss: 0.2379 / Test-Loss: 0.2389 / Time taken: 0:17:13 / ---- Currently Best Val-Epoch: 56 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 57 / Train-Loss: 0.2370 / Val-Loss: 0.2383 / Test-Loss: 0.2391 / Time taken: 0:17:35 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 13/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 58 / Train-Loss: 0.2370 / Val-Loss: 0.2380 / Test-Loss: 0.2388 / Time taken: 0:17:57 / ---- Currently Best Val-Epoch: 56 \n","Ensemble: 13/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 59 / Train-Loss: 0.2370 / Val-Loss: 0.2379 / Test-Loss: 0.2389 / Time taken: 0:18:14 / ---- Currently Best Val-Epoch: 59 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 60 / Train-Loss: 0.2369 / Val-Loss: 0.2380 / Test-Loss: 0.2388 / Time taken: 0:18:30 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 13/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 61 / Train-Loss: 0.2369 / Val-Loss: 0.2380 / Test-Loss: 0.2389 / Time taken: 0:18:46 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 13/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 62 / Train-Loss: 0.2369 / Val-Loss: 0.2381 / Test-Loss: 0.2389 / Time taken: 0:19:02 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 13/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 63 / Train-Loss: 0.2369 / Val-Loss: 0.2379 / Test-Loss: 0.2388 / Time taken: 0:19:18 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 13/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 64 / Train-Loss: 0.2368 / Val-Loss: 0.2380 / Test-Loss: 0.2390 / Time taken: 0:19:40 / ---- Currently Best Val-Epoch: 59 \n","Ensemble: 13/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 65 / Train-Loss: 0.2368 / Val-Loss: 0.2378 / Test-Loss: 0.2388 / Time taken: 0:19:55 / ---- Currently Best Val-Epoch: 65 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 66 / Train-Loss: 0.2368 / Val-Loss: 0.2380 / Test-Loss: 0.2389 / Time taken: 0:20:12 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 67 / Train-Loss: 0.2367 / Val-Loss: 0.2379 / Test-Loss: 0.2388 / Time taken: 0:20:35 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 68 / Train-Loss: 0.2367 / Val-Loss: 0.2382 / Test-Loss: 0.2392 / Time taken: 0:20:51 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 69 / Train-Loss: 0.2367 / Val-Loss: 0.2382 / Test-Loss: 0.2390 / Time taken: 0:21:06 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.031  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 70 / Train-Loss: 0.2366 / Val-Loss: 0.2379 / Test-Loss: 0.2387 / Time taken: 0:21:23 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 71 / Train-Loss: 0.2366 / Val-Loss: 0.2379 / Test-Loss: 0.2388 / Time taken: 0:21:39 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 72 / Train-Loss: 0.2365 / Val-Loss: 0.2379 / Test-Loss: 0.2388 / Time taken: 0:21:55 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0313 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 73 / Train-Loss: 0.2364 / Val-Loss: 0.2379 / Test-Loss: 0.2389 / Time taken: 0:22:17 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 74 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 74 / Train-Loss: 0.2364 / Val-Loss: 0.2379 / Test-Loss: 0.2387 / Time taken: 0:22:33 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 75 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 75 / Train-Loss: 0.2364 / Val-Loss: 0.2379 / Test-Loss: 0.2388 / Time taken: 0:22:55 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 76 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 76 / Train-Loss: 0.2364 / Val-Loss: 0.2379 / Test-Loss: 0.2386 / Time taken: 0:23:16 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 77 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 77 / Train-Loss: 0.2364 / Val-Loss: 0.2378 / Test-Loss: 0.2387 / Time taken: 0:23:33 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 78 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 78 / Train-Loss: 0.2363 / Val-Loss: 0.2379 / Test-Loss: 0.2387 / Time taken: 0:23:50 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 79 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 79 / Train-Loss: 0.2362 / Val-Loss: 0.2379 / Test-Loss: 0.2388 / Time taken: 0:24:06 / ---- Currently Best Val-Epoch: 65 \n","Ensemble: 13/14 / Epoch: 80 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 80 / Train-Loss: 0.2363 / Val-Loss: 0.2377 / Test-Loss: 0.2386 / Time taken: 0:24:22 / ---- Currently Best Val-Epoch: 80 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 81 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 81 / Train-Loss: 0.2361 / Val-Loss: 0.2377 / Test-Loss: 0.2385 / Time taken: 0:24:38 / ---- Currently Best Val-Epoch: 81 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 82 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 82 / Train-Loss: 0.2360 / Val-Loss: 0.2376 / Test-Loss: 0.2386 / Time taken: 0:24:56 / ---- Currently Best Val-Epoch: 82 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 83 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 83 / Train-Loss: 0.2360 / Val-Loss: 0.2376 / Test-Loss: 0.2385 / Time taken: 0:25:18 / ---- Currently Best Val-Epoch: 83 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 84 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 84 / Train-Loss: 0.2361 / Val-Loss: 0.2377 / Test-Loss: 0.2386 / Time taken: 0:25:40 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 13/14 / Epoch: 85 / Batch: 536 / Train-Loss (Batch): 0.0315 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 85 / Train-Loss: 0.2360 / Val-Loss: 0.2377 / Test-Loss: 0.2388 / Time taken: 0:25:56 / ---- Currently Best Val-Epoch: 83 \n","Ensemble: 13/14 / Epoch: 86 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 86 / Train-Loss: 0.2361 / Val-Loss: 0.2376 / Test-Loss: 0.2387 / Time taken: 0:26:12 / ---- Currently Best Val-Epoch: 86 <------- Best VAL Epoch so far\n","Ensemble: 13/14 / Epoch: 87 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 87 / Train-Loss: 0.2360 / Val-Loss: 0.2377 / Test-Loss: 0.2388 / Time taken: 0:26:29 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 88 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 88 / Train-Loss: 0.2357 / Val-Loss: 0.2377 / Test-Loss: 0.2387 / Time taken: 0:26:45 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 89 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 89 / Train-Loss: 0.2359 / Val-Loss: 0.2380 / Test-Loss: 0.2387 / Time taken: 0:27:07 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 90 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 90 / Train-Loss: 0.2358 / Val-Loss: 0.2379 / Test-Loss: 0.2386 / Time taken: 0:27:23 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 91 / Batch: 536 / Train-Loss (Batch): 0.0317 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 91 / Train-Loss: 0.2358 / Val-Loss: 0.2377 / Test-Loss: 0.2385 / Time taken: 0:27:39 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 92 / Batch: 536 / Train-Loss (Batch): 0.0314 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 92 / Train-Loss: 0.2358 / Val-Loss: 0.2379 / Test-Loss: 0.2389 / Time taken: 0:28:00 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 93 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 93 / Train-Loss: 0.2357 / Val-Loss: 0.2378 / Test-Loss: 0.2388 / Time taken: 0:28:16 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 94 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 94 / Train-Loss: 0.2357 / Val-Loss: 0.2379 / Test-Loss: 0.2387 / Time taken: 0:28:33 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 95 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 95 / Train-Loss: 0.2355 / Val-Loss: 0.2379 / Test-Loss: 0.2387 / Time taken: 0:28:49 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 96 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 96 / Train-Loss: 0.2356 / Val-Loss: 0.2377 / Test-Loss: 0.2386 / Time taken: 0:29:11 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 97 / Batch: 536 / Train-Loss (Batch): 0.031  : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 97 / Train-Loss: 0.2357 / Val-Loss: 0.2379 / Test-Loss: 0.2388 / Time taken: 0:29:27 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 98 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 98 / Train-Loss: 0.2356 / Val-Loss: 0.2380 / Test-Loss: 0.2386 / Time taken: 0:29:44 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 99 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 99 / Train-Loss: 0.2356 / Val-Loss: 0.2379 / Test-Loss: 0.2388 / Time taken: 0:30:00 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 100 / Batch: 536 / Train-Loss (Batch): 0.032 : [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 100 / Train-Loss: 0.2355 / Val-Loss: 0.2377 / Test-Loss: 0.2386 / Time taken: 0:30:17 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 101 / Batch: 536 / Train-Loss (Batch): 0.0331: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 101 / Train-Loss: 0.2356 / Val-Loss: 0.2380 / Test-Loss: 0.2388 / Time taken: 0:30:34 / ---- Currently Best Val-Epoch: 86 \n","Ensemble: 13/14 / Epoch: 102 / Batch: 536 / Train-Loss (Batch): 0.0309: [##############################] 99.8%\n","Ensemble: 13/14 / Epoch: 102 / Train-Loss: 0.2354 / Val-Loss: 0.2380 / Test-Loss: 0.2390 / Time taken: 0:30:51 / ---- Currently Best Val-Epoch: 86 \n","596/596 [==============================] - 12s 19ms/step\n","67/67 [==============================] - 1s 17ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-c60ac9d8-329c-472e-9cf2-ebe2c0b20077\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>LocalGLMftt (run: 9)</td>\n","      <td>72</td>\n","      <td>1377.468203</td>\n","      <td>27430</td>\n","      <td>0.236593</td>\n","      <td>0.239080</td>\n","      <td>0.066974</td>\n","      <td>0.067353</td>\n","    </tr>\n","    <tr>\n","      <th>160</th>\n","      <td>LocalGLMftt (run: 10)</td>\n","      <td>40</td>\n","      <td>923.518332</td>\n","      <td>27430</td>\n","      <td>0.237557</td>\n","      <td>0.238749</td>\n","      <td>0.068609</td>\n","      <td>0.068993</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>LocalGLMftt (run: 11)</td>\n","      <td>40</td>\n","      <td>986.134145</td>\n","      <td>27430</td>\n","      <td>0.237617</td>\n","      <td>0.238476</td>\n","      <td>0.068948</td>\n","      <td>0.069450</td>\n","    </tr>\n","    <tr>\n","      <th>162</th>\n","      <td>LocalGLMftt (run: 12)</td>\n","      <td>56</td>\n","      <td>1313.066551</td>\n","      <td>27430</td>\n","      <td>0.237276</td>\n","      <td>0.238862</td>\n","      <td>0.067985</td>\n","      <td>0.068371</td>\n","    </tr>\n","    <tr>\n","      <th>163</th>\n","      <td>LocalGLMftt (run: 13)</td>\n","      <td>86</td>\n","      <td>1851.208139</td>\n","      <td>27430</td>\n","      <td>0.236052</td>\n","      <td>0.238693</td>\n","      <td>0.066132</td>\n","      <td>0.066383</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>164 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c60ac9d8-329c-472e-9cf2-ebe2c0b20077')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c60ac9d8-329c-472e-9cf2-ebe2c0b20077 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c60ac9d8-329c-472e-9cf2-ebe2c0b20077');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f2f786ed-59ed-4f1d-9d7a-27d916fe8cbc\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2f786ed-59ed-4f1d-9d7a-27d916fe8cbc')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f2f786ed-59ed-4f1d-9d7a-27d916fe8cbc button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","159        LocalGLMftt (run: 9)      72  1377.468203          27430   \n","160       LocalGLMftt (run: 10)      40   923.518332          27430   \n","161       LocalGLMftt (run: 11)      40   986.134145          27430   \n","162       LocalGLMftt (run: 12)      56  1313.066551          27430   \n","163       LocalGLMftt (run: 13)      86  1851.208139          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","159    0.236593   0.239080             0.066974            0.067353  \n","160    0.237557   0.238749             0.068609            0.068993  \n","161    0.237617   0.238476             0.068948            0.069450  \n","162    0.237276   0.238862             0.067985            0.068371  \n","163    0.236052   0.238693             0.066132            0.066383  \n","\n","[164 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------We are at Model: 14-----------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","-------------------------------------------------\n","Ensemble: 14/14 / Epoch: 0 / Batch: 536 / Train-Loss (Batch): 0.0341  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 0 / Train-Loss: 0.2420 / Val-Loss: 0.2399 / Test-Loss: 0.2423 / Time taken: 0:00:34 / ---- Currently Best Val-Epoch: 0 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 1 / Batch: 536 / Train-Loss (Batch): 0.0337  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 1 / Train-Loss: 0.2419 / Val-Loss: 0.2396 / Test-Loss: 0.2421 / Time taken: 0:00:56 / ---- Currently Best Val-Epoch: 1 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 2 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 2 / Train-Loss: 0.2417 / Val-Loss: 0.2392 / Test-Loss: 0.2418 / Time taken: 0:01:12 / ---- Currently Best Val-Epoch: 2 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 3 / Batch: 536 / Train-Loss (Batch): 0.0336  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 3 / Train-Loss: 0.2415 / Val-Loss: 0.2389 / Test-Loss: 0.2416 / Time taken: 0:01:28 / ---- Currently Best Val-Epoch: 3 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 4 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 4 / Train-Loss: 0.2414 / Val-Loss: 0.2387 / Test-Loss: 0.2414 / Time taken: 0:01:49 / ---- Currently Best Val-Epoch: 4 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 5 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 5 / Train-Loss: 0.2412 / Val-Loss: 0.2385 / Test-Loss: 0.2412 / Time taken: 0:02:05 / ---- Currently Best Val-Epoch: 5 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 6 / Batch: 536 / Train-Loss (Batch): 0.0334  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 6 / Train-Loss: 0.2410 / Val-Loss: 0.2383 / Test-Loss: 0.2409 / Time taken: 0:02:21 / ---- Currently Best Val-Epoch: 6 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 7 / Batch: 536 / Train-Loss (Batch): 0.0335  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 7 / Train-Loss: 0.2408 / Val-Loss: 0.2383 / Test-Loss: 0.2409 / Time taken: 0:02:37 / ---- Currently Best Val-Epoch: 6 \n","Ensemble: 14/14 / Epoch: 8 / Batch: 536 / Train-Loss (Batch): 0.0331  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 8 / Train-Loss: 0.2406 / Val-Loss: 0.2381 / Test-Loss: 0.2406 / Time taken: 0:02:53 / ---- Currently Best Val-Epoch: 8 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 9 / Batch: 536 / Train-Loss (Batch): 0.033   : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 9 / Train-Loss: 0.2403 / Val-Loss: 0.2380 / Test-Loss: 0.2404 / Time taken: 0:03:15 / ---- Currently Best Val-Epoch: 9 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 10 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 10 / Train-Loss: 0.2401 / Val-Loss: 0.2380 / Test-Loss: 0.2404 / Time taken: 0:03:37 / ---- Currently Best Val-Epoch: 10 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 11 / Batch: 0 / Train-Loss (Batch): 0.18     : [------------------------------] 0.0%"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble: 14/14 / Epoch: 11 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 11 / Train-Loss: 0.2400 / Val-Loss: 0.2380 / Test-Loss: 0.2404 / Time taken: 0:03:52 / ---- Currently Best Val-Epoch: 10 \n","Ensemble: 14/14 / Epoch: 12 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 12 / Train-Loss: 0.2398 / Val-Loss: 0.2375 / Test-Loss: 0.2399 / Time taken: 0:04:14 / ---- Currently Best Val-Epoch: 12 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 13 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 13 / Train-Loss: 0.2397 / Val-Loss: 0.2378 / Test-Loss: 0.2402 / Time taken: 0:04:31 / ---- Currently Best Val-Epoch: 12 \n","Ensemble: 14/14 / Epoch: 14 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 14 / Train-Loss: 0.2395 / Val-Loss: 0.2373 / Test-Loss: 0.2397 / Time taken: 0:04:47 / ---- Currently Best Val-Epoch: 14 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 15 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 15 / Train-Loss: 0.2394 / Val-Loss: 0.2374 / Test-Loss: 0.2398 / Time taken: 0:05:03 / ---- Currently Best Val-Epoch: 14 \n","Ensemble: 14/14 / Epoch: 16 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 16 / Train-Loss: 0.2392 / Val-Loss: 0.2375 / Test-Loss: 0.2398 / Time taken: 0:05:18 / ---- Currently Best Val-Epoch: 14 \n","Ensemble: 14/14 / Epoch: 17 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 17 / Train-Loss: 0.2392 / Val-Loss: 0.2370 / Test-Loss: 0.2395 / Time taken: 0:05:34 / ---- Currently Best Val-Epoch: 17 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 18 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 18 / Train-Loss: 0.2391 / Val-Loss: 0.2372 / Test-Loss: 0.2395 / Time taken: 0:05:50 / ---- Currently Best Val-Epoch: 17 \n","Ensemble: 14/14 / Epoch: 19 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 19 / Train-Loss: 0.2390 / Val-Loss: 0.2370 / Test-Loss: 0.2394 / Time taken: 0:06:06 / ---- Currently Best Val-Epoch: 19 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 20 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 20 / Train-Loss: 0.2390 / Val-Loss: 0.2372 / Test-Loss: 0.2395 / Time taken: 0:06:22 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 14/14 / Epoch: 21 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 21 / Train-Loss: 0.2388 / Val-Loss: 0.2371 / Test-Loss: 0.2394 / Time taken: 0:06:44 / ---- Currently Best Val-Epoch: 19 \n","Ensemble: 14/14 / Epoch: 22 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 22 / Train-Loss: 0.2387 / Val-Loss: 0.2369 / Test-Loss: 0.2393 / Time taken: 0:07:00 / ---- Currently Best Val-Epoch: 22 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 23 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 23 / Train-Loss: 0.2387 / Val-Loss: 0.2373 / Test-Loss: 0.2395 / Time taken: 0:07:16 / ---- Currently Best Val-Epoch: 22 \n","Ensemble: 14/14 / Epoch: 24 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 24 / Train-Loss: 0.2387 / Val-Loss: 0.2368 / Test-Loss: 0.2391 / Time taken: 0:07:38 / ---- Currently Best Val-Epoch: 24 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 25 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 25 / Train-Loss: 0.2385 / Val-Loss: 0.2370 / Test-Loss: 0.2392 / Time taken: 0:08:01 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 14/14 / Epoch: 26 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 26 / Train-Loss: 0.2385 / Val-Loss: 0.2369 / Test-Loss: 0.2392 / Time taken: 0:08:17 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 14/14 / Epoch: 27 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 27 / Train-Loss: 0.2384 / Val-Loss: 0.2370 / Test-Loss: 0.2392 / Time taken: 0:08:38 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 14/14 / Epoch: 28 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 28 / Train-Loss: 0.2384 / Val-Loss: 0.2369 / Test-Loss: 0.2390 / Time taken: 0:08:55 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 14/14 / Epoch: 29 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 29 / Train-Loss: 0.2383 / Val-Loss: 0.2372 / Test-Loss: 0.2393 / Time taken: 0:09:12 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 14/14 / Epoch: 30 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 30 / Train-Loss: 0.2382 / Val-Loss: 0.2370 / Test-Loss: 0.2391 / Time taken: 0:09:28 / ---- Currently Best Val-Epoch: 24 \n","Ensemble: 14/14 / Epoch: 31 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 31 / Train-Loss: 0.2383 / Val-Loss: 0.2367 / Test-Loss: 0.2388 / Time taken: 0:09:43 / ---- Currently Best Val-Epoch: 31 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 32 / Batch: 536 / Train-Loss (Batch): 0.0311 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 32 / Train-Loss: 0.2381 / Val-Loss: 0.2371 / Test-Loss: 0.2391 / Time taken: 0:10:05 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 14/14 / Epoch: 33 / Batch: 536 / Train-Loss (Batch): 0.032  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 33 / Train-Loss: 0.2381 / Val-Loss: 0.2368 / Test-Loss: 0.2389 / Time taken: 0:10:23 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 14/14 / Epoch: 34 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 34 / Train-Loss: 0.2380 / Val-Loss: 0.2372 / Test-Loss: 0.2392 / Time taken: 0:10:44 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 14/14 / Epoch: 35 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 35 / Train-Loss: 0.2380 / Val-Loss: 0.2372 / Test-Loss: 0.2391 / Time taken: 0:11:00 / ---- Currently Best Val-Epoch: 31 \n","Ensemble: 14/14 / Epoch: 36 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 36 / Train-Loss: 0.2380 / Val-Loss: 0.2367 / Test-Loss: 0.2388 / Time taken: 0:11:22 / ---- Currently Best Val-Epoch: 36 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 37 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 37 / Train-Loss: 0.2378 / Val-Loss: 0.2371 / Test-Loss: 0.2390 / Time taken: 0:11:38 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 38 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 38 / Train-Loss: 0.2379 / Val-Loss: 0.2370 / Test-Loss: 0.2390 / Time taken: 0:12:00 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 39 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 39 / Train-Loss: 0.2379 / Val-Loss: 0.2371 / Test-Loss: 0.2391 / Time taken: 0:12:15 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 40 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 40 / Train-Loss: 0.2379 / Val-Loss: 0.2370 / Test-Loss: 0.2390 / Time taken: 0:12:30 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 41 / Batch: 536 / Train-Loss (Batch): 0.0334 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 41 / Train-Loss: 0.2378 / Val-Loss: 0.2374 / Test-Loss: 0.2392 / Time taken: 0:12:52 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 42 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 42 / Train-Loss: 0.2378 / Val-Loss: 0.2368 / Test-Loss: 0.2389 / Time taken: 0:13:09 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 43 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 43 / Train-Loss: 0.2377 / Val-Loss: 0.2368 / Test-Loss: 0.2390 / Time taken: 0:13:25 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 44 / Batch: 536 / Train-Loss (Batch): 0.0318 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 44 / Train-Loss: 0.2377 / Val-Loss: 0.2368 / Test-Loss: 0.2388 / Time taken: 0:13:40 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 45 / Batch: 536 / Train-Loss (Batch): 0.0323 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 45 / Train-Loss: 0.2376 / Val-Loss: 0.2371 / Test-Loss: 0.2390 / Time taken: 0:14:02 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 46 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 46 / Train-Loss: 0.2376 / Val-Loss: 0.2370 / Test-Loss: 0.2390 / Time taken: 0:14:20 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 47 / Batch: 536 / Train-Loss (Batch): 0.0331 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 47 / Train-Loss: 0.2376 / Val-Loss: 0.2371 / Test-Loss: 0.2390 / Time taken: 0:14:35 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 48 / Batch: 536 / Train-Loss (Batch): 0.0332 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 48 / Train-Loss: 0.2375 / Val-Loss: 0.2368 / Test-Loss: 0.2389 / Time taken: 0:14:57 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 49 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 49 / Train-Loss: 0.2375 / Val-Loss: 0.2370 / Test-Loss: 0.2391 / Time taken: 0:15:18 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 50 / Batch: 536 / Train-Loss (Batch): 0.033  : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 50 / Train-Loss: 0.2375 / Val-Loss: 0.2369 / Test-Loss: 0.2389 / Time taken: 0:15:41 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 51 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 51 / Train-Loss: 0.2375 / Val-Loss: 0.2370 / Test-Loss: 0.2391 / Time taken: 0:15:57 / ---- Currently Best Val-Epoch: 36 \n","Ensemble: 14/14 / Epoch: 52 / Batch: 536 / Train-Loss (Batch): 0.0328 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 52 / Train-Loss: 0.2375 / Val-Loss: 0.2367 / Test-Loss: 0.2388 / Time taken: 0:16:12 / ---- Currently Best Val-Epoch: 52 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 53 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 53 / Train-Loss: 0.2374 / Val-Loss: 0.2368 / Test-Loss: 0.2389 / Time taken: 0:16:28 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 14/14 / Epoch: 54 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 54 / Train-Loss: 0.2374 / Val-Loss: 0.2368 / Test-Loss: 0.2391 / Time taken: 0:16:51 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 14/14 / Epoch: 55 / Batch: 536 / Train-Loss (Batch): 0.0337 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 55 / Train-Loss: 0.2374 / Val-Loss: 0.2368 / Test-Loss: 0.2391 / Time taken: 0:17:07 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 14/14 / Epoch: 56 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 56 / Train-Loss: 0.2374 / Val-Loss: 0.2369 / Test-Loss: 0.2391 / Time taken: 0:17:22 / ---- Currently Best Val-Epoch: 52 \n","Ensemble: 14/14 / Epoch: 57 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 57 / Train-Loss: 0.2373 / Val-Loss: 0.2366 / Test-Loss: 0.2389 / Time taken: 0:17:38 / ---- Currently Best Val-Epoch: 57 <------- Best VAL Epoch so far\n","Ensemble: 14/14 / Epoch: 58 / Batch: 536 / Train-Loss (Batch): 0.0336 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 58 / Train-Loss: 0.2374 / Val-Loss: 0.2368 / Test-Loss: 0.2390 / Time taken: 0:17:54 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 59 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 59 / Train-Loss: 0.2373 / Val-Loss: 0.2369 / Test-Loss: 0.2391 / Time taken: 0:18:11 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 60 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 60 / Train-Loss: 0.2372 / Val-Loss: 0.2368 / Test-Loss: 0.2390 / Time taken: 0:18:32 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 61 / Batch: 536 / Train-Loss (Batch): 0.0329 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 61 / Train-Loss: 0.2371 / Val-Loss: 0.2367 / Test-Loss: 0.2390 / Time taken: 0:18:48 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 62 / Batch: 536 / Train-Loss (Batch): 0.0324 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 62 / Train-Loss: 0.2372 / Val-Loss: 0.2367 / Test-Loss: 0.2388 / Time taken: 0:19:04 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 63 / Batch: 536 / Train-Loss (Batch): 0.0319 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 63 / Train-Loss: 0.2372 / Val-Loss: 0.2367 / Test-Loss: 0.2388 / Time taken: 0:19:25 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 64 / Batch: 536 / Train-Loss (Batch): 0.0326 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 64 / Train-Loss: 0.2372 / Val-Loss: 0.2368 / Test-Loss: 0.2391 / Time taken: 0:19:47 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 65 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 65 / Train-Loss: 0.2371 / Val-Loss: 0.2373 / Test-Loss: 0.2393 / Time taken: 0:20:04 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 66 / Batch: 536 / Train-Loss (Batch): 0.0335 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 66 / Train-Loss: 0.2371 / Val-Loss: 0.2370 / Test-Loss: 0.2391 / Time taken: 0:20:20 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 67 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 67 / Train-Loss: 0.2371 / Val-Loss: 0.2371 / Test-Loss: 0.2392 / Time taken: 0:20:36 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 68 / Batch: 536 / Train-Loss (Batch): 0.0327 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 68 / Train-Loss: 0.2370 / Val-Loss: 0.2366 / Test-Loss: 0.2387 / Time taken: 0:20:57 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 69 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 69 / Train-Loss: 0.2370 / Val-Loss: 0.2369 / Test-Loss: 0.2391 / Time taken: 0:21:15 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 70 / Batch: 536 / Train-Loss (Batch): 0.0333 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 70 / Train-Loss: 0.2371 / Val-Loss: 0.2369 / Test-Loss: 0.2390 / Time taken: 0:21:30 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 71 / Batch: 536 / Train-Loss (Batch): 0.0322 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 71 / Train-Loss: 0.2368 / Val-Loss: 0.2368 / Test-Loss: 0.2391 / Time taken: 0:21:46 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 72 / Batch: 536 / Train-Loss (Batch): 0.0325 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 72 / Train-Loss: 0.2368 / Val-Loss: 0.2372 / Test-Loss: 0.2393 / Time taken: 0:22:01 / ---- Currently Best Val-Epoch: 57 \n","Ensemble: 14/14 / Epoch: 73 / Batch: 536 / Train-Loss (Batch): 0.0321 : [##############################] 99.8%\n","Ensemble: 14/14 / Epoch: 73 / Train-Loss: 0.2369 / Val-Loss: 0.2370 / Test-Loss: 0.2393 / Time taken: 0:22:17 / ---- Currently Best Val-Epoch: 57 \n","596/596 [==============================] - 12s 19ms/step\n","67/67 [==============================] - 1s 18ms/step\n"]},{"data":{"text/html":["\n","  <div id=\"df-c50c0032-9616-4ac0-b392-b67b2152257d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model (run: 0)</td>\n","      <td>0</td>\n","      <td>0.025613</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>homogeneous model (run: 1)</td>\n","      <td>0</td>\n","      <td>0.023689</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>homogeneous model (run: 2)</td>\n","      <td>0</td>\n","      <td>0.026122</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>homogeneous model (run: 3)</td>\n","      <td>0</td>\n","      <td>0.023556</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>homogeneous model (run: 4)</td>\n","      <td>0</td>\n","      <td>0.024540</td>\n","      <td>1</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>160</th>\n","      <td>LocalGLMftt (run: 10)</td>\n","      <td>40</td>\n","      <td>923.518332</td>\n","      <td>27430</td>\n","      <td>0.237557</td>\n","      <td>0.238749</td>\n","      <td>0.068609</td>\n","      <td>0.068993</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>LocalGLMftt (run: 11)</td>\n","      <td>40</td>\n","      <td>986.134145</td>\n","      <td>27430</td>\n","      <td>0.237617</td>\n","      <td>0.238476</td>\n","      <td>0.068948</td>\n","      <td>0.069450</td>\n","    </tr>\n","    <tr>\n","      <th>162</th>\n","      <td>LocalGLMftt (run: 12)</td>\n","      <td>56</td>\n","      <td>1313.066551</td>\n","      <td>27430</td>\n","      <td>0.237276</td>\n","      <td>0.238862</td>\n","      <td>0.067985</td>\n","      <td>0.068371</td>\n","    </tr>\n","    <tr>\n","      <th>163</th>\n","      <td>LocalGLMftt (run: 13)</td>\n","      <td>86</td>\n","      <td>1851.208139</td>\n","      <td>27430</td>\n","      <td>0.236052</td>\n","      <td>0.238693</td>\n","      <td>0.066132</td>\n","      <td>0.066383</td>\n","    </tr>\n","    <tr>\n","      <th>164</th>\n","      <td>LocalGLMftt (run: 14)</td>\n","      <td>57</td>\n","      <td>1337.899545</td>\n","      <td>27430</td>\n","      <td>0.236946</td>\n","      <td>0.238912</td>\n","      <td>0.069820</td>\n","      <td>0.070222</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>165 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c50c0032-9616-4ac0-b392-b67b2152257d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c50c0032-9616-4ac0-b392-b67b2152257d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c50c0032-9616-4ac0-b392-b67b2152257d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0feb6f1d-511a-4561-9654-eee85f182e8f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0feb6f1d-511a-4561-9654-eee85f182e8f')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0feb6f1d-511a-4561-9654-eee85f182e8f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                          model  epochs     run_time  nr_parameters  \\\n","0    homogeneous model (run: 0)       0     0.025613              1   \n","1    homogeneous model (run: 1)       0     0.023689              1   \n","2    homogeneous model (run: 2)       0     0.026122              1   \n","3    homogeneous model (run: 3)       0     0.023556              1   \n","4    homogeneous model (run: 4)       0     0.024540              1   \n","..                          ...     ...          ...            ...   \n","160       LocalGLMftt (run: 10)      40   923.518332          27430   \n","161       LocalGLMftt (run: 11)      40   986.134145          27430   \n","162       LocalGLMftt (run: 12)      56  1313.066551          27430   \n","163       LocalGLMftt (run: 13)      86  1851.208139          27430   \n","164       LocalGLMftt (run: 14)      57  1337.899545          27430   \n","\n","     loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0      0.252132   0.254454             0.073631            0.073631  \n","1      0.252132   0.254454             0.073631            0.073631  \n","2      0.252132   0.254454             0.073631            0.073631  \n","3      0.252132   0.254454             0.073631            0.073631  \n","4      0.252132   0.254454             0.073631            0.073631  \n","..          ...        ...                  ...                 ...  \n","160    0.237557   0.238749             0.068609            0.068993  \n","161    0.237617   0.238476             0.068948            0.069450  \n","162    0.237276   0.238862             0.067985            0.068371  \n","163    0.236052   0.238693             0.066132            0.066383  \n","164    0.236946   0.238912             0.069820            0.070222  \n","\n","[165 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# Create the dataframes for creation of the glm-ohe-start model:\n","# --------------------\n","data_nn_ohe_learn, y_true_learn = create_ffn_ohe_data(bool_in_learn)\n","\n","# create dummy glm for initial weights\n","# ----------------------\n","poisson_glm_dummy = PoissonRegressor(alpha = 0,max_iter=1000) # scikit-learn.org: alpha = 0 is equivalent to unpenalized GLMs\n","poisson_glm_dummy.fit(data_nn_ohe_learn[0],y_true_learn/data_nn_ohe_learn[1],sample_weight=data_nn_ohe_learn[1]) # note: data_nn_ohe_learn = [X_ohe,exposure]\n","# get the betas from the glm:\n","glm_nr_col_betas = poisson_glm_dummy.coef_[:len(nr_col)]\n","current_beta_index = len(nr_col)\n","glm_cat_col_betas = {}\n","for c in cat_vocabulary.keys():\n","    glm_cat_col_betas[c] = poisson_glm_dummy.coef_[current_beta_index:current_beta_index+len(cat_vocabulary[c])]\n","    current_beta_index += len(cat_vocabulary[c])\n","glm_intercept = poisson_glm_dummy.intercept_\n","\n","\n","# Create the dataframes needed for evaluation:\n","# --------------------\n","# NOTE: in the 2021 Gorishniy paper the batch size is different for the different Datasets\n","# but is not hyperparameter tuned. Bigger datasets they used a batch size of 1024 and\n","# for smaller datasets a batch size of (256/512).\n","batch_size = 1024\n","learn_data = df_to_tensor(df_freq_prep_nn[bool_in_learn], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","test_data = df_to_tensor(df_freq_prep_nn[bool_in_test], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","for run_index in range(15):\n","\n","    # Create the dataframes needed for training:\n","    learn_train_data = df_to_tensor(df_freq_prep_nn[train_val_split[f\"learn_train_{run_index}\"]],\n","                                    feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","    learn_val_data = df_to_tensor(df_freq_prep_nn[train_val_split[f\"learn_val_{run_index}\"]],\n","                                  feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------We are at Model: {str(run_index).zfill(2)}-----------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    print(f\"-------------------------------------------------\")\n","    # Define FT-Transformer Models:\n","    # ----------------------\n","    # NOTE: we use here tensorflow/keras model subclasses (not the functional or sequential api)\n","    # NOTE: we use here instead of the .fit function a costum training loop\n","\n","    # create the model:\n","    # ----------------------\n","    set_random_seeds(int(random_seeds[run_index]))\n","    LocalGLMftt = EnhActuar.LocalGLM_FT_Transformer(\n","            emb_dim = 32, # NOTE: In the default setting for the 2021 Gorishniy paper they used emb_dim = 192 (but the parameter size would here go trough the roof, so we use something smaller)\n","            nr_features = nr_col,\n","            cat_features = cat_col,\n","            cat_vocabulary = cat_vocabulary,\n","            count_transformer_blocks = 3,\n","            attention_n_heads = 8,\n","            attention_dropout = 0.2,\n","            ffn_d_hidden = None, # NOTE: change to None if ReGLU should be used -> None uses default value (4/3*emb_dim), they write that they used 2*emb_dim if not ReGLU.\n","            ffn_activation_ReGLU = True, # NOTE: set True if ReGLU should be used\n","            ffn_dropout = 0.1,\n","            prenormalization = True,\n","            output_dim = 1,\n","            last_activation = 'exponential',\n","            exposure_name = \"Exposure\",\n","            last_layer_initial_weights = \"zeros\",\n","            last_layer_initial_bias = \"ones\",\n","            init_glm_cat_col_weights = glm_cat_col_betas,\n","            init_glm_nr_col_weights = glm_nr_col_betas,\n","            init_glm_bias = glm_intercept,\n","            trainable_glm_emb = False,\n","            seed_nr = int(random_seeds[run_index])\n","    )\n","\n","    # See here regarding costum training loop: https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch\n","\n","    # Instantiate an optimizer to train the model.\n","    # ----------------------\n","    # create an optimizer AdamW with learning rate 1e-4, weight decay 1e-5:\n","    optimizer = tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5)\n","\n","    # Instantiate a loss function\n","    # ----------------------\n","    # we use our own loss function here\n","    # because it is not included in tensorflow in the same way (see section loss function for more details):\n","    loss_fn = Poisson_loss_for_tf_Wrapped()\n","\n","    # Prepare the metrics.\n","    # ----------------------\n","    # we use a costume metric here (because it is not included in tensorflow in the same way):\n","    train_acc_metric = Poisson_Metric_for_tf()\n","    val_acc_metric = Poisson_Metric_for_tf()\n","    test_acc_metric = Poisson_Metric_for_tf()\n","\n","    @tf.function\n","    def train_step(x, y):\n","        # Open a GradientTape to record the operations run during the forward pass, which enables auto-differentiation.\n","        with tf.GradientTape() as tape:\n","            # Run the forward pass of the layer. The operations that the layer applies to its inputs are going to be recorded on the GradientTape.\n","            y_pred = LocalGLMftt(x, training=True)[\"output\"]  # prediction for this minibatch\n","            # Compute the loss value for this minibatch.\n","            loss_value = loss_fn(y, y_pred)\n","        # Use the gradient tape to automatically retrieve the gradients of the trainable variables with respect to the loss.\n","        grads = tape.gradient(loss_value, LocalGLMftt.trainable_weights)\n","        # Run one step of gradient descent by updating the value of the variables to minimize the loss.\n","        optimizer.apply_gradients(zip(grads, LocalGLMftt.trainable_weights))\n","        # Update training metric.\n","        train_acc_metric.update_state(y, y_pred)\n","        return loss_value\n","\n","    @tf.function\n","    def val_step(x, y):\n","        # Run the forward pass of the layer.\n","        # (note: training=False is needed because the layers have different behavior during training versus inference (e.g. Dropout))\n","        y_pred = LocalGLMftt(x, training=False)[\"output\"]\n","        # Update val metrics\n","        val_acc_metric.update_state(y, y_pred)\n","\n","    @tf.function\n","    def test_step(x, y):\n","        # Run the forward pass of the layer.\n","        # (note: training=False is needed because the layers have different behavior during training versus inference (e.g. Dropout))\n","        y_pred = LocalGLMftt(x, training=False)[\"output\"]\n","        # Update val metrics\n","        test_acc_metric.update_state(y, y_pred)\n","\n","    # model fitting:\n","    # ----------------------\n","    start_time = time.time()\n","    Val_Progress = helper.Easy_ProgressTracker(patience=15)\n","    epochs = 500\n","\n","    for epoch in range(epochs):\n","        # Iterate over the batches of the dataset.\n","        for step, (x_batch_train, y_batch_train) in enumerate(learn_train_data):\n","            loss_value = train_step(x_batch_train, y_batch_train)\n","            helper.costume_progress_bar(f\"Ensemble: {str(run_index).zfill(2)}/{14} / Epoch: {epoch} / Batch: {step} / Train-Loss (Batch): {round(float(loss_value),4)}\",step,len(learn_train_data), 30)\n","\n","        # Display metrics at the end of each epoch.\n","        print_train_loss = train_acc_metric.result()\n","        # Reset training metrics at the end of each epoch\n","        train_acc_metric.reset_states()\n","\n","        # Run a validation at the end of each epoch.\n","        for x_batch_val, y_batch_val in learn_val_data:\n","            val_step(x_batch_val, y_batch_val)\n","        print_val_loss = val_acc_metric.result()\n","        val_acc_metric.reset_states()\n","        for x_batch_test, y_batch_test in test_data:\n","            test_step(x_batch_test, y_batch_test)\n","        print_test_loss = test_acc_metric.result()\n","        test_acc_metric.reset_states()\n","\n","        Val_Progress(current_epoch=epoch, current_score = print_val_loss)\n","\n","        print(f\"\\nEnsemble: {str(run_index).zfill(2)}/{14} / Epoch: {epoch} / Train-Loss: %.4f / Val-Loss: %.4f / Test-Loss: %.4f / Time taken: %s / ---- Currently Best Val-Epoch: %d\" % (\n","            # str(run_index).zfill(2),\n","            float(print_train_loss),\n","            float(print_val_loss),\n","            float(print_test_loss),\n","            datetime.timedelta(seconds=int(time.time() - start_time)),\n","            Val_Progress.best_epoch\n","            ), end = \" \")\n","        if Val_Progress.progress == True:\n","            print(\"<------- Best VAL Epoch so far\")\n","        else:\n","            print(\"\\r\")\n","\n","\n","        # Callback: save best model / early stopping:\n","        # ----------------------\n","        earliest_epoch2save = 10\n","        if Val_Progress.progress and Val_Progress.current_epoch >= earliest_epoch2save:\n","            LocalGLMftt.save_weights(f'{storage_path}/saved_models/Poisson_LocalGLMftt_{run_index}.weights.h5')\n","        if Val_Progress.patience_over:\n","            break\n","\n","    # create some metrics after the loop\n","    best_epoch_LocalGLMftt = Val_Progress.best_epoch\n","    execution_time_LocalGLMftt = time.time() - start_time\n","\n","    # load the best saved model and epochs_and_time from the pickle file:\n","    # ----------------------\n","    LocalGLMftt.load_weights(f'{storage_path}/saved_models/Poisson_LocalGLMftt_{run_index}.weights.h5')\n","\n","    # predict with the model:\n","    # ----------------------\n","    y_pred[\"train\"][f\"LocalGLMftt\"] = np.array([x for [x] in LocalGLMftt.predict(learn_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                )[\"output\"]])\n","    y_pred[\"test\"][f\"LocalGLMftt\"] = np.array([x for [x] in LocalGLMftt.predict(test_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                )[\"output\"]])\n","\n","    # evaluate the model:\n","    # ----------------------\n","    LocalGLMftt_results = Results(model=f\"LocalGLMftt (run: {run_index})\",\n","                                epochs=best_epoch_LocalGLMftt,\n","                                run_time=execution_time_LocalGLMftt,\n","                                nr_parameters=[np.sum([np.prod(v.get_shape().as_list()) for v in LocalGLMftt.trainable_weights])],\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"LocalGLMftt\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"LocalGLMftt\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"LocalGLMftt\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"LocalGLMftt\"].sum()/exposure[\"test\"].sum())\n","    # store the results in the dataframe:\n","    store_results_in_df(LocalGLMftt_results)\n","    display(df_results)\n","    # save the results:\n","    with open(f'{storage_path}/Data/df_results.pickle', 'wb') as handle:\n","        pickle.dump(df_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dX9XtiNNcoVu"},"outputs":[],"source":["# save the results:\n","# with open(f'{storage_path}/Data/df_results.pickle', 'wb') as handle:\n","#     pickle.dump(df_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# load the results:\n","with open(f'{storage_path}/Data/df_results.pickle', 'rb') as handle:\n","    df_results = pickle.load(handle)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"elapsed":421,"status":"ok","timestamp":1699573296821,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"QdAozwhbdCy3","outputId":"5f8fb7e0-9e57-4a96-8b9f-91cf9177f0bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results Average:\n"]},{"data":{"text/html":["\n","  <div id=\"df-6c05297b-4dc7-483c-a4c5-98ba3f2d9451\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model</td>\n","      <td>0.000000</td>\n","      <td>0.054847</td>\n","      <td>1.0</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GLM1</td>\n","      <td>0.000000</td>\n","      <td>2.220158</td>\n","      <td>49.0</td>\n","      <td>0.241015</td>\n","      <td>0.241463</td>\n","      <td>0.073631</td>\n","      <td>0.073900</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GLM2</td>\n","      <td>0.000000</td>\n","      <td>2.752693</td>\n","      <td>48.0</td>\n","      <td>0.240911</td>\n","      <td>0.241125</td>\n","      <td>0.073631</td>\n","      <td>0.073981</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GLM3</td>\n","      <td>0.000000</td>\n","      <td>1.900497</td>\n","      <td>50.0</td>\n","      <td>0.240844</td>\n","      <td>0.241022</td>\n","      <td>0.073631</td>\n","      <td>0.074048</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FFN_OHE</td>\n","      <td>42.200000</td>\n","      <td>37.805560</td>\n","      <td>1306.0</td>\n","      <td>0.237535</td>\n","      <td>0.238652</td>\n","      <td>0.073906</td>\n","      <td>0.074310</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>FNN_CAT_EMB</td>\n","      <td>72.933333</td>\n","      <td>58.728892</td>\n","      <td>792.0</td>\n","      <td>0.237682</td>\n","      <td>0.238267</td>\n","      <td>0.073774</td>\n","      <td>0.074238</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CANN</td>\n","      <td>90.333333</td>\n","      <td>68.559120</td>\n","      <td>792.0</td>\n","      <td>0.237420</td>\n","      <td>0.238102</td>\n","      <td>0.074019</td>\n","      <td>0.074438</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LocalGLMnet</td>\n","      <td>25.333333</td>\n","      <td>29.720892</td>\n","      <td>1737.0</td>\n","      <td>0.237095</td>\n","      <td>0.239211</td>\n","      <td>0.073825</td>\n","      <td>0.074267</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>FT_transformer</td>\n","      <td>78.866667</td>\n","      <td>1569.860410</td>\n","      <td>27133.0</td>\n","      <td>0.237803</td>\n","      <td>0.239389</td>\n","      <td>0.061140</td>\n","      <td>0.061290</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>CAFTT</td>\n","      <td>57.333333</td>\n","      <td>1170.160723</td>\n","      <td>27133.0</td>\n","      <td>0.237146</td>\n","      <td>0.238072</td>\n","      <td>0.065975</td>\n","      <td>0.066235</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LocalGLMftt</td>\n","      <td>53.200000</td>\n","      <td>1187.006637</td>\n","      <td>27430.0</td>\n","      <td>0.237214</td>\n","      <td>0.238801</td>\n","      <td>0.067904</td>\n","      <td>0.068316</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c05297b-4dc7-483c-a4c5-98ba3f2d9451')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6c05297b-4dc7-483c-a4c5-98ba3f2d9451 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6c05297b-4dc7-483c-a4c5-98ba3f2d9451');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2171fb13-db62-4c16-bb94-f67737e58a38\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2171fb13-db62-4c16-bb94-f67737e58a38')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2171fb13-db62-4c16-bb94-f67737e58a38 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                model     epochs     run_time  nr_parameters  loss_train  \\\n","0   homogeneous model   0.000000     0.054847            1.0    0.252132   \n","1                GLM1   0.000000     2.220158           49.0    0.241015   \n","2                GLM2   0.000000     2.752693           48.0    0.240911   \n","3                GLM3   0.000000     1.900497           50.0    0.240844   \n","4             FFN_OHE  42.200000    37.805560         1306.0    0.237535   \n","5         FNN_CAT_EMB  72.933333    58.728892          792.0    0.237682   \n","6                CANN  90.333333    68.559120          792.0    0.237420   \n","7         LocalGLMnet  25.333333    29.720892         1737.0    0.237095   \n","8      FT_transformer  78.866667  1569.860410        27133.0    0.237803   \n","9               CAFTT  57.333333  1170.160723        27133.0    0.237146   \n","10        LocalGLMftt  53.200000  1187.006637        27430.0    0.237214   \n","\n","    loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0    0.254454             0.073631            0.073631  \n","1    0.241463             0.073631            0.073900  \n","2    0.241125             0.073631            0.073981  \n","3    0.241022             0.073631            0.074048  \n","4    0.238652             0.073906            0.074310  \n","5    0.238267             0.073774            0.074238  \n","6    0.238102             0.074019            0.074438  \n","7    0.239211             0.073825            0.074267  \n","8    0.239389             0.061140            0.061290  \n","9    0.238072             0.065975            0.066235  \n","10   0.238801             0.067904            0.068316  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Results Standard-Deviation:\n"]},{"data":{"text/html":["\n","  <div id=\"df-50a26011-4308-4f2c-8fbe-b117e52ac8f8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model</td>\n","      <td>0.000000</td>\n","      <td>0.002512</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>5.745950e-17</td>\n","      <td>2.872975e-17</td>\n","      <td>2.872975e-17</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GLM1</td>\n","      <td>0.000000</td>\n","      <td>0.473819</td>\n","      <td>0.0</td>\n","      <td>5.745950e-17</td>\n","      <td>5.745950e-17</td>\n","      <td>1.436488e-17</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GLM2</td>\n","      <td>0.000000</td>\n","      <td>0.970156</td>\n","      <td>0.0</td>\n","      <td>5.745950e-17</td>\n","      <td>2.872975e-17</td>\n","      <td>0.000000e+00</td>\n","      <td>1.436488e-17</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GLM3</td>\n","      <td>0.000000</td>\n","      <td>0.408252</td>\n","      <td>0.0</td>\n","      <td>2.872975e-17</td>\n","      <td>2.872975e-17</td>\n","      <td>0.000000e+00</td>\n","      <td>1.436488e-17</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FFN_OHE</td>\n","      <td>14.663853</td>\n","      <td>8.624492</td>\n","      <td>0.0</td>\n","      <td>3.255191e-04</td>\n","      <td>1.570462e-04</td>\n","      <td>1.223993e-03</td>\n","      <td>1.209107e-03</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>FNN_CAT_EMB</td>\n","      <td>21.661245</td>\n","      <td>13.907265</td>\n","      <td>0.0</td>\n","      <td>1.590947e-04</td>\n","      <td>1.514444e-04</td>\n","      <td>1.071399e-03</td>\n","      <td>1.088943e-03</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CANN</td>\n","      <td>53.898935</td>\n","      <td>33.162059</td>\n","      <td>0.0</td>\n","      <td>6.076588e-04</td>\n","      <td>3.253586e-04</td>\n","      <td>1.111365e-03</td>\n","      <td>1.103431e-03</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LocalGLMnet</td>\n","      <td>7.622023</td>\n","      <td>5.097405</td>\n","      <td>0.0</td>\n","      <td>3.340630e-04</td>\n","      <td>2.176521e-04</td>\n","      <td>8.787938e-04</td>\n","      <td>9.078453e-04</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>FT_transformer</td>\n","      <td>16.638452</td>\n","      <td>302.316624</td>\n","      <td>0.0</td>\n","      <td>8.982910e-04</td>\n","      <td>5.281384e-04</td>\n","      <td>1.459836e-03</td>\n","      <td>1.458034e-03</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>CAFTT</td>\n","      <td>14.185841</td>\n","      <td>220.449926</td>\n","      <td>0.0</td>\n","      <td>4.739992e-04</td>\n","      <td>1.743234e-04</td>\n","      <td>4.993066e-04</td>\n","      <td>4.707813e-04</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LocalGLMftt</td>\n","      <td>16.384662</td>\n","      <td>310.648783</td>\n","      <td>0.0</td>\n","      <td>5.933743e-04</td>\n","      <td>1.596498e-04</td>\n","      <td>9.643511e-04</td>\n","      <td>9.918441e-04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50a26011-4308-4f2c-8fbe-b117e52ac8f8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-50a26011-4308-4f2c-8fbe-b117e52ac8f8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-50a26011-4308-4f2c-8fbe-b117e52ac8f8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d9e9cd55-5577-46b6-9ab7-916d45c2253d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9e9cd55-5577-46b6-9ab7-916d45c2253d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d9e9cd55-5577-46b6-9ab7-916d45c2253d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                model     epochs    run_time  nr_parameters    loss_train  \\\n","0   homogeneous model   0.000000    0.002512            0.0  0.000000e+00   \n","1                GLM1   0.000000    0.473819            0.0  5.745950e-17   \n","2                GLM2   0.000000    0.970156            0.0  5.745950e-17   \n","3                GLM3   0.000000    0.408252            0.0  2.872975e-17   \n","4             FFN_OHE  14.663853    8.624492            0.0  3.255191e-04   \n","5         FNN_CAT_EMB  21.661245   13.907265            0.0  1.590947e-04   \n","6                CANN  53.898935   33.162059            0.0  6.076588e-04   \n","7         LocalGLMnet   7.622023    5.097405            0.0  3.340630e-04   \n","8      FT_transformer  16.638452  302.316624            0.0  8.982910e-04   \n","9               CAFTT  14.185841  220.449926            0.0  4.739992e-04   \n","10        LocalGLMftt  16.384662  310.648783            0.0  5.933743e-04   \n","\n","       loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0   5.745950e-17         2.872975e-17        2.872975e-17  \n","1   5.745950e-17         1.436488e-17        0.000000e+00  \n","2   2.872975e-17         0.000000e+00        1.436488e-17  \n","3   2.872975e-17         0.000000e+00        1.436488e-17  \n","4   1.570462e-04         1.223993e-03        1.209107e-03  \n","5   1.514444e-04         1.071399e-03        1.088943e-03  \n","6   3.253586e-04         1.111365e-03        1.103431e-03  \n","7   2.176521e-04         8.787938e-04        9.078453e-04  \n","8   5.281384e-04         1.459836e-03        1.458034e-03  \n","9   1.743234e-04         4.993066e-04        4.707813e-04  \n","10  1.596498e-04         9.643511e-04        9.918441e-04  "]},"metadata":{},"output_type":"display_data"}],"source":["print(\"Results Average:\")\n","display(calc_avg_df([\"homogeneous model\",\"GLM1\",\"GLM2\",\"GLM3\",\"FFN_OHE\",\"FNN_CAT_EMB\",\"CANN\",\"LocalGLMnet\",\"FT_transformer\",\"CAFTT\",\"LocalGLMftt\"]))\n","print(\"Results Standard-Deviation:\")\n","display(calc_std_df([\"homogeneous model\",\"GLM1\",\"GLM2\",\"GLM3\",\"FFN_OHE\",\"FNN_CAT_EMB\",\"CANN\",\"LocalGLMnet\",\"FT_transformer\",\"CAFTT\",\"LocalGLMftt\"]))"]},{"cell_type":"markdown","metadata":{"id":"4p-8uxNSo5_G"},"source":["# 5. Ensemble Models"]},{"cell_type":"markdown","metadata":{"id":"SNfQncwWET2i"},"source":["## 5.1 Ensembles FFN OHE:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30650,"status":"ok","timestamp":1699187434301,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"6vf9FbjVEaGh","outputId":"d0bb63a8-a967-4ece-e7f2-210dc479aea3"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","Model: 1\n","Model: 2\n","Model: 3\n","Model: 4\n","range(5, 10)\n","Model: 5\n","Model: 6\n","Model: 7\n","Model: 8\n","Model: 9\n","range(10, 15)\n","Model: 10\n","Model: 11\n","Model: 12\n","Model: 13\n","Model: 14\n"]}],"source":["# Create the dataframes needed for evaluation:\n","data_nn_ohe_learn, y_true_learn = create_ffn_ohe_data(bool_in_learn)\n","data_nn_ohe_test, y_true_test = create_ffn_ohe_data(bool_in_test)\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        print(f\"Model: {run_index}\")\n","        # Define FNN Model:\n","        # ----------------------\n","        # note we use here the function api instead of the model subclassing\n","        # to make the code more readable and easier to understand:\n","        # (for the transformer based models we will use model subclasses)\n","        def Create_Poisson_FFN_OHE(input_dim=42,mean_model_results=1):\n","            # set random seeds\n","            set_random_seeds(int(random_seeds[run_index]))\n","            # Build the network\n","            Input_Matrix_OHE = tf.keras.layers.Input(shape=(input_dim,), dtype='float32', name='Input_Matrix')\n","            Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","            hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(Input_Matrix_OHE)\n","            hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","            hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","            Result_FFN1 = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_FFN1',\n","                            weights=[np.zeros((10, 1)), np.array([np.log(mean_model_results)])],\n","                            trainable=True)(hidden3)\n","            Response = tf.keras.layers.Multiply(name='Result')([Result_FFN1, Input_Exposure])\n","            # Define and Return the model\n","            return tf.keras.models.Model(inputs=[Input_Matrix_OHE, Input_Exposure], outputs=[Response], name='Poisson_FFN_OHE')\n","\n","        # create the model:\n","        # ----------------------\n","        FFN_OHE = Create_Poisson_FFN_OHE(input_dim=40,mean_model_results=constant_model)\n","\n","        # load the saved model weights:\n","        # ----------------------\n","        FFN_OHE.load_weights(f'{storage_path}/saved_models/Poisson_FFN_OHE_{run_index}.weights.h5')\n","\n","\n","        # predict with the models:\n","        # ----------------------\n","        y_pred[\"train\"][f\"FFN_OHE_{run_index}\"] = np.array([x for [x] in FFN_OHE.predict(data_nn_ohe_learn, verbose=0,\n","                                                                            batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","        y_pred[\"test\"][f\"FFN_OHE_{run_index}\"] = np.array([x for [x] in FFN_OHE.predict(data_nn_ohe_test, verbose=0,\n","                                                                            batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","\n","\n","    # evaluate the models:\n","    # ----------------------\n","    # store the results in the results class:\n","    y_pred[\"train\"][f\"Ensemble_FFN_OHE_{index}\"] = np.mean([y_pred[\"train\"][f\"FFN_OHE_{i}\"] for i in ensemble_range], axis=0)\n","    y_pred[\"test\"][f\"Ensemble_FFN_OHE_{index}\"] = np.mean([y_pred[\"test\"][f\"FFN_OHE_{i}\"] for i in ensemble_range], axis=0)\n","\n","    Ensemble_FFN_OHE_results = Results(model=f\"Ensemble_FFN_OHE (run: {index})\",\n","                                epochs=0,\n","                                run_time=0,\n","                                nr_parameters=0,\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"Ensemble_FFN_OHE_{index}\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"Ensemble_FFN_OHE_{index}\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"Ensemble_FFN_OHE_{index}\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"Ensemble_FFN_OHE_{index}\"].sum()/exposure[\"test\"].sum())\n","\n","    # # store the results in the result-dataframe:\n","    store_results_in_df(Ensemble_FFN_OHE_results)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_ohe_learn, data_nn_ohe_test"]},{"cell_type":"markdown","metadata":{"id":"pzrEtDM4ETq4"},"source":["## 5.2 Ensembles FFN CAT EMB:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33551,"status":"ok","timestamp":1699187467838,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"q2GFYkLgEeoG","outputId":"973a83be-f947-4620-bec9-f6d609f1a0ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","Model: 1\n","Model: 2\n","Model: 3\n","Model: 4\n","range(5, 10)\n","Model: 5\n","Model: 6\n","Model: 7\n","Model: 8\n","Model: 9\n","range(10, 15)\n","Model: 10\n","Model: 11\n","Model: 12\n","Model: 13\n","Model: 14\n"]}],"source":["# Create the dataframes needed for evaluation:\n","data_nn_emb_learn, y_true_learn = create_ffn_cat_emb_data(bool_in_learn)\n","data_nn_emb_test, y_true_test = create_ffn_cat_emb_data(bool_in_test)\n","\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        # Define FNN with Cat. Embedding Model:\n","        # ----------------------\n","        # note we use here the function api instead of the model subclassing\n","        # to make the code more readable and easier to understand:\n","        # (for the transformer based models we will use model subclasses)\n","        print(f\"Model: {run_index}\")\n","        def Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=1,mean_model_results=1):\n","            # set random seeds\n","            set_random_seeds(int(random_seeds[run_index]))\n","\n","            Input_Matrix_Num = tf.keras.layers.Input(shape=(input_nr_dim,), dtype='float32', name='Input_Matrix_Num')\n","            Input_VehBrand = tf.keras.layers.Input(shape=(1,), name='Input_VehBrand')\n","            Input_Region = tf.keras.layers.Input(shape=(1,), name='Input_Region')\n","            Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","\n","            All_Inputs = [Input_Matrix_Num,Input_VehBrand,Input_Region,Input_Exposure]\n","\n","            Emb_VehBrand = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"VehBrand\"].keys()),output_dim=emb_dim,\n","                                    embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05 ),\n","                                    name=\"Embedding_VehBrand\")(Input_VehBrand)\n","            Emb_Region = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"Region\"].keys()),output_dim=emb_dim,\n","                                    embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05),\n","                                name=\"Embedding_Region\")(Input_Region)\n","\n","            Reshaped_Emb_VehBrand = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_VehBrand\")(Emb_VehBrand)\n","            Reshaped_Emb_Region = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_Region\")(Emb_Region)\n","\n","            concatenation_layer = tf.keras.layers.Concatenate(name=\"concatenation_layer\")([Input_Matrix_Num,Reshaped_Emb_VehBrand,Reshaped_Emb_Region])\n","\n","            # Build the network\n","            hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(concatenation_layer)\n","            hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","            hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","            Result_FFN1 = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_FFN1',\n","                            weights=[np.zeros((10, 1)), np.array([np.log(mean_model_results)])],\n","                            trainable=True)(hidden3)\n","\n","            Response = tf.keras.layers.Multiply(name='Result')([Result_FFN1, Input_Exposure])\n","\n","            # Define the model\n","            return tf.keras.models.Model(inputs=All_Inputs, outputs=[Response], name='Poisson_CAT_EMB')\n","\n","        # create the model:\n","        # ----------------------\n","        emb_dim=2\n","        FNN_CAT_EMB = Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=emb_dim,mean_model_results=constant_model)\n","\n","        # load the saved model weights:\n","        # ----------------------\n","        FNN_CAT_EMB.load_weights(f'{storage_path}/saved_models/Poisson_FNN_CAT_EMB_{run_index}.weights.h5')\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"FNN_CAT_EMB_{run_index}\"] = np.array([x for [x] in FNN_CAT_EMB.predict(data_nn_emb_learn, verbose=0,\n","                                                                            batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","        y_pred[\"test\"][f\"FNN_CAT_EMB_{run_index}\"] = np.array([x for [x] in FNN_CAT_EMB.predict(data_nn_emb_test, verbose=0,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","\n","\n","    # evaluate the models:\n","    # ----------------------\n","    # store the results in the results class:\n","    y_pred[\"train\"][f\"Ensemble_FNN_CAT_EMB_{index}\"] = np.mean([y_pred[\"train\"][f\"FNN_CAT_EMB_{i}\"] for i in ensemble_range], axis=0)\n","    y_pred[\"test\"][f\"Ensemble_FNN_CAT_EMB_{index}\"] = np.mean([y_pred[\"test\"][f\"FNN_CAT_EMB_{i}\"] for i in ensemble_range], axis=0)\n","\n","    Ensemble_FNN_CAT_EMB_results = Results(model=f\"Ensemble_FNN_CAT_EMB (run: {index})\",\n","                                epochs=0,\n","                                run_time=0,\n","                                nr_parameters=0,\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"Ensemble_FNN_CAT_EMB_{index}\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"Ensemble_FNN_CAT_EMB_{index}\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"Ensemble_FNN_CAT_EMB_{index}\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"Ensemble_FNN_CAT_EMB_{index}\"].sum()/exposure[\"test\"].sum())\n","\n","    # # store the results in the result-dataframe:\n","    store_results_in_df(Ensemble_FNN_CAT_EMB_results)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_emb_learn, data_nn_emb_test"]},{"cell_type":"markdown","metadata":{"id":"hjb29bn-ETiP"},"source":["## 5.3 Ensembles CANN:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33976,"status":"ok","timestamp":1699187501800,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"cCtAUB-6Ej9M","outputId":"48b6dd50-7a90-43a7-bf10-bef394346140"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","Model: 1\n","Model: 2\n","Model: 3\n","Model: 4\n","range(5, 10)\n","Model: 5\n","Model: 6\n","Model: 7\n","Model: 8\n","Model: 9\n","range(10, 15)\n","Model: 10\n","Model: 11\n","Model: 12\n","Model: 13\n","Model: 14\n"]}],"source":["# create the new exposure times GLM3_pred column for CANN models.\n","df_freq_prep_nn[\"Exposure_x_GLM3_pred\"] = list(poisson_glm3.predict(X_glm3)*df_freq_prep_nn[\"Exposure\"])\n","\n","# Create the dataframes needed for evaluation:\n","data_nn_emb_learn, y_true_learn = create_ffn_cat_emb_data(bool_in_learn, exposure_name = \"Exposure_x_GLM3_pred\")\n","data_nn_emb_test, y_true_test = create_ffn_cat_emb_data(bool_in_test, exposure_name = \"Exposure_x_GLM3_pred\")\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        # Define FNN with Cat. Embedding Model:\n","        # ----------------------\n","        # note we use here the function api instead of the model subclassing\n","        # to make the code more readable and easier to understand:\n","        # (for the transformer based models we will use model subclasses)\n","        print(f\"Model: {run_index}\")\n","        def Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=1,mean_model_results=1):\n","            # set random seeds\n","            set_random_seeds(int(random_seeds[run_index]))\n","\n","            Input_Matrix_Num = tf.keras.layers.Input(shape=(input_nr_dim,), dtype='float32', name='Input_Matrix_Num')\n","            Input_VehBrand = tf.keras.layers.Input(shape=(1,), name='Input_VehBrand')\n","            Input_Region = tf.keras.layers.Input(shape=(1,), name='Input_Region')\n","            Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","\n","            All_Inputs = [Input_Matrix_Num,Input_VehBrand,Input_Region,Input_Exposure]\n","\n","            Emb_VehBrand = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"VehBrand\"].keys()),output_dim=emb_dim,\n","                                    embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05 ),\n","                                    name=\"Embedding_VehBrand\")(Input_VehBrand)\n","            Emb_Region = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"Region\"].keys()),output_dim=emb_dim,\n","                                    embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05),\n","                                name=\"Embedding_Region\")(Input_Region)\n","\n","            Reshaped_Emb_VehBrand = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_VehBrand\")(Emb_VehBrand)\n","            Reshaped_Emb_Region = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_Region\")(Emb_Region)\n","\n","            concatenation_layer = tf.keras.layers.Concatenate(name=\"concatenation_layer\")([Input_Matrix_Num,Reshaped_Emb_VehBrand,Reshaped_Emb_Region])\n","\n","            # Build the network\n","            hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(concatenation_layer)\n","            hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","            hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","            Result_FFN1 = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_FFN1',\n","                            weights=[np.zeros((10, 1)), np.array([0])],\n","                            trainable=True)(hidden3)\n","\n","            Response = tf.keras.layers.Multiply(name='Result')([Result_FFN1, Input_Exposure])\n","\n","            # Define the model\n","            return tf.keras.models.Model(inputs=All_Inputs, outputs=[Response], name='Poisson_CAT_EMB')\n","\n","        # create the model:\n","        # ----------------------\n","        emb_dim=2\n","        CANN = Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=emb_dim,mean_model_results=constant_model)\n","\n","        # load the saved model weights:\n","        # ----------------------\n","        CANN.load_weights(f'{storage_path}/saved_models/Poisson_CANN_{run_index}.weights.h5')\n","\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"CANN_{run_index}\"] = np.array([x for [x] in CANN.predict(data_nn_emb_learn, verbose=0,\n","                                                                            batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","        y_pred[\"test\"][f\"CANN_{run_index}\"] = np.array([x for [x] in CANN.predict(data_nn_emb_test, verbose=0,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","\n","\n","    # evaluate the models:\n","    # ----------------------\n","    # store the results in the results class:\n","    y_pred[\"train\"][f\"Ensemble_CANN_{index}\"] = np.mean([y_pred[\"train\"][f\"CANN_{i}\"] for i in ensemble_range], axis=0)\n","    y_pred[\"test\"][f\"Ensemble_CANN_{index}\"] = np.mean([y_pred[\"test\"][f\"CANN_{i}\"] for i in ensemble_range], axis=0)\n","\n","    Ensemble_CANN_results = Results(model=f\"Ensemble_CANN (run: {index})\",\n","                                epochs=0,\n","                                run_time=0,\n","                                nr_parameters=0,\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"Ensemble_CANN_{index}\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"Ensemble_CANN_{index}\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"Ensemble_CANN_{index}\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"Ensemble_CANN_{index}\"].sum()/exposure[\"test\"].sum())\n","\n","    # # store the results in the result-dataframe:\n","    store_results_in_df(Ensemble_CANN_results)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_emb_learn, data_nn_emb_test\n"]},{"cell_type":"markdown","metadata":{"id":"q-dZzIY9ETVN"},"source":["## 5.4 Ensembles LocalGLMnet:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75242,"status":"ok","timestamp":1699187577040,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"zFXmRmpjEn4o","outputId":"93774ace-0ea3-4803-a010-565c0e9f2227"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","Model: 1\n","Model: 2\n","Model: 3\n","Model: 4\n","range(5, 10)\n","Model: 5\n","Model: 6\n","Model: 7\n","Model: 8\n","Model: 9\n","range(10, 15)\n","Model: 10\n","Model: 11\n","Model: 12\n","Model: 13\n","Model: 14\n"]}],"source":["# Create the dataframes needed for evaluation:\n","data_nn_ohe_learn, y_true_learn = create_ffn_ohe_data(bool_in_learn)\n","data_nn_ohe_test, y_true_test = create_ffn_ohe_data(bool_in_test)\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        print(f\"Model: {run_index}\")\n","        # Define FNN with Cat. Embedding Model:\n","        # ----------------------\n","        # note we use here the function api instead of the model subclassing\n","        # to make the code more readable and easier to understand:\n","        # (for the transformer based models we will use model subclasses)\n","\n","        # create dummy glm for initial weights\n","        # ----------------------\n","        poisson_glm_dummy = PoissonRegressor(alpha = 0,max_iter=1000) # scikit-learn.org: alpha = 0 is equivalent to unpenalized GLMs\n","        poisson_glm_dummy.fit(data_nn_ohe_learn[0],y_true_learn/data_nn_ohe_learn[1],sample_weight=data_nn_ohe_learn[1]) # note: data_nn_ohe_learn = [X_ohe,exposure]\n","\n","        # Define LocalGLMnet:\n","        # ----------------------\n","        def Create_Poisson_LocalGLMnet(input_dim=40,initial_glm_bias=1, initial_glm_betas=None):\n","            # set random seeds\n","            set_random_seeds(int(random_seeds[run_index]))\n","            Input_Matrix_OHE = tf.keras.layers.Input(shape=(input_dim,), dtype='float32', name='Input_Matrix')\n","            Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","            # Build the network\n","            hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(Input_Matrix_OHE)\n","            hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","            hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","            Attention = tf.keras.layers.Dense(units=input_dim, activation='linear', name='attention',\n","                            weights=[np.zeros((10, input_dim)), initial_glm_betas])(hidden3)\n","            # note that the weights are set to 0 and the bias is set to the initial glm betas\n","            # create a layer that calculates the dot product between the attention weights (Attention) and the input matrix Input_Matrix_OHE:\n","            # (Attention has the same dimension as the input matrix Input_Matrix_OHE):\n","            weighted_input = tf.keras.layers.Multiply(name='feature_contributions')([Attention, Input_Matrix_OHE])\n","            scalar_product = tf.keras.layers.Dense(units=1, activation='linear', name='scalar_product',\n","                                weights=[np.ones((input_dim, 1)), np.array([0])],\n","                                trainable=False)(weighted_input)\n","            # Note that we actually don't want to make the following weights trainable,\n","            # but to get the bias to be trainable we need to do so. see comment in Book Wüthrich & Merz (2023) page 500\n","            Result_LocalGLMnet_without_Exposure = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_LocalGLMnet_without_Exposure',\n","                            weights=[np.ones((1, 1)), np.array([initial_glm_bias])],\n","                            trainable=True)(scalar_product)\n","            Response = tf.keras.layers.Multiply(name='Result')([Result_LocalGLMnet_without_Exposure, Input_Exposure])\n","            return tf.keras.models.Model(inputs=[Input_Matrix_OHE, Input_Exposure], outputs=[Response], name='Poisson_LocalGLMnet')\n","\n","        # create the model:\n","        # ----------------------\n","        LocalGLMnet = Create_Poisson_LocalGLMnet(input_dim=40,initial_glm_bias=poisson_glm_dummy.intercept_,initial_glm_betas=poisson_glm_dummy.coef_)\n","\n","        # load the saved model weights:\n","        # ----------------------\n","        LocalGLMnet.load_weights(f'{storage_path}/saved_models/Poisson_LocalGLMnet_{run_index}.weights.h5')\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"LocalGLMnet_{run_index}\"] = np.array([x for [x] in LocalGLMnet.predict(data_nn_ohe_learn, verbose=0,\n","                                                                            batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","        y_pred[\"test\"][f\"LocalGLMnet_{run_index}\"] = np.array([x for [x] in LocalGLMnet.predict(data_nn_ohe_test, verbose=0,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","\n","\n","    # evaluate the models:\n","    # ----------------------\n","    # store the results in the results class:\n","    y_pred[\"train\"][f\"Ensemble_LocalGLMnet_{index}\"] = np.mean([y_pred[\"train\"][f\"LocalGLMnet_{i}\"] for i in ensemble_range], axis=0)\n","    y_pred[\"test\"][f\"Ensemble_LocalGLMnet_{index}\"] = np.mean([y_pred[\"test\"][f\"LocalGLMnet_{i}\"] for i in ensemble_range], axis=0)\n","\n","    Ensemble_LocalGLMnet_results = Results(model=f\"Ensemble_LocalGLMnet (run: {index})\",\n","                                epochs=0,\n","                                run_time=0,\n","                                nr_parameters=0,\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"Ensemble_LocalGLMnet_{index}\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"Ensemble_LocalGLMnet_{index}\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"Ensemble_LocalGLMnet_{index}\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"Ensemble_LocalGLMnet_{index}\"].sum()/exposure[\"test\"].sum())\n","\n","    # # store the results in the result-dataframe:\n","    store_results_in_df(Ensemble_LocalGLMnet_results)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_ohe_learn, data_nn_ohe_test\n"]},{"cell_type":"markdown","metadata":{"id":"0JaUP3UbETNo"},"source":["## 5.5 Ensembles FT-Transformer:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216565,"status":"ok","timestamp":1699187793589,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"1_u5kCjzExox","outputId":"d8f557d4-ccef-4943-8810-8112fac97a5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 1\n","Model: 2\n","Model: 3\n","Model: 4\n","range(5, 10)\n","Model: 5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 6\n","Model: 7\n","Model: 8\n","Model: 9\n","range(10, 15)\n","Model: 10\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 11\n","Model: 12\n","Model: 13\n","Model: 14\n"]}],"source":["# Create the dataframes needed for evaluation:\n","# --------------------\n","# NOTE: in the 2021 Gorishniy paper the batch size is different for the different Datasets\n","# but is not hyperparameter tuned. Bigger datasets they used a batch size of 1024 and\n","# for smaller datasets a batch size of (256/512).\n","batch_size = 1024\n","learn_data = df_to_tensor(df_freq_prep_nn[bool_in_learn], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","test_data = df_to_tensor(df_freq_prep_nn[bool_in_test], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","# NOTE we use at first just a fraction of the data to test the code:\n","learn_train_dummy_data = df_to_tensor(df_freq_prep_nn[bool_in_learn_train_dummy], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size,\n","                                      dummy_data_for_build=True)\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        print(f\"Model: {run_index}\")\n","        # Define FT-Transformer Models:\n","        # ----------------------\n","        # NOTE: we use here tensorflow/keras model subclasses (not the functional or sequential api)\n","        # NOTE: we use here instead of the .fit function a costum training loop\n","\n","        # create the model:\n","        # ----------------------\n","        set_random_seeds(int(random_seeds[run_index]))\n","\n","        FT_transformer = EnhActuar.Feature_Tokenizer_Transformer(\n","                emb_dim = 32, # NOTE: In the default setting for the 2021 Gorishniy paper they used emb_dim = 192 (but the parameter size would here go trough the roof, so we use something smaller)\n","                nr_features = nr_col,\n","                cat_features = cat_col,\n","                cat_vocabulary = cat_vocabulary,\n","                count_transformer_blocks = 3,\n","                attention_n_heads = 8,\n","                attention_dropout = 0.2,\n","                ffn_d_hidden = None, # NOTE: change to None if ReGLU should be used -> None uses default value (4/3*emb_dim), they write that they used 2*emb_dim if not ReGLU.\n","                ffn_activation_ReGLU = True, # NOTE: set True if ReGLU should be used\n","                ffn_dropout = 0.1,\n","                prenormalization = True,\n","                output_dim = 1,\n","                last_activation = 'exponential',\n","                exposure_name = \"Exposure\",\n","                seed_nr = int(random_seeds[run_index])\n","        )\n","\n","        FT_transformer.predict(learn_train_dummy_data,verbose=0,batch_size=100000)\n","\n","        # load the best saved model and epochs_and_time from the pickle file:\n","        # ----------------------\n","        # FT_transformer = keras.models.load_model(save_path +'/Poisson_FT_transformer')\n","        FT_transformer.load_weights(f'{storage_path}/saved_models/Poisson_FT_transformer_{run_index}.weights.h5')\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"FT_transformer_{run_index}\"] = np.array([x for [x] in FT_transformer.predict(learn_data,verbose=0,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","        y_pred[\"test\"][f\"FT_transformer_{run_index}\"] = np.array([x for [x] in FT_transformer.predict(test_data,verbose=0,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","\n","\n","    # evaluate the models:\n","    # ----------------------\n","    # store the results in the results class:\n","    y_pred[\"train\"][f\"Ensemble_FT_transformer_{index}\"] = np.mean([y_pred[\"train\"][f\"FT_transformer_{i}\"] for i in ensemble_range], axis=0)\n","    y_pred[\"test\"][f\"Ensemble_FT_transformer_{index}\"] = np.mean([y_pred[\"test\"][f\"FT_transformer_{i}\"] for i in ensemble_range], axis=0)\n","\n","    Ensemble_FT_transformer_results = Results(model=f\"Ensemble_FT_transformer (run: {index})\",\n","                                epochs=0,\n","                                run_time=0,\n","                                nr_parameters=0,\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"Ensemble_FT_transformer_{index}\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"Ensemble_FT_transformer_{index}\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"Ensemble_FT_transformer_{index}\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"Ensemble_FT_transformer_{index}\"].sum()/exposure[\"test\"].sum())\n","\n","    # # store the results in the result-dataframe:\n","    store_results_in_df(Ensemble_FT_transformer_results)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del learn_data, test_data"]},{"cell_type":"markdown","metadata":{"id":"5RLeTLEKETH_"},"source":["## 5.6 Ensembles CAFTT:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209312,"status":"ok","timestamp":1699188498738,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"ZEJ5_BePE-b2","outputId":"f1b4bdb8-7271-49ac-e0b1-ab1cb96c33ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 12ms/step\n","Model: 1\n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 12ms/step\n","Model: 2\n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 3\n","596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 4\n","596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","range(5, 10)\n","Model: 5\n","  1/596 [..............................] - ETA: 15s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 6\n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 7\n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 8\n","596/596 [==============================] - 9s 15ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 9\n","596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","range(10, 15)\n","Model: 10\n","  4/596 [..............................] - ETA: 10s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 11\n","596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 12ms/step\n","Model: 12\n","596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 13\n","596/596 [==============================] - 9s 15ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 14\n","596/596 [==============================] - 9s 15ms/step\n","67/67 [==============================] - 1s 13ms/step\n"]}],"source":["# create the new exposure times GLM3_pred column for CANN models.\n","df_freq_prep_nn[\"Exposure_x_GLM3_pred\"] = list(poisson_glm3.predict(X_glm3)*df_freq_prep_nn[\"Exposure\"])\n","\n","# Create the dataframes needed for evaluation:\n","# --------------------\n","# NOTE: in the 2021 Gorishniy et al paper the batch size is different for the different Datasets\n","# but is not hyperparameter tuned. Bigger datasets they used a batch size of 1024 and\n","# for smaller datasets a batch size of (256/512).\n","batch_size = 1024\n","learn_data = df_to_tensor(df_freq_prep_nn[bool_in_learn], feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size)\n","test_data = df_to_tensor(df_freq_prep_nn[bool_in_test], feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","# NOTE we use at first just a fraction of the data to test the code:\n","learn_train_dummy_data = df_to_tensor(df_freq_prep_nn[bool_in_learn_train_dummy], feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size,\n","                                      dummy_data_for_build=True)\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        print(f\"Model: {run_index}\")\n","        # Define FT-Transformer Models:\n","        # ----------------------\n","        # NOTE: we use here tensorflow/keras model subclasses (not the functional or sequential api)\n","        # NOTE: we use here instead of the .fit function a costum training loop\n","\n","        # create the model:\n","        # ----------------------\n","        set_random_seeds(int(random_seeds[run_index]))\n","\n","        FT_transformer = EnhActuar.Feature_Tokenizer_Transformer(\n","                emb_dim = 32, # NOTE: In the default setting for the 2021 Gorishniy paper they used emb_dim = 192 (but the parameter size would here go trough the roof, so we use something smaller)\n","                nr_features = nr_col,\n","                cat_features = cat_col,\n","                cat_vocabulary = cat_vocabulary,\n","                count_transformer_blocks = 3,\n","                attention_n_heads = 8,\n","                attention_dropout = 0.2,\n","                ffn_d_hidden = None, # NOTE: change to None if ReGLU should be used -> None uses default value (4/3*emb_dim), they write that they used 2*emb_dim if not ReGLU.\n","                ffn_activation_ReGLU = True, # NOTE: set True if ReGLU should be used\n","                ffn_dropout = 0.1,\n","                prenormalization = True,\n","                output_dim = 1,\n","                last_activation = 'exponential',\n","                exposure_name = \"Exposure_x_GLM3_pred\",\n","                last_layer_initial_weights = \"zeros\",\n","                last_layer_initial_bias = \"zeros\",\n","                seed_nr = int(random_seeds[run_index])\n","        )\n","\n","        FT_transformer.predict(learn_train_dummy_data,verbose=0,batch_size=100000)\n","\n","        # load the best saved model and epochs_and_time from the pickle file:\n","        # ----------------------\n","        FT_transformer.load_weights(f'{storage_path}/saved_models/Poisson_CAFTT_{run_index}.weights.h5')\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"CAFTT_{run_index}\"] = np.array([x for [x] in FT_transformer.predict(learn_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","        y_pred[\"test\"][f\"CAFTT_{run_index}\"] = np.array([x for [x] in FT_transformer.predict(test_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","\n","    # evaluate the models:\n","    # ----------------------\n","    # store the results in the results class:\n","    y_pred[\"train\"][f\"Ensemble_CAFTT_{index}\"] = np.mean([y_pred[\"train\"][f\"CAFTT_{i}\"] for i in ensemble_range], axis=0)\n","    y_pred[\"test\"][f\"Ensemble_CAFTT_{index}\"] = np.mean([y_pred[\"test\"][f\"CAFTT_{i}\"] for i in ensemble_range], axis=0)\n","\n","    Ensemble_CAFTT_results = Results(model=f\"Ensemble_CAFTT (run: {index})\",\n","                                epochs=0,\n","                                run_time=0,\n","                                nr_parameters=0,\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"Ensemble_CAFTT_{index}\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"Ensemble_CAFTT_{index}\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"Ensemble_CAFTT_{index}\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"Ensemble_CAFTT_{index}\"].sum()/exposure[\"test\"].sum())\n","\n","    # # store the results in the result-dataframe:\n","    store_results_in_df(Ensemble_CAFTT_results)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del learn_data, test_data"]},{"cell_type":"markdown","metadata":{"id":"cLZvckKwEvXB"},"source":["## 5.7 Ensembles LocalGLMftt:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253036,"status":"ok","timestamp":1699188759467,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"EsCywe7LoxRC","outputId":"f624048d-5040-4975-d486-895e9bec26a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","  1/596 [..............................] - ETA: 21s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 11s 18ms/step\n","67/67 [==============================] - 1s 21ms/step\n","Model: 1\n","596/596 [==============================] - 12s 20ms/step\n","67/67 [==============================] - 2s 36ms/step\n","Model: 2\n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 3\n","596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 15ms/step\n","Model: 4\n","596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 17ms/step\n","range(5, 10)\n","Model: 5\n","  1/596 [..............................] - ETA: 14s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 11s 18ms/step\n","67/67 [==============================] - 1s 15ms/step\n","Model: 6\n","596/596 [==============================] - 9s 15ms/step\n","67/67 [==============================] - 1s 15ms/step\n","Model: 7\n","596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 8\n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 9\n","596/596 [==============================] - 9s 15ms/step\n","67/67 [==============================] - 1s 16ms/step\n","range(10, 15)\n","Model: 10\n","  1/596 [..............................] - ETA: 13s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 15ms/step\n","Model: 11\n","596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 12\n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 13\n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 14\n","596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 15ms/step\n"]}],"source":["# Create the dataframes for creation of the glm-ohe-start model:\n","# --------------------\n","data_nn_ohe_learn, y_true_learn = create_ffn_ohe_data(bool_in_learn)\n","\n","# create dummy glm for initial weights\n","# ----------------------\n","poisson_glm_dummy = PoissonRegressor(alpha = 0,max_iter=1000) # scikit-learn.org: alpha = 0 is equivalent to unpenalized GLMs\n","poisson_glm_dummy.fit(data_nn_ohe_learn[0],y_true_learn/data_nn_ohe_learn[1],sample_weight=data_nn_ohe_learn[1]) # note: data_nn_ohe_learn = [X_ohe,exposure]\n","# get the betas from the glm:\n","glm_nr_col_betas = poisson_glm_dummy.coef_[:len(nr_col)]\n","current_beta_index = len(nr_col)\n","glm_cat_col_betas = {}\n","for c in cat_vocabulary.keys():\n","    glm_cat_col_betas[c] = poisson_glm_dummy.coef_[current_beta_index:current_beta_index+len(cat_vocabulary[c])]\n","    current_beta_index += len(cat_vocabulary[c])\n","glm_intercept = poisson_glm_dummy.intercept_\n","\n","\n","# Create the dataframes needed for evaluation:\n","# --------------------\n","# NOTE: in the 2021 Gorishniy et al paper the batch size is different for the different Datasets\n","# but is not hyperparameter tuned. Bigger datasets they used a batch size of 1024 and\n","# for smaller datasets a batch size of (256/512).\n","batch_size = 1024\n","learn_data = df_to_tensor(df_freq_prep_nn[bool_in_learn], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","test_data = df_to_tensor(df_freq_prep_nn[bool_in_test], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","learn_train_dummy_data = df_to_tensor(df_freq_prep_nn[bool_in_learn_train_dummy], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size,\n","                                      dummy_data_for_build=True)\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        print(f\"Model: {run_index}\")\n","        # Define FT-Transformer Models:\n","        # ----------------------\n","        # NOTE: we use here tensorflow/keras model subclasses (not the functional or sequential api)\n","        # NOTE: we use here instead of the .fit function a costum training loop\n","\n","        # create the model:\n","        # ----------------------\n","        set_random_seeds(int(random_seeds[run_index]))\n","        LocalGLMftt = EnhActuar.LocalGLM_FT_Transformer(\n","                emb_dim = 32, # NOTE: In the default setting for the 2021 Gorishniy paper they used emb_dim = 192 (but the parameter size would here go trough the roof, so we use something smaller)\n","                nr_features = nr_col,\n","                cat_features = cat_col,\n","                cat_vocabulary = cat_vocabulary,\n","                count_transformer_blocks = 3,\n","                attention_n_heads = 8,\n","                attention_dropout = 0.2,\n","                ffn_d_hidden = None, # NOTE: change to None if ReGLU should be used -> None uses default value (4/3*emb_dim), they write that they used 2*emb_dim if not ReGLU.\n","                ffn_activation_ReGLU = True, # NOTE: set True if ReGLU should be used\n","                ffn_dropout = 0.1,\n","                prenormalization = True,\n","                output_dim = 1,\n","                last_activation = 'exponential',\n","                exposure_name = \"Exposure\",\n","                last_layer_initial_weights = \"zeros\",\n","                last_layer_initial_bias = \"ones\",\n","                init_glm_cat_col_weights = glm_cat_col_betas,\n","                init_glm_nr_col_weights = glm_nr_col_betas,\n","                init_glm_bias = glm_intercept,\n","                trainable_glm_emb = False,\n","                seed_nr = int(random_seeds[run_index])\n","        )\n","\n","        LocalGLMftt.predict(learn_train_dummy_data,verbose=0,batch_size=100000)\n","\n","        # load the best saved model and epochs_and_time from the pickle file:\n","        # ----------------------\n","        LocalGLMftt.load_weights(f'{storage_path}/saved_models/Poisson_LocalGLMftt_{run_index}.weights.h5')\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"LocalGLMftt_{run_index}\"] = np.array([x for [x] in LocalGLMftt.predict(learn_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","        y_pred[\"test\"][f\"LocalGLMftt_{run_index}\"] = np.array([x for [x] in LocalGLMftt.predict(test_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","\n","\n","    # evaluate the models:\n","    # ----------------------\n","    # store the results in the results class:\n","    y_pred[\"train\"][f\"Ensemble_LocalGLMftt_{index}\"] = np.mean([y_pred[\"train\"][f\"LocalGLMftt_{i}\"] for i in ensemble_range], axis=0)\n","    y_pred[\"test\"][f\"Ensemble_LocalGLMftt_{index}\"] = np.mean([y_pred[\"test\"][f\"LocalGLMftt_{i}\"] for i in ensemble_range], axis=0)\n","\n","    Ensemble_LocalGLMftt_results = Results(model=f\"Ensemble_LocalGLMftt (run: {index})\",\n","                                epochs=0,\n","                                run_time=0,\n","                                nr_parameters=0,\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"Ensemble_LocalGLMftt_{index}\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"Ensemble_LocalGLMftt_{index}\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"Ensemble_LocalGLMftt_{index}\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"Ensemble_LocalGLMftt_{index}\"].sum()/exposure[\"test\"].sum())\n","\n","    # # store the results in the result-dataframe:\n","    store_results_in_df(Ensemble_LocalGLMftt_results)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del learn_data, test_data\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WA78lFmDh5sA"},"outputs":[],"source":["# # save the results:\n","# with open(f'{storage_path}/Data/df_results.pickle', 'wb') as handle:\n","#     pickle.dump(df_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# load the results:\n","with open(f'{storage_path}/Data/df_results.pickle', 'rb') as handle:\n","    df_results = pickle.load(handle)\n"]},{"cell_type":"markdown","metadata":{"id":"RU2gxzJ4Xmg5"},"source":[]},{"cell_type":"markdown","metadata":{"id":"7-4s8jShX48M"},"source":["# 6. Rebase Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Ni9IbOoaxJc"},"outputs":[],"source":["def create_single_rebase_results(model_name,run_index):\n","    rebase_factor = np.mean(y_true[\"train\"])/np.mean(y_pred[\"train\"][f\"{model_name}_{run_index}\"])\n","\n","    y_pred[\"train\"][f\"Rebase_{model_name}_{run_index}\"] = y_pred[\"train\"][f\"{model_name}_{run_index}\"] * rebase_factor\n","    y_pred[\"test\"][f\"Rebase_{model_name}_{run_index}\"] = y_pred[\"test\"][f\"{model_name}_{run_index}\"] * rebase_factor\n","\n","    Rebase_results = Results(model=f\"Rebase_{model_name} (run: {run_index})\",\n","                                epochs=0,\n","                                run_time=0,\n","                                nr_parameters=0,\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"Rebase_{model_name}_{run_index}\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"Rebase_{model_name}_{run_index}\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"Rebase_{model_name}_{run_index}\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"Rebase_{model_name}_{run_index}\"].sum()/exposure[\"test\"].sum())\n","\n","    #  store the results in the result-dataframe:\n","    store_results_in_df(Rebase_results)\n","\n","def create_ensemble_results(model_name,index):\n","    # evaluate the models:\n","    # ----------------------\n","    # store the results in the results class:\n","    y_pred[\"train\"][f\"Ensemble_{model_name}_{index}\"] = np.mean([y_pred[\"train\"][f\"{model_name}_{i}\"] for i in ensemble_range], axis=0)\n","    y_pred[\"test\"][f\"Ensemble_{model_name}_{index}\"] = np.mean([y_pred[\"test\"][f\"{model_name}_{i}\"] for i in ensemble_range], axis=0)\n","\n","    Ensemble_results = Results(model=f\"Ensemble_{model_name} (run: {index})\",\n","                                epochs=0,\n","                                run_time=0,\n","                                nr_parameters=0,\n","                                poisson_deviance_loss_train=poisson_deviance_loss(y_true[\"train\"], y_pred[\"train\"][f\"Ensemble_{model_name}_{index}\"]),\n","                                poisson_deviance_loss_test=poisson_deviance_loss(y_true[\"test\"], y_pred[\"test\"][f\"Ensemble_{model_name}_{index}\"]),\n","                                pred_avg_freq_train=y_pred[\"train\"][f\"Ensemble_{model_name}_{index}\"].sum()/exposure[\"train\"].sum(),\n","                                pred_avg_freq_test=y_pred[\"test\"][f\"Ensemble_{model_name}_{index}\"].sum()/exposure[\"test\"].sum())\n","\n","    # # store the results in the result-dataframe:\n","    store_results_in_df(Ensemble_results)"]},{"cell_type":"markdown","metadata":{"id":"YPjrW250X48N"},"source":["## 6.1 Rebase FFN OHE:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31911,"status":"ok","timestamp":1699254790987,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"03h2dyMeX48N","outputId":"619bdb00-9774-410c-fee3-5edbba4b53cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","Model: 1\n","Model: 2\n","Model: 3\n","Model: 4\n","range(5, 10)\n","Model: 5\n","Model: 6\n","Model: 7\n","Model: 8\n","Model: 9\n","range(10, 15)\n","Model: 10\n","Model: 11\n","Model: 12\n","Model: 13\n","Model: 14\n"]}],"source":["# Create the dataframes needed for evaluation:\n","data_nn_ohe_learn, y_true_learn = create_ffn_ohe_data(bool_in_learn)\n","data_nn_ohe_test, y_true_test = create_ffn_ohe_data(bool_in_test)\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        print(f\"Model: {run_index}\")\n","        # Define FNN Model:\n","        # ----------------------\n","        # note we use here the function api instead of the model subclassing\n","        # to make the code more readable and easier to understand:\n","        # (for the transformer based models we will use model subclasses)\n","        def Create_Poisson_FFN_OHE(input_dim=42,mean_model_results=1):\n","            # set random seeds\n","            set_random_seeds(int(random_seeds[run_index]))\n","            # Build the network\n","            Input_Matrix_OHE = tf.keras.layers.Input(shape=(input_dim,), dtype='float32', name='Input_Matrix')\n","            Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","            hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(Input_Matrix_OHE)\n","            hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","            hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","            Result_FFN1 = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_FFN1',\n","                            weights=[np.zeros((10, 1)), np.array([np.log(mean_model_results)])],\n","                            trainable=True)(hidden3)\n","            Response = tf.keras.layers.Multiply(name='Result')([Result_FFN1, Input_Exposure])\n","            # Define and Return the model\n","            return tf.keras.models.Model(inputs=[Input_Matrix_OHE, Input_Exposure], outputs=[Response], name='Poisson_FFN_OHE')\n","\n","        # create the model:\n","        # ----------------------\n","        FFN_OHE = Create_Poisson_FFN_OHE(input_dim=40,mean_model_results=constant_model)\n","\n","        # load the saved model weights:\n","        # ----------------------\n","        FFN_OHE.load_weights(f'{storage_path}/saved_models/Poisson_FFN_OHE_{run_index}.weights.h5')\n","\n","\n","        # predict with the models:\n","        # ----------------------\n","        y_pred[\"train\"][f\"FFN_OHE_{run_index}\"] = np.array([x for [x] in FFN_OHE.predict(data_nn_ohe_learn, verbose=0,\n","                                                                            batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","        y_pred[\"test\"][f\"FFN_OHE_{run_index}\"] = np.array([x for [x] in FFN_OHE.predict(data_nn_ohe_test, verbose=0,\n","                                                                            batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","\n","        create_single_rebase_results(\"FFN_OHE\",run_index)\n","    create_ensemble_results(\"Rebase_FFN_OHE\",index)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_ohe_learn, data_nn_ohe_test"]},{"cell_type":"markdown","metadata":{"id":"BT2qkptSX48N"},"source":["## 6.2 Rebase FFN CAT EMB:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33651,"status":"ok","timestamp":1699254824635,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"UEwuFTg7X48N","outputId":"0eaa5bfe-3fdd-48ec-a39f-a1a9fe77d140"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","Model: 1\n","Model: 2\n","Model: 3\n","Model: 4\n","range(5, 10)\n","Model: 5\n","Model: 6\n","Model: 7\n","Model: 8\n","Model: 9\n","range(10, 15)\n","Model: 10\n","Model: 11\n","Model: 12\n","Model: 13\n","Model: 14\n"]}],"source":["# Create the dataframes needed for evaluation:\n","data_nn_emb_learn, y_true_learn = create_ffn_cat_emb_data(bool_in_learn)\n","data_nn_emb_test, y_true_test = create_ffn_cat_emb_data(bool_in_test)\n","\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        # Define FNN with Cat. Embedding Model:\n","        # ----------------------\n","        # note we use here the function api instead of the model subclassing\n","        # to make the code more readable and easier to understand:\n","        # (for the transformer based models we will use model subclasses)\n","        print(f\"Model: {run_index}\")\n","        def Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=1,mean_model_results=1):\n","            # set random seeds\n","            set_random_seeds(int(random_seeds[run_index]))\n","\n","            Input_Matrix_Num = tf.keras.layers.Input(shape=(input_nr_dim,), dtype='float32', name='Input_Matrix_Num')\n","            Input_VehBrand = tf.keras.layers.Input(shape=(1,), name='Input_VehBrand')\n","            Input_Region = tf.keras.layers.Input(shape=(1,), name='Input_Region')\n","            Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","\n","            All_Inputs = [Input_Matrix_Num,Input_VehBrand,Input_Region,Input_Exposure]\n","\n","            Emb_VehBrand = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"VehBrand\"].keys()),output_dim=emb_dim,\n","                                    embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05 ),\n","                                    name=\"Embedding_VehBrand\")(Input_VehBrand)\n","            Emb_Region = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"Region\"].keys()),output_dim=emb_dim,\n","                                    embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05),\n","                                name=\"Embedding_Region\")(Input_Region)\n","\n","            Reshaped_Emb_VehBrand = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_VehBrand\")(Emb_VehBrand)\n","            Reshaped_Emb_Region = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_Region\")(Emb_Region)\n","\n","            concatenation_layer = tf.keras.layers.Concatenate(name=\"concatenation_layer\")([Input_Matrix_Num,Reshaped_Emb_VehBrand,Reshaped_Emb_Region])\n","\n","            # Build the network\n","            hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(concatenation_layer)\n","            hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","            hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","            Result_FFN1 = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_FFN1',\n","                            weights=[np.zeros((10, 1)), np.array([np.log(mean_model_results)])],\n","                            trainable=True)(hidden3)\n","\n","            Response = tf.keras.layers.Multiply(name='Result')([Result_FFN1, Input_Exposure])\n","\n","            # Define the model\n","            return tf.keras.models.Model(inputs=All_Inputs, outputs=[Response], name='Poisson_CAT_EMB')\n","\n","        # create the model:\n","        # ----------------------\n","        emb_dim=2\n","        FNN_CAT_EMB = Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=emb_dim,mean_model_results=constant_model)\n","\n","        # load the saved model weights:\n","        # ----------------------\n","        FNN_CAT_EMB.load_weights(f'{storage_path}/saved_models/Poisson_FNN_CAT_EMB_{run_index}.weights.h5')\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"FNN_CAT_EMB_{run_index}\"] = np.array([x for [x] in FNN_CAT_EMB.predict(data_nn_emb_learn, verbose=0,\n","                                                                            batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","        y_pred[\"test\"][f\"FNN_CAT_EMB_{run_index}\"] = np.array([x for [x] in FNN_CAT_EMB.predict(data_nn_emb_test, verbose=0,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","\n","\n","        create_single_rebase_results(\"FNN_CAT_EMB\",run_index)\n","    create_ensemble_results(\"Rebase_FNN_CAT_EMB\",index)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_emb_learn, data_nn_emb_test"]},{"cell_type":"markdown","metadata":{"id":"bhzdZssuX48O"},"source":["## 6.3 Rebase CANN:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32699,"status":"ok","timestamp":1699254857321,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"-TpDmi7sX48O","outputId":"84e128cd-6389-433a-833d-2e23ea4c82d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","Model: 1\n","Model: 2\n","Model: 3\n","Model: 4\n","range(5, 10)\n","Model: 5\n","Model: 6\n","Model: 7\n","Model: 8\n","Model: 9\n","range(10, 15)\n","Model: 10\n","Model: 11\n","Model: 12\n","Model: 13\n","Model: 14\n"]}],"source":["# create the new exposure times GLM3_pred column for CANN models.\n","df_freq_prep_nn[\"Exposure_x_GLM3_pred\"] = list(poisson_glm3.predict(X_glm3)*df_freq_prep_nn[\"Exposure\"])\n","\n","# Create the dataframes needed for evaluation:\n","data_nn_emb_learn, y_true_learn = create_ffn_cat_emb_data(bool_in_learn, exposure_name = \"Exposure_x_GLM3_pred\")\n","data_nn_emb_test, y_true_test = create_ffn_cat_emb_data(bool_in_test, exposure_name = \"Exposure_x_GLM3_pred\")\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        # Define FNN with Cat. Embedding Model:\n","        # ----------------------\n","        # note we use here the function api instead of the model subclassing\n","        # to make the code more readable and easier to understand:\n","        # (for the transformer based models we will use model subclasses)\n","        print(f\"Model: {run_index}\")\n","        def Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=1,mean_model_results=1):\n","            # set random seeds\n","            set_random_seeds(int(random_seeds[run_index]))\n","\n","            Input_Matrix_Num = tf.keras.layers.Input(shape=(input_nr_dim,), dtype='float32', name='Input_Matrix_Num')\n","            Input_VehBrand = tf.keras.layers.Input(shape=(1,), name='Input_VehBrand')\n","            Input_Region = tf.keras.layers.Input(shape=(1,), name='Input_Region')\n","            Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","\n","            All_Inputs = [Input_Matrix_Num,Input_VehBrand,Input_Region,Input_Exposure]\n","\n","            Emb_VehBrand = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"VehBrand\"].keys()),output_dim=emb_dim,\n","                                    embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05 ),\n","                                    name=\"Embedding_VehBrand\")(Input_VehBrand)\n","            Emb_Region = tf.keras.layers.Embedding(input_dim=len(cat_encoder_all[\"Region\"].keys()),output_dim=emb_dim,\n","                                    embeddings_initializer=keras.initializers.RandomNormal(mean=1.0, stddev=0.05),\n","                                name=\"Embedding_Region\")(Input_Region)\n","\n","            Reshaped_Emb_VehBrand = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_VehBrand\")(Emb_VehBrand)\n","            Reshaped_Emb_Region = tf.keras.layers.Reshape(target_shape=(emb_dim,),name=\"Reshaped_Embedding_Region\")(Emb_Region)\n","\n","            concatenation_layer = tf.keras.layers.Concatenate(name=\"concatenation_layer\")([Input_Matrix_Num,Reshaped_Emb_VehBrand,Reshaped_Emb_Region])\n","\n","            # Build the network\n","            hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(concatenation_layer)\n","            hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","            hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","            Result_FFN1 = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_FFN1',\n","                            weights=[np.zeros((10, 1)), np.array([0])],\n","                            trainable=True)(hidden3)\n","\n","            Response = tf.keras.layers.Multiply(name='Result')([Result_FFN1, Input_Exposure])\n","\n","            # Define the model\n","            return tf.keras.models.Model(inputs=All_Inputs, outputs=[Response], name='Poisson_CAT_EMB')\n","\n","        # create the model:\n","        # ----------------------\n","        emb_dim=2\n","        CANN = Create_Poisson_FNN_CAT_EMB(input_nr_dim=7,emb_dim=emb_dim,mean_model_results=constant_model)\n","\n","        # load the saved model weights:\n","        # ----------------------\n","        CANN.load_weights(f'{storage_path}/saved_models/Poisson_CANN_{run_index}.weights.h5')\n","\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"CANN_{run_index}\"] = np.array([x for [x] in CANN.predict(data_nn_emb_learn, verbose=0,\n","                                                                            batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","        y_pred[\"test\"][f\"CANN_{run_index}\"] = np.array([x for [x] in CANN.predict(data_nn_emb_test, verbose=0,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","\n","        create_single_rebase_results(\"CANN\",run_index)\n","    create_ensemble_results(\"Rebase_CANN\",index)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_emb_learn, data_nn_emb_test\n"]},{"cell_type":"markdown","metadata":{"id":"73OIhwfgX48O"},"source":["## 6.4 Rebase LocalGLMnet:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55076,"status":"ok","timestamp":1699254912393,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"2gdZ8-iNX48O","outputId":"d14a1fad-2010-4ac8-b485-b7c4dc201212"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","Model: 1\n","Model: 2\n","Model: 3\n","Model: 4\n","range(5, 10)\n","Model: 5\n","Model: 6\n","Model: 7\n","Model: 8\n","Model: 9\n","range(10, 15)\n","Model: 10\n","Model: 11\n","Model: 12\n","Model: 13\n","Model: 14\n"]}],"source":["# Create the dataframes needed for evaluation:\n","data_nn_ohe_learn, y_true_learn = create_ffn_ohe_data(bool_in_learn)\n","data_nn_ohe_test, y_true_test = create_ffn_ohe_data(bool_in_test)\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        print(f\"Model: {run_index}\")\n","        # Define FNN with Cat. Embedding Model:\n","        # ----------------------\n","        # note we use here the function api instead of the model subclassing\n","        # to make the code more readable and easier to understand:\n","        # (for the transformer based models we will use model subclasses)\n","\n","        # create dummy glm for initial weights\n","        # ----------------------\n","        poisson_glm_dummy = PoissonRegressor(alpha = 0,max_iter=1000) # scikit-learn.org: alpha = 0 is equivalent to unpenalized GLMs\n","        poisson_glm_dummy.fit(data_nn_ohe_learn[0],y_true_learn/data_nn_ohe_learn[1],sample_weight=data_nn_ohe_learn[1]) # note: data_nn_ohe_learn = [X_ohe,exposure]\n","\n","        # Define LocalGLMnet:\n","        # ----------------------\n","        def Create_Poisson_LocalGLMnet(input_dim=40,initial_glm_bias=1, initial_glm_betas=None):\n","            # set random seeds\n","            set_random_seeds(int(random_seeds[run_index]))\n","            Input_Matrix_OHE = tf.keras.layers.Input(shape=(input_dim,), dtype='float32', name='Input_Matrix')\n","            Input_Exposure = tf.keras.layers.Input(shape=(1,), dtype='float32', name='Input_Exposure')\n","            # Build the network\n","            hidden1 = tf.keras.layers.Dense(units=20, activation=tanh, name='hidden1')(Input_Matrix_OHE)\n","            hidden2 = tf.keras.layers.Dense(units=15, activation=tanh, name='hidden2')(hidden1)\n","            hidden3 = tf.keras.layers.Dense(units=10, activation=tanh, name='hidden3')(hidden2)\n","            Attention = tf.keras.layers.Dense(units=input_dim, activation='linear', name='attention',\n","                            weights=[np.zeros((10, input_dim)), initial_glm_betas])(hidden3)\n","            # note that the weights are set to 0 and the bias is set to the initial glm betas\n","            # create a layer that calculates the dot product between the attention weights (Attention) and the input matrix Input_Matrix_OHE:\n","            # (Attention has the same dimension as the input matrix Input_Matrix_OHE):\n","            weighted_input = tf.keras.layers.Multiply(name='feature_contributions')([Attention, Input_Matrix_OHE])\n","            scalar_product = tf.keras.layers.Dense(units=1, activation='linear', name='scalar_product',\n","                                weights=[np.ones((input_dim, 1)), np.array([0])],\n","                                trainable=False)(weighted_input)\n","            # Note that we actually don't want to make the following weights trainable,\n","            # but to get the bias to be trainable we need to do so. see comment in Book Wüthrich & Merz (2023) page 500\n","            Result_LocalGLMnet_without_Exposure = tf.keras.layers.Dense(units=1, activation='exponential', name='Result_LocalGLMnet_without_Exposure',\n","                            weights=[np.ones((1, 1)), np.array([initial_glm_bias])],\n","                            trainable=True)(scalar_product)\n","            Response = tf.keras.layers.Multiply(name='Result')([Result_LocalGLMnet_without_Exposure, Input_Exposure])\n","            return tf.keras.models.Model(inputs=[Input_Matrix_OHE, Input_Exposure], outputs=[Response], name='Poisson_LocalGLMnet')\n","\n","        # create the model:\n","        # ----------------------\n","        LocalGLMnet = Create_Poisson_LocalGLMnet(input_dim=40,initial_glm_bias=poisson_glm_dummy.intercept_,initial_glm_betas=poisson_glm_dummy.coef_)\n","\n","        # load the saved model weights:\n","        # ----------------------\n","        LocalGLMnet.load_weights(f'{storage_path}/saved_models/Poisson_LocalGLMnet_{run_index}.weights.h5')\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"LocalGLMnet_{run_index}\"] = np.array([x for [x] in LocalGLMnet.predict(data_nn_ohe_learn, verbose=0,\n","                                                                            batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","        y_pred[\"test\"][f\"LocalGLMnet_{run_index}\"] = np.array([x for [x] in LocalGLMnet.predict(data_nn_ohe_test, verbose=0,\n","                                                                        batch_size=100000,use_multiprocessing=True, workers=os.cpu_count())])\n","\n","        create_single_rebase_results(\"LocalGLMnet\",run_index)\n","    create_ensemble_results(\"Rebase_LocalGLMnet\",index)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del data_nn_ohe_learn, data_nn_ohe_test\n"]},{"cell_type":"markdown","metadata":{"id":"jadej3rLX48P"},"source":["## 6.5 Rebase FT-Transformer:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199535,"status":"ok","timestamp":1699255111924,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"ZWxOhy-ZX48P","outputId":"fa003e56-5048-4ac6-862e-92e690256b87"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 1\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 2\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 3\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 4\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["range(5, 10)\n","Model: 5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 6\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 7\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 8\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 9\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["range(10, 15)\n","Model: 10\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 11\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 12\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 13\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Model: 14\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]}],"source":["# Create the dataframes needed for evaluation:\n","# --------------------\n","# NOTE: in the 2021 Gorishniy paper the batch size is different for the different Datasets\n","# but is not hyperparameter tuned. Bigger datasets they used a batch size of 1024 and\n","# for smaller datasets a batch size of (256/512).\n","batch_size = 1024\n","learn_data = df_to_tensor(df_freq_prep_nn[bool_in_learn], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","test_data = df_to_tensor(df_freq_prep_nn[bool_in_test], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","# NOTE we use at first just a fraction of the data to test the code:\n","learn_train_dummy_data = df_to_tensor(df_freq_prep_nn[bool_in_learn_train_dummy], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size,\n","                                      dummy_data_for_build=True)\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        print(f\"Model: {run_index}\")\n","        # Define FT-Transformer Models:\n","        # ----------------------\n","        # NOTE: we use here tensorflow/keras model subclasses (not the functional or sequential api)\n","        # NOTE: we use here instead of the .fit function a costum training loop\n","\n","        # create the model:\n","        # ----------------------\n","        set_random_seeds(int(random_seeds[run_index]))\n","\n","        FT_transformer = EnhActuar.Feature_Tokenizer_Transformer(\n","                emb_dim = 32, # NOTE: In the default setting for the 2021 Gorishniy paper they used emb_dim = 192 (but the parameter size would here go trough the roof, so we use something smaller)\n","                nr_features = nr_col,\n","                cat_features = cat_col,\n","                cat_vocabulary = cat_vocabulary,\n","                count_transformer_blocks = 3,\n","                attention_n_heads = 8,\n","                attention_dropout = 0.2,\n","                ffn_d_hidden = None, # NOTE: change to None if ReGLU should be used -> None uses default value (4/3*emb_dim), they write that they used 2*emb_dim if not ReGLU.\n","                ffn_activation_ReGLU = True, # NOTE: set True if ReGLU should be used\n","                ffn_dropout = 0.1,\n","                prenormalization = True,\n","                output_dim = 1,\n","                last_activation = 'exponential',\n","                exposure_name = \"Exposure\",\n","                seed_nr = int(random_seeds[run_index])\n","        )\n","\n","        FT_transformer.predict(learn_train_dummy_data,verbose=0,batch_size=100000)\n","\n","        # load the best saved model and epochs_and_time from the pickle file:\n","        # ----------------------\n","        # FT_transformer = keras.models.load_model(save_path +'/Poisson_FT_transformer')\n","        FT_transformer.load_weights(f'{storage_path}/saved_models/Poisson_FT_transformer_{run_index}.weights.h5')\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"FT_transformer_{run_index}\"] = np.array([x for [x] in FT_transformer.predict(learn_data,verbose=0,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","        y_pred[\"test\"][f\"FT_transformer_{run_index}\"] = np.array([x for [x] in FT_transformer.predict(test_data,verbose=0,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","\n","        create_single_rebase_results(\"FT_transformer\",run_index)\n","    create_ensemble_results(\"Rebase_FT_transformer\",index)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del learn_data, test_data"]},{"cell_type":"markdown","metadata":{"id":"F_IRqRwAX48P"},"source":["## 6.6 Rebase CAFTT:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211258,"status":"ok","timestamp":1699255323159,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"abD-L7fOX48P","outputId":"96139a9a-1eba-45fb-b182-d64c20f18fd8"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","  1/596 [..............................] - ETA: 20s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 15ms/step\n","Model: 1\n","  4/596 [..............................] - ETA: 11s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 12ms/step\n","Model: 2\n","  1/596 [..............................] - ETA: 13s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 3\n","  4/596 [..............................] - ETA: 10s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 9s 15ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 4\n","  1/596 [..............................] - ETA: 12s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 9s 15ms/step\n","67/67 [==============================] - 1s 15ms/step\n","range(5, 10)\n","Model: 5\n","  4/596 [..............................] - ETA: 11s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 6\n","  4/596 [..............................] - ETA: 10s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 15ms/step\n","Model: 7\n","  4/596 [..............................] - ETA: 10s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 8\n","  1/596 [..............................] - ETA: 13s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 15ms/step\n","Model: 9\n","  1/596 [..............................] - ETA: 13s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 9s 15ms/step\n","67/67 [==============================] - 1s 16ms/step\n","range(10, 15)\n","Model: 10\n","  3/596 [..............................] - ETA: 15s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 11\n","  4/596 [..............................] - ETA: 10s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 15ms/step\n","Model: 12\n","  1/596 [..............................] - ETA: 12s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 15ms/step\n","Model: 13\n","  1/596 [..............................] - ETA: 12s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 14\n","  4/596 [..............................] - ETA: 10s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 9s 16ms/step\n","67/67 [==============================] - 1s 14ms/step\n"]}],"source":["# create the new exposure times GLM3_pred column for CANN models.\n","df_freq_prep_nn[\"Exposure_x_GLM3_pred\"] = list(poisson_glm3.predict(X_glm3)*df_freq_prep_nn[\"Exposure\"])\n","\n","# Create the dataframes needed for evaluation:\n","# --------------------\n","# NOTE: in the 2021 Gorishniy et al paper the batch size is different for the different Datasets\n","# but is not hyperparameter tuned. Bigger datasets they used a batch size of 1024 and\n","# for smaller datasets a batch size of (256/512).\n","batch_size = 1024\n","learn_data = df_to_tensor(df_freq_prep_nn[bool_in_learn], feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size)\n","test_data = df_to_tensor(df_freq_prep_nn[bool_in_test], feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","# NOTE we use at first just a fraction of the data to test the code:\n","learn_train_dummy_data = df_to_tensor(df_freq_prep_nn[bool_in_learn_train_dummy], feature_cols=nr_col+cat_col, exposure=\"Exposure_x_GLM3_pred\", target=\"ClaimNb\", batch_size=batch_size,\n","                                      dummy_data_for_build=True)\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        print(f\"Model: {run_index}\")\n","        # Define FT-Transformer Models:\n","        # ----------------------\n","        # NOTE: we use here tensorflow/keras model subclasses (not the functional or sequential api)\n","        # NOTE: we use here instead of the .fit function a costum training loop\n","\n","        # create the model:\n","        # ----------------------\n","        set_random_seeds(int(random_seeds[run_index]))\n","\n","        FT_transformer = EnhActuar.Feature_Tokenizer_Transformer(\n","                emb_dim = 32, # NOTE: In the default setting for the 2021 Gorishniy paper they used emb_dim = 192 (but the parameter size would here go trough the roof, so we use something smaller)\n","                nr_features = nr_col,\n","                cat_features = cat_col,\n","                cat_vocabulary = cat_vocabulary,\n","                count_transformer_blocks = 3,\n","                attention_n_heads = 8,\n","                attention_dropout = 0.2,\n","                ffn_d_hidden = None, # NOTE: change to None if ReGLU should be used -> None uses default value (4/3*emb_dim), they write that they used 2*emb_dim if not ReGLU.\n","                ffn_activation_ReGLU = True, # NOTE: set True if ReGLU should be used\n","                ffn_dropout = 0.1,\n","                prenormalization = True,\n","                output_dim = 1,\n","                last_activation = 'exponential',\n","                exposure_name = \"Exposure_x_GLM3_pred\",\n","                last_layer_initial_weights = \"zeros\",\n","                last_layer_initial_bias = \"zeros\",\n","                seed_nr = int(random_seeds[run_index])\n","        )\n","\n","        FT_transformer.predict(learn_train_dummy_data,verbose=0,batch_size=100000)\n","\n","        # load the best saved model and epochs_and_time from the pickle file:\n","        # ----------------------\n","        FT_transformer.load_weights(f'{storage_path}/saved_models/Poisson_CAFTT_{run_index}.weights.h5')\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"CAFTT_{run_index}\"] = np.array([x for [x] in FT_transformer.predict(learn_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","        y_pred[\"test\"][f\"CAFTT_{run_index}\"] = np.array([x for [x] in FT_transformer.predict(test_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","\n","        create_single_rebase_results(\"CAFTT\",run_index)\n","    create_ensemble_results(\"Rebase_CAFTT\",index)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del learn_data, test_data"]},{"cell_type":"markdown","metadata":{"id":"TiNQM4GKX48P"},"source":["## 6.7 Rebase LocalGLMftt:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":225844,"status":"ok","timestamp":1699255548979,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"Bm5YxNQeX48Q","outputId":"b861a2b6-ead9-440b-9a65-5894e962afcf"},"outputs":[{"name":"stdout","output_type":"stream","text":["range(0, 5)\n","Model: 0\n","  1/596 [..............................] - ETA: 22s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 1\n","  1/596 [..............................] - ETA: 13s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 12s 20ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 2\n","  1/596 [..............................] - ETA: 14s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 3\n","  1/596 [..............................] - ETA: 13s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 4\n","  1/596 [..............................] - ETA: 14s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 14ms/step\n","range(5, 10)\n","Model: 5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 6\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 7\n","  1/596 [..............................] - ETA: 14s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 8s 14ms/step\n","67/67 [==============================] - 1s 19ms/step\n","Model: 8\n","  1/596 [..............................] - ETA: 13s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 9s 15ms/step\n","67/67 [==============================] - 1s 15ms/step\n","Model: 9\n","  1/596 [..............................] - ETA: 14s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 16ms/step\n","range(10, 15)\n","Model: 10\n","  1/596 [..............................] - ETA: 14s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 11\n","  1/596 [..............................] - ETA: 13s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 12\n","  1/596 [..............................] - ETA: 14s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 16ms/step\n","67/67 [==============================] - 1s 14ms/step\n","Model: 13\n","  1/596 [..............................] - ETA: 13s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 13ms/step\n","Model: 14\n","  1/596 [..............................] - ETA: 13s"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/__init__.py:144: UserWarning:\n","\n","The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomUniform'>, which may lead to improper serialization.\n","\n"]},{"name":"stdout","output_type":"stream","text":["596/596 [==============================] - 10s 17ms/step\n","67/67 [==============================] - 1s 14ms/step\n"]}],"source":["# Create the dataframes for creation of the glm-ohe-start model:\n","# --------------------\n","data_nn_ohe_learn, y_true_learn = create_ffn_ohe_data(bool_in_learn)\n","\n","# create dummy glm for initial weights\n","# ----------------------\n","poisson_glm_dummy = PoissonRegressor(alpha = 0,max_iter=1000) # scikit-learn.org: alpha = 0 is equivalent to unpenalized GLMs\n","poisson_glm_dummy.fit(data_nn_ohe_learn[0],y_true_learn/data_nn_ohe_learn[1],sample_weight=data_nn_ohe_learn[1]) # note: data_nn_ohe_learn = [X_ohe,exposure]\n","# get the betas from the glm:\n","glm_nr_col_betas = poisson_glm_dummy.coef_[:len(nr_col)]\n","current_beta_index = len(nr_col)\n","glm_cat_col_betas = {}\n","for c in cat_vocabulary.keys():\n","    glm_cat_col_betas[c] = poisson_glm_dummy.coef_[current_beta_index:current_beta_index+len(cat_vocabulary[c])]\n","    current_beta_index += len(cat_vocabulary[c])\n","glm_intercept = poisson_glm_dummy.intercept_\n","\n","\n","# Create the dataframes needed for evaluation:\n","# --------------------\n","# NOTE: in the 2021 Gorishniy paper the batch size is different for the different Datasets\n","# but is not hyperparameter tuned. Bigger datasets they used a batch size of 1024 and\n","# for smaller datasets a batch size of (256/512).\n","batch_size = 1024\n","learn_data = df_to_tensor(df_freq_prep_nn[bool_in_learn], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","test_data = df_to_tensor(df_freq_prep_nn[bool_in_test], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size)\n","\n","learn_train_dummy_data = df_to_tensor(df_freq_prep_nn[bool_in_learn_train_dummy], feature_cols=nr_col+cat_col, exposure=\"Exposure\", target=\"ClaimNb\", batch_size=batch_size,\n","                                      dummy_data_for_build=True)\n","\n","for index, ensemble_range in enumerate([range(0,5),range(5,10),range(10,15)]):\n","    print(ensemble_range)\n","    for run_index in ensemble_range:\n","\n","        print(f\"Model: {run_index}\")\n","        # Define FT-Transformer Models:\n","        # ----------------------\n","        # NOTE: we use here tensorflow/keras model subclasses (not the functional or sequential api)\n","        # NOTE: we use here instead of the .fit function a costum training loop\n","\n","        # create the model:\n","        # ----------------------\n","        set_random_seeds(int(random_seeds[run_index]))\n","        LocalGLMftt = EnhActuar.LocalGLM_FT_Transformer(\n","                emb_dim = 32, # NOTE: In the default setting for the 2021 Gorishniy paper they used emb_dim = 192 (but the parameter size would here go trough the roof, so we use something smaller)\n","                nr_features = nr_col,\n","                cat_features = cat_col,\n","                cat_vocabulary = cat_vocabulary,\n","                count_transformer_blocks = 3,\n","                attention_n_heads = 8,\n","                attention_dropout = 0.2,\n","                ffn_d_hidden = None, # NOTE: change to None if ReGLU should be used -> None uses default value (4/3*emb_dim), they write that they used 2*emb_dim if not ReGLU.\n","                ffn_activation_ReGLU = True, # NOTE: set True if ReGLU should be used\n","                ffn_dropout = 0.1,\n","                prenormalization = True,\n","                output_dim = 1,\n","                last_activation = 'exponential',\n","                exposure_name = \"Exposure\",\n","                last_layer_initial_weights = \"zeros\",\n","                last_layer_initial_bias = \"ones\",\n","                init_glm_cat_col_weights = glm_cat_col_betas,\n","                init_glm_nr_col_weights = glm_nr_col_betas,\n","                init_glm_bias = glm_intercept,\n","                trainable_glm_emb = False,\n","                seed_nr = int(random_seeds[run_index])\n","        )\n","\n","        LocalGLMftt.predict(learn_train_dummy_data,verbose=0,batch_size=100000)\n","\n","        # load the best saved model and epochs_and_time from the pickle file:\n","        # ----------------------\n","        LocalGLMftt.load_weights(f'{storage_path}/saved_models/Poisson_LocalGLMftt_{run_index}.weights.h5')\n","\n","        # predict with the model:\n","        # ----------------------\n","        y_pred[\"train\"][f\"LocalGLMftt_{run_index}\"] = np.array([x for [x] in LocalGLMftt.predict(learn_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","        y_pred[\"test\"][f\"LocalGLMftt_{run_index}\"] = np.array([x for [x] in LocalGLMftt.predict(test_data,batch_size=100000,use_multiprocessing=True, workers=os.cpu_count()\n","                                                                                    )[\"output\"]])\n","\n","        create_single_rebase_results(\"LocalGLMftt\",run_index)\n","    create_ensemble_results(\"Rebase_LocalGLMftt\",index)\n","\n","# because notebooks have no garbage collector, we delete here the unneeded data:\n","del learn_data, test_data\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvFw3ZdTX48Q"},"outputs":[],"source":["# # save the results:\n","# with open(f'{storage_path}/Data/df_results.pickle', 'wb') as handle:\n","#     pickle.dump(df_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# load the results:\n","with open(f'{storage_path}/Data/df_results.pickle', 'rb') as handle:\n","    df_results = pickle.load(handle)\n"]},{"cell_type":"markdown","metadata":{"id":"-BK3RArXjymx"},"source":["# Result:"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":417,"status":"ok","timestamp":1699573601376,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"CA8ZY117du_X"},"outputs":[],"source":["# display(df_results)"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"elapsed":429,"status":"ok","timestamp":1699573695955,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"F4N4N_b9duk9","outputId":"cc0b0425-1367-4752-9246-5117d2bde0af"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results Average:\n"]},{"data":{"text/html":["\n","  <div id=\"df-cb2d2973-0f48-43fc-84c8-ad6fed502804\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model</td>\n","      <td>0.000000</td>\n","      <td>0.054847</td>\n","      <td>1.0</td>\n","      <td>0.252132</td>\n","      <td>0.254454</td>\n","      <td>0.073631</td>\n","      <td>0.073631</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GLM1</td>\n","      <td>0.000000</td>\n","      <td>2.220158</td>\n","      <td>49.0</td>\n","      <td>0.241015</td>\n","      <td>0.241463</td>\n","      <td>0.073631</td>\n","      <td>0.073900</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GLM2</td>\n","      <td>0.000000</td>\n","      <td>2.752693</td>\n","      <td>48.0</td>\n","      <td>0.240911</td>\n","      <td>0.241125</td>\n","      <td>0.073631</td>\n","      <td>0.073981</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GLM3</td>\n","      <td>0.000000</td>\n","      <td>1.900497</td>\n","      <td>50.0</td>\n","      <td>0.240844</td>\n","      <td>0.241022</td>\n","      <td>0.073631</td>\n","      <td>0.074048</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FFN_OHE</td>\n","      <td>42.200000</td>\n","      <td>37.805560</td>\n","      <td>1306.0</td>\n","      <td>0.237535</td>\n","      <td>0.238652</td>\n","      <td>0.073906</td>\n","      <td>0.074310</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>FNN_CAT_EMB</td>\n","      <td>72.933333</td>\n","      <td>58.728892</td>\n","      <td>792.0</td>\n","      <td>0.237682</td>\n","      <td>0.238267</td>\n","      <td>0.073774</td>\n","      <td>0.074238</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CANN</td>\n","      <td>90.333333</td>\n","      <td>68.559120</td>\n","      <td>792.0</td>\n","      <td>0.237420</td>\n","      <td>0.238102</td>\n","      <td>0.074019</td>\n","      <td>0.074438</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LocalGLMnet</td>\n","      <td>25.333333</td>\n","      <td>29.720892</td>\n","      <td>1737.0</td>\n","      <td>0.237095</td>\n","      <td>0.239211</td>\n","      <td>0.073825</td>\n","      <td>0.074267</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>FT_transformer</td>\n","      <td>78.866667</td>\n","      <td>1569.860410</td>\n","      <td>27133.0</td>\n","      <td>0.237803</td>\n","      <td>0.239389</td>\n","      <td>0.061140</td>\n","      <td>0.061290</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>CAFTT</td>\n","      <td>57.333333</td>\n","      <td>1170.160723</td>\n","      <td>27133.0</td>\n","      <td>0.237146</td>\n","      <td>0.238072</td>\n","      <td>0.065975</td>\n","      <td>0.066235</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LocalGLMftt</td>\n","      <td>53.200000</td>\n","      <td>1187.006637</td>\n","      <td>27430.0</td>\n","      <td>0.237214</td>\n","      <td>0.238801</td>\n","      <td>0.067904</td>\n","      <td>0.068316</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb2d2973-0f48-43fc-84c8-ad6fed502804')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cb2d2973-0f48-43fc-84c8-ad6fed502804 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cb2d2973-0f48-43fc-84c8-ad6fed502804');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-04343633-6081-458e-8f11-593568fc5a1b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04343633-6081-458e-8f11-593568fc5a1b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-04343633-6081-458e-8f11-593568fc5a1b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                model     epochs     run_time  nr_parameters  loss_train  \\\n","0   homogeneous model   0.000000     0.054847            1.0    0.252132   \n","1                GLM1   0.000000     2.220158           49.0    0.241015   \n","2                GLM2   0.000000     2.752693           48.0    0.240911   \n","3                GLM3   0.000000     1.900497           50.0    0.240844   \n","4             FFN_OHE  42.200000    37.805560         1306.0    0.237535   \n","5         FNN_CAT_EMB  72.933333    58.728892          792.0    0.237682   \n","6                CANN  90.333333    68.559120          792.0    0.237420   \n","7         LocalGLMnet  25.333333    29.720892         1737.0    0.237095   \n","8      FT_transformer  78.866667  1569.860410        27133.0    0.237803   \n","9               CAFTT  57.333333  1170.160723        27133.0    0.237146   \n","10        LocalGLMftt  53.200000  1187.006637        27430.0    0.237214   \n","\n","    loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0    0.254454             0.073631            0.073631  \n","1    0.241463             0.073631            0.073900  \n","2    0.241125             0.073631            0.073981  \n","3    0.241022             0.073631            0.074048  \n","4    0.238652             0.073906            0.074310  \n","5    0.238267             0.073774            0.074238  \n","6    0.238102             0.074019            0.074438  \n","7    0.239211             0.073825            0.074267  \n","8    0.239389             0.061140            0.061290  \n","9    0.238072             0.065975            0.066235  \n","10   0.238801             0.067904            0.068316  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Results Standard-Deviation:\n"]},{"data":{"text/html":["\n","  <div id=\"df-7821e096-a950-40b2-a312-d0f77f405adc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>homogeneous model</td>\n","      <td>0.000000</td>\n","      <td>0.002512</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>5.745950e-17</td>\n","      <td>2.872975e-17</td>\n","      <td>2.872975e-17</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GLM1</td>\n","      <td>0.000000</td>\n","      <td>0.473819</td>\n","      <td>0.0</td>\n","      <td>5.745950e-17</td>\n","      <td>5.745950e-17</td>\n","      <td>1.436488e-17</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GLM2</td>\n","      <td>0.000000</td>\n","      <td>0.970156</td>\n","      <td>0.0</td>\n","      <td>5.745950e-17</td>\n","      <td>2.872975e-17</td>\n","      <td>0.000000e+00</td>\n","      <td>1.436488e-17</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GLM3</td>\n","      <td>0.000000</td>\n","      <td>0.408252</td>\n","      <td>0.0</td>\n","      <td>2.872975e-17</td>\n","      <td>2.872975e-17</td>\n","      <td>0.000000e+00</td>\n","      <td>1.436488e-17</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FFN_OHE</td>\n","      <td>14.663853</td>\n","      <td>8.624492</td>\n","      <td>0.0</td>\n","      <td>3.255191e-04</td>\n","      <td>1.570462e-04</td>\n","      <td>1.223993e-03</td>\n","      <td>1.209107e-03</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>FNN_CAT_EMB</td>\n","      <td>21.661245</td>\n","      <td>13.907265</td>\n","      <td>0.0</td>\n","      <td>1.590947e-04</td>\n","      <td>1.514444e-04</td>\n","      <td>1.071399e-03</td>\n","      <td>1.088943e-03</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CANN</td>\n","      <td>53.898935</td>\n","      <td>33.162059</td>\n","      <td>0.0</td>\n","      <td>6.076588e-04</td>\n","      <td>3.253586e-04</td>\n","      <td>1.111365e-03</td>\n","      <td>1.103431e-03</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LocalGLMnet</td>\n","      <td>7.622023</td>\n","      <td>5.097405</td>\n","      <td>0.0</td>\n","      <td>3.340630e-04</td>\n","      <td>2.176521e-04</td>\n","      <td>8.787938e-04</td>\n","      <td>9.078453e-04</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>FT_transformer</td>\n","      <td>16.638452</td>\n","      <td>302.316624</td>\n","      <td>0.0</td>\n","      <td>8.982910e-04</td>\n","      <td>5.281384e-04</td>\n","      <td>1.459836e-03</td>\n","      <td>1.458034e-03</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>CAFTT</td>\n","      <td>14.185841</td>\n","      <td>220.449926</td>\n","      <td>0.0</td>\n","      <td>4.739992e-04</td>\n","      <td>1.743234e-04</td>\n","      <td>4.993066e-04</td>\n","      <td>4.707813e-04</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LocalGLMftt</td>\n","      <td>16.384662</td>\n","      <td>310.648783</td>\n","      <td>0.0</td>\n","      <td>5.933743e-04</td>\n","      <td>1.596498e-04</td>\n","      <td>9.643511e-04</td>\n","      <td>9.918441e-04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7821e096-a950-40b2-a312-d0f77f405adc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7821e096-a950-40b2-a312-d0f77f405adc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7821e096-a950-40b2-a312-d0f77f405adc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-441c5dc7-b742-4aef-81d9-b53dbf6650c1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-441c5dc7-b742-4aef-81d9-b53dbf6650c1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-441c5dc7-b742-4aef-81d9-b53dbf6650c1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                model     epochs    run_time  nr_parameters    loss_train  \\\n","0   homogeneous model   0.000000    0.002512            0.0  0.000000e+00   \n","1                GLM1   0.000000    0.473819            0.0  5.745950e-17   \n","2                GLM2   0.000000    0.970156            0.0  5.745950e-17   \n","3                GLM3   0.000000    0.408252            0.0  2.872975e-17   \n","4             FFN_OHE  14.663853    8.624492            0.0  3.255191e-04   \n","5         FNN_CAT_EMB  21.661245   13.907265            0.0  1.590947e-04   \n","6                CANN  53.898935   33.162059            0.0  6.076588e-04   \n","7         LocalGLMnet   7.622023    5.097405            0.0  3.340630e-04   \n","8      FT_transformer  16.638452  302.316624            0.0  8.982910e-04   \n","9               CAFTT  14.185841  220.449926            0.0  4.739992e-04   \n","10        LocalGLMftt  16.384662  310.648783            0.0  5.933743e-04   \n","\n","       loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0   5.745950e-17         2.872975e-17        2.872975e-17  \n","1   5.745950e-17         1.436488e-17        0.000000e+00  \n","2   2.872975e-17         0.000000e+00        1.436488e-17  \n","3   2.872975e-17         0.000000e+00        1.436488e-17  \n","4   1.570462e-04         1.223993e-03        1.209107e-03  \n","5   1.514444e-04         1.071399e-03        1.088943e-03  \n","6   3.253586e-04         1.111365e-03        1.103431e-03  \n","7   2.176521e-04         8.787938e-04        9.078453e-04  \n","8   5.281384e-04         1.459836e-03        1.458034e-03  \n","9   1.743234e-04         4.993066e-04        4.707813e-04  \n","10  1.596498e-04         9.643511e-04        9.918441e-04  "]},"metadata":{},"output_type":"display_data"}],"source":["print(\"Results Average:\")\n","display(calc_avg_df([\"homogeneous model\",\"GLM1\",\"GLM2\",\"GLM3\",\"FFN_OHE\",\"FNN_CAT_EMB\",\"CANN\",\"LocalGLMnet\",\"FT_transformer\",\"CAFTT\",\"LocalGLMftt\"]))\n","print(\"Results Standard-Deviation:\")\n","display(calc_std_df([\"homogeneous model\",\"GLM1\",\"GLM2\",\"GLM3\",\"FFN_OHE\",\"FNN_CAT_EMB\",\"CANN\",\"LocalGLMnet\",\"FT_transformer\",\"CAFTT\",\"LocalGLMftt\"]))"]},{"cell_type":"markdown","metadata":{"id":"W-nrJqqdFIFb"},"source":["## Compare Single Model Results to Ensemble (not rebalanced) Results:"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":996},"executionInfo":{"elapsed":457,"status":"ok","timestamp":1699573703038,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"T6uVrSFNduMP","outputId":"470c6d6c-f264-41e6-8b4f-0d6928b85e9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results Average:\n"]},{"data":{"text/html":["\n","  <div id=\"df-075c53c9-5fb0-4c5b-84f5-271a6fb84237\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FFN_OHE</td>\n","      <td>42.200000</td>\n","      <td>37.805560</td>\n","      <td>1306.0</td>\n","      <td>0.237535</td>\n","      <td>0.238652</td>\n","      <td>0.073906</td>\n","      <td>0.074310</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Ensemble_FFN_OHE</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.237152</td>\n","      <td>0.238260</td>\n","      <td>0.073906</td>\n","      <td>0.074310</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FNN_CAT_EMB</td>\n","      <td>72.933333</td>\n","      <td>58.728892</td>\n","      <td>792.0</td>\n","      <td>0.237682</td>\n","      <td>0.238267</td>\n","      <td>0.073774</td>\n","      <td>0.074238</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ensemble_FNN_CAT_EMB</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.237432</td>\n","      <td>0.238009</td>\n","      <td>0.073773</td>\n","      <td>0.074238</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CANN</td>\n","      <td>90.333333</td>\n","      <td>68.559120</td>\n","      <td>792.0</td>\n","      <td>0.237420</td>\n","      <td>0.238102</td>\n","      <td>0.074019</td>\n","      <td>0.074438</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Ensemble_CANN</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.237013</td>\n","      <td>0.237699</td>\n","      <td>0.074019</td>\n","      <td>0.074438</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>LocalGLMnet</td>\n","      <td>25.333333</td>\n","      <td>29.720892</td>\n","      <td>1737.0</td>\n","      <td>0.237095</td>\n","      <td>0.239211</td>\n","      <td>0.073825</td>\n","      <td>0.074267</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Ensemble_LocalGLMnet</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.236635</td>\n","      <td>0.238734</td>\n","      <td>0.073825</td>\n","      <td>0.074267</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>FT_transformer</td>\n","      <td>78.866667</td>\n","      <td>1569.860410</td>\n","      <td>27133.0</td>\n","      <td>0.237803</td>\n","      <td>0.239389</td>\n","      <td>0.061140</td>\n","      <td>0.061290</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Ensemble_FT_transformer</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.237176</td>\n","      <td>0.238803</td>\n","      <td>0.061140</td>\n","      <td>0.061290</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>CAFTT</td>\n","      <td>57.333333</td>\n","      <td>1170.160723</td>\n","      <td>27133.0</td>\n","      <td>0.237146</td>\n","      <td>0.238072</td>\n","      <td>0.065975</td>\n","      <td>0.066235</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Ensemble_CAFTT</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.236748</td>\n","      <td>0.237675</td>\n","      <td>0.065975</td>\n","      <td>0.066235</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>LocalGLMftt</td>\n","      <td>53.200000</td>\n","      <td>1187.006637</td>\n","      <td>27430.0</td>\n","      <td>0.237214</td>\n","      <td>0.238801</td>\n","      <td>0.067904</td>\n","      <td>0.068316</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Ensemble_LocalGLMftt</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.236705</td>\n","      <td>0.238319</td>\n","      <td>0.067904</td>\n","      <td>0.068316</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-075c53c9-5fb0-4c5b-84f5-271a6fb84237')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-075c53c9-5fb0-4c5b-84f5-271a6fb84237 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-075c53c9-5fb0-4c5b-84f5-271a6fb84237');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d72ba005-fc7c-4c35-b755-57573159496e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d72ba005-fc7c-4c35-b755-57573159496e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d72ba005-fc7c-4c35-b755-57573159496e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                      model     epochs     run_time  nr_parameters  \\\n","0                   FFN_OHE  42.200000    37.805560         1306.0   \n","1          Ensemble_FFN_OHE   0.000000     0.000000            0.0   \n","2               FNN_CAT_EMB  72.933333    58.728892          792.0   \n","3      Ensemble_FNN_CAT_EMB   0.000000     0.000000            0.0   \n","4                      CANN  90.333333    68.559120          792.0   \n","5             Ensemble_CANN   0.000000     0.000000            0.0   \n","6               LocalGLMnet  25.333333    29.720892         1737.0   \n","7      Ensemble_LocalGLMnet   0.000000     0.000000            0.0   \n","8            FT_transformer  78.866667  1569.860410        27133.0   \n","9   Ensemble_FT_transformer   0.000000     0.000000            0.0   \n","10                    CAFTT  57.333333  1170.160723        27133.0   \n","11           Ensemble_CAFTT   0.000000     0.000000            0.0   \n","12              LocalGLMftt  53.200000  1187.006637        27430.0   \n","13     Ensemble_LocalGLMftt   0.000000     0.000000            0.0   \n","\n","    loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0     0.237535   0.238652             0.073906            0.074310  \n","1     0.237152   0.238260             0.073906            0.074310  \n","2     0.237682   0.238267             0.073774            0.074238  \n","3     0.237432   0.238009             0.073773            0.074238  \n","4     0.237420   0.238102             0.074019            0.074438  \n","5     0.237013   0.237699             0.074019            0.074438  \n","6     0.237095   0.239211             0.073825            0.074267  \n","7     0.236635   0.238734             0.073825            0.074267  \n","8     0.237803   0.239389             0.061140            0.061290  \n","9     0.237176   0.238803             0.061140            0.061290  \n","10    0.237146   0.238072             0.065975            0.066235  \n","11    0.236748   0.237675             0.065975            0.066235  \n","12    0.237214   0.238801             0.067904            0.068316  \n","13    0.236705   0.238319             0.067904            0.068316  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Results Standard-Deviation:\n"]},{"data":{"text/html":["\n","  <div id=\"df-91ae0d7d-b441-41a6-bce6-51607c8058ca\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FFN_OHE</td>\n","      <td>14.663853</td>\n","      <td>8.624492</td>\n","      <td>0.0</td>\n","      <td>0.000326</td>\n","      <td>0.000157</td>\n","      <td>0.001224</td>\n","      <td>0.001209</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Ensemble_FFN_OHE</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000224</td>\n","      <td>0.000098</td>\n","      <td>0.000648</td>\n","      <td>0.000667</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FNN_CAT_EMB</td>\n","      <td>21.661245</td>\n","      <td>13.907265</td>\n","      <td>0.0</td>\n","      <td>0.000159</td>\n","      <td>0.000151</td>\n","      <td>0.001071</td>\n","      <td>0.001089</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ensemble_FNN_CAT_EMB</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000034</td>\n","      <td>0.000109</td>\n","      <td>0.000603</td>\n","      <td>0.000630</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CANN</td>\n","      <td>53.898935</td>\n","      <td>33.162059</td>\n","      <td>0.0</td>\n","      <td>0.000608</td>\n","      <td>0.000325</td>\n","      <td>0.001111</td>\n","      <td>0.001103</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Ensemble_CANN</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000434</td>\n","      <td>0.000299</td>\n","      <td>0.000732</td>\n","      <td>0.000739</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>LocalGLMnet</td>\n","      <td>7.622023</td>\n","      <td>5.097405</td>\n","      <td>0.0</td>\n","      <td>0.000334</td>\n","      <td>0.000218</td>\n","      <td>0.000879</td>\n","      <td>0.000908</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Ensemble_LocalGLMnet</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000133</td>\n","      <td>0.000017</td>\n","      <td>0.000105</td>\n","      <td>0.000106</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>FT_transformer</td>\n","      <td>16.638452</td>\n","      <td>302.316624</td>\n","      <td>0.0</td>\n","      <td>0.000898</td>\n","      <td>0.000528</td>\n","      <td>0.001460</td>\n","      <td>0.001458</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Ensemble_FT_transformer</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000066</td>\n","      <td>0.000143</td>\n","      <td>0.000132</td>\n","      <td>0.000109</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>CAFTT</td>\n","      <td>14.185841</td>\n","      <td>220.449926</td>\n","      <td>0.0</td>\n","      <td>0.000474</td>\n","      <td>0.000174</td>\n","      <td>0.000499</td>\n","      <td>0.000471</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Ensemble_CAFTT</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000201</td>\n","      <td>0.000073</td>\n","      <td>0.000131</td>\n","      <td>0.000120</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>LocalGLMftt</td>\n","      <td>16.384662</td>\n","      <td>310.648783</td>\n","      <td>0.0</td>\n","      <td>0.000593</td>\n","      <td>0.000160</td>\n","      <td>0.000964</td>\n","      <td>0.000992</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Ensemble_LocalGLMftt</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000348</td>\n","      <td>0.000114</td>\n","      <td>0.000343</td>\n","      <td>0.000319</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91ae0d7d-b441-41a6-bce6-51607c8058ca')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-91ae0d7d-b441-41a6-bce6-51607c8058ca button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-91ae0d7d-b441-41a6-bce6-51607c8058ca');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-19777b90-5c9c-4e58-8e37-697a7973ddc9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19777b90-5c9c-4e58-8e37-697a7973ddc9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-19777b90-5c9c-4e58-8e37-697a7973ddc9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                      model     epochs    run_time  nr_parameters  loss_train  \\\n","0                   FFN_OHE  14.663853    8.624492            0.0    0.000326   \n","1          Ensemble_FFN_OHE   0.000000    0.000000            0.0    0.000224   \n","2               FNN_CAT_EMB  21.661245   13.907265            0.0    0.000159   \n","3      Ensemble_FNN_CAT_EMB   0.000000    0.000000            0.0    0.000034   \n","4                      CANN  53.898935   33.162059            0.0    0.000608   \n","5             Ensemble_CANN   0.000000    0.000000            0.0    0.000434   \n","6               LocalGLMnet   7.622023    5.097405            0.0    0.000334   \n","7      Ensemble_LocalGLMnet   0.000000    0.000000            0.0    0.000133   \n","8            FT_transformer  16.638452  302.316624            0.0    0.000898   \n","9   Ensemble_FT_transformer   0.000000    0.000000            0.0    0.000066   \n","10                    CAFTT  14.185841  220.449926            0.0    0.000474   \n","11           Ensemble_CAFTT   0.000000    0.000000            0.0    0.000201   \n","12              LocalGLMftt  16.384662  310.648783            0.0    0.000593   \n","13     Ensemble_LocalGLMftt   0.000000    0.000000            0.0    0.000348   \n","\n","    loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0    0.000157             0.001224            0.001209  \n","1    0.000098             0.000648            0.000667  \n","2    0.000151             0.001071            0.001089  \n","3    0.000109             0.000603            0.000630  \n","4    0.000325             0.001111            0.001103  \n","5    0.000299             0.000732            0.000739  \n","6    0.000218             0.000879            0.000908  \n","7    0.000017             0.000105            0.000106  \n","8    0.000528             0.001460            0.001458  \n","9    0.000143             0.000132            0.000109  \n","10   0.000174             0.000499            0.000471  \n","11   0.000073             0.000131            0.000120  \n","12   0.000160             0.000964            0.000992  \n","13   0.000114             0.000343            0.000319  "]},"metadata":{},"output_type":"display_data"}],"source":["print(\"Results Average:\")\n","display(calc_avg_df([\"FFN_OHE\",\"Ensemble_FFN_OHE\",\n","                     \"FNN_CAT_EMB\",\"Ensemble_FNN_CAT_EMB\",\n","                     \"CANN\",\"Ensemble_CANN\",\n","                     \"LocalGLMnet\",\"Ensemble_LocalGLMnet\",\n","                     \"FT_transformer\",\"Ensemble_FT_transformer\",\n","                     \"CAFTT\", \"Ensemble_CAFTT\",\n","                     \"LocalGLMftt\", \"Ensemble_LocalGLMftt\"]))\n","print(\"Results Standard-Deviation:\")\n","display(calc_std_df([\"FFN_OHE\",\"Ensemble_FFN_OHE\",\n","                     \"FNN_CAT_EMB\",\"Ensemble_FNN_CAT_EMB\",\n","                     \"CANN\",\"Ensemble_CANN\",\n","                     \"LocalGLMnet\",\"Ensemble_LocalGLMnet\",\n","                     \"FT_transformer\",\"Ensemble_FT_transformer\",\n","                     \"CAFTT\", \"Ensemble_CAFTT\",\n","                     \"LocalGLMftt\", \"Ensemble_LocalGLMftt\"]))"]},{"cell_type":"markdown","metadata":{"id":"6fSgosapeyOu"},"source":["## Rebased Results (FT_transformer):"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":683},"executionInfo":{"elapsed":539,"status":"ok","timestamp":1699573884686,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"byeZy_4ge0Kd","outputId":"2fc104d3-6340-4917-a381-b878a7e044be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results Average:\n"]},{"data":{"text/html":["\n","  <div id=\"df-42e5842a-1ee9-4e9b-8642-e404079d6320\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FT_transformer</td>\n","      <td>78.866667</td>\n","      <td>1569.860410</td>\n","      <td>27133.0</td>\n","      <td>0.237803</td>\n","      <td>0.239389</td>\n","      <td>0.061140</td>\n","      <td>0.061290</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rebase_FT_transformer</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.236517</td>\n","      <td>0.238149</td>\n","      <td>0.073631</td>\n","      <td>0.073812</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ensemble_Rebase_FT_transformer</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.235922</td>\n","      <td>0.237587</td>\n","      <td>0.073631</td>\n","      <td>0.073812</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CAFTT</td>\n","      <td>57.333333</td>\n","      <td>1170.160723</td>\n","      <td>27133.0</td>\n","      <td>0.237146</td>\n","      <td>0.238072</td>\n","      <td>0.065975</td>\n","      <td>0.066235</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Rebase_CAFTT</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.236692</td>\n","      <td>0.237659</td>\n","      <td>0.073631</td>\n","      <td>0.073921</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Ensemble_Rebase_CAFTT</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.236296</td>\n","      <td>0.237263</td>\n","      <td>0.073631</td>\n","      <td>0.073921</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>LocalGLMftt</td>\n","      <td>53.200000</td>\n","      <td>1187.006637</td>\n","      <td>27430.0</td>\n","      <td>0.237214</td>\n","      <td>0.238801</td>\n","      <td>0.067904</td>\n","      <td>0.068316</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Rebase_LocalGLMftt</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.236958</td>\n","      <td>0.238589</td>\n","      <td>0.073631</td>\n","      <td>0.074077</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Ensemble_Rebase_LocalGLMftt</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.236448</td>\n","      <td>0.238111</td>\n","      <td>0.073631</td>\n","      <td>0.074077</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42e5842a-1ee9-4e9b-8642-e404079d6320')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-42e5842a-1ee9-4e9b-8642-e404079d6320 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-42e5842a-1ee9-4e9b-8642-e404079d6320');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9d5d5b86-361c-45f5-938a-1c83f8abd1e1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d5d5b86-361c-45f5-938a-1c83f8abd1e1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9d5d5b86-361c-45f5-938a-1c83f8abd1e1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                            model     epochs     run_time  nr_parameters  \\\n","0                  FT_transformer  78.866667  1569.860410        27133.0   \n","1           Rebase_FT_transformer   0.000000     0.000000            0.0   \n","2  Ensemble_Rebase_FT_transformer   0.000000     0.000000            0.0   \n","3                           CAFTT  57.333333  1170.160723        27133.0   \n","4                    Rebase_CAFTT   0.000000     0.000000            0.0   \n","5           Ensemble_Rebase_CAFTT   0.000000     0.000000            0.0   \n","6                     LocalGLMftt  53.200000  1187.006637        27430.0   \n","7              Rebase_LocalGLMftt   0.000000     0.000000            0.0   \n","8     Ensemble_Rebase_LocalGLMftt   0.000000     0.000000            0.0   \n","\n","   loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0    0.237803   0.239389             0.061140            0.061290  \n","1    0.236517   0.238149             0.073631            0.073812  \n","2    0.235922   0.237587             0.073631            0.073812  \n","3    0.237146   0.238072             0.065975            0.066235  \n","4    0.236692   0.237659             0.073631            0.073921  \n","5    0.236296   0.237263             0.073631            0.073921  \n","6    0.237214   0.238801             0.067904            0.068316  \n","7    0.236958   0.238589             0.073631            0.074077  \n","8    0.236448   0.238111             0.073631            0.074077  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Results Standard-Deviation:\n"]},{"data":{"text/html":["\n","  <div id=\"df-8ee969cc-1df7-46bb-b972-9aa7d1a3f49c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>epochs</th>\n","      <th>run_time</th>\n","      <th>nr_parameters</th>\n","      <th>loss_train</th>\n","      <th>loss_test</th>\n","      <th>pred_avg_freq_train</th>\n","      <th>pred_avg_freq_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FT_transformer</td>\n","      <td>16.638452</td>\n","      <td>302.316624</td>\n","      <td>0.0</td>\n","      <td>0.000898</td>\n","      <td>0.000528</td>\n","      <td>1.459836e-03</td>\n","      <td>0.001458</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rebase_FT_transformer</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000636</td>\n","      <td>0.000360</td>\n","      <td>1.299345e-08</td>\n","      <td>0.000106</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ensemble_Rebase_FT_transformer</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000035</td>\n","      <td>0.000144</td>\n","      <td>1.947447e-08</td>\n","      <td>0.000027</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CAFTT</td>\n","      <td>14.185841</td>\n","      <td>220.449926</td>\n","      <td>0.0</td>\n","      <td>0.000474</td>\n","      <td>0.000174</td>\n","      <td>4.993066e-04</td>\n","      <td>0.000471</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Rebase_CAFTT</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000458</td>\n","      <td>0.000171</td>\n","      <td>1.597395e-08</td>\n","      <td>0.000055</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Ensemble_Rebase_CAFTT</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000185</td>\n","      <td>0.000060</td>\n","      <td>3.497719e-09</td>\n","      <td>0.000014</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>LocalGLMftt</td>\n","      <td>16.384662</td>\n","      <td>310.648783</td>\n","      <td>0.0</td>\n","      <td>0.000593</td>\n","      <td>0.000160</td>\n","      <td>9.643511e-04</td>\n","      <td>0.000992</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Rebase_LocalGLMftt</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000659</td>\n","      <td>0.000170</td>\n","      <td>1.735819e-08</td>\n","      <td>0.000067</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Ensemble_Rebase_LocalGLMftt</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000338</td>\n","      <td>0.000099</td>\n","      <td>2.731805e-08</td>\n","      <td>0.000028</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ee969cc-1df7-46bb-b972-9aa7d1a3f49c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8ee969cc-1df7-46bb-b972-9aa7d1a3f49c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8ee969cc-1df7-46bb-b972-9aa7d1a3f49c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a965419b-6c3c-4046-90a7-e2ac82f10aa7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a965419b-6c3c-4046-90a7-e2ac82f10aa7')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a965419b-6c3c-4046-90a7-e2ac82f10aa7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                            model     epochs    run_time  nr_parameters  \\\n","0                  FT_transformer  16.638452  302.316624            0.0   \n","1           Rebase_FT_transformer   0.000000    0.000000            0.0   \n","2  Ensemble_Rebase_FT_transformer   0.000000    0.000000            0.0   \n","3                           CAFTT  14.185841  220.449926            0.0   \n","4                    Rebase_CAFTT   0.000000    0.000000            0.0   \n","5           Ensemble_Rebase_CAFTT   0.000000    0.000000            0.0   \n","6                     LocalGLMftt  16.384662  310.648783            0.0   \n","7              Rebase_LocalGLMftt   0.000000    0.000000            0.0   \n","8     Ensemble_Rebase_LocalGLMftt   0.000000    0.000000            0.0   \n","\n","   loss_train  loss_test  pred_avg_freq_train  pred_avg_freq_test  \n","0    0.000898   0.000528         1.459836e-03            0.001458  \n","1    0.000636   0.000360         1.299345e-08            0.000106  \n","2    0.000035   0.000144         1.947447e-08            0.000027  \n","3    0.000474   0.000174         4.993066e-04            0.000471  \n","4    0.000458   0.000171         1.597395e-08            0.000055  \n","5    0.000185   0.000060         3.497719e-09            0.000014  \n","6    0.000593   0.000160         9.643511e-04            0.000992  \n","7    0.000659   0.000170         1.735819e-08            0.000067  \n","8    0.000338   0.000099         2.731805e-08            0.000028  "]},"metadata":{},"output_type":"display_data"}],"source":["print(\"Results Average:\")\n","display(calc_avg_df([\"FT_transformer\",\"Rebase_FT_transformer\",\"Ensemble_Rebase_FT_transformer\",\"CAFTT\",\"Rebase_CAFTT\",\"Ensemble_Rebase_CAFTT\",\"LocalGLMftt\",\"Rebase_LocalGLMftt\",\"Ensemble_Rebase_LocalGLMftt\"]))\n","print(\"Results Standard-Deviation:\")\n","display(calc_std_df([\"FT_transformer\",\"Rebase_FT_transformer\",\"Ensemble_Rebase_FT_transformer\",\"CAFTT\",\"Rebase_CAFTT\",\"Ensemble_Rebase_CAFTT\",\"LocalGLMftt\",\"Rebase_LocalGLMftt\",\"Ensemble_Rebase_LocalGLMftt\"]))"]},{"cell_type":"markdown","metadata":{"id":"nL44-Wckjym0"},"source":["# Information about the Packages and Environment:"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2244,"status":"ok","timestamp":1699574850162,"user":{"displayName":"Alexej","userId":"05436248405167721905"},"user_tz":-60},"id":"fT0zm60Ljym0","outputId":"d3ef86f7-fce4-4182-df1b-c059b8cb113f"},"outputs":[{"name":"stdout","output_type":"stream","text":["the python version is:\n","3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n","sys.version_info(major=3, minor=10, micro=12, releaselevel='final', serial=0)\n","\n","print pip list:\n","Package                          Version\n","-------------------------------- ---------------------\n","absl-py                          1.4.0\n","aiohttp                          3.8.6\n","aiosignal                        1.3.1\n","alabaster                        0.7.13\n","albumentations                   1.3.1\n","altair                           4.2.2\n","anyio                            3.7.1\n","appdirs                          1.4.4\n","argon2-cffi                      23.1.0\n","argon2-cffi-bindings             21.2.0\n","array-record                     0.5.0\n","arviz                            0.15.1\n","astropy                          5.3.4\n","astunparse                       1.6.3\n","async-timeout                    4.0.3\n","atpublic                         4.0\n","attrs                            23.1.0\n","audioread                        3.0.1\n","autograd                         1.6.2\n","Babel                            2.13.1\n","backcall                         0.2.0\n","beautifulsoup4                   4.11.2\n","bidict                           0.22.1\n","bigframes                        0.12.0\n","bleach                           6.1.0\n","blinker                          1.4\n","blis                             0.7.11\n","blosc2                           2.0.0\n","bokeh                            3.3.0\n","bqplot                           0.12.42\n","branca                           0.7.0\n","build                            1.0.3\n","CacheControl                     0.13.1\n","cachetools                       5.3.2\n","catalogue                        2.0.10\n","certifi                          2023.7.22\n","cffi                             1.16.0\n","chardet                          5.2.0\n","charset-normalizer               3.3.2\n","chex                             0.1.7\n","click                            8.1.7\n","click-plugins                    1.1.1\n","cligj                            0.7.2\n","cloudpickle                      2.2.1\n","cmake                            3.27.7\n","cmdstanpy                        1.2.0\n","colorcet                         3.0.1\n","colorlover                       0.3.0\n","colour                           0.1.5\n","community                        1.0.0b1\n","confection                       0.1.3\n","cons                             0.4.6\n","contextlib2                      21.6.0\n","contourpy                        1.2.0\n","cryptography                     41.0.5\n","cufflinks                        0.17.3\n","cupy-cuda11x                     11.0.0\n","cvxopt                           1.3.2\n","cvxpy                            1.3.2\n","cycler                           0.12.1\n","cymem                            2.0.8\n","Cython                           3.0.5\n","dask                             2023.8.1\n","datascience                      0.17.6\n","db-dtypes                        1.1.1\n","dbus-python                      1.2.18\n","debugpy                          1.6.6\n","decorator                        4.4.2\n","defusedxml                       0.7.1\n","diskcache                        5.6.3\n","distributed                      2023.8.1\n","distro                           1.7.0\n","dlib                             19.24.2\n","dm-tree                          0.1.8\n","docutils                         0.18.1\n","dopamine-rl                      4.0.6\n","duckdb                           0.9.1\n","earthengine-api                  0.1.377\n","easydict                         1.11\n","ecos                             2.0.12\n","editdistance                     0.6.2\n","eerepr                           0.0.4\n","en-core-web-sm                   3.6.0\n","entrypoints                      0.4\n","et-xmlfile                       1.1.0\n","etils                            1.5.2\n","etuples                          0.3.9\n","exceptiongroup                   1.1.3\n","fastai                           2.7.13\n","fastcore                         1.5.29\n","fastdownload                     0.0.7\n","fastjsonschema                   2.18.1\n","fastprogress                     1.0.3\n","fastrlock                        0.8.2\n","filelock                         3.13.1\n","fiona                            1.9.5\n","firebase-admin                   5.3.0\n","Flask                            2.2.5\n","flatbuffers                      23.5.26\n","flax                             0.7.5\n","folium                           0.14.0\n","fonttools                        4.44.0\n","frozendict                       2.3.8\n","frozenlist                       1.4.0\n","fsspec                           2023.6.0\n","future                           0.18.3\n","gast                             0.5.4\n","gcsfs                            2023.6.0\n","GDAL                             3.4.3\n","gdown                            4.6.6\n","geemap                           0.28.2\n","gensim                           4.3.2\n","geocoder                         1.38.1\n","geographiclib                    2.0\n","geopandas                        0.13.2\n","geopy                            2.3.0\n","gin-config                       0.5.0\n","glob2                            0.7\n","google                           2.0.3\n","google-api-core                  2.11.1\n","google-api-python-client         2.84.0\n","google-auth                      2.17.3\n","google-auth-httplib2             0.1.1\n","google-auth-oauthlib             1.0.0\n","google-cloud-bigquery            3.12.0\n","google-cloud-bigquery-connection 1.12.1\n","google-cloud-bigquery-storage    2.22.0\n","google-cloud-core                2.3.3\n","google-cloud-datastore           2.15.2\n","google-cloud-firestore           2.11.1\n","google-cloud-functions           1.13.3\n","google-cloud-iam                 2.12.2\n","google-cloud-language            2.9.1\n","google-cloud-resource-manager    1.10.4\n","google-cloud-storage             2.8.0\n","google-cloud-translate           3.11.3\n","google-colab                     1.0.0\n","google-crc32c                    1.5.0\n","google-pasta                     0.2.0\n","google-resumable-media           2.6.0\n","googleapis-common-protos         1.61.0\n","googledrivedownloader            0.4\n","graphviz                         0.20.1\n","greenlet                         3.0.1\n","grpc-google-iam-v1               0.12.6\n","grpcio                           1.59.2\n","grpcio-status                    1.48.2\n","gspread                          3.4.2\n","gspread-dataframe                3.3.1\n","gym                              0.25.2\n","gym-notices                      0.0.8\n","h5netcdf                         1.3.0\n","h5py                             3.9.0\n","holidays                         0.36\n","holoviews                        1.17.1\n","html5lib                         1.1\n","httpimport                       1.3.1\n","httplib2                         0.22.0\n","humanize                         4.7.0\n","hyperopt                         0.2.7\n","ibis-framework                   6.2.0\n","idna                             3.4\n","imageio                          2.31.6\n","imageio-ffmpeg                   0.4.9\n","imagesize                        1.4.1\n","imbalanced-learn                 0.10.1\n","imgaug                           0.4.0\n","importlib-metadata               6.8.0\n","importlib-resources              6.1.1\n","imutils                          0.5.4\n","inflect                          7.0.0\n","iniconfig                        2.0.0\n","install                          1.3.5\n","intel-openmp                     2023.2.0\n","ipyevents                        2.0.2\n","ipyfilechooser                   0.6.0\n","ipykernel                        5.5.6\n","ipyleaflet                       0.17.4\n","ipython                          7.34.0\n","ipython-genutils                 0.2.0\n","ipython-sql                      0.5.0\n","ipytree                          0.2.2\n","ipywidgets                       7.7.1\n","itsdangerous                     2.1.2\n","jax                              0.4.20\n","jaxlib                           0.4.20+cuda11.cudnn86\n","jeepney                          0.7.1\n","jieba                            0.42.1\n","Jinja2                           3.1.2\n","joblib                           1.3.2\n","jsonpickle                       3.0.2\n","jsonschema                       4.19.2\n","jsonschema-specifications        2023.7.1\n","jupyter-client                   6.1.12\n","jupyter-console                  6.1.0\n","jupyter_core                     5.5.0\n","jupyter-server                   1.24.0\n","jupyterlab-pygments              0.2.2\n","jupyterlab-widgets               3.0.9\n","kaggle                           1.5.16\n","keras                            2.14.0\n","keyring                          23.5.0\n","kiwisolver                       1.4.5\n","langcodes                        3.3.0\n","launchpadlib                     1.10.16\n","lazr.restfulclient               0.14.4\n","lazr.uri                         1.0.6\n","lazy_loader                      0.3\n","libclang                         16.0.6\n","librosa                          0.10.1\n","lida                             0.0.10\n","lightgbm                         4.1.0\n","linkify-it-py                    2.0.2\n","llmx                             0.0.15a0\n","llvmlite                         0.41.1\n","locket                           1.0.0\n","logical-unification              0.4.6\n","lxml                             4.9.3\n","malloy                           2023.1064\n","Markdown                         3.5.1\n","markdown-it-py                   3.0.0\n","MarkupSafe                       2.1.3\n","matplotlib                       3.7.1\n","matplotlib-inline                0.1.6\n","matplotlib-venn                  0.11.9\n","mdit-py-plugins                  0.4.0\n","mdurl                            0.1.2\n","miniKanren                       1.0.3\n","missingno                        0.5.2\n","mistune                          0.8.4\n","mizani                           0.9.3\n","mkl                              2023.2.0\n","ml-dtypes                        0.2.0\n","mlxtend                          0.22.0\n","more-itertools                   10.1.0\n","moviepy                          1.0.3\n","mpmath                           1.3.0\n","msgpack                          1.0.7\n","multidict                        6.0.4\n","multipledispatch                 1.0.0\n","multitasking                     0.0.11\n","murmurhash                       1.0.10\n","music21                          9.1.0\n","natsort                          8.4.0\n","nbclassic                        1.0.0\n","nbclient                         0.9.0\n","nbconvert                        6.5.4\n","nbformat                         5.9.2\n","nest-asyncio                     1.5.8\n","networkx                         3.2.1\n","nibabel                          4.0.2\n","nltk                             3.8.1\n","notebook                         6.5.5\n","notebook_shim                    0.2.3\n","numba                            0.58.1\n","numexpr                          2.8.7\n","numpy                            1.23.5\n","oauth2client                     4.1.3\n","oauthlib                         3.2.2\n","opencv-contrib-python            4.8.0.76\n","opencv-python                    4.8.0.76\n","opencv-python-headless           4.8.1.78\n","openpyxl                         3.1.2\n","opt-einsum                       3.3.0\n","optax                            0.1.7\n","orbax-checkpoint                 0.4.2\n","osqp                             0.6.2.post8\n","packaging                        23.2\n","pandas                           1.5.3\n","pandas-datareader                0.10.0\n","pandas-gbq                       0.17.9\n","pandas-stubs                     1.5.3.230304\n","pandocfilters                    1.5.0\n","panel                            1.3.1\n","param                            2.0.0\n","parso                            0.8.3\n","parsy                            2.1\n","partd                            1.4.1\n","pathlib                          1.0.1\n","pathy                            0.10.3\n","patsy                            0.5.3\n","peewee                           3.17.0\n","pexpect                          4.8.0\n","pickleshare                      0.7.5\n","Pillow                           9.4.0\n","pip                              23.1.2\n","pip-tools                        6.13.0\n","platformdirs                     3.11.0\n","plotly                           5.15.0\n","plotnine                         0.12.4\n","pluggy                           1.3.0\n","polars                           0.17.3\n","pooch                            1.8.0\n","portpicker                       1.5.2\n","prefetch-generator               1.0.3\n","preshed                          3.0.9\n","prettytable                      3.9.0\n","proglog                          0.1.10\n","progressbar2                     4.2.0\n","prometheus-client                0.18.0\n","promise                          2.3\n","prompt-toolkit                   3.0.39\n","prophet                          1.1.5\n","proto-plus                       1.22.3\n","protobuf                         3.20.3\n","psutil                           5.9.5\n","psycopg2                         2.9.9\n","ptyprocess                       0.7.0\n","py-cpuinfo                       9.0.0\n","py4j                             0.10.9.7\n","pyarrow                          9.0.0\n","pyasn1                           0.5.0\n","pyasn1-modules                   0.3.0\n","pycocotools                      2.0.7\n","pycparser                        2.21\n","pyct                             0.5.0\n","pydantic                         1.10.13\n","pydata-google-auth               1.8.2\n","pydot                            1.4.2\n","pydot-ng                         2.0.0\n","pydotplus                        2.0.2\n","PyDrive                          1.3.1\n","PyDrive2                         1.6.3\n","pyerfa                           2.0.1.1\n","pygame                           2.5.2\n","Pygments                         2.16.1\n","PyGObject                        3.42.1\n","PyJWT                            2.3.0\n","pymc                             5.7.2\n","pymystem3                        0.2.0\n","PyOpenGL                         3.1.7\n","pyOpenSSL                        23.3.0\n","pyparsing                        3.1.1\n","pyperclip                        1.8.2\n","pyproj                           3.6.1\n","pyproject_hooks                  1.0.0\n","pyshp                            2.3.1\n","PySocks                          1.7.1\n","pytensor                         2.14.2\n","pytest                           7.4.3\n","python-apt                       0.0.0\n","python-box                       7.1.1\n","python-dateutil                  2.8.2\n","python-louvain                   0.16\n","python-slugify                   8.0.1\n","python-utils                     3.8.1\n","pytz                             2023.3.post1\n","pyviz_comms                      3.0.0\n","PyWavelets                       1.4.1\n","PyYAML                           6.0.1\n","pyzmq                            23.2.1\n","qdldl                            0.1.7.post0\n","qudida                           0.0.4\n","ratelim                          0.1.6\n","referencing                      0.30.2\n","regex                            2023.6.3\n","requests                         2.31.0\n","requests-oauthlib                1.3.1\n","requirements-parser              0.5.0\n","rich                             13.6.0\n","rpds-py                          0.12.0\n","rpy2                             3.4.2\n","rsa                              4.9\n","scikit-image                     0.19.3\n","scikit-learn                     1.2.2\n","scipy                            1.11.3\n","scooby                           0.9.2\n","scs                              3.2.3\n","seaborn                          0.12.2\n","SecretStorage                    3.3.1\n","Send2Trash                       1.8.2\n","setuptools                       67.7.2\n","shapely                          2.0.2\n","six                              1.16.0\n","sklearn-pandas                   2.2.0\n","smart-open                       6.4.0\n","sniffio                          1.3.0\n","snowballstemmer                  2.2.0\n","sortedcontainers                 2.4.0\n","soundfile                        0.12.1\n","soupsieve                        2.5\n","soxr                             0.3.7\n","spacy                            3.6.1\n","spacy-legacy                     3.0.12\n","spacy-loggers                    1.0.5\n","Sphinx                           5.0.2\n","sphinxcontrib-applehelp          1.0.7\n","sphinxcontrib-devhelp            1.0.5\n","sphinxcontrib-htmlhelp           2.0.4\n","sphinxcontrib-jsmath             1.0.1\n","sphinxcontrib-qthelp             1.0.6\n","sphinxcontrib-serializinghtml    1.1.9\n","SQLAlchemy                       2.0.23\n","sqlglot                          17.16.2\n","sqlparse                         0.4.4\n","srsly                            2.4.8\n","stanio                           0.3.0\n","statsmodels                      0.14.0\n","sympy                            1.12\n","tables                           3.8.0\n","tabulate                         0.9.0\n","tbb                              2021.10.0\n","tblib                            3.0.0\n","tenacity                         8.2.3\n","tensorboard                      2.14.1\n","tensorboard-data-server          0.7.2\n","tensorflow                       2.14.0\n","tensorflow-datasets              4.9.3\n","tensorflow-estimator             2.14.0\n","tensorflow-gcs-config            2.14.0\n","tensorflow-hub                   0.15.0\n","tensorflow-io-gcs-filesystem     0.34.0\n","tensorflow-metadata              1.14.0\n","tensorflow-probability           0.22.0\n","tensorstore                      0.1.45\n","termcolor                        2.3.0\n","terminado                        0.17.1\n","text-unidecode                   1.3\n","textblob                         0.17.1\n","tf-slim                          1.1.0\n","thinc                            8.1.12\n","threadpoolctl                    3.2.0\n","tifffile                         2023.9.26\n","tinycss2                         1.2.1\n","toml                             0.10.2\n","tomli                            2.0.1\n","toolz                            0.12.0\n","torch                            2.1.0+cu118\n","torchaudio                       2.1.0+cu118\n","torchdata                        0.7.0\n","torchsummary                     1.5.1\n","torchtext                        0.16.0\n","torchvision                      0.16.0+cu118\n","tornado                          6.3.2\n","tqdm                             4.66.1\n","traitlets                        5.7.1\n","traittypes                       0.2.1\n","triton                           2.1.0\n","tweepy                           4.14.0\n","typer                            0.9.0\n","types-pytz                       2023.3.1.1\n","types-setuptools                 68.2.0.0\n","typing_extensions                4.5.0\n","tzlocal                          5.2\n","uc-micro-py                      1.0.2\n","uritemplate                      4.1.1\n","urllib3                          2.0.7\n","vega-datasets                    0.9.0\n","wadllib                          1.3.6\n","wasabi                           1.1.2\n","wcwidth                          0.2.9\n","webcolors                        1.13\n","webencodings                     0.5.1\n","websocket-client                 1.6.4\n","Werkzeug                         3.0.1\n","wheel                            0.41.3\n","widgetsnbextension               3.6.6\n","wordcloud                        1.9.2\n","wrapt                            1.14.1\n","xarray                           2023.7.0\n","xarray-einstats                  0.6.0\n","xgboost                          2.0.1\n","xlrd                             2.0.1\n","xxhash                           3.4.1\n","xyzservices                      2023.10.1\n","yarl                             1.9.2\n","yellowbrick                      1.5\n","yfinance                         0.2.31\n","zict                             3.0.0\n","zipp                             3.17.0\n","\n","print conda list:\n","/bin/bash: line 1: conda: command not found\n"]}],"source":["#print python version\n","print(\"the python version is:\")\n","print(sys.version)\n","print(sys.version_info)\n","print()\n","print(\"print pip list:\")\n","!pip list\n","print()\n","print(\"print conda list:\")\n","!conda list"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"},"vscode":{"interpreter":{"hash":"1c610201dd013e8a553c0c81ea3f6aba71316b0cca1afc83fa96b8db366642e7"}}},"nbformat":4,"nbformat_minor":0}
